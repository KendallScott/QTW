{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "#df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f85851-59fb-4425-d32c-df002736a1d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb43e0a-c392-4d43-e125-5f397ed4ec64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "57659bb6-704d-457c-cc9a-88583e813058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "27b76db5-4bbe-40bc-9429-f26bbdb9f7e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: x24, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "0fa143d7-c27b-4145-df95-1b48639ddbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "348848eb-576a-4562-f937-75523005a20a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "a7ee09a0-0735-43f2-bea3-04e381f49bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3, figsize = (25, 5))\n",
        "plt.subplots_adjust(wspace=.18,hspace=1)\n",
        "fig.subplots_adjust(top = .96)\n",
        "sns.set(rc={'figure.figsize':(5.5,6)})\n",
        "sns.countplot(x = 'x29', data = df, hue = 'y', ax = axes[0]);\n",
        "sns.countplot(x = 'x30', data = df, hue = 'y', ax = axes[1]);\n",
        "sns.countplot(x = 'x24', data = df, hue = 'y', ax = axes[2]);\n",
        "\n",
        "fig.suptitle('Count plots for categorical features')"
      ],
      "metadata": {
        "id": "lCaK4Zy0zbuh",
        "outputId": "e560983d-dff9-4731-8882-abff08ee39ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Count plots for categorical features')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "40f3912a-1f17-4119-8b7e-f91826a87f02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: x30, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "8343b999-7d14-43a4-a6b4-313d2e9871d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "af3f5ac9-73ab-4001-c060-176f7cd6c1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: x32, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "a066c008-1113-4f6f-f328-3c32bbb40c8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: x37, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "8f5f5eb1-6ced-4373-cf85-e654a34265bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "9517b5fb-dbc5-461d-f725-a9dcbb4c6180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3981fd4d-2435-465d-a36d-68ec226f773d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3981fd4d-2435-465d-a36d-68ec226f773d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-fc8dc4c8-f0b4-4526-859d-b8aa2c5d126b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc8dc4c8-f0b4-4526-859d-b8aa2c5d126b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-fc8dc4c8-f0b4-4526-859d-b8aa2c5d126b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3981fd4d-2435-465d-a36d-68ec226f773d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3981fd4d-2435-465d-a36d-68ec226f773d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#created categorical variable for high/low volume based on month/continent\n",
        "conditions = [\n",
        "    (df['x24'] == 'america'),\n",
        "    (df['x24'] =='asia') & (df['x29'] == 'Jan'),\n",
        "    (df['x24'] =='asia') & (df['x29'] != 'Jan'),\n",
        "    (df['x24'] =='euorpe')\n",
        "    ]\n",
        "\n",
        "values = ['low', 'low', 'high', 'high']\n",
        "df['Volume'] = np.select(conditions, values)\n",
        "df[['Volume', 'y']].groupby(['Volume']).count()"
      ],
      "metadata": {
        "id": "Ul1CRi4b4kGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c8103ccb-d19e-4196-c64e-6661411ab794"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y\n",
              "Volume        \n",
              "high    155522\n",
              "low       4478"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-95e4ca52-d7b2-43fe-a855-52e74d3eb6a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>155522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>4478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95e4ca52-d7b2-43fe-a855-52e74d3eb6a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e8561315-068d-4fec-ad36-7873d8c73fff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8561315-068d-4fec-ad36-7873d8c73fff')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e8561315-068d-4fec-ad36-7873d8c73fff button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95e4ca52-d7b2-43fe-a855-52e74d3eb6a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95e4ca52-d7b2-43fe-a855-52e74d3eb6a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "dfae1260-6a3b-4df0-d1fb-4c8500344fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1zPG-Q7z7U3",
        "outputId": "c3a2c547-d698-4da1-ca9a-fc33f3d16f38"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 69)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "a62c5dfa-7ac4-48fc-ee75-5476213a8a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    95803\n",
              "1    64197\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost_func(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratifiedkfold by high/lower volume created category\n",
        "#in order to get an equal distribution of the 0s during high volume time and 1s during low, replace with binary imediately after\n",
        "\n",
        "y=df[['Volume', 'y']].astype(str).apply(\"-\".join, axis=1)\n",
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)\n",
        "y = df['y'].values.flatten()"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "#params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "#lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "#lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lr_params = lr_clf.best_params_\n",
        "lr_params ={'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1"
      ],
      "metadata": {
        "id": "3katCHeBPQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bda8f6-8b1f-4d57-a034-3dc86cdcfe9f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7707427436265313,\n",
              "  'recall': 0.7289646462010584,\n",
              "  'f1-score': 0.7492717782558083,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.625796224239804,\n",
              "  'recall': 0.6764179011480287,\n",
              "  'f1-score': 0.6501231407247711,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.70788125,\n",
              " 'macro avg': {'precision': 0.6982694839331676,\n",
              "  'recall': 0.7026912736745435,\n",
              "  'f1-score': 0.6996974594902896,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.7125856704698453,\n",
              "  'recall': 0.70788125,\n",
              "  'f1-score': 0.7094902464834333,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)"
      ],
      "metadata": {
        "id": "ent8XHdUPayB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "3a6adad5-5d02-443b-8218-44fcaefede36"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a33709e2020>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost_func(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2be9aa-d6ec-4da3-c9cd-ac5be26491e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5712550"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "#params = {'n_estimators':[100, 200],'max_features':['sqrt','log2',20]}\n",
        "#rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "12f4caae-9c96-47f7-87f9-ac547e74cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_features': ['sqrt', 'log2', 20],\n",
              "                         'n_estimators': [100, 200]})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rf_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jhHtsE6rFk",
        "outputId": "268d129a-e1f6-430c-d247-a7a524d48ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {'max_features': 20, 'n_estimators': 200}\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cee27a5-b28e-465c-959a-620a1c24807e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "a32d2502-44c6-49a7-e7e4-7a9cd05f69d0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-c2093db50b55>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m807\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds_m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = pd.read_csv(\"/content/rf_results.csv\")"
      ],
      "metadata": {
        "id": "PFByIS7pi7fR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xJeX4IS7jP_W",
        "outputId": "7653397f-ff40-4b96-8a97-5271be72228d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  0\n",
              "0                0  0\n",
              "1                1  0\n",
              "2                2  0\n",
              "3                3  1\n",
              "4                4  1\n",
              "...            ... ..\n",
              "159995      159995  1\n",
              "159996      159996  0\n",
              "159997      159997  0\n",
              "159998      159998  0\n",
              "159999      159999  1\n",
              "\n",
              "[160000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d871d8fb-32b6-4e36-b215-cabe76d4ccb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>159995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>159996</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>159997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>159998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159999</th>\n",
              "      <td>159999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160000 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d871d8fb-32b6-4e36-b215-cabe76d4ccb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-593e7020-9709-4d44-b8af-5d8bf00e62ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-593e7020-9709-4d44-b8af-5d8bf00e62ed')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-593e7020-9709-4d44-b8af-5d8bf00e62ed button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d871d8fb-32b6-4e36-b215-cabe76d4ccb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d871d8fb-32b6-4e36-b215-cabe76d4ccb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = preds_m2['0']"
      ],
      "metadata": {
        "id": "dczRs5VZjHoV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54673c27-df35-40e1-d493-124d37a7b23a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.9305797512457967,\n",
              "  'recall': 0.9590305105268102,\n",
              "  'f1-score': 0.9445909476443828,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.9359371939674871,\n",
              "  'recall': 0.8932348863654065,\n",
              "  'f1-score': 0.914087594149763,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.93263125,\n",
              " 'macro avg': {'precision': 0.933258472606642,\n",
              "  'recall': 0.9261326984461083,\n",
              "  'f1-score': 0.9293392708970729,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.932729324685824,\n",
              "  'recall': 0.93263125,\n",
              "  'f1-score': 0.9323520489925445,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2 ,cmap='Blues', colorbar=False)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "731e7f6d-c320-4471-b575-fd35b9e270dd"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a32ac3c1300>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost_func(preds_m2,y)\n",
        "cost_m2"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf1d5c8-5c2c-4093-fab2-f393e43112ef"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1420600"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crFxa8d68wBQ",
        "outputId": "b15aaf95-050b-41cc-d058-d3734fb23abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.10         20      3       1    0.0\n",
              "1             0.25         20      1       3    0.0\n",
              "2             0.35         20      1       3    0.0\n",
              "3             0.35          3      0       2    0.0\n",
              "4             0.25          5      3       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.25         20      0       3    0.1\n",
              "320           0.10          3      1       2    1.0\n",
              "321           0.25         10      3       2    1.0\n",
              "322           0.25          5      1       1    0.0\n",
              "323           0.25          3      0       3    0.1\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c3d091ef-80fa-4745-8f71-54c43ba7eb27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows  5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d091ef-80fa-4745-8f71-54c43ba7eb27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b1b1a599-f754-46e9-a83e-11693c67c937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1b1a599-f754-46e9-a83e-11693c67c937')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b1b1a599-f754-46e9-a83e-11693c67c937 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "\n",
        "trials = 30\n",
        "best_params = {}\n",
        "i=0\n",
        "\n",
        "for i in range(trials):\n",
        "  #random sampling from paramdf\n",
        "  hyperparams = {'objective': 'binary:logistic',\n",
        "                 'eta': xgb_param['learning_rate'][i],\n",
        "                 'max_depth': xgb_param['max_depth'][i],\n",
        "                 'gamma': xgb_param['gamma'][i],\n",
        "                 'lambda': xgb_param['lambda'][i],\n",
        "                 'alpha': xgb_param['alpha'][i],\n",
        "                 'eval_metric': 'aucpr'\n",
        "                 }\n",
        "\n",
        "  print(hyperparams)\n",
        "  out=xgb.cv(params=hyperparams,\n",
        "             num_boost_round=20,\n",
        "             dtrain=dtrain,\n",
        "             nfold=5,\n",
        "             stratified=True,\n",
        "             early_stopping_rounds=3,\n",
        "             verbose_eval=1\n",
        "             )\n",
        "\n",
        "  index=out.shape[0]-1\n",
        "  result=out.iloc[index,2]\n",
        "  if i< 1.1:\n",
        "    best_result = result\n",
        "    best_params = hyperparams\n",
        "\n",
        "  if result> best_result:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "      print('result: ' ,result)\n",
        "      print('best result: ' ,best_result)\n",
        "      print('hyperparameters: ' ,hyperparams)\n",
        "      print('best hyperparameters: ' ,best_params)\n",
        "      i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "35897351-2785-4c1d-d03a-faa23ff501af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73761+0.00208\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74850+0.00132\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75308+0.00284\ttest-aucpr:0.74841+0.00202\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00501\n",
            "[8]\ttrain-aucpr:0.78353+0.00227\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00160\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00166\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81465+0.00377\ttest-aucpr:0.80908+0.00378\n",
            "[14]\ttrain-aucpr:0.81993+0.00351\ttest-aucpr:0.81426+0.00372\n",
            "[15]\ttrain-aucpr:0.82332+0.00361\ttest-aucpr:0.81784+0.00370\n",
            "[16]\ttrain-aucpr:0.82662+0.00381\ttest-aucpr:0.82082+0.00337\n",
            "[17]\ttrain-aucpr:0.83062+0.00327\ttest-aucpr:0.82481+0.00400\n",
            "[18]\ttrain-aucpr:0.83598+0.00418\ttest-aucpr:0.83030+0.00522\n",
            "[19]\ttrain-aucpr:0.83916+0.00467\ttest-aucpr:0.83345+0.00572\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00235\ttest-aucpr:0.75927+0.00435\n",
            "[1]\ttrain-aucpr:0.81318+0.00225\ttest-aucpr:0.80539+0.00334\n",
            "[2]\ttrain-aucpr:0.83318+0.00295\ttest-aucpr:0.82591+0.00336\n",
            "[3]\ttrain-aucpr:0.84939+0.00145\ttest-aucpr:0.84225+0.00267\n",
            "[4]\ttrain-aucpr:0.85931+0.00101\ttest-aucpr:0.85189+0.00276\n",
            "[5]\ttrain-aucpr:0.86673+0.00230\ttest-aucpr:0.85947+0.00362\n",
            "[6]\ttrain-aucpr:0.87432+0.00233\ttest-aucpr:0.86671+0.00337\n",
            "[7]\ttrain-aucpr:0.88360+0.00369\ttest-aucpr:0.87603+0.00496\n",
            "[8]\ttrain-aucpr:0.89029+0.00271\ttest-aucpr:0.88296+0.00332\n",
            "[9]\ttrain-aucpr:0.89450+0.00311\ttest-aucpr:0.88709+0.00372\n",
            "[10]\ttrain-aucpr:0.89871+0.00108\ttest-aucpr:0.89103+0.00216\n",
            "[11]\ttrain-aucpr:0.90387+0.00182\ttest-aucpr:0.89611+0.00226\n",
            "[12]\ttrain-aucpr:0.90796+0.00308\ttest-aucpr:0.90005+0.00332\n",
            "[13]\ttrain-aucpr:0.91089+0.00251\ttest-aucpr:0.90283+0.00223\n",
            "[14]\ttrain-aucpr:0.91468+0.00190\ttest-aucpr:0.90639+0.00206\n",
            "[15]\ttrain-aucpr:0.91783+0.00235\ttest-aucpr:0.90934+0.00278\n",
            "[16]\ttrain-aucpr:0.91965+0.00216\ttest-aucpr:0.91114+0.00209\n",
            "[17]\ttrain-aucpr:0.92165+0.00265\ttest-aucpr:0.91322+0.00278\n",
            "[18]\ttrain-aucpr:0.92351+0.00273\ttest-aucpr:0.91509+0.00272\n",
            "[19]\ttrain-aucpr:0.92562+0.00328\ttest-aucpr:0.91723+0.00321\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90560+0.00136\ttest-aucpr:0.87281+0.00246\n",
            "[1]\ttrain-aucpr:0.93138+0.00371\ttest-aucpr:0.90324+0.00377\n",
            "[2]\ttrain-aucpr:0.94181+0.00295\ttest-aucpr:0.91546+0.00261\n",
            "[3]\ttrain-aucpr:0.94852+0.00280\ttest-aucpr:0.92354+0.00318\n",
            "[4]\ttrain-aucpr:0.95339+0.00224\ttest-aucpr:0.92893+0.00228\n",
            "[5]\ttrain-aucpr:0.95770+0.00096\ttest-aucpr:0.93427+0.00122\n",
            "[6]\ttrain-aucpr:0.96061+0.00112\ttest-aucpr:0.93722+0.00081\n",
            "[7]\ttrain-aucpr:0.96275+0.00110\ttest-aucpr:0.93929+0.00083\n",
            "[8]\ttrain-aucpr:0.96501+0.00076\ttest-aucpr:0.94173+0.00098\n",
            "[9]\ttrain-aucpr:0.96701+0.00047\ttest-aucpr:0.94391+0.00050\n",
            "[10]\ttrain-aucpr:0.96869+0.00022\ttest-aucpr:0.94571+0.00087\n",
            "[11]\ttrain-aucpr:0.97022+0.00020\ttest-aucpr:0.94726+0.00064\n",
            "[12]\ttrain-aucpr:0.97141+0.00024\ttest-aucpr:0.94847+0.00048\n",
            "[13]\ttrain-aucpr:0.97253+0.00035\ttest-aucpr:0.94970+0.00024\n",
            "[14]\ttrain-aucpr:0.97353+0.00022\ttest-aucpr:0.95084+0.00033\n",
            "[15]\ttrain-aucpr:0.97467+0.00022\ttest-aucpr:0.95221+0.00034\n",
            "[16]\ttrain-aucpr:0.97580+0.00040\ttest-aucpr:0.95340+0.00038\n",
            "[17]\ttrain-aucpr:0.97659+0.00038\ttest-aucpr:0.95420+0.00039\n",
            "[18]\ttrain-aucpr:0.97736+0.00026\ttest-aucpr:0.95502+0.00038\n",
            "[19]\ttrain-aucpr:0.97818+0.00021\ttest-aucpr:0.95586+0.00038\n",
            "result:  0.9558574813295282\n",
            "best result:  0.9558574813295282\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68916+0.00516\ttest-aucpr:0.68605+0.00458\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71815+0.00233\ttest-aucpr:0.71444+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74144+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74512+0.00232\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74908+0.00173\ttest-aucpr:0.74434+0.00441\n",
            "[9]\ttrain-aucpr:0.75073+0.00079\ttest-aucpr:0.74618+0.00414\n",
            "[10]\ttrain-aucpr:0.75240+0.00215\ttest-aucpr:0.74759+0.00479\n",
            "[11]\ttrain-aucpr:0.75616+0.00265\ttest-aucpr:0.75156+0.00445\n",
            "[12]\ttrain-aucpr:0.75850+0.00161\ttest-aucpr:0.75370+0.00417\n",
            "[13]\ttrain-aucpr:0.76290+0.00245\ttest-aucpr:0.75780+0.00201\n",
            "[14]\ttrain-aucpr:0.76493+0.00215\ttest-aucpr:0.76010+0.00309\n",
            "[15]\ttrain-aucpr:0.76779+0.00324\ttest-aucpr:0.76279+0.00328\n",
            "[16]\ttrain-aucpr:0.77002+0.00213\ttest-aucpr:0.76497+0.00301\n",
            "[17]\ttrain-aucpr:0.77335+0.00251\ttest-aucpr:0.76821+0.00227\n",
            "[18]\ttrain-aucpr:0.77641+0.00283\ttest-aucpr:0.77114+0.00366\n",
            "[19]\ttrain-aucpr:0.78056+0.00281\ttest-aucpr:0.77480+0.00361\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94669+0.00203\ttest-aucpr:0.88450+0.00314\n",
            "[1]\ttrain-aucpr:0.96495+0.00291\ttest-aucpr:0.90774+0.00501\n",
            "[2]\ttrain-aucpr:0.97536+0.00234\ttest-aucpr:0.92202+0.00414\n",
            "[3]\ttrain-aucpr:0.98032+0.00163\ttest-aucpr:0.93012+0.00276\n",
            "[4]\ttrain-aucpr:0.98418+0.00137\ttest-aucpr:0.93630+0.00233\n",
            "[5]\ttrain-aucpr:0.98717+0.00084\ttest-aucpr:0.94131+0.00210\n",
            "[6]\ttrain-aucpr:0.98915+0.00069\ttest-aucpr:0.94423+0.00167\n",
            "[7]\ttrain-aucpr:0.99068+0.00046\ttest-aucpr:0.94685+0.00141\n",
            "[8]\ttrain-aucpr:0.99197+0.00040\ttest-aucpr:0.94973+0.00114\n",
            "[9]\ttrain-aucpr:0.99287+0.00039\ttest-aucpr:0.95147+0.00103\n",
            "[10]\ttrain-aucpr:0.99371+0.00029\ttest-aucpr:0.95323+0.00086\n",
            "[11]\ttrain-aucpr:0.99441+0.00025\ttest-aucpr:0.95485+0.00099\n",
            "[12]\ttrain-aucpr:0.99495+0.00024\ttest-aucpr:0.95595+0.00082\n",
            "[13]\ttrain-aucpr:0.99545+0.00025\ttest-aucpr:0.95708+0.00062\n",
            "[14]\ttrain-aucpr:0.99591+0.00014\ttest-aucpr:0.95810+0.00051\n",
            "[15]\ttrain-aucpr:0.99630+0.00016\ttest-aucpr:0.95899+0.00044\n",
            "[16]\ttrain-aucpr:0.99667+0.00015\ttest-aucpr:0.96003+0.00033\n",
            "[17]\ttrain-aucpr:0.99693+0.00014\ttest-aucpr:0.96072+0.00034\n",
            "[18]\ttrain-aucpr:0.99719+0.00012\ttest-aucpr:0.96160+0.00054\n",
            "[19]\ttrain-aucpr:0.99744+0.00010\ttest-aucpr:0.96219+0.00056\n",
            "result:  0.9621872731832992\n",
            "best result:  0.9621872731832992\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95555+0.00089\ttest-aucpr:0.88733+0.00278\n",
            "[1]\ttrain-aucpr:0.97987+0.00160\ttest-aucpr:0.91923+0.00264\n",
            "[2]\ttrain-aucpr:0.98830+0.00110\ttest-aucpr:0.93501+0.00291\n",
            "[3]\ttrain-aucpr:0.99182+0.00061\ttest-aucpr:0.94304+0.00234\n",
            "[4]\ttrain-aucpr:0.99392+0.00043\ttest-aucpr:0.94862+0.00150\n",
            "[5]\ttrain-aucpr:0.99538+0.00020\ttest-aucpr:0.95260+0.00105\n",
            "[6]\ttrain-aucpr:0.99631+0.00019\ttest-aucpr:0.95589+0.00121\n",
            "[7]\ttrain-aucpr:0.99709+0.00013\ttest-aucpr:0.95838+0.00098\n",
            "[8]\ttrain-aucpr:0.99762+0.00009\ttest-aucpr:0.96050+0.00092\n",
            "[9]\ttrain-aucpr:0.99804+0.00010\ttest-aucpr:0.96232+0.00086\n",
            "[10]\ttrain-aucpr:0.99837+0.00010\ttest-aucpr:0.96367+0.00061\n",
            "[11]\ttrain-aucpr:0.99866+0.00007\ttest-aucpr:0.96515+0.00070\n",
            "[12]\ttrain-aucpr:0.99888+0.00006\ttest-aucpr:0.96616+0.00060\n",
            "[13]\ttrain-aucpr:0.99906+0.00005\ttest-aucpr:0.96717+0.00058\n",
            "[14]\ttrain-aucpr:0.99920+0.00004\ttest-aucpr:0.96818+0.00077\n",
            "[15]\ttrain-aucpr:0.99932+0.00004\ttest-aucpr:0.96891+0.00079\n",
            "[16]\ttrain-aucpr:0.99941+0.00004\ttest-aucpr:0.96963+0.00084\n",
            "[17]\ttrain-aucpr:0.99949+0.00003\ttest-aucpr:0.97036+0.00089\n",
            "[18]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.97084+0.00094\n",
            "[19]\ttrain-aucpr:0.99962+0.00002\ttest-aucpr:0.97134+0.00099\n",
            "result:  0.9713368907046164\n",
            "best result:  0.9713368907046164\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00754\ttest-aucpr:0.71973+0.01007\n",
            "[3]\ttrain-aucpr:0.73763+0.00209\ttest-aucpr:0.73403+0.00556\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75306+0.00284\ttest-aucpr:0.74839+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75896+0.00563\n",
            "[7]\ttrain-aucpr:0.77440+0.00388\ttest-aucpr:0.76927+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77828+0.00214\n",
            "[9]\ttrain-aucpr:0.79097+0.00270\ttest-aucpr:0.78570+0.00044\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79890+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00373\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00393\n",
            "[15]\ttrain-aucpr:0.82372+0.00387\ttest-aucpr:0.81764+0.00323\n",
            "[16]\ttrain-aucpr:0.82728+0.00452\ttest-aucpr:0.82121+0.00374\n",
            "[17]\ttrain-aucpr:0.83238+0.00400\ttest-aucpr:0.82622+0.00430\n",
            "[18]\ttrain-aucpr:0.83627+0.00462\ttest-aucpr:0.83022+0.00562\n",
            "[19]\ttrain-aucpr:0.83893+0.00416\ttest-aucpr:0.83280+0.00508\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95752+0.00066\ttest-aucpr:0.88951+0.00308\n",
            "[1]\ttrain-aucpr:0.98161+0.00142\ttest-aucpr:0.91862+0.00349\n",
            "[2]\ttrain-aucpr:0.98959+0.00056\ttest-aucpr:0.93323+0.00072\n",
            "[3]\ttrain-aucpr:0.99333+0.00038\ttest-aucpr:0.94294+0.00132\n",
            "[4]\ttrain-aucpr:0.99539+0.00007\ttest-aucpr:0.94884+0.00132\n",
            "[5]\ttrain-aucpr:0.99661+0.00009\ttest-aucpr:0.95324+0.00085\n",
            "[6]\ttrain-aucpr:0.99741+0.00007\ttest-aucpr:0.95635+0.00081\n",
            "[7]\ttrain-aucpr:0.99804+0.00008\ttest-aucpr:0.95861+0.00074\n",
            "[8]\ttrain-aucpr:0.99847+0.00005\ttest-aucpr:0.96095+0.00071\n",
            "[9]\ttrain-aucpr:0.99878+0.00003\ttest-aucpr:0.96255+0.00080\n",
            "[10]\ttrain-aucpr:0.99904+0.00005\ttest-aucpr:0.96405+0.00047\n",
            "[11]\ttrain-aucpr:0.99925+0.00001\ttest-aucpr:0.96533+0.00057\n",
            "[12]\ttrain-aucpr:0.99941+0.00001\ttest-aucpr:0.96634+0.00042\n",
            "[13]\ttrain-aucpr:0.99953+0.00002\ttest-aucpr:0.96736+0.00042\n",
            "[14]\ttrain-aucpr:0.99963+0.00002\ttest-aucpr:0.96824+0.00051\n",
            "[15]\ttrain-aucpr:0.99970+0.00002\ttest-aucpr:0.96896+0.00047\n",
            "[16]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96960+0.00051\n",
            "[17]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97020+0.00048\n",
            "[18]\ttrain-aucpr:0.99984+0.00001\ttest-aucpr:0.97081+0.00037\n",
            "[19]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.97130+0.00041\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.68945+0.00533\ttest-aucpr:0.68631+0.00481\n",
            "[2]\ttrain-aucpr:0.70779+0.00228\ttest-aucpr:0.70469+0.00584\n",
            "[3]\ttrain-aucpr:0.71829+0.00226\ttest-aucpr:0.71451+0.00574\n",
            "[4]\ttrain-aucpr:0.72944+0.00515\ttest-aucpr:0.72491+0.00992\n",
            "[5]\ttrain-aucpr:0.73478+0.00406\ttest-aucpr:0.73042+0.00908\n",
            "[6]\ttrain-aucpr:0.74147+0.00198\ttest-aucpr:0.73732+0.00612\n",
            "[7]\ttrain-aucpr:0.74517+0.00230\ttest-aucpr:0.74083+0.00550\n",
            "[8]\ttrain-aucpr:0.74914+0.00175\ttest-aucpr:0.74438+0.00441\n",
            "[9]\ttrain-aucpr:0.75080+0.00085\ttest-aucpr:0.74623+0.00417\n",
            "[10]\ttrain-aucpr:0.75245+0.00215\ttest-aucpr:0.74762+0.00479\n",
            "[11]\ttrain-aucpr:0.75622+0.00268\ttest-aucpr:0.75159+0.00444\n",
            "[12]\ttrain-aucpr:0.75858+0.00165\ttest-aucpr:0.75371+0.00411\n",
            "[13]\ttrain-aucpr:0.76305+0.00231\ttest-aucpr:0.75788+0.00194\n",
            "[14]\ttrain-aucpr:0.76508+0.00199\ttest-aucpr:0.76020+0.00303\n",
            "[15]\ttrain-aucpr:0.76758+0.00364\ttest-aucpr:0.76262+0.00341\n",
            "[16]\ttrain-aucpr:0.76989+0.00242\ttest-aucpr:0.76480+0.00301\n",
            "[17]\ttrain-aucpr:0.77372+0.00206\ttest-aucpr:0.76851+0.00204\n",
            "[18]\ttrain-aucpr:0.77671+0.00247\ttest-aucpr:0.77134+0.00347\n",
            "[19]\ttrain-aucpr:0.78047+0.00316\ttest-aucpr:0.77465+0.00370\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00403\n",
            "[1]\ttrain-aucpr:0.81349+0.00249\ttest-aucpr:0.80541+0.00348\n",
            "[2]\ttrain-aucpr:0.83384+0.00283\ttest-aucpr:0.82622+0.00343\n",
            "[3]\ttrain-aucpr:0.84957+0.00175\ttest-aucpr:0.84230+0.00258\n",
            "[4]\ttrain-aucpr:0.85957+0.00124\ttest-aucpr:0.85205+0.00262\n",
            "[5]\ttrain-aucpr:0.86772+0.00294\ttest-aucpr:0.86016+0.00411\n",
            "[6]\ttrain-aucpr:0.87563+0.00216\ttest-aucpr:0.86792+0.00401\n",
            "[7]\ttrain-aucpr:0.88307+0.00263\ttest-aucpr:0.87529+0.00418\n",
            "[8]\ttrain-aucpr:0.88884+0.00110\ttest-aucpr:0.88119+0.00137\n",
            "[9]\ttrain-aucpr:0.89481+0.00136\ttest-aucpr:0.88704+0.00242\n",
            "[10]\ttrain-aucpr:0.89810+0.00080\ttest-aucpr:0.89005+0.00161\n",
            "[11]\ttrain-aucpr:0.90183+0.00033\ttest-aucpr:0.89373+0.00146\n",
            "[12]\ttrain-aucpr:0.90700+0.00128\ttest-aucpr:0.89889+0.00060\n",
            "[13]\ttrain-aucpr:0.91026+0.00239\ttest-aucpr:0.90216+0.00215\n",
            "[14]\ttrain-aucpr:0.91400+0.00227\ttest-aucpr:0.90591+0.00184\n",
            "[15]\ttrain-aucpr:0.91630+0.00253\ttest-aucpr:0.90810+0.00227\n",
            "[16]\ttrain-aucpr:0.91886+0.00255\ttest-aucpr:0.91071+0.00266\n",
            "[17]\ttrain-aucpr:0.92122+0.00209\ttest-aucpr:0.91296+0.00211\n",
            "[18]\ttrain-aucpr:0.92320+0.00226\ttest-aucpr:0.91482+0.00221\n",
            "[19]\ttrain-aucpr:0.92519+0.00272\ttest-aucpr:0.91667+0.00267\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.69996+0.00178\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72428+0.00732\ttest-aucpr:0.71979+0.01005\n",
            "[3]\ttrain-aucpr:0.73812+0.00237\ttest-aucpr:0.73389+0.00550\n",
            "[4]\ttrain-aucpr:0.74914+0.00187\ttest-aucpr:0.74508+0.00522\n",
            "[5]\ttrain-aucpr:0.75370+0.00235\ttest-aucpr:0.74899+0.00137\n",
            "[6]\ttrain-aucpr:0.76480+0.00353\ttest-aucpr:0.75970+0.00542\n",
            "[7]\ttrain-aucpr:0.77330+0.00225\ttest-aucpr:0.76828+0.00398\n",
            "[8]\ttrain-aucpr:0.78143+0.00403\ttest-aucpr:0.77629+0.00409\n",
            "[9]\ttrain-aucpr:0.78920+0.00341\ttest-aucpr:0.78401+0.00238\n",
            "[10]\ttrain-aucpr:0.79564+0.00400\ttest-aucpr:0.79041+0.00363\n",
            "[11]\ttrain-aucpr:0.80268+0.00379\ttest-aucpr:0.79778+0.00413\n",
            "[12]\ttrain-aucpr:0.80901+0.00186\ttest-aucpr:0.80386+0.00164\n",
            "[13]\ttrain-aucpr:0.81633+0.00264\ttest-aucpr:0.81099+0.00205\n",
            "[14]\ttrain-aucpr:0.82101+0.00283\ttest-aucpr:0.81542+0.00336\n",
            "[15]\ttrain-aucpr:0.82425+0.00309\ttest-aucpr:0.81874+0.00328\n",
            "[16]\ttrain-aucpr:0.82800+0.00388\ttest-aucpr:0.82251+0.00443\n",
            "[17]\ttrain-aucpr:0.83153+0.00326\ttest-aucpr:0.82601+0.00497\n",
            "[18]\ttrain-aucpr:0.83714+0.00166\ttest-aucpr:0.83188+0.00329\n",
            "[19]\ttrain-aucpr:0.83971+0.00204\ttest-aucpr:0.83441+0.00379\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73762+0.00207\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74851+0.00130\ttest-aucpr:0.74450+0.00514\n",
            "[5]\ttrain-aucpr:0.75307+0.00283\ttest-aucpr:0.74840+0.00201\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00502\n",
            "[8]\ttrain-aucpr:0.78353+0.00228\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00161\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00167\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81445+0.00354\ttest-aucpr:0.80886+0.00372\n",
            "[14]\ttrain-aucpr:0.81982+0.00349\ttest-aucpr:0.81398+0.00393\n",
            "[15]\ttrain-aucpr:0.82378+0.00386\ttest-aucpr:0.81770+0.00322\n",
            "[16]\ttrain-aucpr:0.82735+0.00451\ttest-aucpr:0.82128+0.00374\n",
            "[17]\ttrain-aucpr:0.83244+0.00400\ttest-aucpr:0.82628+0.00430\n",
            "[18]\ttrain-aucpr:0.83634+0.00463\ttest-aucpr:0.83028+0.00562\n",
            "[19]\ttrain-aucpr:0.83899+0.00417\ttest-aucpr:0.83285+0.00509\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90143+0.00174\ttest-aucpr:0.87209+0.00410\n",
            "[1]\ttrain-aucpr:0.93481+0.00131\ttest-aucpr:0.90821+0.00184\n",
            "[2]\ttrain-aucpr:0.94936+0.00095\ttest-aucpr:0.92508+0.00082\n",
            "[3]\ttrain-aucpr:0.95746+0.00102\ttest-aucpr:0.93383+0.00131\n",
            "[4]\ttrain-aucpr:0.96245+0.00090\ttest-aucpr:0.93935+0.00062\n",
            "[5]\ttrain-aucpr:0.96621+0.00108\ttest-aucpr:0.94336+0.00079\n",
            "[6]\ttrain-aucpr:0.96954+0.00123\ttest-aucpr:0.94693+0.00100\n",
            "[7]\ttrain-aucpr:0.97212+0.00130\ttest-aucpr:0.94966+0.00105\n",
            "[8]\ttrain-aucpr:0.97436+0.00095\ttest-aucpr:0.95238+0.00065\n",
            "[9]\ttrain-aucpr:0.97658+0.00079\ttest-aucpr:0.95482+0.00055\n",
            "[10]\ttrain-aucpr:0.97821+0.00052\ttest-aucpr:0.95685+0.00037\n",
            "[11]\ttrain-aucpr:0.97939+0.00044\ttest-aucpr:0.95822+0.00038\n",
            "[12]\ttrain-aucpr:0.98029+0.00047\ttest-aucpr:0.95936+0.00071\n",
            "[13]\ttrain-aucpr:0.98130+0.00051\ttest-aucpr:0.96064+0.00049\n",
            "[14]\ttrain-aucpr:0.98255+0.00043\ttest-aucpr:0.96222+0.00027\n",
            "[15]\ttrain-aucpr:0.98318+0.00046\ttest-aucpr:0.96309+0.00020\n",
            "[16]\ttrain-aucpr:0.98392+0.00052\ttest-aucpr:0.96400+0.00053\n",
            "[17]\ttrain-aucpr:0.98439+0.00054\ttest-aucpr:0.96476+0.00050\n",
            "[18]\ttrain-aucpr:0.98489+0.00075\ttest-aucpr:0.96538+0.00043\n",
            "[19]\ttrain-aucpr:0.98532+0.00061\ttest-aucpr:0.96596+0.00042\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90107+0.00181\ttest-aucpr:0.87201+0.00406\n",
            "[1]\ttrain-aucpr:0.92761+0.00399\ttest-aucpr:0.90065+0.00401\n",
            "[2]\ttrain-aucpr:0.93951+0.00295\ttest-aucpr:0.91439+0.00244\n",
            "[3]\ttrain-aucpr:0.94586+0.00238\ttest-aucpr:0.92160+0.00217\n",
            "[4]\ttrain-aucpr:0.95245+0.00125\ttest-aucpr:0.92944+0.00152\n",
            "[5]\ttrain-aucpr:0.95588+0.00136\ttest-aucpr:0.93315+0.00114\n",
            "[6]\ttrain-aucpr:0.95862+0.00086\ttest-aucpr:0.93630+0.00085\n",
            "[7]\ttrain-aucpr:0.96064+0.00092\ttest-aucpr:0.93849+0.00088\n",
            "[8]\ttrain-aucpr:0.96290+0.00077\ttest-aucpr:0.94087+0.00073\n",
            "[9]\ttrain-aucpr:0.96449+0.00072\ttest-aucpr:0.94249+0.00027\n",
            "[10]\ttrain-aucpr:0.96624+0.00031\ttest-aucpr:0.94429+0.00045\n",
            "[11]\ttrain-aucpr:0.96761+0.00043\ttest-aucpr:0.94576+0.00045\n",
            "[12]\ttrain-aucpr:0.96890+0.00046\ttest-aucpr:0.94701+0.00049\n",
            "[13]\ttrain-aucpr:0.97039+0.00061\ttest-aucpr:0.94880+0.00062\n",
            "[14]\ttrain-aucpr:0.97154+0.00062\ttest-aucpr:0.95004+0.00067\n",
            "[15]\ttrain-aucpr:0.97263+0.00084\ttest-aucpr:0.95115+0.00068\n",
            "[16]\ttrain-aucpr:0.97373+0.00100\ttest-aucpr:0.95239+0.00095\n",
            "[17]\ttrain-aucpr:0.97459+0.00088\ttest-aucpr:0.95338+0.00108\n",
            "[18]\ttrain-aucpr:0.97543+0.00085\ttest-aucpr:0.95435+0.00087\n",
            "[19]\ttrain-aucpr:0.97630+0.00102\ttest-aucpr:0.95526+0.00108\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00755\ttest-aucpr:0.71973+0.01008\n",
            "[3]\ttrain-aucpr:0.73762+0.00208\ttest-aucpr:0.73402+0.00557\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74448+0.00515\n",
            "[5]\ttrain-aucpr:0.75305+0.00284\ttest-aucpr:0.74838+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75895+0.00563\n",
            "[7]\ttrain-aucpr:0.77439+0.00388\ttest-aucpr:0.76926+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77827+0.00214\n",
            "[9]\ttrain-aucpr:0.79096+0.00271\ttest-aucpr:0.78570+0.00045\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79889+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00372\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00392\n",
            "[15]\ttrain-aucpr:0.82411+0.00447\ttest-aucpr:0.81813+0.00418\n",
            "[16]\ttrain-aucpr:0.82775+0.00520\ttest-aucpr:0.82170+0.00470\n",
            "[17]\ttrain-aucpr:0.83303+0.00484\ttest-aucpr:0.82689+0.00525\n",
            "[18]\ttrain-aucpr:0.83699+0.00510\ttest-aucpr:0.83099+0.00622\n",
            "[19]\ttrain-aucpr:0.83933+0.00456\ttest-aucpr:0.83319+0.00548\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96995+0.00060\ttest-aucpr:0.89124+0.00327\n",
            "[1]\ttrain-aucpr:0.98800+0.00114\ttest-aucpr:0.91813+0.00197\n",
            "[2]\ttrain-aucpr:0.99404+0.00072\ttest-aucpr:0.93402+0.00240\n",
            "[3]\ttrain-aucpr:0.99648+0.00043\ttest-aucpr:0.94225+0.00277\n",
            "[4]\ttrain-aucpr:0.99777+0.00018\ttest-aucpr:0.94829+0.00208\n",
            "[5]\ttrain-aucpr:0.99853+0.00011\ttest-aucpr:0.95284+0.00202\n",
            "[6]\ttrain-aucpr:0.99897+0.00009\ttest-aucpr:0.95597+0.00165\n",
            "[7]\ttrain-aucpr:0.99924+0.00008\ttest-aucpr:0.95835+0.00148\n",
            "[8]\ttrain-aucpr:0.99945+0.00005\ttest-aucpr:0.96022+0.00134\n",
            "[9]\ttrain-aucpr:0.99961+0.00006\ttest-aucpr:0.96192+0.00110\n",
            "[10]\ttrain-aucpr:0.99970+0.00005\ttest-aucpr:0.96339+0.00106\n",
            "[11]\ttrain-aucpr:0.99979+0.00003\ttest-aucpr:0.96457+0.00105\n",
            "[12]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.96563+0.00095\n",
            "[13]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.96666+0.00111\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96772+0.00087\n",
            "[15]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96842+0.00079\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.96922+0.00078\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.96981+0.00091\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97035+0.00095\n",
            "[19]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97082+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00402\n",
            "[1]\ttrain-aucpr:0.79887+0.00361\ttest-aucpr:0.79184+0.00372\n",
            "[2]\ttrain-aucpr:0.81831+0.00312\ttest-aucpr:0.81134+0.00402\n",
            "[3]\ttrain-aucpr:0.82970+0.00179\ttest-aucpr:0.82294+0.00487\n",
            "[4]\ttrain-aucpr:0.83700+0.00306\ttest-aucpr:0.83006+0.00456\n",
            "[5]\ttrain-aucpr:0.84354+0.00213\ttest-aucpr:0.83694+0.00378\n",
            "[6]\ttrain-aucpr:0.84714+0.00189\ttest-aucpr:0.84010+0.00377\n",
            "[7]\ttrain-aucpr:0.85265+0.00180\ttest-aucpr:0.84523+0.00248\n",
            "[8]\ttrain-aucpr:0.85632+0.00130\ttest-aucpr:0.84904+0.00272\n",
            "[9]\ttrain-aucpr:0.86071+0.00142\ttest-aucpr:0.85347+0.00328\n",
            "[10]\ttrain-aucpr:0.86405+0.00092\ttest-aucpr:0.85671+0.00278\n",
            "[11]\ttrain-aucpr:0.86777+0.00084\ttest-aucpr:0.86032+0.00215\n",
            "[12]\ttrain-aucpr:0.87107+0.00076\ttest-aucpr:0.86358+0.00222\n",
            "[13]\ttrain-aucpr:0.87356+0.00068\ttest-aucpr:0.86599+0.00242\n",
            "[14]\ttrain-aucpr:0.87669+0.00070\ttest-aucpr:0.86923+0.00258\n",
            "[15]\ttrain-aucpr:0.87924+0.00058\ttest-aucpr:0.87175+0.00216\n",
            "[16]\ttrain-aucpr:0.88214+0.00103\ttest-aucpr:0.87452+0.00221\n",
            "[17]\ttrain-aucpr:0.88479+0.00100\ttest-aucpr:0.87706+0.00226\n",
            "[18]\ttrain-aucpr:0.88692+0.00113\ttest-aucpr:0.87919+0.00265\n",
            "[19]\ttrain-aucpr:0.89032+0.00092\ttest-aucpr:0.88262+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90648+0.00131\ttest-aucpr:0.87250+0.00255\n",
            "[1]\ttrain-aucpr:0.93227+0.00376\ttest-aucpr:0.90315+0.00362\n",
            "[2]\ttrain-aucpr:0.94224+0.00211\ttest-aucpr:0.91512+0.00145\n",
            "[3]\ttrain-aucpr:0.94845+0.00199\ttest-aucpr:0.92203+0.00166\n",
            "[4]\ttrain-aucpr:0.95365+0.00173\ttest-aucpr:0.92839+0.00185\n",
            "[5]\ttrain-aucpr:0.95819+0.00062\ttest-aucpr:0.93349+0.00071\n",
            "[6]\ttrain-aucpr:0.96129+0.00099\ttest-aucpr:0.93693+0.00075\n",
            "[7]\ttrain-aucpr:0.96351+0.00087\ttest-aucpr:0.93913+0.00053\n",
            "[8]\ttrain-aucpr:0.96553+0.00085\ttest-aucpr:0.94118+0.00069\n",
            "[9]\ttrain-aucpr:0.96761+0.00101\ttest-aucpr:0.94329+0.00088\n",
            "[10]\ttrain-aucpr:0.96913+0.00080\ttest-aucpr:0.94480+0.00058\n",
            "[11]\ttrain-aucpr:0.97052+0.00081\ttest-aucpr:0.94627+0.00069\n",
            "[12]\ttrain-aucpr:0.97201+0.00057\ttest-aucpr:0.94783+0.00054\n",
            "[13]\ttrain-aucpr:0.97308+0.00060\ttest-aucpr:0.94886+0.00061\n",
            "[14]\ttrain-aucpr:0.97422+0.00055\ttest-aucpr:0.95007+0.00057\n",
            "[15]\ttrain-aucpr:0.97536+0.00053\ttest-aucpr:0.95115+0.00067\n",
            "[16]\ttrain-aucpr:0.97624+0.00042\ttest-aucpr:0.95221+0.00063\n",
            "[17]\ttrain-aucpr:0.97729+0.00049\ttest-aucpr:0.95323+0.00072\n",
            "[18]\ttrain-aucpr:0.97820+0.00044\ttest-aucpr:0.95427+0.00081\n",
            "[19]\ttrain-aucpr:0.97899+0.00050\ttest-aucpr:0.95510+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75887+0.00420\n",
            "[1]\ttrain-aucpr:0.81337+0.00230\ttest-aucpr:0.80537+0.00343\n",
            "[2]\ttrain-aucpr:0.83328+0.00309\ttest-aucpr:0.82599+0.00338\n",
            "[3]\ttrain-aucpr:0.84947+0.00147\ttest-aucpr:0.84236+0.00255\n",
            "[4]\ttrain-aucpr:0.85936+0.00094\ttest-aucpr:0.85202+0.00250\n",
            "[5]\ttrain-aucpr:0.86762+0.00275\ttest-aucpr:0.86011+0.00398\n",
            "[6]\ttrain-aucpr:0.87499+0.00138\ttest-aucpr:0.86730+0.00306\n",
            "[7]\ttrain-aucpr:0.88209+0.00234\ttest-aucpr:0.87446+0.00337\n",
            "[8]\ttrain-aucpr:0.88837+0.00227\ttest-aucpr:0.88052+0.00217\n",
            "[9]\ttrain-aucpr:0.89361+0.00226\ttest-aucpr:0.88577+0.00276\n",
            "[10]\ttrain-aucpr:0.89709+0.00179\ttest-aucpr:0.88897+0.00235\n",
            "[11]\ttrain-aucpr:0.90149+0.00180\ttest-aucpr:0.89335+0.00287\n",
            "[12]\ttrain-aucpr:0.90548+0.00101\ttest-aucpr:0.89725+0.00195\n",
            "[13]\ttrain-aucpr:0.90933+0.00136\ttest-aucpr:0.90113+0.00241\n",
            "[14]\ttrain-aucpr:0.91240+0.00122\ttest-aucpr:0.90415+0.00211\n",
            "[15]\ttrain-aucpr:0.91515+0.00106\ttest-aucpr:0.90709+0.00146\n",
            "[16]\ttrain-aucpr:0.91742+0.00093\ttest-aucpr:0.90934+0.00074\n",
            "[17]\ttrain-aucpr:0.91991+0.00190\ttest-aucpr:0.91169+0.00258\n",
            "[18]\ttrain-aucpr:0.92227+0.00253\ttest-aucpr:0.91407+0.00346\n",
            "[19]\ttrain-aucpr:0.92493+0.00176\ttest-aucpr:0.91673+0.00257\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.81329+0.00228\ttest-aucpr:0.80537+0.00332\n",
            "[2]\ttrain-aucpr:0.83322+0.00300\ttest-aucpr:0.82593+0.00336\n",
            "[3]\ttrain-aucpr:0.84949+0.00146\ttest-aucpr:0.84230+0.00261\n",
            "[4]\ttrain-aucpr:0.85945+0.00091\ttest-aucpr:0.85195+0.00265\n",
            "[5]\ttrain-aucpr:0.86692+0.00230\ttest-aucpr:0.85960+0.00352\n",
            "[6]\ttrain-aucpr:0.87440+0.00160\ttest-aucpr:0.86668+0.00273\n",
            "[7]\ttrain-aucpr:0.88236+0.00259\ttest-aucpr:0.87460+0.00358\n",
            "[8]\ttrain-aucpr:0.88904+0.00102\ttest-aucpr:0.88132+0.00140\n",
            "[9]\ttrain-aucpr:0.89339+0.00155\ttest-aucpr:0.88553+0.00096\n",
            "[10]\ttrain-aucpr:0.89747+0.00144\ttest-aucpr:0.88909+0.00035\n",
            "[11]\ttrain-aucpr:0.90172+0.00147\ttest-aucpr:0.89324+0.00101\n",
            "[12]\ttrain-aucpr:0.90622+0.00147\ttest-aucpr:0.89768+0.00166\n",
            "[13]\ttrain-aucpr:0.90929+0.00095\ttest-aucpr:0.90087+0.00141\n",
            "[14]\ttrain-aucpr:0.91321+0.00120\ttest-aucpr:0.90473+0.00176\n",
            "[15]\ttrain-aucpr:0.91442+0.00125\ttest-aucpr:0.90591+0.00146\n",
            "[16]\ttrain-aucpr:0.91721+0.00164\ttest-aucpr:0.90866+0.00221\n",
            "[17]\ttrain-aucpr:0.91923+0.00122\ttest-aucpr:0.91073+0.00159\n",
            "[18]\ttrain-aucpr:0.92139+0.00105\ttest-aucpr:0.91275+0.00176\n",
            "[19]\ttrain-aucpr:0.92425+0.00164\ttest-aucpr:0.91547+0.00245\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89849+0.00177\ttest-aucpr:0.87056+0.00377\n",
            "[1]\ttrain-aucpr:0.93193+0.00123\ttest-aucpr:0.90645+0.00169\n",
            "[2]\ttrain-aucpr:0.94755+0.00104\ttest-aucpr:0.92373+0.00150\n",
            "[3]\ttrain-aucpr:0.95520+0.00059\ttest-aucpr:0.93160+0.00064\n",
            "[4]\ttrain-aucpr:0.96071+0.00090\ttest-aucpr:0.93729+0.00133\n",
            "[5]\ttrain-aucpr:0.96499+0.00070\ttest-aucpr:0.94206+0.00123\n",
            "[6]\ttrain-aucpr:0.96854+0.00088\ttest-aucpr:0.94574+0.00152\n",
            "[7]\ttrain-aucpr:0.97151+0.00058\ttest-aucpr:0.94880+0.00119\n",
            "[8]\ttrain-aucpr:0.97394+0.00070\ttest-aucpr:0.95135+0.00139\n",
            "[9]\ttrain-aucpr:0.97615+0.00045\ttest-aucpr:0.95399+0.00116\n",
            "[10]\ttrain-aucpr:0.97832+0.00037\ttest-aucpr:0.95645+0.00075\n",
            "[11]\ttrain-aucpr:0.97989+0.00039\ttest-aucpr:0.95818+0.00089\n",
            "[12]\ttrain-aucpr:0.98078+0.00026\ttest-aucpr:0.95929+0.00091\n",
            "[13]\ttrain-aucpr:0.98195+0.00048\ttest-aucpr:0.96090+0.00116\n",
            "[14]\ttrain-aucpr:0.98258+0.00058\ttest-aucpr:0.96176+0.00131\n",
            "[15]\ttrain-aucpr:0.98339+0.00061\ttest-aucpr:0.96265+0.00120\n",
            "[16]\ttrain-aucpr:0.98418+0.00073\ttest-aucpr:0.96355+0.00134\n",
            "[17]\ttrain-aucpr:0.98478+0.00075\ttest-aucpr:0.96423+0.00111\n",
            "[18]\ttrain-aucpr:0.98530+0.00067\ttest-aucpr:0.96492+0.00109\n",
            "[19]\ttrain-aucpr:0.98581+0.00087\ttest-aucpr:0.96544+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90305+0.00167\ttest-aucpr:0.87212+0.00414\n",
            "[1]\ttrain-aucpr:0.93640+0.00176\ttest-aucpr:0.90820+0.00217\n",
            "[2]\ttrain-aucpr:0.95121+0.00103\ttest-aucpr:0.92526+0.00195\n",
            "[3]\ttrain-aucpr:0.95965+0.00132\ttest-aucpr:0.93387+0.00168\n",
            "[4]\ttrain-aucpr:0.96405+0.00153\ttest-aucpr:0.93858+0.00170\n",
            "[5]\ttrain-aucpr:0.96849+0.00128\ttest-aucpr:0.94290+0.00118\n",
            "[6]\ttrain-aucpr:0.97222+0.00117\ttest-aucpr:0.94680+0.00126\n",
            "[7]\ttrain-aucpr:0.97505+0.00130\ttest-aucpr:0.94980+0.00143\n",
            "[8]\ttrain-aucpr:0.97770+0.00099\ttest-aucpr:0.95274+0.00096\n",
            "[9]\ttrain-aucpr:0.97967+0.00112\ttest-aucpr:0.95493+0.00126\n",
            "[10]\ttrain-aucpr:0.98132+0.00109\ttest-aucpr:0.95688+0.00152\n",
            "[11]\ttrain-aucpr:0.98311+0.00078\ttest-aucpr:0.95913+0.00084\n",
            "[12]\ttrain-aucpr:0.98395+0.00060\ttest-aucpr:0.96028+0.00083\n",
            "[13]\ttrain-aucpr:0.98502+0.00041\ttest-aucpr:0.96144+0.00070\n",
            "[14]\ttrain-aucpr:0.98573+0.00061\ttest-aucpr:0.96227+0.00103\n",
            "[15]\ttrain-aucpr:0.98654+0.00060\ttest-aucpr:0.96336+0.00119\n",
            "[16]\ttrain-aucpr:0.98711+0.00074\ttest-aucpr:0.96418+0.00105\n",
            "[17]\ttrain-aucpr:0.98769+0.00039\ttest-aucpr:0.96486+0.00093\n",
            "[18]\ttrain-aucpr:0.98833+0.00033\ttest-aucpr:0.96551+0.00101\n",
            "[19]\ttrain-aucpr:0.98875+0.00046\ttest-aucpr:0.96602+0.00107\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70763+0.00244\ttest-aucpr:0.70463+0.00584\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73731+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74079+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00173\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75075+0.00079\ttest-aucpr:0.74620+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74760+0.00479\n",
            "[11]\ttrain-aucpr:0.75618+0.00265\ttest-aucpr:0.75157+0.00444\n",
            "[12]\ttrain-aucpr:0.75853+0.00161\ttest-aucpr:0.75369+0.00411\n",
            "[13]\ttrain-aucpr:0.76292+0.00245\ttest-aucpr:0.75780+0.00197\n",
            "[14]\ttrain-aucpr:0.76496+0.00215\ttest-aucpr:0.76011+0.00306\n",
            "[15]\ttrain-aucpr:0.76782+0.00325\ttest-aucpr:0.76280+0.00325\n",
            "[16]\ttrain-aucpr:0.77006+0.00213\ttest-aucpr:0.76498+0.00299\n",
            "[17]\ttrain-aucpr:0.77340+0.00251\ttest-aucpr:0.76823+0.00224\n",
            "[18]\ttrain-aucpr:0.77646+0.00284\ttest-aucpr:0.77114+0.00363\n",
            "[19]\ttrain-aucpr:0.78061+0.00282\ttest-aucpr:0.77482+0.00358\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89869+0.00174\ttest-aucpr:0.87054+0.00378\n",
            "[1]\ttrain-aucpr:0.93221+0.00151\ttest-aucpr:0.90655+0.00175\n",
            "[2]\ttrain-aucpr:0.94847+0.00128\ttest-aucpr:0.92439+0.00122\n",
            "[3]\ttrain-aucpr:0.95545+0.00099\ttest-aucpr:0.93159+0.00098\n",
            "[4]\ttrain-aucpr:0.96087+0.00136\ttest-aucpr:0.93693+0.00165\n",
            "[5]\ttrain-aucpr:0.96482+0.00103\ttest-aucpr:0.94152+0.00102\n",
            "[6]\ttrain-aucpr:0.96890+0.00035\ttest-aucpr:0.94608+0.00079\n",
            "[7]\ttrain-aucpr:0.97211+0.00055\ttest-aucpr:0.94953+0.00104\n",
            "[8]\ttrain-aucpr:0.97421+0.00047\ttest-aucpr:0.95171+0.00110\n",
            "[9]\ttrain-aucpr:0.97655+0.00073\ttest-aucpr:0.95413+0.00107\n",
            "[10]\ttrain-aucpr:0.97834+0.00080\ttest-aucpr:0.95619+0.00091\n",
            "[11]\ttrain-aucpr:0.97995+0.00083\ttest-aucpr:0.95788+0.00092\n",
            "[12]\ttrain-aucpr:0.98132+0.00041\ttest-aucpr:0.95939+0.00059\n",
            "[13]\ttrain-aucpr:0.98210+0.00050\ttest-aucpr:0.96042+0.00041\n",
            "[14]\ttrain-aucpr:0.98291+0.00029\ttest-aucpr:0.96147+0.00041\n",
            "[15]\ttrain-aucpr:0.98385+0.00040\ttest-aucpr:0.96264+0.00058\n",
            "[16]\ttrain-aucpr:0.98435+0.00029\ttest-aucpr:0.96326+0.00061\n",
            "[17]\ttrain-aucpr:0.98538+0.00039\ttest-aucpr:0.96453+0.00039\n",
            "[18]\ttrain-aucpr:0.98589+0.00026\ttest-aucpr:0.96519+0.00044\n",
            "[19]\ttrain-aucpr:0.98640+0.00040\ttest-aucpr:0.96565+0.00039\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75886+0.00421\n",
            "[1]\ttrain-aucpr:0.79813+0.00424\ttest-aucpr:0.79127+0.00391\n",
            "[2]\ttrain-aucpr:0.81796+0.00286\ttest-aucpr:0.81121+0.00397\n",
            "[3]\ttrain-aucpr:0.82899+0.00115\ttest-aucpr:0.82236+0.00436\n",
            "[4]\ttrain-aucpr:0.83654+0.00304\ttest-aucpr:0.82981+0.00439\n",
            "[5]\ttrain-aucpr:0.84330+0.00201\ttest-aucpr:0.83689+0.00376\n",
            "[6]\ttrain-aucpr:0.84729+0.00198\ttest-aucpr:0.84033+0.00403\n",
            "[7]\ttrain-aucpr:0.85277+0.00198\ttest-aucpr:0.84548+0.00243\n",
            "[8]\ttrain-aucpr:0.85683+0.00174\ttest-aucpr:0.84967+0.00322\n",
            "[9]\ttrain-aucpr:0.86067+0.00139\ttest-aucpr:0.85345+0.00318\n",
            "[10]\ttrain-aucpr:0.86454+0.00093\ttest-aucpr:0.85746+0.00260\n",
            "[11]\ttrain-aucpr:0.86742+0.00127\ttest-aucpr:0.86016+0.00288\n",
            "[12]\ttrain-aucpr:0.87021+0.00102\ttest-aucpr:0.86290+0.00295\n",
            "[13]\ttrain-aucpr:0.87331+0.00072\ttest-aucpr:0.86599+0.00267\n",
            "[14]\ttrain-aucpr:0.87622+0.00084\ttest-aucpr:0.86906+0.00260\n",
            "[15]\ttrain-aucpr:0.87910+0.00068\ttest-aucpr:0.87181+0.00249\n",
            "[16]\ttrain-aucpr:0.88170+0.00080\ttest-aucpr:0.87431+0.00248\n",
            "[17]\ttrain-aucpr:0.88430+0.00055\ttest-aucpr:0.87661+0.00221\n",
            "[18]\ttrain-aucpr:0.88698+0.00147\ttest-aucpr:0.87933+0.00311\n",
            "[19]\ttrain-aucpr:0.88954+0.00129\ttest-aucpr:0.88184+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90627+0.00135\ttest-aucpr:0.87263+0.00253\n",
            "[1]\ttrain-aucpr:0.93801+0.00154\ttest-aucpr:0.90831+0.00187\n",
            "[2]\ttrain-aucpr:0.95256+0.00107\ttest-aucpr:0.92557+0.00231\n",
            "[3]\ttrain-aucpr:0.95948+0.00160\ttest-aucpr:0.93293+0.00203\n",
            "[4]\ttrain-aucpr:0.96529+0.00061\ttest-aucpr:0.93917+0.00055\n",
            "[5]\ttrain-aucpr:0.96986+0.00122\ttest-aucpr:0.94438+0.00087\n",
            "[6]\ttrain-aucpr:0.97279+0.00092\ttest-aucpr:0.94755+0.00095\n",
            "[7]\ttrain-aucpr:0.97572+0.00101\ttest-aucpr:0.95070+0.00101\n",
            "[8]\ttrain-aucpr:0.97791+0.00105\ttest-aucpr:0.95308+0.00078\n",
            "[9]\ttrain-aucpr:0.98033+0.00082\ttest-aucpr:0.95589+0.00064\n",
            "[10]\ttrain-aucpr:0.98231+0.00070\ttest-aucpr:0.95785+0.00077\n",
            "[11]\ttrain-aucpr:0.98357+0.00065\ttest-aucpr:0.95941+0.00082\n",
            "[12]\ttrain-aucpr:0.98467+0.00040\ttest-aucpr:0.96085+0.00075\n",
            "[13]\ttrain-aucpr:0.98563+0.00033\ttest-aucpr:0.96189+0.00089\n",
            "[14]\ttrain-aucpr:0.98628+0.00032\ttest-aucpr:0.96274+0.00083\n",
            "[15]\ttrain-aucpr:0.98689+0.00035\ttest-aucpr:0.96344+0.00072\n",
            "[16]\ttrain-aucpr:0.98750+0.00048\ttest-aucpr:0.96415+0.00064\n",
            "[17]\ttrain-aucpr:0.98818+0.00063\ttest-aucpr:0.96501+0.00067\n",
            "[18]\ttrain-aucpr:0.98885+0.00057\ttest-aucpr:0.96576+0.00079\n",
            "[19]\ttrain-aucpr:0.98941+0.00084\ttest-aucpr:0.96626+0.00092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "xXJEj4W_8T-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69863b78-b66d-45ff-bb28-49504e4cb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:logistic',\n",
              " 'eta': 0.25,\n",
              " 'max_depth': 20,\n",
              " 'gamma': 1,\n",
              " 'lambda': 1,\n",
              " 'alpha': 1.0,\n",
              " 'eval_metric': 'aucpr'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aucpr_params = {'objective': 'binary:logistic',\n",
        "         'eta': 0.25,\n",
        "         'max_depth': 20,\n",
        "         'gamma': 1,\n",
        "         'lambda': 1,\n",
        "         'alpha': 1.0,\n",
        "         'eval_metric': 'aucpr'}"
      ],
      "metadata": {
        "id": "_RjSFnb1SXl7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "    dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "    dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    tr=xgb.train(params=aucpr_params,\n",
        "                 num_boost_round=222,\n",
        "                 dtrain=dtrain,\n",
        "                 verbose_eval=1,\n",
        "                 evals=evallist,\n",
        "                 early_stopping_rounds = 3\n",
        "             )\n",
        "\n",
        "    preds_XGB = np.round(tr.predict(dtest), 0)\n",
        "\n",
        "    classification_report(y[test_index],np.round(preds_XGB, 0),output_dict=True)\n",
        "    fold_results.update({i:{'predictions':preds_XGB,'index':test_index,'y_true':y[test_index]}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQFpdGo4cZNV",
        "outputId": "973c9ca3-729b-4dc0-bb56-54656ef37dde"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-aucpr:0.95959\teval-aucpr:0.89759\n",
            "[1]\ttrain-aucpr:0.98119\teval-aucpr:0.93133\n",
            "[2]\ttrain-aucpr:0.98777\teval-aucpr:0.93999\n",
            "[3]\ttrain-aucpr:0.99178\teval-aucpr:0.94840\n",
            "[4]\ttrain-aucpr:0.99375\teval-aucpr:0.95154\n",
            "[5]\ttrain-aucpr:0.99507\teval-aucpr:0.95507\n",
            "[6]\ttrain-aucpr:0.99611\teval-aucpr:0.95924\n",
            "[7]\ttrain-aucpr:0.99678\teval-aucpr:0.96071\n",
            "[8]\ttrain-aucpr:0.99724\teval-aucpr:0.96271\n",
            "[9]\ttrain-aucpr:0.99786\teval-aucpr:0.96437\n",
            "[10]\ttrain-aucpr:0.99815\teval-aucpr:0.96569\n",
            "[11]\ttrain-aucpr:0.99847\teval-aucpr:0.96755\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96863\n",
            "[13]\ttrain-aucpr:0.99891\teval-aucpr:0.96901\n",
            "[14]\ttrain-aucpr:0.99905\teval-aucpr:0.97010\n",
            "[15]\ttrain-aucpr:0.99918\teval-aucpr:0.97096\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97178\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97243\n",
            "[18]\ttrain-aucpr:0.99945\teval-aucpr:0.97295\n",
            "[19]\ttrain-aucpr:0.99952\teval-aucpr:0.97329\n",
            "[20]\ttrain-aucpr:0.99959\teval-aucpr:0.97385\n",
            "[21]\ttrain-aucpr:0.99964\teval-aucpr:0.97411\n",
            "[22]\ttrain-aucpr:0.99969\teval-aucpr:0.97427\n",
            "[23]\ttrain-aucpr:0.99974\teval-aucpr:0.97428\n",
            "[24]\ttrain-aucpr:0.99977\teval-aucpr:0.97461\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97471\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97508\n",
            "[27]\ttrain-aucpr:0.99985\teval-aucpr:0.97521\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97526\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97525\n",
            "[30]\ttrain-aucpr:0.99989\teval-aucpr:0.97545\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97545\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97568\n",
            "[33]\ttrain-aucpr:0.99993\teval-aucpr:0.97562\n",
            "[34]\ttrain-aucpr:0.99994\teval-aucpr:0.97561\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97574\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97598\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97599\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97598\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97600\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97609\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97599\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97598\n",
            "[0]\ttrain-aucpr:0.95801\teval-aucpr:0.89513\n",
            "[1]\ttrain-aucpr:0.98134\teval-aucpr:0.92580\n",
            "[2]\ttrain-aucpr:0.98951\teval-aucpr:0.94370\n",
            "[3]\ttrain-aucpr:0.99249\teval-aucpr:0.94937\n",
            "[4]\ttrain-aucpr:0.99421\teval-aucpr:0.95291\n",
            "[5]\ttrain-aucpr:0.99555\teval-aucpr:0.95742\n",
            "[6]\ttrain-aucpr:0.99642\teval-aucpr:0.96023\n",
            "[7]\ttrain-aucpr:0.99712\teval-aucpr:0.96190\n",
            "[8]\ttrain-aucpr:0.99760\teval-aucpr:0.96321\n",
            "[9]\ttrain-aucpr:0.99799\teval-aucpr:0.96421\n",
            "[10]\ttrain-aucpr:0.99831\teval-aucpr:0.96589\n",
            "[11]\ttrain-aucpr:0.99856\teval-aucpr:0.96749\n",
            "[12]\ttrain-aucpr:0.99882\teval-aucpr:0.96892\n",
            "[13]\ttrain-aucpr:0.99901\teval-aucpr:0.96981\n",
            "[14]\ttrain-aucpr:0.99917\teval-aucpr:0.97063\n",
            "[15]\ttrain-aucpr:0.99929\teval-aucpr:0.97132\n",
            "[16]\ttrain-aucpr:0.99940\teval-aucpr:0.97161\n",
            "[17]\ttrain-aucpr:0.99948\teval-aucpr:0.97185\n",
            "[18]\ttrain-aucpr:0.99956\teval-aucpr:0.97228\n",
            "[19]\ttrain-aucpr:0.99962\teval-aucpr:0.97303\n",
            "[20]\ttrain-aucpr:0.99966\teval-aucpr:0.97324\n",
            "[21]\ttrain-aucpr:0.99972\teval-aucpr:0.97357\n",
            "[22]\ttrain-aucpr:0.99975\teval-aucpr:0.97385\n",
            "[23]\ttrain-aucpr:0.99979\teval-aucpr:0.97436\n",
            "[24]\ttrain-aucpr:0.99982\teval-aucpr:0.97428\n",
            "[25]\ttrain-aucpr:0.99984\teval-aucpr:0.97455\n",
            "[26]\ttrain-aucpr:0.99986\teval-aucpr:0.97467\n",
            "[27]\ttrain-aucpr:0.99988\teval-aucpr:0.97459\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97472\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97484\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97489\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97500\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97496\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97491\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97501\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97525\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97522\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97530\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97550\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97539\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97540\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97536\n",
            "[0]\ttrain-aucpr:0.95727\teval-aucpr:0.89617\n",
            "[1]\ttrain-aucpr:0.97878\teval-aucpr:0.92792\n",
            "[2]\ttrain-aucpr:0.98863\teval-aucpr:0.94272\n",
            "[3]\ttrain-aucpr:0.99154\teval-aucpr:0.95010\n",
            "[4]\ttrain-aucpr:0.99391\teval-aucpr:0.95603\n",
            "[5]\ttrain-aucpr:0.99528\teval-aucpr:0.96038\n",
            "[6]\ttrain-aucpr:0.99612\teval-aucpr:0.96273\n",
            "[7]\ttrain-aucpr:0.99677\teval-aucpr:0.96486\n",
            "[8]\ttrain-aucpr:0.99733\teval-aucpr:0.96650\n",
            "[9]\ttrain-aucpr:0.99777\teval-aucpr:0.96775\n",
            "[10]\ttrain-aucpr:0.99811\teval-aucpr:0.96883\n",
            "[11]\ttrain-aucpr:0.99844\teval-aucpr:0.96989\n",
            "[12]\ttrain-aucpr:0.99873\teval-aucpr:0.97055\n",
            "[13]\ttrain-aucpr:0.99889\teval-aucpr:0.97115\n",
            "[14]\ttrain-aucpr:0.99905\teval-aucpr:0.97226\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97291\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97348\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97400\n",
            "[18]\ttrain-aucpr:0.99949\teval-aucpr:0.97457\n",
            "[19]\ttrain-aucpr:0.99956\teval-aucpr:0.97465\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97462\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97492\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97526\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97598\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97608\n",
            "[25]\ttrain-aucpr:0.99983\teval-aucpr:0.97645\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97660\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97679\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97684\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97689\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97710\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97738\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97741\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97758\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97762\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97750\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97780\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97797\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97799\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97807\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97824\n",
            "[41]\ttrain-aucpr:0.99999\teval-aucpr:0.97819\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97826\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97850\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97854\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97855\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97844\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97851\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97860\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97860\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97861\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97865\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97865\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97872\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97881\n",
            "[57]\ttrain-aucpr:1.00000\teval-aucpr:0.97879\n",
            "[58]\ttrain-aucpr:1.00000\teval-aucpr:0.97883\n",
            "[59]\ttrain-aucpr:1.00000\teval-aucpr:0.97886\n",
            "[60]\ttrain-aucpr:1.00000\teval-aucpr:0.97903\n",
            "[61]\ttrain-aucpr:1.00000\teval-aucpr:0.97907\n",
            "[62]\ttrain-aucpr:1.00000\teval-aucpr:0.97909\n",
            "[63]\ttrain-aucpr:1.00000\teval-aucpr:0.97921\n",
            "[64]\ttrain-aucpr:1.00000\teval-aucpr:0.97924\n",
            "[65]\ttrain-aucpr:1.00000\teval-aucpr:0.97923\n",
            "[66]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[67]\ttrain-aucpr:1.00000\teval-aucpr:0.97931\n",
            "[68]\ttrain-aucpr:1.00000\teval-aucpr:0.97932\n",
            "[69]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[70]\ttrain-aucpr:1.00000\teval-aucpr:0.97929\n",
            "[71]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[0]\ttrain-aucpr:0.95861\teval-aucpr:0.89379\n",
            "[1]\ttrain-aucpr:0.98252\teval-aucpr:0.92981\n",
            "[2]\ttrain-aucpr:0.98929\teval-aucpr:0.94090\n",
            "[3]\ttrain-aucpr:0.99224\teval-aucpr:0.94901\n",
            "[4]\ttrain-aucpr:0.99390\teval-aucpr:0.95400\n",
            "[5]\ttrain-aucpr:0.99530\teval-aucpr:0.95655\n",
            "[6]\ttrain-aucpr:0.99613\teval-aucpr:0.95870\n",
            "[7]\ttrain-aucpr:0.99685\teval-aucpr:0.96131\n",
            "[8]\ttrain-aucpr:0.99743\teval-aucpr:0.96315\n",
            "[9]\ttrain-aucpr:0.99790\teval-aucpr:0.96530\n",
            "[10]\ttrain-aucpr:0.99823\teval-aucpr:0.96668\n",
            "[11]\ttrain-aucpr:0.99850\teval-aucpr:0.96795\n",
            "[12]\ttrain-aucpr:0.99868\teval-aucpr:0.96927\n",
            "[13]\ttrain-aucpr:0.99887\teval-aucpr:0.97029\n",
            "[14]\ttrain-aucpr:0.99902\teval-aucpr:0.97088\n",
            "[15]\ttrain-aucpr:0.99916\teval-aucpr:0.97150\n",
            "[16]\ttrain-aucpr:0.99927\teval-aucpr:0.97200\n",
            "[17]\ttrain-aucpr:0.99937\teval-aucpr:0.97254\n",
            "[18]\ttrain-aucpr:0.99946\teval-aucpr:0.97321\n",
            "[19]\ttrain-aucpr:0.99954\teval-aucpr:0.97371\n",
            "[20]\ttrain-aucpr:0.99958\teval-aucpr:0.97389\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97434\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97440\n",
            "[23]\ttrain-aucpr:0.99971\teval-aucpr:0.97456\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97489\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97499\n",
            "[26]\ttrain-aucpr:0.99981\teval-aucpr:0.97529\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97528\n",
            "[28]\ttrain-aucpr:0.99987\teval-aucpr:0.97537\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97522\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97543\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97569\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97588\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97593\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97596\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97602\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97613\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97616\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97605\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97617\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97613\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97617\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97619\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97635\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97644\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97647\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97650\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97645\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97647\n",
            "[0]\ttrain-aucpr:0.95768\teval-aucpr:0.89666\n",
            "[1]\ttrain-aucpr:0.97882\teval-aucpr:0.92033\n",
            "[2]\ttrain-aucpr:0.98827\teval-aucpr:0.93851\n",
            "[3]\ttrain-aucpr:0.99182\teval-aucpr:0.94801\n",
            "[4]\ttrain-aucpr:0.99370\teval-aucpr:0.95212\n",
            "[5]\ttrain-aucpr:0.99489\teval-aucpr:0.95683\n",
            "[6]\ttrain-aucpr:0.99599\teval-aucpr:0.96004\n",
            "[7]\ttrain-aucpr:0.99672\teval-aucpr:0.96261\n",
            "[8]\ttrain-aucpr:0.99732\teval-aucpr:0.96427\n",
            "[9]\ttrain-aucpr:0.99776\teval-aucpr:0.96598\n",
            "[10]\ttrain-aucpr:0.99807\teval-aucpr:0.96720\n",
            "[11]\ttrain-aucpr:0.99836\teval-aucpr:0.96863\n",
            "[12]\ttrain-aucpr:0.99867\teval-aucpr:0.96956\n",
            "[13]\ttrain-aucpr:0.99889\teval-aucpr:0.97061\n",
            "[14]\ttrain-aucpr:0.99906\teval-aucpr:0.97132\n",
            "[15]\ttrain-aucpr:0.99917\teval-aucpr:0.97157\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97233\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97296\n",
            "[18]\ttrain-aucpr:0.99946\teval-aucpr:0.97334\n",
            "[19]\ttrain-aucpr:0.99951\teval-aucpr:0.97367\n",
            "[20]\ttrain-aucpr:0.99957\teval-aucpr:0.97424\n",
            "[21]\ttrain-aucpr:0.99962\teval-aucpr:0.97451\n",
            "[22]\ttrain-aucpr:0.99966\teval-aucpr:0.97441\n",
            "[23]\ttrain-aucpr:0.99971\teval-aucpr:0.97478\n",
            "[24]\ttrain-aucpr:0.99973\teval-aucpr:0.97488\n",
            "[25]\ttrain-aucpr:0.99974\teval-aucpr:0.97499\n",
            "[26]\ttrain-aucpr:0.99978\teval-aucpr:0.97517\n",
            "[27]\ttrain-aucpr:0.99981\teval-aucpr:0.97513\n",
            "[28]\ttrain-aucpr:0.99984\teval-aucpr:0.97524\n",
            "[29]\ttrain-aucpr:0.99986\teval-aucpr:0.97537\n",
            "[30]\ttrain-aucpr:0.99988\teval-aucpr:0.97570\n",
            "[31]\ttrain-aucpr:0.99990\teval-aucpr:0.97583\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97598\n",
            "[33]\ttrain-aucpr:0.99993\teval-aucpr:0.97621\n",
            "[34]\ttrain-aucpr:0.99994\teval-aucpr:0.97646\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97643\n",
            "[36]\ttrain-aucpr:0.99995\teval-aucpr:0.97645\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97657\n",
            "[38]\ttrain-aucpr:0.99996\teval-aucpr:0.97668\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97660\n",
            "[40]\ttrain-aucpr:0.99997\teval-aucpr:0.97660\n",
            "[0]\ttrain-aucpr:0.96092\teval-aucpr:0.90690\n",
            "[1]\ttrain-aucpr:0.98014\teval-aucpr:0.93451\n",
            "[2]\ttrain-aucpr:0.98790\teval-aucpr:0.94811\n",
            "[3]\ttrain-aucpr:0.99204\teval-aucpr:0.95522\n",
            "[4]\ttrain-aucpr:0.99411\teval-aucpr:0.95921\n",
            "[5]\ttrain-aucpr:0.99527\teval-aucpr:0.96241\n",
            "[6]\ttrain-aucpr:0.99612\teval-aucpr:0.96398\n",
            "[7]\ttrain-aucpr:0.99688\teval-aucpr:0.96658\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96751\n",
            "[9]\ttrain-aucpr:0.99782\teval-aucpr:0.96868\n",
            "[10]\ttrain-aucpr:0.99822\teval-aucpr:0.97003\n",
            "[11]\ttrain-aucpr:0.99849\teval-aucpr:0.97103\n",
            "[12]\ttrain-aucpr:0.99875\teval-aucpr:0.97174\n",
            "[13]\ttrain-aucpr:0.99895\teval-aucpr:0.97237\n",
            "[14]\ttrain-aucpr:0.99912\teval-aucpr:0.97300\n",
            "[15]\ttrain-aucpr:0.99925\teval-aucpr:0.97388\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97442\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97491\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97539\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97574\n",
            "[20]\ttrain-aucpr:0.99963\teval-aucpr:0.97616\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97623\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97668\n",
            "[23]\ttrain-aucpr:0.99973\teval-aucpr:0.97694\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97705\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97728\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97744\n",
            "[27]\ttrain-aucpr:0.99985\teval-aucpr:0.97761\n",
            "[28]\ttrain-aucpr:0.99987\teval-aucpr:0.97765\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97763\n",
            "[30]\ttrain-aucpr:0.99989\teval-aucpr:0.97767\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97779\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97774\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97782\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97781\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97787\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97802\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97817\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97826\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97831\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97841\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97842\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97843\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97848\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97849\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97856\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97865\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97867\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97873\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97872\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97873\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97878\n",
            "[52]\ttrain-aucpr:0.99999\teval-aucpr:0.97880\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97892\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97903\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97902\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97899\n",
            "[0]\ttrain-aucpr:0.95693\teval-aucpr:0.90258\n",
            "[1]\ttrain-aucpr:0.98237\teval-aucpr:0.93263\n",
            "[2]\ttrain-aucpr:0.98938\teval-aucpr:0.94299\n",
            "[3]\ttrain-aucpr:0.99211\teval-aucpr:0.95102\n",
            "[4]\ttrain-aucpr:0.99421\teval-aucpr:0.95600\n",
            "[5]\ttrain-aucpr:0.99539\teval-aucpr:0.95897\n",
            "[6]\ttrain-aucpr:0.99626\teval-aucpr:0.96128\n",
            "[7]\ttrain-aucpr:0.99685\teval-aucpr:0.96353\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96566\n",
            "[9]\ttrain-aucpr:0.99784\teval-aucpr:0.96718\n",
            "[10]\ttrain-aucpr:0.99825\teval-aucpr:0.96856\n",
            "[11]\ttrain-aucpr:0.99850\teval-aucpr:0.96955\n",
            "[12]\ttrain-aucpr:0.99876\teval-aucpr:0.97064\n",
            "[13]\ttrain-aucpr:0.99894\teval-aucpr:0.97149\n",
            "[14]\ttrain-aucpr:0.99911\teval-aucpr:0.97238\n",
            "[15]\ttrain-aucpr:0.99924\teval-aucpr:0.97277\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97366\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97404\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97458\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97481\n",
            "[20]\ttrain-aucpr:0.99965\teval-aucpr:0.97521\n",
            "[21]\ttrain-aucpr:0.99969\teval-aucpr:0.97536\n",
            "[22]\ttrain-aucpr:0.99973\teval-aucpr:0.97535\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97556\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97608\n",
            "[25]\ttrain-aucpr:0.99982\teval-aucpr:0.97646\n",
            "[26]\ttrain-aucpr:0.99986\teval-aucpr:0.97656\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97680\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97672\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97706\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97737\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97748\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97771\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97784\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97783\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97795\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97818\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97803\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97806\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97799\n",
            "[0]\ttrain-aucpr:0.95826\teval-aucpr:0.90189\n",
            "[1]\ttrain-aucpr:0.98201\teval-aucpr:0.93658\n",
            "[2]\ttrain-aucpr:0.98893\teval-aucpr:0.94766\n",
            "[3]\ttrain-aucpr:0.99220\teval-aucpr:0.95450\n",
            "[4]\ttrain-aucpr:0.99392\teval-aucpr:0.95832\n",
            "[5]\ttrain-aucpr:0.99522\teval-aucpr:0.96179\n",
            "[6]\ttrain-aucpr:0.99607\teval-aucpr:0.96335\n",
            "[7]\ttrain-aucpr:0.99681\teval-aucpr:0.96478\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96697\n",
            "[9]\ttrain-aucpr:0.99778\teval-aucpr:0.96869\n",
            "[10]\ttrain-aucpr:0.99824\teval-aucpr:0.96972\n",
            "[11]\ttrain-aucpr:0.99854\teval-aucpr:0.97073\n",
            "[12]\ttrain-aucpr:0.99872\teval-aucpr:0.97191\n",
            "[13]\ttrain-aucpr:0.99890\teval-aucpr:0.97258\n",
            "[14]\ttrain-aucpr:0.99907\teval-aucpr:0.97304\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97404\n",
            "[16]\ttrain-aucpr:0.99929\teval-aucpr:0.97449\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97492\n",
            "[18]\ttrain-aucpr:0.99948\teval-aucpr:0.97533\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97566\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97573\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97613\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97612\n",
            "[23]\ttrain-aucpr:0.99972\teval-aucpr:0.97635\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97647\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97647\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97673\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97700\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97717\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97742\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97739\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97763\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97761\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97767\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97800\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97812\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97820\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97824\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97821\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97835\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97842\n",
            "[41]\ttrain-aucpr:0.99999\teval-aucpr:0.97842\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97842\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97858\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97867\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97869\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97874\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97875\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97868\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97866\n",
            "[0]\ttrain-aucpr:0.95892\teval-aucpr:0.89196\n",
            "[1]\ttrain-aucpr:0.97821\teval-aucpr:0.91875\n",
            "[2]\ttrain-aucpr:0.98816\teval-aucpr:0.94167\n",
            "[3]\ttrain-aucpr:0.99183\teval-aucpr:0.94968\n",
            "[4]\ttrain-aucpr:0.99388\teval-aucpr:0.95508\n",
            "[5]\ttrain-aucpr:0.99537\teval-aucpr:0.95780\n",
            "[6]\ttrain-aucpr:0.99623\teval-aucpr:0.95934\n",
            "[7]\ttrain-aucpr:0.99689\teval-aucpr:0.96085\n",
            "[8]\ttrain-aucpr:0.99742\teval-aucpr:0.96265\n",
            "[9]\ttrain-aucpr:0.99781\teval-aucpr:0.96463\n",
            "[10]\ttrain-aucpr:0.99822\teval-aucpr:0.96611\n",
            "[11]\ttrain-aucpr:0.99843\teval-aucpr:0.96749\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96853\n",
            "[13]\ttrain-aucpr:0.99893\teval-aucpr:0.96954\n",
            "[14]\ttrain-aucpr:0.99908\teval-aucpr:0.97040\n",
            "[15]\ttrain-aucpr:0.99920\teval-aucpr:0.97097\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97173\n",
            "[17]\ttrain-aucpr:0.99942\teval-aucpr:0.97206\n",
            "[18]\ttrain-aucpr:0.99952\teval-aucpr:0.97261\n",
            "[19]\ttrain-aucpr:0.99958\teval-aucpr:0.97299\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97368\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97376\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97401\n",
            "[23]\ttrain-aucpr:0.99974\teval-aucpr:0.97399\n",
            "[24]\ttrain-aucpr:0.99978\teval-aucpr:0.97426\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97428\n",
            "[26]\ttrain-aucpr:0.99983\teval-aucpr:0.97452\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97452\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97455\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97457\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97476\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97473\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97474\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97489\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97506\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97503\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97495\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97529\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97539\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97535\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97523\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97540\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97569\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97585\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97593\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97601\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97600\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97603\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97606\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97610\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97618\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97615\n",
            "[52]\ttrain-aucpr:0.99999\teval-aucpr:0.97624\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97640\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97643\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97642\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97641\n",
            "[0]\ttrain-aucpr:0.95662\teval-aucpr:0.89489\n",
            "[1]\ttrain-aucpr:0.97949\teval-aucpr:0.92672\n",
            "[2]\ttrain-aucpr:0.98794\teval-aucpr:0.94024\n",
            "[3]\ttrain-aucpr:0.99173\teval-aucpr:0.94889\n",
            "[4]\ttrain-aucpr:0.99363\teval-aucpr:0.95289\n",
            "[5]\ttrain-aucpr:0.99503\teval-aucpr:0.95696\n",
            "[6]\ttrain-aucpr:0.99601\teval-aucpr:0.95995\n",
            "[7]\ttrain-aucpr:0.99673\teval-aucpr:0.96160\n",
            "[8]\ttrain-aucpr:0.99727\teval-aucpr:0.96314\n",
            "[9]\ttrain-aucpr:0.99771\teval-aucpr:0.96451\n",
            "[10]\ttrain-aucpr:0.99814\teval-aucpr:0.96621\n",
            "[11]\ttrain-aucpr:0.99839\teval-aucpr:0.96715\n",
            "[12]\ttrain-aucpr:0.99866\teval-aucpr:0.96872\n",
            "[13]\ttrain-aucpr:0.99888\teval-aucpr:0.96948\n",
            "[14]\ttrain-aucpr:0.99907\teval-aucpr:0.97029\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97080\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97137\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97151\n",
            "[18]\ttrain-aucpr:0.99947\teval-aucpr:0.97224\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97300\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97326\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97340\n",
            "[22]\ttrain-aucpr:0.99969\teval-aucpr:0.97371\n",
            "[23]\ttrain-aucpr:0.99973\teval-aucpr:0.97402\n",
            "[24]\ttrain-aucpr:0.99975\teval-aucpr:0.97426\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97414\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97428\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97465\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97454\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97463\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97505\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97521\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97529\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97540\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97535\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97532\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97548\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97568\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97552\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97558\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97571\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97566\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97574\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97565\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97566\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97577\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97580\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97581\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97594\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97590\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m3[idx] = np.round(fold_results.get(i).get('predictions')[j], 0)"
      ],
      "metadata": {
        "id": "7hSFBjJSXmnc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_cost = cost_func(preds_m3,y)\n",
        "m3_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSw-zr1_YDa6",
        "outputId": "9e96772a-2b84-4be7-8add-13072bea76b0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1164650"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new3[idx] = 1\n",
        "    else:\n",
        "      preds_new3[idx] = 0\n",
        "m3_cost_t = cost_func(y,preds_new3)\n",
        "m3_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adyt-BMxEjNf",
        "outputId": "4c1e79f8-cb75-44a3-eac4-a4aeda3caa09"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100600"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sets binary values for predictions\n",
        "def cost(y_true,y_pred):\n",
        "\n",
        "  bin_p = K.switch(K.greater_equal(y_pred,0.5),K.constant(1,shape=y_pred.shape),\n",
        "                   K.constant(0,shape=y_pred.shape))\n",
        "  diff = bin_p-y_true\n",
        "\n",
        "  error = K.switch(\n",
        "      K.equal(diff,1),K.constant(100,shape=y_pred.shape),\n",
        "      K.switch(\n",
        "          K.equal(diff,-1),K.constant(150,shape=y_pred.shape),\n",
        "          K.constant(0,shape=y_pred.shape)\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error))"
      ],
      "metadata": {
        "id": "z2vUglkTkzxm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### define a cost function used in validation with keras and backend\n",
        "### returns the average cost (total cost divided by array tensor size)\n",
        "def cost(y_true,y_pred):\n",
        "  bin_p = tf.where(tf.greater_equal(y_pred,0.5),tf.constant(1,dtype='float32'),tf.constant(0,dtype='float32'))\n",
        "\n",
        "  diff = bin_p - y_true\n",
        "\n",
        "  error = tf.where(\n",
        "      tf.equal(diff,1),100,\n",
        "      tf.where(\n",
        "          tf.equal(diff,-1),150,\n",
        "          0\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error)/tf.size(bin_p))"
      ],
      "metadata": {
        "id": "EV-gIgK12n02"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model4.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "32627df5-0f67-4087-88f6-3323e954d6d9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5461 - auc: 0.7797 - accuracy: 0.7152 - cost: 37.7363 - val_loss: 0.4092 - val_auc: 0.8941 - val_accuracy: 0.8208 - val_cost: 22.7181\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3658 - auc: 0.9148 - accuracy: 0.8432 - cost: 19.9780 - val_loss: 0.3208 - val_auc: 0.9346 - val_accuracy: 0.8622 - val_cost: 17.0117\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3153 - auc: 0.9372 - accuracy: 0.8704 - cost: 16.3913 - val_loss: 0.2950 - val_auc: 0.9455 - val_accuracy: 0.8770 - val_cost: 15.6771\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2870 - auc: 0.9480 - accuracy: 0.8832 - cost: 14.7903 - val_loss: 0.2706 - val_auc: 0.9540 - val_accuracy: 0.8917 - val_cost: 13.1771\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2663 - auc: 0.9553 - accuracy: 0.8932 - cost: 13.4905 - val_loss: 0.2522 - val_auc: 0.9599 - val_accuracy: 0.9006 - val_cost: 12.3340\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2477 - auc: 0.9613 - accuracy: 0.9033 - cost: 12.2641 - val_loss: 0.2382 - val_auc: 0.9648 - val_accuracy: 0.9069 - val_cost: 11.1621\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2323 - auc: 0.9660 - accuracy: 0.9096 - cost: 11.4452 - val_loss: 0.2220 - val_auc: 0.9689 - val_accuracy: 0.9168 - val_cost: 10.0228\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2188 - auc: 0.9697 - accuracy: 0.9161 - cost: 10.6258 - val_loss: 0.2101 - val_auc: 0.9719 - val_accuracy: 0.9228 - val_cost: 9.5898\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2074 - auc: 0.9727 - accuracy: 0.9218 - cost: 9.9067 - val_loss: 0.1998 - val_auc: 0.9746 - val_accuracy: 0.9269 - val_cost: 8.9844\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1971 - auc: 0.9752 - accuracy: 0.9257 - cost: 9.4033 - val_loss: 0.1901 - val_auc: 0.9767 - val_accuracy: 0.9292 - val_cost: 8.8151\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1885 - auc: 0.9772 - accuracy: 0.9300 - cost: 8.8843 - val_loss: 0.1815 - val_auc: 0.9786 - val_accuracy: 0.9352 - val_cost: 8.0404\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1795 - auc: 0.9792 - accuracy: 0.9344 - cost: 8.3312 - val_loss: 0.1749 - val_auc: 0.9800 - val_accuracy: 0.9393 - val_cost: 7.5228\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1729 - auc: 0.9806 - accuracy: 0.9376 - cost: 7.9260 - val_loss: 0.1690 - val_auc: 0.9814 - val_accuracy: 0.9410 - val_cost: 7.2786\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1676 - auc: 0.9817 - accuracy: 0.9401 - cost: 7.6061 - val_loss: 0.1650 - val_auc: 0.9820 - val_accuracy: 0.9422 - val_cost: 7.3014\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1631 - auc: 0.9826 - accuracy: 0.9421 - cost: 7.3632 - val_loss: 0.1604 - val_auc: 0.9830 - val_accuracy: 0.9442 - val_cost: 7.2721\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9837 - accuracy: 0.9445 - cost: 7.0479 - val_loss: 0.1575 - val_auc: 0.9836 - val_accuracy: 0.9442 - val_cost: 6.8099\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1533 - auc: 0.9843 - accuracy: 0.9465 - cost: 6.7833 - val_loss: 0.1530 - val_auc: 0.9844 - val_accuracy: 0.9478 - val_cost: 6.4811\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9848 - accuracy: 0.9486 - cost: 6.5357 - val_loss: 0.1503 - val_auc: 0.9847 - val_accuracy: 0.9497 - val_cost: 6.7578\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1465 - auc: 0.9855 - accuracy: 0.9501 - cost: 6.3220 - val_loss: 0.1473 - val_auc: 0.9850 - val_accuracy: 0.9503 - val_cost: 6.2500\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1435 - auc: 0.9861 - accuracy: 0.9505 - cost: 6.2868 - val_loss: 0.1443 - val_auc: 0.9855 - val_accuracy: 0.9519 - val_cost: 6.0449\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1403 - auc: 0.9866 - accuracy: 0.9522 - cost: 6.0633 - val_loss: 0.1438 - val_auc: 0.9856 - val_accuracy: 0.9517 - val_cost: 6.3672\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1373 - auc: 0.9870 - accuracy: 0.9540 - cost: 5.8308 - val_loss: 0.1407 - val_auc: 0.9860 - val_accuracy: 0.9525 - val_cost: 5.9863\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1356 - auc: 0.9872 - accuracy: 0.9545 - cost: 5.7731 - val_loss: 0.1383 - val_auc: 0.9863 - val_accuracy: 0.9544 - val_cost: 5.9538\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1323 - auc: 0.9878 - accuracy: 0.9563 - cost: 5.5696 - val_loss: 0.1361 - val_auc: 0.9866 - val_accuracy: 0.9556 - val_cost: 5.7487\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1304 - auc: 0.9881 - accuracy: 0.9563 - cost: 5.5456 - val_loss: 0.1344 - val_auc: 0.9870 - val_accuracy: 0.9562 - val_cost: 5.5566\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9883 - accuracy: 0.9578 - cost: 5.3654 - val_loss: 0.1336 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.4850\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1266 - auc: 0.9885 - accuracy: 0.9587 - cost: 5.2537 - val_loss: 0.1335 - val_auc: 0.9869 - val_accuracy: 0.9562 - val_cost: 5.6771\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1250 - auc: 0.9888 - accuracy: 0.9593 - cost: 5.1885 - val_loss: 0.1314 - val_auc: 0.9874 - val_accuracy: 0.9570 - val_cost: 5.5762\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1228 - auc: 0.9891 - accuracy: 0.9597 - cost: 5.1361 - val_loss: 0.1300 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.0846\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1221 - auc: 0.9892 - accuracy: 0.9605 - cost: 5.0269 - val_loss: 0.1278 - val_auc: 0.9876 - val_accuracy: 0.9589 - val_cost: 5.3483\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1197 - auc: 0.9894 - accuracy: 0.9616 - cost: 4.8803 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9608 - val_cost: 4.8991\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9898 - accuracy: 0.9619 - cost: 4.8355 - val_loss: 0.1263 - val_auc: 0.9877 - val_accuracy: 0.9609 - val_cost: 5.0553\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1175 - auc: 0.9899 - accuracy: 0.9628 - cost: 4.7314 - val_loss: 0.1240 - val_auc: 0.9879 - val_accuracy: 0.9608 - val_cost: 4.8893\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1154 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.6791 - val_loss: 0.1233 - val_auc: 0.9882 - val_accuracy: 0.9618 - val_cost: 4.9544\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.6888 - val_loss: 0.1228 - val_auc: 0.9884 - val_accuracy: 0.9608 - val_cost: 5.0195\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1126 - auc: 0.9905 - accuracy: 0.9642 - cost: 4.5519 - val_loss: 0.1220 - val_auc: 0.9884 - val_accuracy: 0.9620 - val_cost: 4.7526\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9650 - cost: 4.4610 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9627 - val_cost: 4.8014\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1107 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4477 - val_loss: 0.1208 - val_auc: 0.9883 - val_accuracy: 0.9630 - val_cost: 4.7591\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9654 - cost: 4.4106 - val_loss: 0.1189 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.7038\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1102 - auc: 0.9907 - accuracy: 0.9654 - cost: 4.4053 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9630 - val_cost: 4.7201\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1074 - auc: 0.9911 - accuracy: 0.9669 - cost: 4.2130 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9635 - val_cost: 4.6191\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1070 - auc: 0.9911 - accuracy: 0.9667 - cost: 4.2258 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.6973\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1068 - auc: 0.9911 - accuracy: 0.9665 - cost: 4.2609 - val_loss: 0.1195 - val_auc: 0.9886 - val_accuracy: 0.9640 - val_cost: 4.5898\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1061 - auc: 0.9912 - accuracy: 0.9673 - cost: 4.1806 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.6289\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1036 - auc: 0.9914 - accuracy: 0.9679 - cost: 4.0859 - val_loss: 0.1153 - val_auc: 0.9892 - val_accuracy: 0.9650 - val_cost: 4.5182\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9915 - accuracy: 0.9681 - cost: 4.0694 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3783\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1036 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0770 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.5117\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0100 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9666 - val_cost: 4.2253\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9690 - cost: 3.9614 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9659 - val_cost: 4.4987\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1003 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8707 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.5573\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1009 - auc: 0.9918 - accuracy: 0.9694 - cost: 3.9033 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9661 - val_cost: 4.2155\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8851 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.3034\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0986 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8769 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1569\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8188 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0267\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7813 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9669 - val_cost: 4.2513\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7684 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 4.2090\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0968 - auc: 0.9923 - accuracy: 0.9709 - cost: 3.7214 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.1536\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0962 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6549 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.8542\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0960 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6545 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.1309\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9718 - cost: 3.6053 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9675 - val_cost: 3.9193\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9923 - accuracy: 0.9719 - cost: 3.5894 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1439\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0945 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5517 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9095\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5690 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0560\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0937 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5651 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.9453\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9723 - cost: 3.5518 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.2839\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5086 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.8249\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9928 - accuracy: 0.9729 - cost: 3.4615 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 3.9746\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4822 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0951\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9925 - accuracy: 0.9731 - cost: 3.4426 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.0007\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9928 - accuracy: 0.9733 - cost: 3.4271 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 4.0007\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9734 - cost: 3.4001 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0951\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9740 - cost: 3.3415 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0690\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4026 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 4.0332\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3679 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9193\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3670 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8574\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9736 - cost: 3.3812 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0202\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9930 - accuracy: 0.9740 - cost: 3.3186 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.7923\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9930 - accuracy: 0.9742 - cost: 3.3195 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8021\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9928 - accuracy: 0.9743 - cost: 3.3110 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.6361\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2818 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.6458\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9738 - cost: 3.3609 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9931 - accuracy: 0.9743 - cost: 3.2893 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9290\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1803 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 4.1243\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2286 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6556\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2335 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.5775\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2846 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 4.0658\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9930 - accuracy: 0.9746 - cost: 3.2670 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.9876\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2036 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6719\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2092 - val_loss: 0.1119 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1736 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9062\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1596 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8216\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1980 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9681\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9744 - cost: 3.3000 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.2058 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.9941\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1462 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7630\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9935 - accuracy: 0.9753 - cost: 3.1773 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6589\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1273 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9909\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1408 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5254\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0976 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.5840\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0794 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.8444\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9762 - cost: 3.0723 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1629 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0740 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.7728\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0490 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.9030\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1262 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0370 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6426\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9766 - cost: 2.9980 - val_loss: 0.1073 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8607\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0722 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.8281\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0372 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7728\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9886 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.8802\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9935 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6523\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0128 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6198\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9769 - cost: 2.9743 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.9193\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9985 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9160\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0547 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.8314\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9402 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.9062\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9971 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8607\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0160 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.5677\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9603 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.9714\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9503 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7858\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9301 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6393\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9737 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.9160\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9577 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4896\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9919 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9532 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 4.0853\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9261 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8890 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.5807\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9251 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9264 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7988\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0146 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9423 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8477\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8795 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9353 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8640 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7044\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9676 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8734 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.7793\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9090 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7305\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8790 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7174\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9058 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8851 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.7207\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8410 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8566 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7337\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8688 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7793\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8439 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8437 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9942 - accuracy: 0.9780 - cost: 2.8302 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7012\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8739 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6719\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8682 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8703 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8258 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.9128\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8440 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8272 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.7240\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8470 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8337 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.3691\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8437 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6491\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8912 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8810 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6230\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8501 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.7272\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8427 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5905\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8234 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7337\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7825 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7779 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 4.1960\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7896 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6947\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8071 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7974 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7272\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7907 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.8672\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7846 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6068\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7938 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 4.0462\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7515 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6816\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8206 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 4.0104\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9789 - cost: 2.7116 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8542\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7770 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5579\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7914 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5775\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7618 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.9648\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7066 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.6458\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7938 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8479 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.8053\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7642 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8095 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7663\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8423 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6296\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7412 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7142\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7024 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5156\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7824 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5352\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7504 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6198\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7610 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7305\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7606 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6677 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7573 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6686\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7629 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.3496\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7894 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7407 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6784\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7627 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7490 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.7891\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7947 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7305 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7534 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7444 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7216 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8053\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7288 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7953 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.9030\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7336 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7760\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7737 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5645\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7932 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7530 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7219 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.7159 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6956 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4993\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7003 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5579\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7149 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5775\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6923 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.5645\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7454 - val_loss: 0.1163 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6947\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7160 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.7038 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5514\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7588 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7069 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7278 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4245\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6827 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6910 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9714\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6832 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.7044\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7127 - val_loss: 0.1148 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5612\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7031 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.6003\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7520 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8021\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6910 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9714\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6670 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.6426\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6750 - val_loss: 0.1140 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6294 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.6426\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6958 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6815 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.8770\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6957 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7891\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7072 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7402\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6016 - val_loss: 0.1133 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.5189\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6583 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.7858\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6667 - val_loss: 0.1142 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.4505\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6729 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6747 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.9128\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6757 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.9128\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6981 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.6914\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6365 - val_loss: 0.1140 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5352\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6050 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.9583\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1130 - auc: 0.9901 - accuracy: 0.9699 - cost: 3.7344\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:17.147550\n",
            "fold accuracy: 0.9699375033378601 - fold cost: 3.734375\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5475 - auc: 0.7785 - accuracy: 0.7141 - cost: 37.8737 - val_loss: 0.4109 - val_auc: 0.8938 - val_accuracy: 0.8208 - val_cost: 23.7793\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3679 - auc: 0.9139 - accuracy: 0.8416 - cost: 20.2092 - val_loss: 0.3219 - val_auc: 0.9345 - val_accuracy: 0.8628 - val_cost: 17.0345\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3135 - auc: 0.9379 - accuracy: 0.8704 - cost: 16.3609 - val_loss: 0.2929 - val_auc: 0.9459 - val_accuracy: 0.8790 - val_cost: 15.2279\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2863 - auc: 0.9483 - accuracy: 0.8832 - cost: 14.7550 - val_loss: 0.2692 - val_auc: 0.9544 - val_accuracy: 0.8913 - val_cost: 13.6719\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2637 - auc: 0.9563 - accuracy: 0.8948 - cost: 13.3009 - val_loss: 0.2502 - val_auc: 0.9607 - val_accuracy: 0.9008 - val_cost: 12.3340\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2442 - auc: 0.9624 - accuracy: 0.9035 - cost: 12.1949 - val_loss: 0.2336 - val_auc: 0.9656 - val_accuracy: 0.9110 - val_cost: 11.2760\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2292 - auc: 0.9669 - accuracy: 0.9108 - cost: 11.2420 - val_loss: 0.2203 - val_auc: 0.9693 - val_accuracy: 0.9172 - val_cost: 10.5143\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2168 - auc: 0.9703 - accuracy: 0.9176 - cost: 10.4188 - val_loss: 0.2075 - val_auc: 0.9728 - val_accuracy: 0.9245 - val_cost: 9.8405\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2050 - auc: 0.9732 - accuracy: 0.9226 - cost: 9.8039 - val_loss: 0.1971 - val_auc: 0.9752 - val_accuracy: 0.9278 - val_cost: 9.3848\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1946 - auc: 0.9758 - accuracy: 0.9279 - cost: 9.1503 - val_loss: 0.1888 - val_auc: 0.9771 - val_accuracy: 0.9328 - val_cost: 8.4668\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1865 - auc: 0.9777 - accuracy: 0.9314 - cost: 8.7052 - val_loss: 0.1807 - val_auc: 0.9789 - val_accuracy: 0.9363 - val_cost: 8.2324\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1791 - auc: 0.9792 - accuracy: 0.9342 - cost: 8.3429 - val_loss: 0.1752 - val_auc: 0.9798 - val_accuracy: 0.9388 - val_cost: 8.0371\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1719 - auc: 0.9808 - accuracy: 0.9379 - cost: 7.8777 - val_loss: 0.1689 - val_auc: 0.9813 - val_accuracy: 0.9405 - val_cost: 7.7018\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1669 - auc: 0.9818 - accuracy: 0.9404 - cost: 7.5785 - val_loss: 0.1644 - val_auc: 0.9821 - val_accuracy: 0.9419 - val_cost: 7.6530\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1623 - auc: 0.9827 - accuracy: 0.9429 - cost: 7.2463 - val_loss: 0.1605 - val_auc: 0.9829 - val_accuracy: 0.9449 - val_cost: 7.1908\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1588 - auc: 0.9834 - accuracy: 0.9446 - cost: 7.0406 - val_loss: 0.1581 - val_auc: 0.9833 - val_accuracy: 0.9454 - val_cost: 7.1289\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1535 - auc: 0.9843 - accuracy: 0.9466 - cost: 6.7739 - val_loss: 0.1562 - val_auc: 0.9836 - val_accuracy: 0.9463 - val_cost: 7.1354\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1497 - auc: 0.9849 - accuracy: 0.9487 - cost: 6.5230 - val_loss: 0.1509 - val_auc: 0.9847 - val_accuracy: 0.9475 - val_cost: 6.9206\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1462 - auc: 0.9856 - accuracy: 0.9497 - cost: 6.4178 - val_loss: 0.1509 - val_auc: 0.9846 - val_accuracy: 0.9479 - val_cost: 6.7871\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9860 - accuracy: 0.9510 - cost: 6.2409 - val_loss: 0.1473 - val_auc: 0.9853 - val_accuracy: 0.9490 - val_cost: 6.5885\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1410 - auc: 0.9864 - accuracy: 0.9519 - cost: 6.1337 - val_loss: 0.1461 - val_auc: 0.9854 - val_accuracy: 0.9500 - val_cost: 6.4974\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1384 - auc: 0.9868 - accuracy: 0.9533 - cost: 5.9436 - val_loss: 0.1430 - val_auc: 0.9860 - val_accuracy: 0.9518 - val_cost: 6.1849\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1352 - auc: 0.9874 - accuracy: 0.9544 - cost: 5.8025 - val_loss: 0.1419 - val_auc: 0.9862 - val_accuracy: 0.9510 - val_cost: 6.6016\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1332 - auc: 0.9876 - accuracy: 0.9550 - cost: 5.7295 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9534 - val_cost: 6.1100\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1305 - auc: 0.9880 - accuracy: 0.9563 - cost: 5.5699 - val_loss: 0.1370 - val_auc: 0.9867 - val_accuracy: 0.9550 - val_cost: 5.9342\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9579 - cost: 5.3390 - val_loss: 0.1362 - val_auc: 0.9868 - val_accuracy: 0.9564 - val_cost: 5.6283\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9585 - cost: 5.3002 - val_loss: 0.1363 - val_auc: 0.9869 - val_accuracy: 0.9550 - val_cost: 5.7487\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9888 - accuracy: 0.9588 - cost: 5.2385 - val_loss: 0.1351 - val_auc: 0.9871 - val_accuracy: 0.9555 - val_cost: 5.8431\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1234 - auc: 0.9891 - accuracy: 0.9594 - cost: 5.1516 - val_loss: 0.1321 - val_auc: 0.9875 - val_accuracy: 0.9574 - val_cost: 5.6185\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9893 - accuracy: 0.9602 - cost: 5.0716 - val_loss: 0.1306 - val_auc: 0.9876 - val_accuracy: 0.9581 - val_cost: 5.4622\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1209 - auc: 0.9895 - accuracy: 0.9608 - cost: 4.9835 - val_loss: 0.1320 - val_auc: 0.9873 - val_accuracy: 0.9573 - val_cost: 5.6413\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1181 - auc: 0.9898 - accuracy: 0.9617 - cost: 4.8911 - val_loss: 0.1314 - val_auc: 0.9874 - val_accuracy: 0.9586 - val_cost: 5.1855\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1171 - auc: 0.9899 - accuracy: 0.9622 - cost: 4.8129 - val_loss: 0.1289 - val_auc: 0.9879 - val_accuracy: 0.9587 - val_cost: 5.4915\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1156 - auc: 0.9900 - accuracy: 0.9626 - cost: 4.7597 - val_loss: 0.1267 - val_auc: 0.9880 - val_accuracy: 0.9601 - val_cost: 5.2995\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9902 - accuracy: 0.9636 - cost: 4.6368 - val_loss: 0.1275 - val_auc: 0.9881 - val_accuracy: 0.9596 - val_cost: 5.1204\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1133 - auc: 0.9903 - accuracy: 0.9640 - cost: 4.5770 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9597 - val_cost: 5.2051\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9643 - cost: 4.5482 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9614 - val_cost: 4.8958\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9648 - cost: 4.4848 - val_loss: 0.1257 - val_auc: 0.9883 - val_accuracy: 0.9615 - val_cost: 4.8796\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1097 - auc: 0.9907 - accuracy: 0.9652 - cost: 4.4384 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9610 - val_cost: 5.1628\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1089 - auc: 0.9908 - accuracy: 0.9659 - cost: 4.3463 - val_loss: 0.1221 - val_auc: 0.9888 - val_accuracy: 0.9620 - val_cost: 4.9805\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9910 - accuracy: 0.9662 - cost: 4.3046 - val_loss: 0.1236 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.6289\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9909 - accuracy: 0.9662 - cost: 4.3023 - val_loss: 0.1230 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.7103\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9912 - accuracy: 0.9667 - cost: 4.2482 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9639 - val_cost: 4.5833\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9912 - accuracy: 0.9672 - cost: 4.1774 - val_loss: 0.1254 - val_auc: 0.9885 - val_accuracy: 0.9615 - val_cost: 4.7038\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1048 - auc: 0.9914 - accuracy: 0.9671 - cost: 4.1942 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9629 - val_cost: 4.6419\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9671 - cost: 4.1993 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.6354\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1033 - auc: 0.9916 - accuracy: 0.9675 - cost: 4.1398 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.5475\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1030 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0805 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9643 - val_cost: 4.3294\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9681 - cost: 4.0844 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9640 - val_cost: 4.5475\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9920 - accuracy: 0.9689 - cost: 3.9658 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9632 - val_cost: 4.7461\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1010 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9646 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9649 - val_cost: 4.4010\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0998 - auc: 0.9920 - accuracy: 0.9692 - cost: 3.9427 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9647 - val_cost: 4.4727\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.8916 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.3424\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8329 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.4531\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8300 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9648 - val_cost: 4.5280\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9920 - accuracy: 0.9698 - cost: 3.8608 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.4238\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9923 - accuracy: 0.9707 - cost: 3.7349 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.2383\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9923 - accuracy: 0.9701 - cost: 3.8203 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9658 - val_cost: 4.4499\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9923 - accuracy: 0.9703 - cost: 3.8009 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9661 - val_cost: 4.5150\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0964 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7554 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.1797\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9925 - accuracy: 0.9716 - cost: 3.6350 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.1764\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0941 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6605 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9657 - val_cost: 4.2643\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9926 - accuracy: 0.9712 - cost: 3.6799 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.2383\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.6307 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9671 - val_cost: 4.0625\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9714 - cost: 3.6541 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1081\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0923 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5758 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0690\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5938 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9652 - val_cost: 4.2546\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5549 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1667\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9727 - cost: 3.5055 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3457\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5702 - val_loss: 0.1140 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0332\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9722 - cost: 3.5642 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0137\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4375 - val_loss: 0.1121 - val_auc: 0.9893 - val_accuracy: 0.9684 - val_cost: 3.9746\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4976 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0788\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4919 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9662 - val_cost: 4.1895\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0910 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.5010 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.9453\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3613 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 3.9811\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0905 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4886 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.8965\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9731 - cost: 3.4485 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0820\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4689 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.0788\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3905 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 3.9974\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4413 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.2090\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3411 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.2057\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3122 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.1992\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3681 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0918\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3286 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 3.9583\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3033 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8249\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2629 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0918\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2395 - val_loss: 0.1145 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 4.3392\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2778 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0690\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9931 - accuracy: 0.9746 - cost: 3.2509 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.1634\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2662 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9666 - val_cost: 4.0267\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2916 - val_loss: 0.1108 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.1211\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9933 - accuracy: 0.9750 - cost: 3.2019 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9682 - val_cost: 4.1634\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2357 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9388\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9745 - cost: 3.2756 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2328 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.7891\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1905 - val_loss: 0.1122 - val_auc: 0.9891 - val_accuracy: 0.9689 - val_cost: 3.9876\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2626 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.2253\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1969 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9934 - accuracy: 0.9755 - cost: 3.1493 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9844\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0846 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1969 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.0169\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1221 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8737\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1128 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7240\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0814 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0828 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0757 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0839 - auc: 0.9935 - accuracy: 0.9757 - cost: 3.1239 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.7240\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.1062 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9062\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1529 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1421 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8509\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1197 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.6979\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0963 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.7891\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.1021 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6751\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0525 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.7565\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9935 - accuracy: 0.9760 - cost: 3.0856 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7760\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0776 - val_loss: 0.1115 - val_auc: 0.9892 - val_accuracy: 0.9695 - val_cost: 3.7663\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0727 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6589\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0873 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.9323\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0535 - val_loss: 0.1101 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0204 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7109\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9937 - accuracy: 0.9769 - cost: 2.9732 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.6556\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0366 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0225 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6328\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9869 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5775\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9802 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9768 - cost: 3.0054 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7402\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0500 - val_loss: 0.1101 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7728\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9998 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9688 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0235 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0097 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8411\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9635 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7044\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9539 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7402\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0296 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8184\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9390 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7793\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0208 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8879 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9331 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6458\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9902 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9942 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9230 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.7272\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8991 - val_loss: 0.1132 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6914\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9317 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.9714\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9533 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6751\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9113 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5352\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8800 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5189\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9146 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.5807\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9136 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.8249\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8929 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6751\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8431 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6426\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8507 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6361\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8503 - val_loss: 0.1095 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6035\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8557 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8535 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9941 - accuracy: 0.9780 - cost: 2.8357 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6230\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8616 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8418 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5514\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8689 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8483 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5514\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8369 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8488 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7917 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5156\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7819 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8282 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8153 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8653 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.7826\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8140 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5677\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8537 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8315 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4733\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7375 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7732 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5059\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7807 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8485 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7615 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.4440\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8579 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8639\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8284 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8099 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3626\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.8083 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6328\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8200 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7706 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.5775\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8337 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5254\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7875 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4570\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7492 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6263\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7339 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8395 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7371 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8032 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8165 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5059\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7624 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6100\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7198 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7911 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.4993\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7487 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7676 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7457 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7207\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7856 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7753 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6882\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7190 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6820 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4505\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7637 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6003\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7352 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.5026\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6821 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.4538\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7536 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6361\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6624 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4147\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7252 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6597 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6797 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5710\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7375 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6963 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4342\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7663 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6799 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.6003\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7278 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5710\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7266 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7169 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.6621\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7469 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6704 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9794 - cost: 2.6639 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4733\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7131 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7012\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6395 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.5286\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6929 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4993\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6423 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6263\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7452 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6439 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6708 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.4570\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6899 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.4635\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7047 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.6068\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7287 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4505\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7072 - val_loss: 0.1184 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.5384\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1072 - auc: 0.9911 - accuracy: 0.9711 - cost: 3.6344\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:11.903353\n",
            "fold accuracy: 0.9710624814033508 - fold cost: 3.6343750953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5467 - auc: 0.7790 - accuracy: 0.7148 - cost: 37.7937 - val_loss: 0.4074 - val_auc: 0.8945 - val_accuracy: 0.8222 - val_cost: 22.7148\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3648 - auc: 0.9152 - accuracy: 0.8435 - cost: 19.9384 - val_loss: 0.3225 - val_auc: 0.9337 - val_accuracy: 0.8635 - val_cost: 16.8164\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3139 - auc: 0.9376 - accuracy: 0.8695 - cost: 16.4941 - val_loss: 0.2949 - val_auc: 0.9449 - val_accuracy: 0.8788 - val_cost: 14.7428\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2877 - auc: 0.9478 - accuracy: 0.8835 - cost: 14.7044 - val_loss: 0.2721 - val_auc: 0.9534 - val_accuracy: 0.8903 - val_cost: 13.6914\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2665 - auc: 0.9552 - accuracy: 0.8933 - cost: 13.5054 - val_loss: 0.2510 - val_auc: 0.9604 - val_accuracy: 0.9014 - val_cost: 11.9889\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9025 - cost: 12.3291 - val_loss: 0.2341 - val_auc: 0.9653 - val_accuracy: 0.9128 - val_cost: 10.7812\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2296 - auc: 0.9667 - accuracy: 0.9105 - cost: 11.3346 - val_loss: 0.2214 - val_auc: 0.9689 - val_accuracy: 0.9169 - val_cost: 10.1725\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2169 - auc: 0.9702 - accuracy: 0.9171 - cost: 10.4828 - val_loss: 0.2086 - val_auc: 0.9722 - val_accuracy: 0.9224 - val_cost: 9.6582\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2047 - auc: 0.9734 - accuracy: 0.9225 - cost: 9.8141 - val_loss: 0.1980 - val_auc: 0.9749 - val_accuracy: 0.9267 - val_cost: 9.1862\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1957 - auc: 0.9756 - accuracy: 0.9265 - cost: 9.3076 - val_loss: 0.1912 - val_auc: 0.9765 - val_accuracy: 0.9308 - val_cost: 8.8379\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1865 - auc: 0.9777 - accuracy: 0.9306 - cost: 8.8252 - val_loss: 0.1835 - val_auc: 0.9783 - val_accuracy: 0.9336 - val_cost: 8.4993\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1806 - auc: 0.9789 - accuracy: 0.9341 - cost: 8.3596 - val_loss: 0.1782 - val_auc: 0.9795 - val_accuracy: 0.9337 - val_cost: 8.4180\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1754 - auc: 0.9801 - accuracy: 0.9364 - cost: 8.0795 - val_loss: 0.1728 - val_auc: 0.9805 - val_accuracy: 0.9376 - val_cost: 8.0599\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1688 - auc: 0.9813 - accuracy: 0.9386 - cost: 7.8002 - val_loss: 0.1687 - val_auc: 0.9814 - val_accuracy: 0.9383 - val_cost: 7.7799\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9824 - accuracy: 0.9412 - cost: 7.4746 - val_loss: 0.1651 - val_auc: 0.9820 - val_accuracy: 0.9415 - val_cost: 7.5749\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1597 - auc: 0.9831 - accuracy: 0.9436 - cost: 7.1390 - val_loss: 0.1615 - val_auc: 0.9829 - val_accuracy: 0.9432 - val_cost: 7.6042\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1559 - auc: 0.9839 - accuracy: 0.9454 - cost: 6.9471 - val_loss: 0.1591 - val_auc: 0.9834 - val_accuracy: 0.9424 - val_cost: 7.2233\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1512 - auc: 0.9846 - accuracy: 0.9469 - cost: 6.7405 - val_loss: 0.1547 - val_auc: 0.9840 - val_accuracy: 0.9457 - val_cost: 7.1680\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1488 - auc: 0.9850 - accuracy: 0.9488 - cost: 6.4934 - val_loss: 0.1540 - val_auc: 0.9842 - val_accuracy: 0.9460 - val_cost: 6.7773\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1467 - auc: 0.9854 - accuracy: 0.9495 - cost: 6.4008 - val_loss: 0.1500 - val_auc: 0.9847 - val_accuracy: 0.9470 - val_cost: 7.0931\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1433 - auc: 0.9861 - accuracy: 0.9506 - cost: 6.2826 - val_loss: 0.1496 - val_auc: 0.9848 - val_accuracy: 0.9477 - val_cost: 6.4388\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1416 - auc: 0.9864 - accuracy: 0.9513 - cost: 6.1756 - val_loss: 0.1469 - val_auc: 0.9853 - val_accuracy: 0.9485 - val_cost: 6.5951\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9867 - accuracy: 0.9528 - cost: 5.9851 - val_loss: 0.1445 - val_auc: 0.9855 - val_accuracy: 0.9503 - val_cost: 6.3607\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9872 - accuracy: 0.9544 - cost: 5.7917 - val_loss: 0.1438 - val_auc: 0.9857 - val_accuracy: 0.9505 - val_cost: 6.1914\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9875 - accuracy: 0.9548 - cost: 5.7513 - val_loss: 0.1417 - val_auc: 0.9858 - val_accuracy: 0.9516 - val_cost: 6.2891\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1314 - auc: 0.9879 - accuracy: 0.9565 - cost: 5.5330 - val_loss: 0.1406 - val_auc: 0.9861 - val_accuracy: 0.9518 - val_cost: 6.1882\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1302 - auc: 0.9881 - accuracy: 0.9566 - cost: 5.5089 - val_loss: 0.1418 - val_auc: 0.9862 - val_accuracy: 0.9520 - val_cost: 6.1458\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1290 - auc: 0.9883 - accuracy: 0.9572 - cost: 5.4229 - val_loss: 0.1373 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 6.2760\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9887 - accuracy: 0.9577 - cost: 5.3776 - val_loss: 0.1373 - val_auc: 0.9865 - val_accuracy: 0.9533 - val_cost: 6.2891\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1256 - auc: 0.9886 - accuracy: 0.9590 - cost: 5.2234 - val_loss: 0.1366 - val_auc: 0.9867 - val_accuracy: 0.9556 - val_cost: 5.7650\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1237 - auc: 0.9890 - accuracy: 0.9595 - cost: 5.1450 - val_loss: 0.1333 - val_auc: 0.9871 - val_accuracy: 0.9564 - val_cost: 5.7520\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9891 - accuracy: 0.9608 - cost: 4.9772 - val_loss: 0.1338 - val_auc: 0.9870 - val_accuracy: 0.9563 - val_cost: 5.7682\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1200 - auc: 0.9895 - accuracy: 0.9611 - cost: 4.9391 - val_loss: 0.1317 - val_auc: 0.9872 - val_accuracy: 0.9577 - val_cost: 5.4427\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9895 - accuracy: 0.9618 - cost: 4.8478 - val_loss: 0.1324 - val_auc: 0.9873 - val_accuracy: 0.9572 - val_cost: 5.5273\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1174 - auc: 0.9898 - accuracy: 0.9621 - cost: 4.7901 - val_loss: 0.1292 - val_auc: 0.9876 - val_accuracy: 0.9577 - val_cost: 5.6087\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9900 - accuracy: 0.9632 - cost: 4.6867 - val_loss: 0.1300 - val_auc: 0.9874 - val_accuracy: 0.9592 - val_cost: 5.3971\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9902 - accuracy: 0.9633 - cost: 4.6597 - val_loss: 0.1291 - val_auc: 0.9874 - val_accuracy: 0.9594 - val_cost: 5.1465\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9902 - accuracy: 0.9636 - cost: 4.6275 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9596 - val_cost: 5.0586\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9903 - accuracy: 0.9637 - cost: 4.6192 - val_loss: 0.1255 - val_auc: 0.9877 - val_accuracy: 0.9593 - val_cost: 5.4329\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9648 - cost: 4.4812 - val_loss: 0.1264 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 5.2474\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9905 - accuracy: 0.9648 - cost: 4.4861 - val_loss: 0.1261 - val_auc: 0.9878 - val_accuracy: 0.9607 - val_cost: 4.9089\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1109 - auc: 0.9906 - accuracy: 0.9652 - cost: 4.4299 - val_loss: 0.1245 - val_auc: 0.9879 - val_accuracy: 0.9614 - val_cost: 4.8568\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1096 - auc: 0.9907 - accuracy: 0.9657 - cost: 4.3761 - val_loss: 0.1230 - val_auc: 0.9883 - val_accuracy: 0.9616 - val_cost: 4.9316\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9908 - accuracy: 0.9659 - cost: 4.3354 - val_loss: 0.1231 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.1758\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9910 - accuracy: 0.9666 - cost: 4.2498 - val_loss: 0.1245 - val_auc: 0.9877 - val_accuracy: 0.9623 - val_cost: 4.7103\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9909 - accuracy: 0.9668 - cost: 4.2262 - val_loss: 0.1246 - val_auc: 0.9879 - val_accuracy: 0.9622 - val_cost: 4.7233\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9671 - cost: 4.1896 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.8210\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9914 - accuracy: 0.9674 - cost: 4.1544 - val_loss: 0.1216 - val_auc: 0.9883 - val_accuracy: 0.9622 - val_cost: 5.0456\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1313 - val_loss: 0.1203 - val_auc: 0.9883 - val_accuracy: 0.9629 - val_cost: 4.8503\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1040 - auc: 0.9914 - accuracy: 0.9682 - cost: 4.0647 - val_loss: 0.1211 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.7721\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1035 - auc: 0.9916 - accuracy: 0.9680 - cost: 4.0852 - val_loss: 0.1192 - val_auc: 0.9884 - val_accuracy: 0.9641 - val_cost: 4.6517\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1028 - auc: 0.9915 - accuracy: 0.9685 - cost: 4.0148 - val_loss: 0.1220 - val_auc: 0.9883 - val_accuracy: 0.9637 - val_cost: 4.6745\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9917 - accuracy: 0.9688 - cost: 3.9708 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9629 - val_cost: 5.0163\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9374 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.6647\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9918 - accuracy: 0.9693 - cost: 3.9069 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9644 - val_cost: 4.7591\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8720 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9635 - val_cost: 4.8861\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9920 - accuracy: 0.9696 - cost: 3.8808 - val_loss: 0.1187 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.5345\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8380 - val_loss: 0.1202 - val_auc: 0.9885 - val_accuracy: 0.9647 - val_cost: 4.5345\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8304 - val_loss: 0.1167 - val_auc: 0.9887 - val_accuracy: 0.9652 - val_cost: 4.5638\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9920 - accuracy: 0.9705 - cost: 3.7615 - val_loss: 0.1183 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.4206\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9922 - accuracy: 0.9703 - cost: 3.7901 - val_loss: 0.1179 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.3490\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9920 - accuracy: 0.9707 - cost: 3.7417 - val_loss: 0.1203 - val_auc: 0.9885 - val_accuracy: 0.9645 - val_cost: 4.6680\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7705 - val_loss: 0.1176 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.3620\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0975 - auc: 0.9921 - accuracy: 0.9704 - cost: 3.7930 - val_loss: 0.1183 - val_auc: 0.9886 - val_accuracy: 0.9650 - val_cost: 4.5833\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0962 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7203 - val_loss: 0.1167 - val_auc: 0.9889 - val_accuracy: 0.9664 - val_cost: 4.3913\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7178 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.3197\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9717 - cost: 3.6214 - val_loss: 0.1167 - val_auc: 0.9886 - val_accuracy: 0.9655 - val_cost: 4.4824\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9721 - cost: 3.5721 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9649 - val_cost: 4.3457\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6452 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9656 - val_cost: 4.4434\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6715 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9657 - val_cost: 4.3262\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0933 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5785 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9662 - val_cost: 4.3034\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5795 - val_loss: 0.1157 - val_auc: 0.9887 - val_accuracy: 0.9660 - val_cost: 4.3620\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0925 - auc: 0.9926 - accuracy: 0.9727 - cost: 3.4885 - val_loss: 0.1174 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.3066\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9926 - accuracy: 0.9725 - cost: 3.5140 - val_loss: 0.1158 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.2546\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9724 - cost: 3.5234 - val_loss: 0.1168 - val_auc: 0.9887 - val_accuracy: 0.9674 - val_cost: 4.1374\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9724 - cost: 3.5267 - val_loss: 0.1169 - val_auc: 0.9886 - val_accuracy: 0.9665 - val_cost: 4.2220\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5140 - val_loss: 0.1188 - val_auc: 0.9886 - val_accuracy: 0.9659 - val_cost: 4.2578\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5047 - val_loss: 0.1166 - val_auc: 0.9885 - val_accuracy: 0.9665 - val_cost: 4.2936\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4730 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9670 - val_cost: 4.2936\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9928 - accuracy: 0.9729 - cost: 3.4648 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.1699\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9927 - accuracy: 0.9727 - cost: 3.4980 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1081\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4313 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 4.0918\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4213 - val_loss: 0.1165 - val_auc: 0.9887 - val_accuracy: 0.9664 - val_cost: 4.3783\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9931 - accuracy: 0.9734 - cost: 3.4093 - val_loss: 0.1157 - val_auc: 0.9888 - val_accuracy: 0.9668 - val_cost: 4.0527\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3728 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9676 - val_cost: 4.1439\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4290 - val_loss: 0.1141 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 4.0820\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9733 - cost: 3.4163 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 4.1309\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3302 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9675 - val_cost: 4.1699\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9740 - cost: 3.3216 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 4.0332\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3841 - val_loss: 0.1170 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.3490\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0887 - auc: 0.9933 - accuracy: 0.9739 - cost: 3.3457 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.2350\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9740 - cost: 3.3305 - val_loss: 0.1139 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.9909\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3315 - val_loss: 0.1152 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 4.0527\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3176 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9682 - val_cost: 4.1178\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2949 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 4.3457\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9931 - accuracy: 0.9742 - cost: 3.3022 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.2025\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3135 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 4.0592\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2443 - val_loss: 0.1141 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 4.0755\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9934 - accuracy: 0.9744 - cost: 3.2913 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.1406\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.3001 - val_loss: 0.1125 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.9551\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2104 - val_loss: 0.1129 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9290\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2811 - val_loss: 0.1129 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 4.1895\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2580 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9687 - val_cost: 4.0202\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2127 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 4.0397\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2391 - val_loss: 0.1133 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 4.1569\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0859 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2379 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.2383\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9745 - cost: 3.2657 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.1885 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 4.2871\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2077 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 4.0560\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1728 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0169\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2426 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1732\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2013 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9689 - val_cost: 4.2090\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9752 - cost: 3.1645 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0495\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1525 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.9160\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1970 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 4.0462\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.1944 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.1374\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1434 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1296 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 4.1764\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1144 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.8672\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1056 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.8867\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9756 - cost: 3.1387 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1180 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.8607\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1401 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 4.0365\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1531 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1171 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.1037 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.9160\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0657 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0755\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0765 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.1146\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1438 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.9518\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9758 - cost: 3.0999 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 4.1699\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0823 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.0267\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0947 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9062\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0367 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0202\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0564 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.0495\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0457 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9909\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0945 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.9128\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0464 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9779\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0159 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 4.0625\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0634 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8509\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9874 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9323\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0082 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 4.0104\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0441 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 4.0039\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9959 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 4.0202\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0153 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.9193\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0825 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 4.1406\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0273 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9518\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0544 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8770\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9777 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8346\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9766 - cost: 3.0248 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9827 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.8509\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0131 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8509\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9246 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.8802\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9615 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.9421\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9667 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9551\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9579 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.8997\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9623 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.9876\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0412 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.9193\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9202 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 4.1569\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.9135 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9759 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9258\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9033 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.9909\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8932 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8444\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8869 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.1862\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9482 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9909\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9728 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9401 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9583 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.1178\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9270 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9007 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.8835\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9561 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6621\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8626 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8216\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9103 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.8151\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8470 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.8704\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9556 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.9486\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9232 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8965\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8681 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9209 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6947\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8554 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8914 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9686 - val_cost: 3.8574\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8833 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 4.1048\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8102 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8557 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.8672\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8997 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7402\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8319 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8846 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6556\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8710 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7207\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8625 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.9453\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8565 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7858\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8787 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8224 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.9160\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8825 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.9323\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8826 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8346\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8125 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7854 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8118\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8119 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.9681\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8510 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.6621\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8154 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8173 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8346\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9038 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.9714\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8440 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6328\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8410 - val_loss: 0.1191 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.9746\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8513 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8606 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6068\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8439 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8088 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8053\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8818 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.0918\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8009 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8737\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8026 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 4.1406\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7714 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7370\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7972 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8281\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8299 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8495 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.9095\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8672 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6263\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8281 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7598\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7606 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6686\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8249 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8346\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7492 - val_loss: 0.1167 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6914\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8152 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.6458\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7944 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8436 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.8542\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8692 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7917 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6458\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7320 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6003\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7288 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7337\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7605 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8082 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0954 - auc: 0.9921 - accuracy: 0.9741 - cost: 3.2844\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:10.344717\n",
            "fold accuracy: 0.9741250276565552 - fold cost: 3.284374952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5455 - auc: 0.7810 - accuracy: 0.7161 - cost: 37.5245 - val_loss: 0.4033 - val_auc: 0.8968 - val_accuracy: 0.8242 - val_cost: 22.7767\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3640 - auc: 0.9156 - accuracy: 0.8429 - cost: 19.9758 - val_loss: 0.3182 - val_auc: 0.9357 - val_accuracy: 0.8672 - val_cost: 16.3021\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3139 - auc: 0.9377 - accuracy: 0.8694 - cost: 16.5100 - val_loss: 0.2889 - val_auc: 0.9474 - val_accuracy: 0.8813 - val_cost: 14.5964\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2866 - auc: 0.9482 - accuracy: 0.8830 - cost: 14.7634 - val_loss: 0.2666 - val_auc: 0.9550 - val_accuracy: 0.8930 - val_cost: 13.2031\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2640 - auc: 0.9561 - accuracy: 0.8941 - cost: 13.3849 - val_loss: 0.2482 - val_auc: 0.9612 - val_accuracy: 0.9013 - val_cost: 12.0540\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2463 - auc: 0.9619 - accuracy: 0.9032 - cost: 12.2342 - val_loss: 0.2315 - val_auc: 0.9660 - val_accuracy: 0.9112 - val_cost: 10.9212\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2293 - auc: 0.9668 - accuracy: 0.9113 - cost: 11.2080 - val_loss: 0.2186 - val_auc: 0.9699 - val_accuracy: 0.9180 - val_cost: 10.1432\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2161 - auc: 0.9705 - accuracy: 0.9175 - cost: 10.4511 - val_loss: 0.2049 - val_auc: 0.9734 - val_accuracy: 0.9245 - val_cost: 9.3327\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2049 - auc: 0.9734 - accuracy: 0.9220 - cost: 9.8620 - val_loss: 0.1954 - val_auc: 0.9759 - val_accuracy: 0.9297 - val_cost: 8.5547\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1956 - auc: 0.9757 - accuracy: 0.9274 - cost: 9.1895 - val_loss: 0.1869 - val_auc: 0.9775 - val_accuracy: 0.9336 - val_cost: 8.5807\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1871 - auc: 0.9776 - accuracy: 0.9310 - cost: 8.7689 - val_loss: 0.1802 - val_auc: 0.9790 - val_accuracy: 0.9369 - val_cost: 7.7799\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1783 - auc: 0.9796 - accuracy: 0.9349 - cost: 8.2646 - val_loss: 0.1749 - val_auc: 0.9802 - val_accuracy: 0.9387 - val_cost: 8.1738\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1719 - auc: 0.9808 - accuracy: 0.9378 - cost: 7.8931 - val_loss: 0.1682 - val_auc: 0.9814 - val_accuracy: 0.9401 - val_cost: 7.8548\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1670 - auc: 0.9818 - accuracy: 0.9399 - cost: 7.6315 - val_loss: 0.1648 - val_auc: 0.9823 - val_accuracy: 0.9418 - val_cost: 7.4414\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1631 - auc: 0.9826 - accuracy: 0.9424 - cost: 7.3198 - val_loss: 0.1634 - val_auc: 0.9829 - val_accuracy: 0.9431 - val_cost: 7.2038\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9836 - accuracy: 0.9449 - cost: 7.0114 - val_loss: 0.1573 - val_auc: 0.9837 - val_accuracy: 0.9448 - val_cost: 6.8555\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1531 - auc: 0.9844 - accuracy: 0.9469 - cost: 6.7455 - val_loss: 0.1544 - val_auc: 0.9840 - val_accuracy: 0.9463 - val_cost: 6.7741\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9850 - accuracy: 0.9479 - cost: 6.6231 - val_loss: 0.1516 - val_auc: 0.9847 - val_accuracy: 0.9464 - val_cost: 7.0540\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1478 - auc: 0.9853 - accuracy: 0.9490 - cost: 6.4843 - val_loss: 0.1502 - val_auc: 0.9846 - val_accuracy: 0.9486 - val_cost: 6.6276\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1436 - auc: 0.9860 - accuracy: 0.9509 - cost: 6.2507 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9503 - val_cost: 6.2956\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1403 - auc: 0.9866 - accuracy: 0.9525 - cost: 6.0373 - val_loss: 0.1443 - val_auc: 0.9858 - val_accuracy: 0.9519 - val_cost: 6.3737\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1383 - auc: 0.9868 - accuracy: 0.9532 - cost: 5.9374 - val_loss: 0.1425 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.2760\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9873 - accuracy: 0.9543 - cost: 5.8171 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9535 - val_cost: 5.9603\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9877 - accuracy: 0.9554 - cost: 5.6692 - val_loss: 0.1386 - val_auc: 0.9866 - val_accuracy: 0.9544 - val_cost: 5.9049\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1317 - auc: 0.9879 - accuracy: 0.9564 - cost: 5.5584 - val_loss: 0.1371 - val_auc: 0.9866 - val_accuracy: 0.9553 - val_cost: 5.7975\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1284 - auc: 0.9885 - accuracy: 0.9575 - cost: 5.4132 - val_loss: 0.1354 - val_auc: 0.9868 - val_accuracy: 0.9572 - val_cost: 5.6315\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9581 - cost: 5.3365 - val_loss: 0.1341 - val_auc: 0.9870 - val_accuracy: 0.9565 - val_cost: 5.8691\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1245 - auc: 0.9889 - accuracy: 0.9595 - cost: 5.1548 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9581 - val_cost: 5.3906\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9892 - accuracy: 0.9597 - cost: 5.1265 - val_loss: 0.1321 - val_auc: 0.9872 - val_accuracy: 0.9597 - val_cost: 5.2474\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9602 - cost: 5.0536 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9599 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1210 - auc: 0.9894 - accuracy: 0.9609 - cost: 4.9750 - val_loss: 0.1302 - val_auc: 0.9875 - val_accuracy: 0.9592 - val_cost: 5.2539\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9896 - accuracy: 0.9617 - cost: 4.8703 - val_loss: 0.1291 - val_auc: 0.9878 - val_accuracy: 0.9606 - val_cost: 5.1009\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1167 - auc: 0.9899 - accuracy: 0.9621 - cost: 4.8243 - val_loss: 0.1274 - val_auc: 0.9879 - val_accuracy: 0.9599 - val_cost: 5.1855\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9628 - cost: 4.7273 - val_loss: 0.1286 - val_auc: 0.9878 - val_accuracy: 0.9601 - val_cost: 5.1204\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1155 - auc: 0.9901 - accuracy: 0.9628 - cost: 4.7379 - val_loss: 0.1258 - val_auc: 0.9879 - val_accuracy: 0.9613 - val_cost: 4.6745\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1143 - auc: 0.9902 - accuracy: 0.9635 - cost: 4.6484 - val_loss: 0.1256 - val_auc: 0.9881 - val_accuracy: 0.9611 - val_cost: 4.9707\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1128 - auc: 0.9904 - accuracy: 0.9644 - cost: 4.5193 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9619 - val_cost: 4.8763\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9642 - cost: 4.5694 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.7949\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9905 - accuracy: 0.9648 - cost: 4.4719 - val_loss: 0.1248 - val_auc: 0.9880 - val_accuracy: 0.9624 - val_cost: 4.8503\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1103 - auc: 0.9907 - accuracy: 0.9656 - cost: 4.3807 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.6452\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9910 - accuracy: 0.9662 - cost: 4.2952 - val_loss: 0.1236 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.8470\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2893 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9634 - val_cost: 4.6387\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2766 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9638 - val_cost: 4.6387\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9665 - cost: 4.2677 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.7266\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9916 - accuracy: 0.9671 - cost: 4.1868 - val_loss: 0.1222 - val_auc: 0.9884 - val_accuracy: 0.9636 - val_cost: 4.5866\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9676 - cost: 4.1268 - val_loss: 0.1219 - val_auc: 0.9885 - val_accuracy: 0.9628 - val_cost: 4.7721\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1040 - auc: 0.9914 - accuracy: 0.9676 - cost: 4.1304 - val_loss: 0.1211 - val_auc: 0.9887 - val_accuracy: 0.9631 - val_cost: 4.9902\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0195 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9630 - val_cost: 4.7428\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9682 - cost: 4.0478 - val_loss: 0.1215 - val_auc: 0.9883 - val_accuracy: 0.9634 - val_cost: 4.7526\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1030 - auc: 0.9916 - accuracy: 0.9681 - cost: 4.0654 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.5671\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9918 - accuracy: 0.9692 - cost: 3.9368 - val_loss: 0.1197 - val_auc: 0.9886 - val_accuracy: 0.9644 - val_cost: 4.5671\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9718 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.4857\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9918 - accuracy: 0.9693 - cost: 3.9143 - val_loss: 0.1178 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.4629\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0997 - auc: 0.9920 - accuracy: 0.9694 - cost: 3.8984 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9650 - val_cost: 4.4759\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9700 - cost: 3.8256 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.4466\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9696 - cost: 3.8702 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.5052\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9697 - cost: 3.8642 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.3717\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0975 - auc: 0.9922 - accuracy: 0.9703 - cost: 3.7822 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.3848\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9706 - cost: 3.7607 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9667 - val_cost: 4.3359\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9923 - accuracy: 0.9704 - cost: 3.7658 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9645 - val_cost: 4.7559\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9711 - cost: 3.6952 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9657 - val_cost: 4.3945\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9924 - accuracy: 0.9711 - cost: 3.6918 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3424\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9710 - cost: 3.7090 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.4759\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9925 - accuracy: 0.9713 - cost: 3.6578 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.3685\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5743 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.1471\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9717 - cost: 3.6185 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.2383\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9719 - cost: 3.5874 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0853\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9927 - accuracy: 0.9718 - cost: 3.6036 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.3652\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0928 - auc: 0.9926 - accuracy: 0.9723 - cost: 3.5314 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.3164\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9722 - cost: 3.5613 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.2383\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5475 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0853\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.4939 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9486\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9928 - accuracy: 0.9735 - cost: 3.3916 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.1634\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4973 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.2253\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9724 - cost: 3.5355 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.9714\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.4885 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.2025\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0904 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4467 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.9290\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4052 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 4.0495\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9737 - cost: 3.3709 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.9030\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9734 - cost: 3.4054 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9225\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3138 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8477\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.4132 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 4.0299\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3166 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.6751\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3716 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8118\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3135 - val_loss: 0.1094 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 4.0592\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2866 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9743 - cost: 3.3018 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3169 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9740 - cost: 3.3245 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8997\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0858 - auc: 0.9936 - accuracy: 0.9747 - cost: 3.2506 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.8281\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2258 - val_loss: 0.1082 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.9323\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9749 - cost: 3.2201 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8704\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9749 - cost: 3.2219 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7598\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1931 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2302 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.7174\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2407 - val_loss: 0.1074 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.9518\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9934 - accuracy: 0.9758 - cost: 3.1052 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9355\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1243 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9193\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2057 - val_loss: 0.1096 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.1980 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6979\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0730 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.7630\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1009 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7760\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1182 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7077\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.1961 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7533\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0931 - val_loss: 0.1103 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.7142\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1270 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0948 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9095\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9935 - accuracy: 0.9755 - cost: 3.1323 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.7598\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9764 - cost: 3.0254 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7793\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0628 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.8346\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0645 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0368 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6328\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0534 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6914\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0799 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.8086\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0081 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7337\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.0954 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0583 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6751\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0503 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6068\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9762 - val_loss: 0.1090 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5677\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0291 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.7467\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0434 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9766 - val_loss: 0.1081 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.7728\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.8944 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0214 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.7305\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9036 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6719\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9879 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6100\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0010 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.6523\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9488 - val_loss: 0.1094 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7207\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9569 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9978 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9534 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.7077\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9776 - cost: 2.8717 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8700 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6263\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9261 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.7435\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8473 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6979\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.8896 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8946 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.7923\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9204 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6914\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9226 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9249 - val_loss: 0.1097 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6198\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8784 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5710\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8546 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6393\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9104 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6491\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8083 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6556\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8486 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6556\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8508 - val_loss: 0.1098 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6947\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8293 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.7370\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8687 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8718 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.5742\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8395 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6947\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8485 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.5775\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7672 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7370\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8596 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6979\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9047 - val_loss: 0.1081 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7109\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8582 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5677\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7898 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6751\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8172 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8683 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7627 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.8379\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7746 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.7305\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8037 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7609 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6719\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8390 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5319\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7433 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9721 - val_cost: 3.5742\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7378 - val_loss: 0.1108 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7467\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8193 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.5775\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8134 - val_loss: 0.1104 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6035\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.7817 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5254\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7823 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6296\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7456 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.6263\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.7935 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.8574\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7700 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8123 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5514\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7511 - val_loss: 0.1103 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7044\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7974 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.5254\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7134 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.5352\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7503 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6686\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7574 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7283 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.7402\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7887 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5254\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7303 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.7077\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7309 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6068\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7111 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.5482\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7586 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.6523\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7362 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.6068\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7256 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4961\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6655 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5710\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7511 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7092 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6914\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7246 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9727 - val_cost: 3.3757\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6503 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.8053\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6692 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7021 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6165\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7290 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6881 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5449\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6887 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.6165\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5892 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.5319\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6595 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.5352\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7252 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9731 - val_cost: 3.4635\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6984 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5286\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6919 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9729 - val_cost: 3.4831\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6346 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4993\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6355 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.5059\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6339 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6328\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6608 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5091\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6311 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.5221\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5812 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9721 - val_cost: 3.5840\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6780 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.7793\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6827 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5710\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6744 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.6198\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7591 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5091\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9799 - cost: 2.5846 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.5156\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7279 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5807\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6782 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6693 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9725 - val_cost: 3.6458\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6633 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.7044\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6330 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6296\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6594 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6491\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6398 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.7565\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6679 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.5645\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6387 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6942 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.5872\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6179 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5156\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6592 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5797 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.6068\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6178 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9722 - val_cost: 3.5645\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5645\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6037 - val_loss: 0.1137 - val_auc: 0.9891 - val_accuracy: 0.9735 - val_cost: 3.3594\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6692 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5905\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9804 - cost: 2.5348 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.4798\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6591 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5938\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9946 - accuracy: 0.9797 - cost: 2.6204 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5971 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9723 - val_cost: 3.5384\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5774 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.4277\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5675 - val_loss: 0.1143 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6359 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.6003\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6249 - val_loss: 0.1163 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6250 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9947 - accuracy: 0.9800 - cost: 2.5889 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5547\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6697 - val_loss: 0.1129 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.4993\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9799 - cost: 2.6106 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5775\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5385 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5645\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5781 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5221\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5608 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5933 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.5384\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6180 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9724 - val_cost: 3.5254\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6149 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9722 - val_cost: 3.5840\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6030 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9803 - cost: 2.5453 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7565\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6130 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.6035\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6152 - val_loss: 0.1149 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.5156\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6119 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6192 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6207 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9729 - val_cost: 3.4798\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.6031 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.4831\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5905 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5059\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9804 - cost: 2.5321 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9720 - val_cost: 3.5547\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.5918 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7565\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5632 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5645\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9798 - cost: 2.6091 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9723 - val_cost: 3.7174\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5728 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.7174\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9808 - cost: 2.4867 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9728 - val_cost: 3.5254\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5559 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.5026\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5491 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.6003\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6354 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4408\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9806 - cost: 2.4886 - val_loss: 0.1173 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.4375\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5952 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7142\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9949 - accuracy: 0.9807 - cost: 2.4896 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9733 - val_cost: 3.4538\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5610 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9720 - val_cost: 3.5905\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5400 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9729 - val_cost: 3.4277\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9806 - cost: 2.5051 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.5189\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5909 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9733 - val_cost: 3.4310\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5716 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9731 - val_cost: 3.4505\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5639 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.5742\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9804 - cost: 2.5293 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9807 - cost: 2.4863 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5352\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5730 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4766\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5488 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.5938\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1051 - auc: 0.9903 - accuracy: 0.9728 - cost: 3.5000\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:40.180745\n",
            "fold accuracy: 0.9728124737739563 - fold cost: 3.5\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5482 - auc: 0.7776 - accuracy: 0.7138 - cost: 37.9318 - val_loss: 0.4101 - val_auc: 0.8935 - val_accuracy: 0.8213 - val_cost: 23.5059\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3677 - auc: 0.9139 - accuracy: 0.8417 - cost: 20.1542 - val_loss: 0.3223 - val_auc: 0.9340 - val_accuracy: 0.8628 - val_cost: 16.9824\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3151 - auc: 0.9372 - accuracy: 0.8695 - cost: 16.5251 - val_loss: 0.2941 - val_auc: 0.9455 - val_accuracy: 0.8798 - val_cost: 14.4564\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2876 - auc: 0.9478 - accuracy: 0.8828 - cost: 14.8247 - val_loss: 0.2695 - val_auc: 0.9539 - val_accuracy: 0.8908 - val_cost: 13.6719\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2659 - auc: 0.9554 - accuracy: 0.8939 - cost: 13.4195 - val_loss: 0.2506 - val_auc: 0.9606 - val_accuracy: 0.9013 - val_cost: 12.0736\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2468 - auc: 0.9616 - accuracy: 0.9027 - cost: 12.2990 - val_loss: 0.2332 - val_auc: 0.9657 - val_accuracy: 0.9114 - val_cost: 11.0254\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2315 - auc: 0.9662 - accuracy: 0.9096 - cost: 11.4396 - val_loss: 0.2203 - val_auc: 0.9693 - val_accuracy: 0.9177 - val_cost: 10.2083\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2180 - auc: 0.9699 - accuracy: 0.9170 - cost: 10.5095 - val_loss: 0.2072 - val_auc: 0.9728 - val_accuracy: 0.9224 - val_cost: 9.4206\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2072 - auc: 0.9728 - accuracy: 0.9214 - cost: 9.9617 - val_loss: 0.1973 - val_auc: 0.9752 - val_accuracy: 0.9282 - val_cost: 8.8835\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1966 - auc: 0.9754 - accuracy: 0.9258 - cost: 9.4029 - val_loss: 0.1888 - val_auc: 0.9771 - val_accuracy: 0.9300 - val_cost: 8.7305\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1884 - auc: 0.9773 - accuracy: 0.9309 - cost: 8.7840 - val_loss: 0.1812 - val_auc: 0.9790 - val_accuracy: 0.9344 - val_cost: 8.1152\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1798 - auc: 0.9792 - accuracy: 0.9340 - cost: 8.3934 - val_loss: 0.1754 - val_auc: 0.9800 - val_accuracy: 0.9381 - val_cost: 7.6660\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1745 - auc: 0.9803 - accuracy: 0.9365 - cost: 8.0916 - val_loss: 0.1696 - val_auc: 0.9812 - val_accuracy: 0.9403 - val_cost: 7.7767\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1688 - auc: 0.9814 - accuracy: 0.9402 - cost: 7.6007 - val_loss: 0.1650 - val_auc: 0.9822 - val_accuracy: 0.9411 - val_cost: 7.6758\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1621 - auc: 0.9828 - accuracy: 0.9423 - cost: 7.3420 - val_loss: 0.1603 - val_auc: 0.9829 - val_accuracy: 0.9442 - val_cost: 7.3568\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9441 - cost: 7.1110 - val_loss: 0.1567 - val_auc: 0.9837 - val_accuracy: 0.9449 - val_cost: 6.8587\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1541 - auc: 0.9842 - accuracy: 0.9460 - cost: 6.8655 - val_loss: 0.1523 - val_auc: 0.9845 - val_accuracy: 0.9468 - val_cost: 6.9596\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1496 - auc: 0.9850 - accuracy: 0.9484 - cost: 6.5570 - val_loss: 0.1502 - val_auc: 0.9848 - val_accuracy: 0.9481 - val_cost: 7.0117\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1468 - auc: 0.9855 - accuracy: 0.9495 - cost: 6.4523 - val_loss: 0.1482 - val_auc: 0.9852 - val_accuracy: 0.9485 - val_cost: 6.3216\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1427 - auc: 0.9861 - accuracy: 0.9511 - cost: 6.2219 - val_loss: 0.1453 - val_auc: 0.9856 - val_accuracy: 0.9506 - val_cost: 6.3704\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1411 - auc: 0.9863 - accuracy: 0.9522 - cost: 6.0863 - val_loss: 0.1424 - val_auc: 0.9859 - val_accuracy: 0.9515 - val_cost: 6.3932\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9871 - accuracy: 0.9543 - cost: 5.8090 - val_loss: 0.1405 - val_auc: 0.9861 - val_accuracy: 0.9535 - val_cost: 6.1784\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1357 - auc: 0.9873 - accuracy: 0.9545 - cost: 5.7991 - val_loss: 0.1372 - val_auc: 0.9865 - val_accuracy: 0.9540 - val_cost: 6.0449\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1315 - auc: 0.9880 - accuracy: 0.9558 - cost: 5.6401 - val_loss: 0.1354 - val_auc: 0.9870 - val_accuracy: 0.9551 - val_cost: 5.8366\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1291 - auc: 0.9883 - accuracy: 0.9566 - cost: 5.5170 - val_loss: 0.1350 - val_auc: 0.9870 - val_accuracy: 0.9561 - val_cost: 5.6738\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9883 - accuracy: 0.9578 - cost: 5.3726 - val_loss: 0.1324 - val_auc: 0.9874 - val_accuracy: 0.9561 - val_cost: 5.7878\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1257 - auc: 0.9888 - accuracy: 0.9588 - cost: 5.2675 - val_loss: 0.1315 - val_auc: 0.9874 - val_accuracy: 0.9570 - val_cost: 5.5697\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9891 - accuracy: 0.9597 - cost: 5.1400 - val_loss: 0.1303 - val_auc: 0.9877 - val_accuracy: 0.9576 - val_cost: 5.4036\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1228 - auc: 0.9891 - accuracy: 0.9604 - cost: 5.0554 - val_loss: 0.1306 - val_auc: 0.9877 - val_accuracy: 0.9569 - val_cost: 5.3678\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1213 - auc: 0.9893 - accuracy: 0.9603 - cost: 5.0545 - val_loss: 0.1294 - val_auc: 0.9878 - val_accuracy: 0.9590 - val_cost: 5.6022\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1183 - auc: 0.9897 - accuracy: 0.9616 - cost: 4.8785 - val_loss: 0.1275 - val_auc: 0.9879 - val_accuracy: 0.9602 - val_cost: 5.0651\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9898 - accuracy: 0.9624 - cost: 4.7998 - val_loss: 0.1243 - val_auc: 0.9883 - val_accuracy: 0.9604 - val_cost: 5.2246\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9628 - cost: 4.7407 - val_loss: 0.1264 - val_auc: 0.9883 - val_accuracy: 0.9597 - val_cost: 5.4622\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9635 - cost: 4.6535 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9610 - val_cost: 5.3190\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9903 - accuracy: 0.9638 - cost: 4.6182 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9622 - val_cost: 5.0358\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4625 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 5.0033\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1113 - auc: 0.9906 - accuracy: 0.9648 - cost: 4.4969 - val_loss: 0.1208 - val_auc: 0.9886 - val_accuracy: 0.9640 - val_cost: 4.6126\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1106 - auc: 0.9907 - accuracy: 0.9646 - cost: 4.5091 - val_loss: 0.1191 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 5.0130\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1092 - auc: 0.9908 - accuracy: 0.9656 - cost: 4.3993 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9635 - val_cost: 4.6842\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9910 - accuracy: 0.9663 - cost: 4.2879 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.5150\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1071 - auc: 0.9912 - accuracy: 0.9665 - cost: 4.2686 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.7135\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9666 - cost: 4.2636 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9636 - val_cost: 4.7982\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1048 - auc: 0.9914 - accuracy: 0.9671 - cost: 4.2055 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3717\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9913 - accuracy: 0.9680 - cost: 4.0965 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9654 - val_cost: 4.4564\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9679 - cost: 4.0892 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.3164\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9915 - accuracy: 0.9683 - cost: 4.0536 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9647 - val_cost: 4.6094\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9918 - accuracy: 0.9685 - cost: 4.0207 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9657 - val_cost: 4.5020\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9918 - accuracy: 0.9694 - cost: 3.9088 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.3717\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9695 - cost: 3.9052 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.2155\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8975 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 4.1634\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9701 - cost: 3.8220 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.6061\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8151 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.3457\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8304 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 4.1374\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7345 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 4.2285\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9921 - accuracy: 0.9709 - cost: 3.7127 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.2936\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0966 - auc: 0.9922 - accuracy: 0.9709 - cost: 3.7238 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.1895\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0959 - auc: 0.9923 - accuracy: 0.9714 - cost: 3.6515 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 4.0072\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6584 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 4.0332\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7144 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0788\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6585 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 4.0885\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5578 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0820\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0938 - auc: 0.9925 - accuracy: 0.9723 - cost: 3.5610 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9928 - accuracy: 0.9727 - cost: 3.5058 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 4.0299\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4779 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0951\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4551 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.0788\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9927 - accuracy: 0.9730 - cost: 3.4677 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0560\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9927 - accuracy: 0.9730 - cost: 3.4609 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0527\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4303 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0397\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9930 - accuracy: 0.9735 - cost: 3.3925 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9927 - accuracy: 0.9736 - cost: 3.3740 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 4.0072\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0896 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3588 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9684 - val_cost: 4.0755\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9929 - accuracy: 0.9737 - cost: 3.3698 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9095\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9929 - accuracy: 0.9736 - cost: 3.3877 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.9583\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9929 - accuracy: 0.9743 - cost: 3.3017 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9486\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9930 - accuracy: 0.9742 - cost: 3.3009 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 4.0853\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3368 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 4.1634\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9930 - accuracy: 0.9743 - cost: 3.2934 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8639\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9741 - cost: 3.3343 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.3051 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.7923\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0868 - auc: 0.9932 - accuracy: 0.9746 - cost: 3.2597 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8835\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3456 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9932 - accuracy: 0.9753 - cost: 3.1837 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9486\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1857 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.9616\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2898 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8737\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2094 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8184\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9932 - accuracy: 0.9747 - cost: 3.2494 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 4.0820\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1556 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8379\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9933 - accuracy: 0.9752 - cost: 3.1761 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.6979\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9753 - cost: 3.1614 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8216\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9932 - accuracy: 0.9751 - cost: 3.1967 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.2088 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9696 - val_cost: 3.8770\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9936 - accuracy: 0.9752 - cost: 3.1898 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6882\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1239 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.5091\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9935 - accuracy: 0.9760 - cost: 3.0927 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.5319\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9934 - accuracy: 0.9756 - cost: 3.1271 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6198\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1470 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.3561\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1297 - val_loss: 0.1078 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.7077\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9935 - accuracy: 0.9762 - cost: 3.0548 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6198\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9935 - accuracy: 0.9763 - cost: 3.0522 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.3366\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9936 - accuracy: 0.9767 - cost: 3.0052 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.5905\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9761 - cost: 3.0741 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.4928\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0955 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.3691\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0831 - auc: 0.9936 - accuracy: 0.9764 - cost: 3.0522 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9936 - accuracy: 0.9763 - cost: 3.0478 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9766 - cost: 3.0020 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8932\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9764 - cost: 3.0422 - val_loss: 0.1077 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.3952\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0477 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.9421\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0622 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.9258\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0127 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9938 - accuracy: 0.9771 - cost: 2.9402 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.2715\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0124 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.2324\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9938 - accuracy: 0.9769 - cost: 2.9649 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9936 - accuracy: 0.9770 - cost: 2.9649 - val_loss: 0.1107 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.3659\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0070 - val_loss: 0.1122 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.7240\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9771 - cost: 2.9570 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6686\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9938 - accuracy: 0.9767 - cost: 2.9768 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.3268\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0136 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.5645\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9939 - accuracy: 0.9772 - cost: 2.9444 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.3854\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9637 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9471 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.7728\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9528 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.7435\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9938 - accuracy: 0.9771 - cost: 2.9496 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5872\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9775 - cost: 2.8943 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7305\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9543 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.7858\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9490 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.4798\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9940 - accuracy: 0.9772 - cost: 2.9324 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.4570\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8778 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.4928\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9779 - cost: 2.8294 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.3822\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9939 - accuracy: 0.9773 - cost: 2.9223 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9777 - cost: 2.8789 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7956\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9940 - accuracy: 0.9778 - cost: 2.8603 - val_loss: 0.1115 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.8867\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9006 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.9811\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9266 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6458\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9777 - cost: 2.8697 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.4701\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9396 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4440\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9776 - cost: 2.8825 - val_loss: 0.1133 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9062 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.3561\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9941 - accuracy: 0.9780 - cost: 2.8314 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.3594\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8895 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6882\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9000 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.3691\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9783 - cost: 2.7925 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.7891\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9941 - accuracy: 0.9779 - cost: 2.8404 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9307 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.5189\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8489 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.4668\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9785 - cost: 2.7704 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.5091\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8827 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4408\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9942 - accuracy: 0.9783 - cost: 2.7948 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8346\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7836 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.4733\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9779 - cost: 2.8482 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.4863\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8492 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9942 - accuracy: 0.9784 - cost: 2.7981 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.4505\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8948 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3691\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8082 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9698 - val_cost: 3.5514\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9941 - accuracy: 0.9786 - cost: 2.7584 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8021\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8560 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8412 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9784 - cost: 2.7883 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.4766\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9782 - cost: 2.7922 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7565\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.7872 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.4928\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8344 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7370\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9786 - cost: 2.7504 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7793\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0978 - auc: 0.9919 - accuracy: 0.9729 - cost: 3.4406\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:33.388056\n",
            "fold accuracy: 0.9729375243186951 - fold cost: 3.440624952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5445 - auc: 0.7817 - accuracy: 0.7161 - cost: 37.5719 - val_loss: 0.4099 - val_auc: 0.8933 - val_accuracy: 0.8222 - val_cost: 22.5749\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3664 - auc: 0.9145 - accuracy: 0.8422 - cost: 20.0714 - val_loss: 0.3243 - val_auc: 0.9334 - val_accuracy: 0.8618 - val_cost: 16.5951\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3140 - auc: 0.9376 - accuracy: 0.8702 - cost: 16.3767 - val_loss: 0.2948 - val_auc: 0.9452 - val_accuracy: 0.8778 - val_cost: 14.6289\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2861 - auc: 0.9485 - accuracy: 0.8831 - cost: 14.7534 - val_loss: 0.2721 - val_auc: 0.9532 - val_accuracy: 0.8905 - val_cost: 13.1608\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2640 - auc: 0.9562 - accuracy: 0.8939 - cost: 13.3815 - val_loss: 0.2521 - val_auc: 0.9600 - val_accuracy: 0.9013 - val_cost: 12.0345\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2467 - auc: 0.9617 - accuracy: 0.9037 - cost: 12.1611 - val_loss: 0.2355 - val_auc: 0.9651 - val_accuracy: 0.9083 - val_cost: 11.2142\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2304 - auc: 0.9666 - accuracy: 0.9106 - cost: 11.3000 - val_loss: 0.2249 - val_auc: 0.9682 - val_accuracy: 0.9151 - val_cost: 10.2344\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2181 - auc: 0.9700 - accuracy: 0.9164 - cost: 10.5916 - val_loss: 0.2122 - val_auc: 0.9715 - val_accuracy: 0.9205 - val_cost: 9.8568\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2062 - auc: 0.9731 - accuracy: 0.9226 - cost: 9.7807 - val_loss: 0.2019 - val_auc: 0.9742 - val_accuracy: 0.9259 - val_cost: 8.9030\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1960 - auc: 0.9755 - accuracy: 0.9267 - cost: 9.2955 - val_loss: 0.1923 - val_auc: 0.9762 - val_accuracy: 0.9305 - val_cost: 8.5970\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1883 - auc: 0.9773 - accuracy: 0.9302 - cost: 8.8368 - val_loss: 0.1842 - val_auc: 0.9780 - val_accuracy: 0.9331 - val_cost: 8.3529\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1815 - auc: 0.9789 - accuracy: 0.9337 - cost: 8.4205 - val_loss: 0.1786 - val_auc: 0.9794 - val_accuracy: 0.9363 - val_cost: 7.8613\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1745 - auc: 0.9803 - accuracy: 0.9369 - cost: 7.9949 - val_loss: 0.1730 - val_auc: 0.9805 - val_accuracy: 0.9399 - val_cost: 7.6139\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1693 - auc: 0.9813 - accuracy: 0.9394 - cost: 7.6940 - val_loss: 0.1688 - val_auc: 0.9813 - val_accuracy: 0.9399 - val_cost: 7.3633\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1629 - auc: 0.9825 - accuracy: 0.9418 - cost: 7.3882 - val_loss: 0.1629 - val_auc: 0.9824 - val_accuracy: 0.9430 - val_cost: 7.1810\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1590 - auc: 0.9834 - accuracy: 0.9442 - cost: 7.0818 - val_loss: 0.1605 - val_auc: 0.9829 - val_accuracy: 0.9444 - val_cost: 7.0866\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1551 - auc: 0.9840 - accuracy: 0.9449 - cost: 6.9803 - val_loss: 0.1565 - val_auc: 0.9838 - val_accuracy: 0.9453 - val_cost: 6.9434\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1523 - auc: 0.9846 - accuracy: 0.9468 - cost: 6.7631 - val_loss: 0.1537 - val_auc: 0.9843 - val_accuracy: 0.9471 - val_cost: 6.9336\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1487 - auc: 0.9851 - accuracy: 0.9485 - cost: 6.5507 - val_loss: 0.1511 - val_auc: 0.9847 - val_accuracy: 0.9469 - val_cost: 6.7806\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1464 - auc: 0.9856 - accuracy: 0.9498 - cost: 6.3831 - val_loss: 0.1512 - val_auc: 0.9847 - val_accuracy: 0.9488 - val_cost: 6.4714\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1435 - auc: 0.9860 - accuracy: 0.9518 - cost: 6.1352 - val_loss: 0.1467 - val_auc: 0.9855 - val_accuracy: 0.9506 - val_cost: 6.4128\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1403 - auc: 0.9867 - accuracy: 0.9520 - cost: 6.0851 - val_loss: 0.1460 - val_auc: 0.9857 - val_accuracy: 0.9513 - val_cost: 6.3542\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9868 - accuracy: 0.9533 - cost: 5.9293 - val_loss: 0.1416 - val_auc: 0.9863 - val_accuracy: 0.9529 - val_cost: 5.9928\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1353 - auc: 0.9873 - accuracy: 0.9545 - cost: 5.7860 - val_loss: 0.1407 - val_auc: 0.9864 - val_accuracy: 0.9533 - val_cost: 6.0547\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9876 - accuracy: 0.9557 - cost: 5.6166 - val_loss: 0.1397 - val_auc: 0.9866 - val_accuracy: 0.9528 - val_cost: 6.0742\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1321 - auc: 0.9878 - accuracy: 0.9558 - cost: 5.6268 - val_loss: 0.1375 - val_auc: 0.9868 - val_accuracy: 0.9543 - val_cost: 5.9635\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1296 - auc: 0.9883 - accuracy: 0.9566 - cost: 5.5089 - val_loss: 0.1358 - val_auc: 0.9870 - val_accuracy: 0.9558 - val_cost: 5.6478\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1278 - auc: 0.9885 - accuracy: 0.9579 - cost: 5.3546 - val_loss: 0.1353 - val_auc: 0.9872 - val_accuracy: 0.9563 - val_cost: 5.7292\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1272 - auc: 0.9885 - accuracy: 0.9581 - cost: 5.3163 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9580 - val_cost: 5.6055\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9890 - accuracy: 0.9592 - cost: 5.1953 - val_loss: 0.1336 - val_auc: 0.9872 - val_accuracy: 0.9574 - val_cost: 5.6901\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9892 - accuracy: 0.9598 - cost: 5.0976 - val_loss: 0.1304 - val_auc: 0.9877 - val_accuracy: 0.9578 - val_cost: 5.4004\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1216 - auc: 0.9893 - accuracy: 0.9603 - cost: 5.0514 - val_loss: 0.1303 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.0651\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1191 - auc: 0.9895 - accuracy: 0.9615 - cost: 4.8987 - val_loss: 0.1279 - val_auc: 0.9878 - val_accuracy: 0.9601 - val_cost: 5.1465\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9624 - cost: 4.7962 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.0814\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9625 - cost: 4.7796 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9603 - val_cost: 5.2474\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1155 - auc: 0.9901 - accuracy: 0.9631 - cost: 4.7020 - val_loss: 0.1250 - val_auc: 0.9882 - val_accuracy: 0.9615 - val_cost: 4.8275\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9635 - cost: 4.6299 - val_loss: 0.1243 - val_auc: 0.9883 - val_accuracy: 0.9622 - val_cost: 4.7884\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1128 - auc: 0.9904 - accuracy: 0.9643 - cost: 4.5415 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.8796\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9906 - accuracy: 0.9644 - cost: 4.5317 - val_loss: 0.1226 - val_auc: 0.9885 - val_accuracy: 0.9622 - val_cost: 4.7559\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9649 - cost: 4.4740 - val_loss: 0.1234 - val_auc: 0.9882 - val_accuracy: 0.9625 - val_cost: 4.7168\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1100 - auc: 0.9907 - accuracy: 0.9657 - cost: 4.3742 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9635 - val_cost: 4.6842\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9905 - accuracy: 0.9655 - cost: 4.4050 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.2611\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9910 - accuracy: 0.9666 - cost: 4.2453 - val_loss: 0.1209 - val_auc: 0.9885 - val_accuracy: 0.9639 - val_cost: 4.3685\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9911 - accuracy: 0.9660 - cost: 4.3322 - val_loss: 0.1188 - val_auc: 0.9888 - val_accuracy: 0.9646 - val_cost: 4.3848\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9666 - cost: 4.2515 - val_loss: 0.1198 - val_auc: 0.9889 - val_accuracy: 0.9644 - val_cost: 4.4564\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9672 - cost: 4.1730 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9633 - val_cost: 4.5898\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9915 - accuracy: 0.9676 - cost: 4.1325 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.2025\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1043 - auc: 0.9914 - accuracy: 0.9677 - cost: 4.1236 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9651 - val_cost: 4.1927\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0737 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.4792\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9681 - cost: 4.0748 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.1569\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1021 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9664 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9657 - val_cost: 4.1699\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9424 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9656 - val_cost: 4.2025\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1020 - auc: 0.9917 - accuracy: 0.9693 - cost: 3.9301 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9661 - val_cost: 4.2188\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9694 - cost: 3.9055 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9656 - val_cost: 4.3164\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9698 - cost: 3.8601 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.0853\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0993 - auc: 0.9921 - accuracy: 0.9701 - cost: 3.8148 - val_loss: 0.1145 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.0723\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9700 - cost: 3.8394 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.0560\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9920 - accuracy: 0.9702 - cost: 3.7992 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9672 - val_cost: 4.0658\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7822 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.0104\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0971 - auc: 0.9922 - accuracy: 0.9710 - cost: 3.7063 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9662 - val_cost: 4.2122\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9921 - accuracy: 0.9706 - cost: 3.7816 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9665 - val_cost: 4.0853\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0962 - auc: 0.9923 - accuracy: 0.9712 - cost: 3.6745 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9680 - val_cost: 3.9290\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0970 - auc: 0.9922 - accuracy: 0.9711 - cost: 3.7056 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9665 - val_cost: 4.0560\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9924 - accuracy: 0.9716 - cost: 3.6393 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0885\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.6174 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 3.9583\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0945 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6594 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.0039\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0940 - auc: 0.9925 - accuracy: 0.9721 - cost: 3.5700 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.2513\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9925 - accuracy: 0.9720 - cost: 3.5859 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 3.9844\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9724 - cost: 3.5483 - val_loss: 0.1145 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.0137\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5483 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.0137\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4908 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9679 - val_cost: 3.9323\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9725 - cost: 3.5189 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.1146\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4341 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0267\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4845 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.8477\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9729 - cost: 3.4740 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.1243\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9929 - accuracy: 0.9730 - cost: 3.4587 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9670 - val_cost: 4.1667\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9930 - accuracy: 0.9736 - cost: 3.3826 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0495\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9931 - accuracy: 0.9731 - cost: 3.4527 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.7826\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0908 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4566 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7240\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9929 - accuracy: 0.9730 - cost: 3.4512 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7858\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9929 - accuracy: 0.9734 - cost: 3.4133 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.8053\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9930 - accuracy: 0.9733 - cost: 3.4145 - val_loss: 0.1092 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.7240\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9733 - cost: 3.4274 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.6198\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9930 - accuracy: 0.9741 - cost: 3.3101 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.4668\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3743 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0169\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3750 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9095\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9932 - accuracy: 0.9745 - cost: 3.2787 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7402\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2649 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0880 - auc: 0.9931 - accuracy: 0.9743 - cost: 3.3091 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0879 - auc: 0.9931 - accuracy: 0.9741 - cost: 3.3217 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8704\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3315 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.6882\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2291 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.7793\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0858 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.1921 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.6686\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9932 - accuracy: 0.9749 - cost: 3.2281 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7012\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9746 - cost: 3.2620 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.6426\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2568 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7826\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2048 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.9258\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1688 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7435\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9934 - accuracy: 0.9753 - cost: 3.2001 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.8151\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9934 - accuracy: 0.9749 - cost: 3.2159 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.5254\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9937 - accuracy: 0.9751 - cost: 3.2087 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.6361\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.2150 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.5645\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1831 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8151\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1797 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.5905\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1379 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3984\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1135 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.4928\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1916 - val_loss: 0.1070 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.5677\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9758 - cost: 3.1088 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0983 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.2975\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1628 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.4310\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1405 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5156\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.1209 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1344 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0336 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5449\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0695 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.4115\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0695 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.6914\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0965 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.5156\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0856 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0798 - val_loss: 0.1079 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4733\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.1180 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3919\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9761 - cost: 3.0839 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.3594\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9903 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.4147\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9767 - cost: 3.0026 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0591 - val_loss: 0.1090 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.1167 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.5840\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9766 - cost: 3.0139 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9921 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5319\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0266 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.4147\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0514 - val_loss: 0.1084 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.4961\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0922 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9695 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.2780\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9902 - val_loss: 0.1081 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9767 - cost: 3.0029 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.4831\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0803 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9888 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9815 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.5254\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9551 - val_loss: 0.1100 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0807 - auc: 0.9937 - accuracy: 0.9763 - cost: 3.0461 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.5742\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9859 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3691\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9720 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9405 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9642 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4277\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9114 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5189\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9728 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.2422\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8993 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.4701\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9581 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.2878\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9237 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9227 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.4277\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9451 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.4245\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9297 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.3594\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8685 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.8936 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5742\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8959 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.4440\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8671 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.3431\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9381 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4831\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9191 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7012\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8597 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8989 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4993\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9941 - accuracy: 0.9778 - cost: 2.8650 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.5612\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.9029 - val_loss: 0.1102 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.6068\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.9079 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.3724\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9775 - cost: 2.9010 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5286\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8950 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6556\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.9119 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.3366\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8290 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.3887\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8325 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7109\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8400 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5352\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9591 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.3529\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8419 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.4245\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9258 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.2357\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8168 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4473\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8885 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8552 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.3529\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8189 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.3789\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8727 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8213 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.3854\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8400 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.3398\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9205 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.4701\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8531 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7853 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.3724\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9942 - accuracy: 0.9782 - cost: 2.8178 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.3854\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7848 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.2975\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8665 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4993\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8313 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.2747\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9787 - cost: 2.7691 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4961\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7977 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.3626\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8088 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7844 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7774 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5970\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7377 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6556\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8221 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8747 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.3659\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8069 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4538\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7900 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8618 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.7533\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7871 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.4896\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7743 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.2487\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7870 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4961\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7899 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.3268\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7437 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5710\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8124 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8040 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5645\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7631 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.3301\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7134 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6491\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7986 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4245\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.7006 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9945 - accuracy: 0.9790 - cost: 2.7118 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7940 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.3789\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.8106 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.7826\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.8100 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.3464\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7321 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.6979\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7440 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.3040\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7307 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.6589\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7668 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.5872\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9789 - cost: 2.7237 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.4408\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7938 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4049\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7542 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6751\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7728 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7435 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.2487\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.8069 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.2096\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7357 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5677\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8217 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4505\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.7054 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.3919\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7644 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.6165\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7629 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9725 - val_cost: 3.4798\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.7042 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.3887\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7094 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.4961\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6489 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.7077\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.5547\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7133 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6751 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9727 - val_cost: 3.5254\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7103 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4017\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6362 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.6328\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6827 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4701\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6638 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.3561\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.3724\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6697 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7229 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.3626\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6951 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.6458\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6992 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4180\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7241 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6719\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9946 - accuracy: 0.9792 - cost: 2.6905 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.2878\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7106 - val_loss: 0.1161 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6523\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6600 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6875 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6436 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.3561\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6614 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9735 - val_cost: 3.2812\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6944 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6910 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.2520\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9802 - cost: 2.5651 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5872\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6408 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9947 - accuracy: 0.9795 - cost: 2.6568 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.3952\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6722 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.3464\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7377 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.7240\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6653 - val_loss: 0.1148 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.4733\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6389 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5872\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6355 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6509 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5319\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6413 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.3561\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.7011 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6801 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3984\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6556 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4570\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6998 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.4961\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6308 - val_loss: 0.1174 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.5905\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6754 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6427 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.4375\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6336 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.5970\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6718 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4570\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6071 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9725 - val_cost: 3.5742\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6046 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.5905\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1096 - auc: 0.9907 - accuracy: 0.9708 - cost: 3.6875\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.211919\n",
            "fold accuracy: 0.9708124995231628 - fold cost: 3.6875\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5458 - auc: 0.7802 - accuracy: 0.7158 - cost: 37.6375 - val_loss: 0.4082 - val_auc: 0.8940 - val_accuracy: 0.8201 - val_cost: 23.7012\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3657 - auc: 0.9148 - accuracy: 0.8415 - cost: 20.1920 - val_loss: 0.3210 - val_auc: 0.9346 - val_accuracy: 0.8619 - val_cost: 16.8880\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3142 - auc: 0.9377 - accuracy: 0.8707 - cost: 16.3326 - val_loss: 0.2927 - val_auc: 0.9460 - val_accuracy: 0.8781 - val_cost: 14.9316\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2871 - auc: 0.9481 - accuracy: 0.8832 - cost: 14.7582 - val_loss: 0.2708 - val_auc: 0.9539 - val_accuracy: 0.8901 - val_cost: 13.4049\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9557 - accuracy: 0.8934 - cost: 13.4843 - val_loss: 0.2530 - val_auc: 0.9595 - val_accuracy: 0.9012 - val_cost: 12.0638\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9617 - accuracy: 0.9027 - cost: 12.2923 - val_loss: 0.2373 - val_auc: 0.9646 - val_accuracy: 0.9088 - val_cost: 11.1686\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2311 - auc: 0.9664 - accuracy: 0.9104 - cost: 11.3029 - val_loss: 0.2233 - val_auc: 0.9686 - val_accuracy: 0.9151 - val_cost: 10.4297\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2170 - auc: 0.9702 - accuracy: 0.9165 - cost: 10.5548 - val_loss: 0.2113 - val_auc: 0.9718 - val_accuracy: 0.9213 - val_cost: 9.8763\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2050 - auc: 0.9733 - accuracy: 0.9224 - cost: 9.8117 - val_loss: 0.2006 - val_auc: 0.9746 - val_accuracy: 0.9276 - val_cost: 8.7630\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1949 - auc: 0.9758 - accuracy: 0.9271 - cost: 9.2664 - val_loss: 0.1925 - val_auc: 0.9763 - val_accuracy: 0.9300 - val_cost: 8.4277\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9775 - accuracy: 0.9304 - cost: 8.8296 - val_loss: 0.1858 - val_auc: 0.9776 - val_accuracy: 0.9335 - val_cost: 7.9557\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1798 - auc: 0.9792 - accuracy: 0.9334 - cost: 8.4467 - val_loss: 0.1796 - val_auc: 0.9792 - val_accuracy: 0.9351 - val_cost: 8.2585\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1731 - auc: 0.9805 - accuracy: 0.9372 - cost: 7.9694 - val_loss: 0.1757 - val_auc: 0.9798 - val_accuracy: 0.9379 - val_cost: 7.7604\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1672 - auc: 0.9817 - accuracy: 0.9398 - cost: 7.6289 - val_loss: 0.1699 - val_auc: 0.9811 - val_accuracy: 0.9419 - val_cost: 6.9499\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1624 - auc: 0.9827 - accuracy: 0.9415 - cost: 7.4403 - val_loss: 0.1671 - val_auc: 0.9814 - val_accuracy: 0.9422 - val_cost: 6.9661\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9443 - cost: 7.0919 - val_loss: 0.1634 - val_auc: 0.9822 - val_accuracy: 0.9434 - val_cost: 6.8815\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1543 - auc: 0.9842 - accuracy: 0.9463 - cost: 6.8306 - val_loss: 0.1600 - val_auc: 0.9831 - val_accuracy: 0.9453 - val_cost: 6.5723\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1502 - auc: 0.9849 - accuracy: 0.9479 - cost: 6.6206 - val_loss: 0.1566 - val_auc: 0.9835 - val_accuracy: 0.9473 - val_cost: 6.5299\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1470 - auc: 0.9855 - accuracy: 0.9486 - cost: 6.5353 - val_loss: 0.1540 - val_auc: 0.9840 - val_accuracy: 0.9474 - val_cost: 6.4290\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9860 - accuracy: 0.9506 - cost: 6.2547 - val_loss: 0.1516 - val_auc: 0.9843 - val_accuracy: 0.9492 - val_cost: 6.3737\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9522 - cost: 6.0801 - val_loss: 0.1506 - val_auc: 0.9843 - val_accuracy: 0.9493 - val_cost: 6.3477\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1393 - auc: 0.9867 - accuracy: 0.9526 - cost: 6.0282 - val_loss: 0.1471 - val_auc: 0.9851 - val_accuracy: 0.9504 - val_cost: 5.9408\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1355 - auc: 0.9875 - accuracy: 0.9539 - cost: 5.8666 - val_loss: 0.1455 - val_auc: 0.9855 - val_accuracy: 0.9517 - val_cost: 5.7096\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9878 - accuracy: 0.9553 - cost: 5.6819 - val_loss: 0.1428 - val_auc: 0.9858 - val_accuracy: 0.9522 - val_cost: 5.8659\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1321 - auc: 0.9878 - accuracy: 0.9554 - cost: 5.6668 - val_loss: 0.1409 - val_auc: 0.9861 - val_accuracy: 0.9544 - val_cost: 5.4883\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9568 - cost: 5.4991 - val_loss: 0.1400 - val_auc: 0.9862 - val_accuracy: 0.9548 - val_cost: 5.5208\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1273 - auc: 0.9886 - accuracy: 0.9583 - cost: 5.3001 - val_loss: 0.1393 - val_auc: 0.9862 - val_accuracy: 0.9551 - val_cost: 5.6641\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1260 - auc: 0.9887 - accuracy: 0.9579 - cost: 5.3379 - val_loss: 0.1357 - val_auc: 0.9868 - val_accuracy: 0.9566 - val_cost: 5.2604\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1238 - auc: 0.9890 - accuracy: 0.9588 - cost: 5.2341 - val_loss: 0.1354 - val_auc: 0.9867 - val_accuracy: 0.9558 - val_cost: 5.3353\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1215 - auc: 0.9894 - accuracy: 0.9604 - cost: 5.0328 - val_loss: 0.1331 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.1888\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9608 - cost: 4.9855 - val_loss: 0.1321 - val_auc: 0.9872 - val_accuracy: 0.9576 - val_cost: 5.0716\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9617 - cost: 4.8759 - val_loss: 0.1312 - val_auc: 0.9871 - val_accuracy: 0.9588 - val_cost: 5.0879\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1183 - auc: 0.9898 - accuracy: 0.9622 - cost: 4.8239 - val_loss: 0.1294 - val_auc: 0.9876 - val_accuracy: 0.9600 - val_cost: 4.8698\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9901 - accuracy: 0.9623 - cost: 4.7855 - val_loss: 0.1291 - val_auc: 0.9874 - val_accuracy: 0.9599 - val_cost: 4.8600\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9904 - accuracy: 0.9628 - cost: 4.7371 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9596 - val_cost: 4.8079\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1134 - auc: 0.9904 - accuracy: 0.9638 - cost: 4.6149 - val_loss: 0.1269 - val_auc: 0.9880 - val_accuracy: 0.9599 - val_cost: 4.7624\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1120 - auc: 0.9906 - accuracy: 0.9639 - cost: 4.5956 - val_loss: 0.1261 - val_auc: 0.9881 - val_accuracy: 0.9606 - val_cost: 4.7363\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9653 - cost: 4.4147 - val_loss: 0.1243 - val_auc: 0.9882 - val_accuracy: 0.9611 - val_cost: 4.7038\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1097 - auc: 0.9908 - accuracy: 0.9655 - cost: 4.4009 - val_loss: 0.1236 - val_auc: 0.9882 - val_accuracy: 0.9621 - val_cost: 4.7624\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9656 - cost: 4.3858 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9630 - val_cost: 4.5508\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9672 - cost: 4.1761 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.4694\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9911 - accuracy: 0.9664 - cost: 4.2721 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.4336\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1059 - auc: 0.9914 - accuracy: 0.9667 - cost: 4.2276 - val_loss: 0.1218 - val_auc: 0.9885 - val_accuracy: 0.9633 - val_cost: 4.4173\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9674 - cost: 4.1492 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9634 - val_cost: 4.4466\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9672 - cost: 4.1973 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9653 - val_cost: 4.2741\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9689 - cost: 3.9606 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.6484\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9916 - accuracy: 0.9685 - cost: 4.0111 - val_loss: 0.1217 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.2969\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9684 - cost: 4.0418 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.5410\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1004 - auc: 0.9919 - accuracy: 0.9691 - cost: 3.9423 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9651 - val_cost: 4.4401\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9693 - cost: 3.9136 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9647 - val_cost: 4.2611\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9919 - accuracy: 0.9692 - cost: 3.9139 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9652 - val_cost: 4.3783\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8135 - val_loss: 0.1181 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.2839\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9921 - accuracy: 0.9699 - cost: 3.8271 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.1634\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8196 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.3066\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9922 - accuracy: 0.9705 - cost: 3.7738 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.2057\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7118 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.1602\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9706 - cost: 3.7454 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1211\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9923 - accuracy: 0.9706 - cost: 3.7588 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 4.0462\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7390 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.3359\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0957 - auc: 0.9923 - accuracy: 0.9716 - cost: 3.6418 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.2448\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.6153 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 4.4434\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0954 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6487 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.2969\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9716 - cost: 3.6397 - val_loss: 0.1161 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 3.9258\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0935 - auc: 0.9926 - accuracy: 0.9722 - cost: 3.5508 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 4.1309\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9926 - accuracy: 0.9723 - cost: 3.5505 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.2057\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9718 - cost: 3.6001 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0332\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9721 - cost: 3.5750 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.2025\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9927 - accuracy: 0.9729 - cost: 3.4738 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.2676\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0909 - auc: 0.9928 - accuracy: 0.9726 - cost: 3.5125 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 4.0885\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9728 - cost: 3.4980 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0690\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4207 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9518\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9927 - accuracy: 0.9728 - cost: 3.4760 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9682 - val_cost: 4.0560\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9929 - accuracy: 0.9733 - cost: 3.4221 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.2057\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9736 - cost: 3.3902 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.3392\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4487 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0462\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9739 - cost: 3.3328 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.1536\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9730 - cost: 3.4427 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9680 - val_cost: 4.1341\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3676 - val_loss: 0.1130 - val_auc: 0.9891 - val_accuracy: 0.9684 - val_cost: 3.9974\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9742 - cost: 3.2954 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9673 - val_cost: 4.1276\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2766 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.9811\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2823 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.0560\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3192 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0592\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2406 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9686 - val_cost: 3.9811\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9932 - accuracy: 0.9745 - cost: 3.2713 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.2018 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1341\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2308 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 4.0072\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9743 - cost: 3.2865 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2402 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0788\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9934 - accuracy: 0.9758 - cost: 3.1062 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2234 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9749 - cost: 3.2167 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 3.9648\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9751 - cost: 3.1978 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.9388\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2095 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.9290\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9936 - accuracy: 0.9748 - cost: 3.2388 - val_loss: 0.1138 - val_auc: 0.9890 - val_accuracy: 0.9691 - val_cost: 3.9648\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1457 - val_loss: 0.1151 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 4.0885\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1361 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9755 - cost: 3.1443 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.7891\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9750 - cost: 3.2021 - val_loss: 0.1150 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.9714\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1267 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 4.0462\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1182 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9691 - val_cost: 3.7695\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0551 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9518\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1444 - val_loss: 0.1167 - val_auc: 0.9890 - val_accuracy: 0.9687 - val_cost: 4.0039\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0904 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6263\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1400 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.6882\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0824 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.1048 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8053\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0774 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8477\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0847 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1109 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6393\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9754 - cost: 3.1599 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6719\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0910 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0218 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.8542\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9871 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9938 - accuracy: 0.9765 - cost: 3.0171 - val_loss: 0.1129 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0249 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.9648\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0784 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9767 - cost: 2.9911 - val_loss: 0.1135 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9746\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0250 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.9779\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9820 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9937 - accuracy: 0.9765 - cost: 3.0189 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0166 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0582 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9682 - val_cost: 4.0234\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9768 - cost: 2.9754 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8900\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9091 - val_loss: 0.1164 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.9225\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9636 - val_loss: 0.1144 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.9746\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9580 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.9355\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9877 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.8672\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9945 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6263\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9399 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9189 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8281\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9974 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9687 - val_cost: 3.7337\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9829 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7370\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9348 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9322 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8805 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.6296\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9585 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.6230\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8868 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.9876\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9343 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9435 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0658\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8985 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9746\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9650 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8802\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9200 - val_loss: 0.1171 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8613 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9691 - val_cost: 3.8216\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9115 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6784\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8388 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.7858\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8868 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.7337\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9164 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6719\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9779 - cost: 2.8287 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0983\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.7922 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 4.0397\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8824 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9693 - val_cost: 3.7207\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9778 - cost: 2.8543 - val_loss: 0.1169 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6068\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8246 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7923\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9203 - val_loss: 0.1160 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.9030\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8580 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 4.0332\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8890 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.6882\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8310 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.7272\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8129 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8525 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8245 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9241 - val_loss: 0.1151 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.9941\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8359 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.8281\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7870 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8657 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7630\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8765 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6458\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7920 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9030\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8346 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6426\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8520 - val_loss: 0.1157 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8020 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9689 - val_cost: 3.8900\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8214 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9702 - val_cost: 4.0462\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8178 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7543 - val_loss: 0.1152 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.9225\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8395 - val_loss: 0.1161 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.8802\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7866 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8490 - val_loss: 0.1179 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7493 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6784\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7673 - val_loss: 0.1173 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7922 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.6426\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7215 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.5872\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7419 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8574\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7598 - val_loss: 0.1165 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7367 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.7207\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9783 - cost: 2.7914 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7044\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6592 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7442 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7912 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7034 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7305\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7815 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.5775\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7529 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6230\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7311 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7305\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8120 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.7695\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6918 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7616 - val_loss: 0.1173 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.7891\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6882 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.4961\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7981 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.7500\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7228 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7404 - val_loss: 0.1182 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7053 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6976 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.5742\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7241 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6556\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7232 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7305\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6684 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7188 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7600 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.8086\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7699 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7826\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7593 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.7826\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6957 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8932\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7283 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6760 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7511 - val_loss: 0.1206 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7793\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7613 - val_loss: 0.1194 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.8379\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6550 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6994 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7072 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9709 - val_cost: 3.5026\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6254 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7711 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6762 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9712 - val_cost: 3.6458\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7337 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.6491\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7296 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7320 - val_loss: 0.1222 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.4896\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6449 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7293 - val_loss: 0.1213 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6523\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0728 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6654 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7207\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.7018 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6816\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6992 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9713 - val_cost: 3.7174\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6499 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8118\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6309 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8086\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6907 - val_loss: 0.1201 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.8932\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6140 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6705 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.5319\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.5824 - val_loss: 0.1199 - val_auc: 0.9887 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6614 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6932 - val_loss: 0.1218 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5725 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6758 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6220 - val_loss: 0.1198 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8151\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6276 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9725 - val_cost: 3.5124\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6724 - val_loss: 0.1214 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6655 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5855 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7565\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0715 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6137 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6770 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.7533\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.6046 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6255 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.6393\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7140 - val_loss: 0.1214 - val_auc: 0.9884 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6230 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.4212\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6238 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6695 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9722 - val_cost: 3.5742\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6263 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.7402\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6581 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5997 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6308 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5454 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5911 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.8216\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5598 - val_loss: 0.1210 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.6751\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.6044 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7923\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6419 - val_loss: 0.1212 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5926 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6211 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6874 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6196 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.5384\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6060 - val_loss: 0.1188 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6914\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6350 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.8411\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5720 - val_loss: 0.1189 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.6032 - val_loss: 0.1211 - val_auc: 0.9887 - val_accuracy: 0.9715 - val_cost: 3.6263\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6054 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.4831\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5794 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9719 - val_cost: 3.6751\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5382 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6035\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5998 - val_loss: 0.1221 - val_auc: 0.9885 - val_accuracy: 0.9713 - val_cost: 3.7142\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5541 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.5677\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5474 - val_loss: 0.1190 - val_auc: 0.9889 - val_accuracy: 0.9721 - val_cost: 3.6296\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6127 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5268 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6074 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9713 - val_cost: 3.6849\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5828 - val_loss: 0.1202 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.9811\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.6035 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.5612\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5799 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9803 - cost: 2.5600 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.6719\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5889 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6012 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.5482\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9802 - cost: 2.5637 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.7077\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5536 - val_loss: 0.1210 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.6523\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5341 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.5742\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5776 - val_loss: 0.1206 - val_auc: 0.9888 - val_accuracy: 0.9720 - val_cost: 3.6068\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5978 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5681 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5753 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.8314\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5976 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5217 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.5016 - val_loss: 0.1215 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5381 - val_loss: 0.1218 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.8346\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5729 - val_loss: 0.1186 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.7467\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6168 - val_loss: 0.1238 - val_auc: 0.9884 - val_accuracy: 0.9704 - val_cost: 3.7467\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1037 - auc: 0.9909 - accuracy: 0.9728 - cost: 3.4000\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:50.984269\n",
            "fold accuracy: 0.9727500081062317 - fold cost: 3.4000000953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5455 - auc: 0.7810 - accuracy: 0.7158 - cost: 37.6462 - val_loss: 0.4066 - val_auc: 0.8963 - val_accuracy: 0.8217 - val_cost: 23.4701\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3653 - auc: 0.9151 - accuracy: 0.8432 - cost: 19.9915 - val_loss: 0.3224 - val_auc: 0.9340 - val_accuracy: 0.8621 - val_cost: 17.0638\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3132 - auc: 0.9380 - accuracy: 0.8701 - cost: 16.4269 - val_loss: 0.2957 - val_auc: 0.9446 - val_accuracy: 0.8765 - val_cost: 15.3353\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2860 - auc: 0.9484 - accuracy: 0.8836 - cost: 14.6830 - val_loss: 0.2708 - val_auc: 0.9538 - val_accuracy: 0.8903 - val_cost: 13.4115\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2647 - auc: 0.9558 - accuracy: 0.8941 - cost: 13.3587 - val_loss: 0.2522 - val_auc: 0.9600 - val_accuracy: 0.8994 - val_cost: 12.2363\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2463 - auc: 0.9618 - accuracy: 0.9033 - cost: 12.2278 - val_loss: 0.2370 - val_auc: 0.9645 - val_accuracy: 0.9087 - val_cost: 11.2663\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2312 - auc: 0.9662 - accuracy: 0.9105 - cost: 11.3140 - val_loss: 0.2231 - val_auc: 0.9686 - val_accuracy: 0.9152 - val_cost: 10.3613\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2180 - auc: 0.9699 - accuracy: 0.9164 - cost: 10.5685 - val_loss: 0.2116 - val_auc: 0.9718 - val_accuracy: 0.9210 - val_cost: 9.6875\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2059 - auc: 0.9732 - accuracy: 0.9217 - cost: 9.8939 - val_loss: 0.2007 - val_auc: 0.9745 - val_accuracy: 0.9250 - val_cost: 9.3359\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1963 - auc: 0.9754 - accuracy: 0.9266 - cost: 9.2954 - val_loss: 0.1916 - val_auc: 0.9764 - val_accuracy: 0.9300 - val_cost: 8.9486\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1868 - auc: 0.9776 - accuracy: 0.9308 - cost: 8.7698 - val_loss: 0.1847 - val_auc: 0.9780 - val_accuracy: 0.9345 - val_cost: 8.1022\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1801 - auc: 0.9791 - accuracy: 0.9342 - cost: 8.3383 - val_loss: 0.1780 - val_auc: 0.9794 - val_accuracy: 0.9383 - val_cost: 7.8516\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1736 - auc: 0.9805 - accuracy: 0.9374 - cost: 7.9541 - val_loss: 0.1724 - val_auc: 0.9807 - val_accuracy: 0.9401 - val_cost: 7.5228\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1674 - auc: 0.9817 - accuracy: 0.9400 - cost: 7.5942 - val_loss: 0.1669 - val_auc: 0.9816 - val_accuracy: 0.9436 - val_cost: 7.1387\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1635 - auc: 0.9824 - accuracy: 0.9416 - cost: 7.4254 - val_loss: 0.1628 - val_auc: 0.9826 - val_accuracy: 0.9433 - val_cost: 7.2461\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1601 - auc: 0.9830 - accuracy: 0.9436 - cost: 7.1713 - val_loss: 0.1592 - val_auc: 0.9832 - val_accuracy: 0.9451 - val_cost: 6.7806\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1539 - auc: 0.9842 - accuracy: 0.9455 - cost: 6.9268 - val_loss: 0.1564 - val_auc: 0.9835 - val_accuracy: 0.9465 - val_cost: 6.6895\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1524 - auc: 0.9845 - accuracy: 0.9465 - cost: 6.8136 - val_loss: 0.1556 - val_auc: 0.9837 - val_accuracy: 0.9462 - val_cost: 6.6471\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1483 - auc: 0.9852 - accuracy: 0.9491 - cost: 6.4757 - val_loss: 0.1516 - val_auc: 0.9844 - val_accuracy: 0.9488 - val_cost: 6.3965\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1452 - auc: 0.9857 - accuracy: 0.9503 - cost: 6.3186 - val_loss: 0.1489 - val_auc: 0.9848 - val_accuracy: 0.9487 - val_cost: 6.6439\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1424 - auc: 0.9862 - accuracy: 0.9512 - cost: 6.2118 - val_loss: 0.1467 - val_auc: 0.9851 - val_accuracy: 0.9510 - val_cost: 6.3607\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1402 - auc: 0.9865 - accuracy: 0.9521 - cost: 6.0944 - val_loss: 0.1452 - val_auc: 0.9854 - val_accuracy: 0.9508 - val_cost: 6.4811\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1373 - auc: 0.9870 - accuracy: 0.9536 - cost: 5.8835 - val_loss: 0.1431 - val_auc: 0.9858 - val_accuracy: 0.9528 - val_cost: 6.0840\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9536 - cost: 5.9118 - val_loss: 0.1432 - val_auc: 0.9858 - val_accuracy: 0.9542 - val_cost: 5.6185\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1328 - auc: 0.9878 - accuracy: 0.9552 - cost: 5.7046 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9544 - val_cost: 5.8040\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1315 - auc: 0.9879 - accuracy: 0.9554 - cost: 5.6825 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9544 - val_cost: 5.6608\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9884 - accuracy: 0.9572 - cost: 5.4332 - val_loss: 0.1380 - val_auc: 0.9865 - val_accuracy: 0.9549 - val_cost: 5.7878\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1278 - auc: 0.9884 - accuracy: 0.9579 - cost: 5.3557 - val_loss: 0.1376 - val_auc: 0.9865 - val_accuracy: 0.9558 - val_cost: 5.7715\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1265 - auc: 0.9886 - accuracy: 0.9582 - cost: 5.3153 - val_loss: 0.1365 - val_auc: 0.9866 - val_accuracy: 0.9569 - val_cost: 5.4818\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1237 - auc: 0.9890 - accuracy: 0.9590 - cost: 5.2108 - val_loss: 0.1346 - val_auc: 0.9869 - val_accuracy: 0.9572 - val_cost: 5.4134\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9599 - cost: 5.1146 - val_loss: 0.1327 - val_auc: 0.9872 - val_accuracy: 0.9586 - val_cost: 5.1790\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1213 - auc: 0.9893 - accuracy: 0.9605 - cost: 5.0214 - val_loss: 0.1291 - val_auc: 0.9876 - val_accuracy: 0.9593 - val_cost: 5.1921\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1201 - auc: 0.9895 - accuracy: 0.9615 - cost: 4.9090 - val_loss: 0.1296 - val_auc: 0.9874 - val_accuracy: 0.9604 - val_cost: 5.0944\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9897 - accuracy: 0.9616 - cost: 4.8976 - val_loss: 0.1289 - val_auc: 0.9877 - val_accuracy: 0.9595 - val_cost: 5.2083\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9900 - accuracy: 0.9627 - cost: 4.7468 - val_loss: 0.1280 - val_auc: 0.9878 - val_accuracy: 0.9607 - val_cost: 4.9316\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9628 - cost: 4.7349 - val_loss: 0.1286 - val_auc: 0.9880 - val_accuracy: 0.9600 - val_cost: 4.8340\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9630 - cost: 4.6929 - val_loss: 0.1269 - val_auc: 0.9878 - val_accuracy: 0.9615 - val_cost: 4.8047\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9904 - accuracy: 0.9636 - cost: 4.6230 - val_loss: 0.1263 - val_auc: 0.9879 - val_accuracy: 0.9608 - val_cost: 4.7917\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1135 - auc: 0.9904 - accuracy: 0.9639 - cost: 4.5962 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9604 - val_cost: 5.0879\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9905 - accuracy: 0.9640 - cost: 4.5979 - val_loss: 0.1233 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 5.0977\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1106 - auc: 0.9906 - accuracy: 0.9650 - cost: 4.4658 - val_loss: 0.1239 - val_auc: 0.9882 - val_accuracy: 0.9616 - val_cost: 4.6549\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9655 - cost: 4.3920 - val_loss: 0.1219 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.5801\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1094 - auc: 0.9908 - accuracy: 0.9652 - cost: 4.4331 - val_loss: 0.1222 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.6322\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9911 - accuracy: 0.9657 - cost: 4.3721 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9627 - val_cost: 4.7201\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1069 - auc: 0.9911 - accuracy: 0.9662 - cost: 4.3197 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9640 - val_cost: 4.6029\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1062 - auc: 0.9911 - accuracy: 0.9664 - cost: 4.2864 - val_loss: 0.1226 - val_auc: 0.9882 - val_accuracy: 0.9628 - val_cost: 4.5215\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1053 - auc: 0.9913 - accuracy: 0.9674 - cost: 4.1489 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.6484\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1054 - auc: 0.9913 - accuracy: 0.9670 - cost: 4.1995 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.4694\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1036 - auc: 0.9916 - accuracy: 0.9674 - cost: 4.1649 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.5150\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1405 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9629 - val_cost: 4.5020\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1031 - auc: 0.9915 - accuracy: 0.9682 - cost: 4.0462 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9653 - val_cost: 4.3359\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1028 - auc: 0.9916 - accuracy: 0.9680 - cost: 4.0812 - val_loss: 0.1174 - val_auc: 0.9889 - val_accuracy: 0.9644 - val_cost: 4.5117\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1015 - auc: 0.9917 - accuracy: 0.9692 - cost: 3.9391 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9649 - val_cost: 4.2643\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1011 - auc: 0.9917 - accuracy: 0.9691 - cost: 3.9430 - val_loss: 0.1191 - val_auc: 0.9885 - val_accuracy: 0.9642 - val_cost: 4.4661\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1012 - auc: 0.9917 - accuracy: 0.9690 - cost: 3.9620 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.5866\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9918 - accuracy: 0.9692 - cost: 3.9293 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9653 - val_cost: 4.5215\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0995 - auc: 0.9921 - accuracy: 0.9692 - cost: 3.9540 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.4629\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8270 - val_loss: 0.1169 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.3717\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8635 - val_loss: 0.1189 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.3262\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8758 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.8372\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9704 - cost: 3.7825 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.2188\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9702 - cost: 3.8077 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9662 - val_cost: 4.1699\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9706 - cost: 3.7715 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 4.1667\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7272 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.1178\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9710 - cost: 3.7017 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9668 - val_cost: 4.1829\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9711 - cost: 3.6896 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9654 - val_cost: 4.2643\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6550 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 4.2318\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9925 - accuracy: 0.9714 - cost: 3.6628 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.2025\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9926 - accuracy: 0.9713 - cost: 3.6686 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0625\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5730 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9661 - val_cost: 4.4076\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9721 - cost: 3.5696 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.1309\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9717 - cost: 3.6169 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.0365\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5331 - val_loss: 0.1152 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0202\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0928 - auc: 0.9927 - accuracy: 0.9723 - cost: 3.5334 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9811\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9732 - cost: 3.4290 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9160\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9729 - cost: 3.4742 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9682 - val_cost: 3.9648\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5099 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9616\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9929 - accuracy: 0.9726 - cost: 3.5045 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.0723\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9931 - accuracy: 0.9728 - cost: 3.4738 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 4.0690\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0903 - auc: 0.9930 - accuracy: 0.9730 - cost: 3.4452 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.3099\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9734 - cost: 3.4026 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8574\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4471 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7923\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9732 - cost: 3.4404 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9388\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9930 - accuracy: 0.9735 - cost: 3.3781 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.9290\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4352 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9737 - cost: 3.3683 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0072\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9933 - accuracy: 0.9741 - cost: 3.3203 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9323\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9743 - cost: 3.2881 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7956\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3256 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 4.0267\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2761 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.8216\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.2956 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8542\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9933 - accuracy: 0.9742 - cost: 3.2955 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - cost: 3.2759 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9062\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9747 - cost: 3.2569 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.6784\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9747 - cost: 3.2369 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8574\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9743 - cost: 3.2938 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 4.0169\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9748 - cost: 3.2373 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0857 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2616 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9755 - cost: 3.1332 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.6914\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.1938 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8737\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9751 - cost: 3.1890 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1687 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.8477\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1606 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.8346\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2145 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.7435\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9754 - cost: 3.1520 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.5970\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9754 - cost: 3.1501 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.7109\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9758 - cost: 3.1030 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.8281\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1750 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0867 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9761 - cost: 3.0734 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 3.7109\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1420 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.8542\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1238 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9696 - val_cost: 3.8281\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9759 - cost: 3.0783 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5091\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0846 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.8118\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9758 - cost: 3.0919 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9937 - accuracy: 0.9762 - cost: 3.0649 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9757 - cost: 3.1288 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0836 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.4831\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9761 - cost: 3.0751 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6882\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1468 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6686\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0651 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6784\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0376 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 3.6719\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0511 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0366 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0478 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6068\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9940 - accuracy: 0.9766 - cost: 3.0147 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0481 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0158 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6491\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0228 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9846 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9511 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9857 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0433 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7370\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9262 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9952 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6556\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9611 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6751\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9768 - cost: 2.9892 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9722 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.6784\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9341 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9464 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5905\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9766 - cost: 3.0107 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6003\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9767 - cost: 3.0098 - val_loss: 0.1103 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.7565\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9607 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9328 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7663\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9718 - val_loss: 0.1117 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6296\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9757 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8411\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9725 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.6947\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9067 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7109\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9402 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7695\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9245 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9695 - val_cost: 3.7467\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8815 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8672\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9559 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5319\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.9241 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9543 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.6719\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9777 - cost: 2.8708 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8971 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7174\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9781 - cost: 2.8227 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8346\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8691 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.8249\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8757 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.8509\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8593 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8763 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7370\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8887 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7956\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8987 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4473\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8521 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6361\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9125 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6816\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8982 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5807\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8662 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8900\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8346 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.6914\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8988 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.9388\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8623 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6296\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8485 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5026\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8282 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.8346\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8915 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8118\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8106 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.7370\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8263 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.8704\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8002 - val_loss: 0.1121 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7044\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8083 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6328\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.8272 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8209 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6003\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8214 - val_loss: 0.1117 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8146 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8608 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8459 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7498 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7748 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8055 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.5710\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8104 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7773 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.8379\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7258 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7533\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8202 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.6719\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8203 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6296\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8267 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5482\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7772 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8176 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5091\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7193 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6979\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7992 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8307 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.8444\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7530 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6491\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7513 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.4896\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7784 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.8997\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7516 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.9518\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8143 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6909 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9723 - val_cost: 3.4342\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7281 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6426\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7343 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8120 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7168 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6838 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6751\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7511 - val_loss: 0.1128 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7830 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7314 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4733\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7591 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7512 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5612\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7708 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.7002 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5482\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7065 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7736 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.8542\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.8145 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9695 - val_cost: 3.7826\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7166 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5059\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7975 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5547\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7212 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7167 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6198\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7457 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.5938\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6803 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6068\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6479 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5026\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7074 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4147\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6694 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.8509\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7423 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.7923\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7169 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5514\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7680 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7012\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7305 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 4.1276\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7867 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.4733\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7726 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6426\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7092 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5807\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6394 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9721 - val_cost: 3.6686\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6490 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.5775\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6964 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6826 - val_loss: 0.1114 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6630 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5579\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6968 - val_loss: 0.1128 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6929 - val_loss: 0.1150 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5254\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7353 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.6035\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6811 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6621\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6704 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6100\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7137 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.5352\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6579 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6300 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7143 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 4.0397\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7540 - val_loss: 0.1185 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6815 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5645\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6609 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9723 - val_cost: 3.4245\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6718 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.5384\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7674 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6914\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5654 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6621\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6578 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.4798\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6912 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6393\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7054 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6849 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6426\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6655 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6823 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6426\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6299 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5091\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6629 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6582 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5254\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7453 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6523\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5814 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4310\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9798 - cost: 2.6153 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.4701\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6241 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5775\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5681 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5482\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6271 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.5547\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6712 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5091\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6380 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4993\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7130 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6499 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6519 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6229 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4408\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6224 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.5352\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1059 - auc: 0.9908 - accuracy: 0.9719 - cost: 3.5187\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:39.565478\n",
            "fold accuracy: 0.9719374775886536 - fold cost: 3.518749952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5481 - auc: 0.7775 - accuracy: 0.7137 - cost: 37.9522 - val_loss: 0.4113 - val_auc: 0.8930 - val_accuracy: 0.8189 - val_cost: 23.0273\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3656 - auc: 0.9147 - accuracy: 0.8422 - cost: 20.0921 - val_loss: 0.3220 - val_auc: 0.9347 - val_accuracy: 0.8634 - val_cost: 16.3932\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3136 - auc: 0.9379 - accuracy: 0.8701 - cost: 16.4113 - val_loss: 0.2917 - val_auc: 0.9464 - val_accuracy: 0.8792 - val_cost: 14.6712\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2871 - auc: 0.9480 - accuracy: 0.8832 - cost: 14.7536 - val_loss: 0.2689 - val_auc: 0.9547 - val_accuracy: 0.8917 - val_cost: 13.1901\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2643 - auc: 0.9561 - accuracy: 0.8946 - cost: 13.2905 - val_loss: 0.2508 - val_auc: 0.9606 - val_accuracy: 0.9012 - val_cost: 12.3991\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9618 - accuracy: 0.9031 - cost: 12.2792 - val_loss: 0.2343 - val_auc: 0.9653 - val_accuracy: 0.9107 - val_cost: 11.0449\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2303 - auc: 0.9665 - accuracy: 0.9108 - cost: 11.2697 - val_loss: 0.2211 - val_auc: 0.9694 - val_accuracy: 0.9163 - val_cost: 9.9577\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2176 - auc: 0.9700 - accuracy: 0.9163 - cost: 10.5301 - val_loss: 0.2083 - val_auc: 0.9725 - val_accuracy: 0.9241 - val_cost: 9.4336\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2053 - auc: 0.9732 - accuracy: 0.9222 - cost: 9.8272 - val_loss: 0.1984 - val_auc: 0.9751 - val_accuracy: 0.9272 - val_cost: 8.8184\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1961 - auc: 0.9756 - accuracy: 0.9258 - cost: 9.3657 - val_loss: 0.1893 - val_auc: 0.9771 - val_accuracy: 0.9324 - val_cost: 8.2747\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1867 - auc: 0.9776 - accuracy: 0.9311 - cost: 8.7279 - val_loss: 0.1828 - val_auc: 0.9782 - val_accuracy: 0.9353 - val_cost: 7.9557\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1801 - auc: 0.9791 - accuracy: 0.9344 - cost: 8.3225 - val_loss: 0.1760 - val_auc: 0.9796 - val_accuracy: 0.9378 - val_cost: 7.8158\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1743 - auc: 0.9803 - accuracy: 0.9368 - cost: 7.9964 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9388 - val_cost: 7.6758\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1694 - auc: 0.9814 - accuracy: 0.9391 - cost: 7.7099 - val_loss: 0.1686 - val_auc: 0.9813 - val_accuracy: 0.9414 - val_cost: 7.2982\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9823 - accuracy: 0.9414 - cost: 7.4484 - val_loss: 0.1636 - val_auc: 0.9820 - val_accuracy: 0.9428 - val_cost: 7.0801\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1597 - auc: 0.9831 - accuracy: 0.9433 - cost: 7.2003 - val_loss: 0.1598 - val_auc: 0.9828 - val_accuracy: 0.9445 - val_cost: 6.8880\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1564 - auc: 0.9838 - accuracy: 0.9449 - cost: 6.9813 - val_loss: 0.1570 - val_auc: 0.9833 - val_accuracy: 0.9463 - val_cost: 6.6113\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9463 - cost: 6.8156 - val_loss: 0.1556 - val_auc: 0.9837 - val_accuracy: 0.9471 - val_cost: 6.5592\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1491 - auc: 0.9851 - accuracy: 0.9483 - cost: 6.5633 - val_loss: 0.1530 - val_auc: 0.9841 - val_accuracy: 0.9488 - val_cost: 6.3379\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1466 - auc: 0.9855 - accuracy: 0.9494 - cost: 6.4339 - val_loss: 0.1506 - val_auc: 0.9844 - val_accuracy: 0.9490 - val_cost: 6.3053\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1425 - auc: 0.9862 - accuracy: 0.9508 - cost: 6.2342 - val_loss: 0.1493 - val_auc: 0.9846 - val_accuracy: 0.9510 - val_cost: 6.1947\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1415 - auc: 0.9863 - accuracy: 0.9519 - cost: 6.1240 - val_loss: 0.1469 - val_auc: 0.9852 - val_accuracy: 0.9521 - val_cost: 5.7878\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9867 - accuracy: 0.9528 - cost: 5.9848 - val_loss: 0.1460 - val_auc: 0.9854 - val_accuracy: 0.9517 - val_cost: 5.9375\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1362 - auc: 0.9871 - accuracy: 0.9545 - cost: 5.7853 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9531 - val_cost: 5.8724\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9549 - cost: 5.7244 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9530 - val_cost: 5.8366\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1328 - auc: 0.9877 - accuracy: 0.9556 - cost: 5.6590 - val_loss: 0.1397 - val_auc: 0.9860 - val_accuracy: 0.9547 - val_cost: 5.6966\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1298 - auc: 0.9882 - accuracy: 0.9564 - cost: 5.5380 - val_loss: 0.1387 - val_auc: 0.9861 - val_accuracy: 0.9557 - val_cost: 5.6152\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9883 - accuracy: 0.9571 - cost: 5.4734 - val_loss: 0.1381 - val_auc: 0.9864 - val_accuracy: 0.9567 - val_cost: 5.4036\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1272 - auc: 0.9887 - accuracy: 0.9574 - cost: 5.4392 - val_loss: 0.1358 - val_auc: 0.9867 - val_accuracy: 0.9579 - val_cost: 5.3678\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1252 - auc: 0.9889 - accuracy: 0.9586 - cost: 5.2780 - val_loss: 0.1358 - val_auc: 0.9866 - val_accuracy: 0.9583 - val_cost: 5.0130\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9890 - accuracy: 0.9591 - cost: 5.2256 - val_loss: 0.1334 - val_auc: 0.9871 - val_accuracy: 0.9587 - val_cost: 5.3613\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1225 - auc: 0.9893 - accuracy: 0.9602 - cost: 5.0530 - val_loss: 0.1345 - val_auc: 0.9869 - val_accuracy: 0.9576 - val_cost: 5.3190\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9598 - cost: 5.1302 - val_loss: 0.1328 - val_auc: 0.9870 - val_accuracy: 0.9583 - val_cost: 5.2409\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1198 - auc: 0.9895 - accuracy: 0.9613 - cost: 4.9288 - val_loss: 0.1302 - val_auc: 0.9871 - val_accuracy: 0.9599 - val_cost: 4.9349\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9615 - cost: 4.8934 - val_loss: 0.1313 - val_auc: 0.9870 - val_accuracy: 0.9590 - val_cost: 5.2409\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1179 - auc: 0.9898 - accuracy: 0.9621 - cost: 4.8236 - val_loss: 0.1295 - val_auc: 0.9873 - val_accuracy: 0.9595 - val_cost: 5.0814\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1158 - auc: 0.9901 - accuracy: 0.9630 - cost: 4.7141 - val_loss: 0.1291 - val_auc: 0.9873 - val_accuracy: 0.9600 - val_cost: 5.0293\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9902 - accuracy: 0.9634 - cost: 4.6569 - val_loss: 0.1281 - val_auc: 0.9874 - val_accuracy: 0.9609 - val_cost: 4.9902\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9638 - cost: 4.6248 - val_loss: 0.1276 - val_auc: 0.9873 - val_accuracy: 0.9617 - val_cost: 4.7526\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1121 - auc: 0.9906 - accuracy: 0.9644 - cost: 4.5412 - val_loss: 0.1288 - val_auc: 0.9873 - val_accuracy: 0.9614 - val_cost: 4.8047\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9645 - cost: 4.5446 - val_loss: 0.1261 - val_auc: 0.9876 - val_accuracy: 0.9610 - val_cost: 4.8600\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1095 - auc: 0.9908 - accuracy: 0.9655 - cost: 4.3930 - val_loss: 0.1253 - val_auc: 0.9878 - val_accuracy: 0.9624 - val_cost: 4.6159\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9911 - accuracy: 0.9658 - cost: 4.3404 - val_loss: 0.1259 - val_auc: 0.9878 - val_accuracy: 0.9622 - val_cost: 4.5768\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1087 - auc: 0.9909 - accuracy: 0.9656 - cost: 4.3892 - val_loss: 0.1240 - val_auc: 0.9879 - val_accuracy: 0.9629 - val_cost: 4.5150\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9660 - cost: 4.3337 - val_loss: 0.1230 - val_auc: 0.9881 - val_accuracy: 0.9640 - val_cost: 4.3132\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1073 - auc: 0.9911 - accuracy: 0.9667 - cost: 4.2540 - val_loss: 0.1233 - val_auc: 0.9877 - val_accuracy: 0.9636 - val_cost: 4.2806\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9673 - cost: 4.1700 - val_loss: 0.1238 - val_auc: 0.9880 - val_accuracy: 0.9635 - val_cost: 4.4694\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9914 - accuracy: 0.9673 - cost: 4.1801 - val_loss: 0.1237 - val_auc: 0.9881 - val_accuracy: 0.9644 - val_cost: 4.1471\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9675 - cost: 4.1548 - val_loss: 0.1228 - val_auc: 0.9882 - val_accuracy: 0.9636 - val_cost: 4.4336\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9916 - accuracy: 0.9676 - cost: 4.1368 - val_loss: 0.1225 - val_auc: 0.9881 - val_accuracy: 0.9643 - val_cost: 4.6224\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9919 - accuracy: 0.9688 - cost: 3.9841 - val_loss: 0.1206 - val_auc: 0.9885 - val_accuracy: 0.9651 - val_cost: 4.4564\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9919 - accuracy: 0.9690 - cost: 3.9699 - val_loss: 0.1227 - val_auc: 0.9882 - val_accuracy: 0.9670 - val_cost: 4.0202\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9918 - accuracy: 0.9689 - cost: 3.9818 - val_loss: 0.1198 - val_auc: 0.9883 - val_accuracy: 0.9674 - val_cost: 3.9486\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1005 - auc: 0.9920 - accuracy: 0.9699 - cost: 3.8604 - val_loss: 0.1207 - val_auc: 0.9884 - val_accuracy: 0.9649 - val_cost: 4.3164\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9695 - cost: 3.8963 - val_loss: 0.1198 - val_auc: 0.9886 - val_accuracy: 0.9656 - val_cost: 4.2253\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9921 - accuracy: 0.9697 - cost: 3.8739 - val_loss: 0.1178 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2057\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9922 - accuracy: 0.9700 - cost: 3.8360 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2220\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9702 - cost: 3.8124 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9673 - val_cost: 3.8444\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0970 - auc: 0.9923 - accuracy: 0.9705 - cost: 3.7617 - val_loss: 0.1197 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 3.8151\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9923 - accuracy: 0.9708 - cost: 3.7263 - val_loss: 0.1171 - val_auc: 0.9886 - val_accuracy: 0.9668 - val_cost: 4.1471\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9925 - accuracy: 0.9710 - cost: 3.7103 - val_loss: 0.1168 - val_auc: 0.9886 - val_accuracy: 0.9674 - val_cost: 4.0527\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9925 - accuracy: 0.9712 - cost: 3.6814 - val_loss: 0.1165 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.1276\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0954 - auc: 0.9925 - accuracy: 0.9709 - cost: 3.7225 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 3.8509\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9716 - cost: 3.6331 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 3.9062\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9719 - cost: 3.6121 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.8770\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0949 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.6141 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9681 - val_cost: 3.9746\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9926 - accuracy: 0.9718 - cost: 3.5933 - val_loss: 0.1164 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 3.9811\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0937 - auc: 0.9927 - accuracy: 0.9719 - cost: 3.5793 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.8086\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4887 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7109\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9721 - cost: 3.5767 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0072\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9727 - cost: 3.4996 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9160\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9728 - cost: 3.4929 - val_loss: 0.1147 - val_auc: 0.9887 - val_accuracy: 0.9688 - val_cost: 3.8607\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9928 - accuracy: 0.9730 - cost: 3.4638 - val_loss: 0.1141 - val_auc: 0.9887 - val_accuracy: 0.9686 - val_cost: 3.8411\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9733 - cost: 3.4321 - val_loss: 0.1158 - val_auc: 0.9887 - val_accuracy: 0.9700 - val_cost: 3.7109\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4594 - val_loss: 0.1143 - val_auc: 0.9888 - val_accuracy: 0.9685 - val_cost: 3.6979\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3710 - val_loss: 0.1156 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.7207\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9735 - cost: 3.3926 - val_loss: 0.1155 - val_auc: 0.9884 - val_accuracy: 0.9675 - val_cost: 4.0202\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9734 - cost: 3.4003 - val_loss: 0.1133 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.9128\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9742 - cost: 3.3170 - val_loss: 0.1126 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7793\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9738 - cost: 3.3515 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9691 - val_cost: 3.8118\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9931 - accuracy: 0.9740 - cost: 3.3532 - val_loss: 0.1120 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.8053\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9736 - cost: 3.3898 - val_loss: 0.1112 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7695\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9745 - cost: 3.2617 - val_loss: 0.1139 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8672\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9748 - cost: 3.2519 - val_loss: 0.1129 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6719\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2376 - val_loss: 0.1120 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6556\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9739 - cost: 3.3589 - val_loss: 0.1125 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6719\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0857 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2307 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.7695\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9746 - cost: 3.2639 - val_loss: 0.1147 - val_auc: 0.9884 - val_accuracy: 0.9679 - val_cost: 3.7988\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.1920 - val_loss: 0.1128 - val_auc: 0.9892 - val_accuracy: 0.9693 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9748 - cost: 3.2272 - val_loss: 0.1141 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9749 - cost: 3.2326 - val_loss: 0.1129 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8509\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2045 - val_loss: 0.1132 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7207\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9753 - cost: 3.1710 - val_loss: 0.1131 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6882\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9935 - accuracy: 0.9748 - cost: 3.2665 - val_loss: 0.1135 - val_auc: 0.9891 - val_accuracy: 0.9698 - val_cost: 3.6393\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9936 - accuracy: 0.9754 - cost: 3.1608 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.7533\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1672 - val_loss: 0.1127 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.7467\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9753 - cost: 3.1667 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1881 - val_loss: 0.1134 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.7370\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.1140 - val_loss: 0.1119 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9752 - cost: 3.1731 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1156 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9936 - accuracy: 0.9759 - cost: 3.0920 - val_loss: 0.1159 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.5319\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1250 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9938 - accuracy: 0.9766 - cost: 3.0128 - val_loss: 0.1108 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.6719\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1545 - val_loss: 0.1127 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6328\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9936 - accuracy: 0.9757 - cost: 3.1264 - val_loss: 0.1141 - val_auc: 0.9889 - val_accuracy: 0.9695 - val_cost: 3.8053\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0647 - val_loss: 0.1144 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.7012\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0549 - val_loss: 0.1130 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.8542\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0746 - val_loss: 0.1134 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9760 - cost: 3.0867 - val_loss: 0.1132 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.7370\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9736 - val_loss: 0.1154 - val_auc: 0.9887 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9764 - cost: 3.0397 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.4961\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9815 - val_loss: 0.1136 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0118 - val_loss: 0.1147 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.7565\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9938 - accuracy: 0.9767 - cost: 3.0041 - val_loss: 0.1136 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.5775\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9937 - accuracy: 0.9762 - cost: 3.0664 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.5645\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9531 - val_loss: 0.1142 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9614 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7012\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9879 - val_loss: 0.1132 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7370\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9770 - cost: 2.9573 - val_loss: 0.1159 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9598 - val_loss: 0.1140 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.4310\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9731 - val_loss: 0.1157 - val_auc: 0.9888 - val_accuracy: 0.9711 - val_cost: 3.5319\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9518 - val_loss: 0.1139 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 4.0430\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0798 - auc: 0.9940 - accuracy: 0.9774 - cost: 2.9052 - val_loss: 0.1138 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.4798\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0198 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7923\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9939 - accuracy: 0.9771 - cost: 2.9472 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5807\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9439 - val_loss: 0.1131 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9902 - val_loss: 0.1165 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8867\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8949 - val_loss: 0.1138 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.6686\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.8927 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.6947\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9770 - cost: 2.9516 - val_loss: 0.1122 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9138 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9232 - val_loss: 0.1158 - val_auc: 0.9888 - val_accuracy: 0.9716 - val_cost: 3.4733\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9354 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5840\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8677 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.6589\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9173 - val_loss: 0.1136 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4831\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9132 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5905\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8865 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6947\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9287 - val_loss: 0.1133 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4180\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9096 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6947\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8889 - val_loss: 0.1162 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.4961\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1170 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.6491\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8918 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.6947\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.9128 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.7500\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9782 - cost: 2.8254 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.5905\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8531 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9120 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8777 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.8965 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8930 - val_loss: 0.1128 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.4766\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8786 - val_loss: 0.1170 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5807\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8439 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9777 - cost: 2.8636 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.4342\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8469 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.5938\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9783 - cost: 2.7830 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4733\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8447 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.5059\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7668 - val_loss: 0.1143 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7207\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9779 - cost: 2.8293 - val_loss: 0.1179 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7672 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7917 - val_loss: 0.1155 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5807\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9785 - cost: 2.7854 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.8184\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7994 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.4863\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8063 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7732 - val_loss: 0.1147 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7593 - val_loss: 0.1152 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4733\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9787 - cost: 2.7380 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8110 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.7598\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7810 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4082\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8066 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5352\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7960 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9785 - cost: 2.7704 - val_loss: 0.1161 - val_auc: 0.9890 - val_accuracy: 0.9721 - val_cost: 3.4570\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8261 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4538\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.8034 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4766\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7926 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4408\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.6936 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7653 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.4473\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7903 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8104 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9711 - val_cost: 3.3366\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7644 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.4570\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7385 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9946 - accuracy: 0.9791 - cost: 2.6911 - val_loss: 0.1174 - val_auc: 0.9891 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7354 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5189\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7298 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9725 - val_cost: 3.3919\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7680 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.5482\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7354 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7137 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9714 - val_cost: 3.4635\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7057 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.6068\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7080 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.6230\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6979 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5612\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6762 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.6133\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9789 - cost: 2.7150 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5189\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7533 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6926 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.7131 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4180\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7427 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.5449\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6546 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6547 - val_loss: 0.1176 - val_auc: 0.9889 - val_accuracy: 0.9723 - val_cost: 3.3887\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6965 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.6035\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6164 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3691\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6487 - val_loss: 0.1175 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.8249\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6351 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5775\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6593 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.4277\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7058 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.6100\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7082 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6547 - val_loss: 0.1151 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5612\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6872 - val_loss: 0.1177 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5124\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9795 - cost: 2.6397 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5189\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7352 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9726 - val_cost: 3.5352\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7084 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6657 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6291 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5449\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7133 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.5579\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5955 - val_loss: 0.1191 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.5286\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7188 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.7728\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6635 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9797 - cost: 2.6170 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5059\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9793 - cost: 2.6665 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.5221\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6625 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.8151\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6295 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6654\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6638 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6715 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6682 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4896\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9797 - cost: 2.6199 - val_loss: 0.1179 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3887\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6873 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.7858\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6416 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5091\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6129 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6486 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4115\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1009 - auc: 0.9911 - accuracy: 0.9732 - cost: 3.3281\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:12.507871\n",
            "fold accuracy: 0.9732499718666077 - fold cost: 3.328125\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5426 - auc: 0.7831 - accuracy: 0.7179 - cost: 37.3215 - val_loss: 0.4068 - val_auc: 0.8965 - val_accuracy: 0.8234 - val_cost: 22.4056\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3650 - auc: 0.9151 - accuracy: 0.8438 - cost: 19.8780 - val_loss: 0.3179 - val_auc: 0.9361 - val_accuracy: 0.8653 - val_cost: 16.3835\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3152 - auc: 0.9371 - accuracy: 0.8691 - cost: 16.5779 - val_loss: 0.2903 - val_auc: 0.9467 - val_accuracy: 0.8791 - val_cost: 14.8014\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2877 - auc: 0.9477 - accuracy: 0.8829 - cost: 14.8147 - val_loss: 0.2676 - val_auc: 0.9550 - val_accuracy: 0.8910 - val_cost: 13.8704\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9556 - accuracy: 0.8943 - cost: 13.3937 - val_loss: 0.2477 - val_auc: 0.9611 - val_accuracy: 0.9025 - val_cost: 12.2428\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9612 - accuracy: 0.9022 - cost: 12.3806 - val_loss: 0.2320 - val_auc: 0.9660 - val_accuracy: 0.9106 - val_cost: 10.8854\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2326 - auc: 0.9658 - accuracy: 0.9103 - cost: 11.3385 - val_loss: 0.2187 - val_auc: 0.9701 - val_accuracy: 0.9175 - val_cost: 10.1888\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2186 - auc: 0.9698 - accuracy: 0.9163 - cost: 10.5839 - val_loss: 0.2073 - val_auc: 0.9729 - val_accuracy: 0.9229 - val_cost: 9.5280\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2068 - auc: 0.9728 - accuracy: 0.9221 - cost: 9.8734 - val_loss: 0.1947 - val_auc: 0.9758 - val_accuracy: 0.9294 - val_cost: 8.7826\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1962 - auc: 0.9755 - accuracy: 0.9270 - cost: 9.2458 - val_loss: 0.1870 - val_auc: 0.9774 - val_accuracy: 0.9300 - val_cost: 8.8249\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9775 - accuracy: 0.9308 - cost: 8.7775 - val_loss: 0.1788 - val_auc: 0.9794 - val_accuracy: 0.9358 - val_cost: 8.4408\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1797 - auc: 0.9792 - accuracy: 0.9351 - cost: 8.2605 - val_loss: 0.1721 - val_auc: 0.9807 - val_accuracy: 0.9378 - val_cost: 7.7604\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1749 - auc: 0.9801 - accuracy: 0.9367 - cost: 8.0293 - val_loss: 0.1661 - val_auc: 0.9819 - val_accuracy: 0.9403 - val_cost: 7.9134\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1679 - auc: 0.9816 - accuracy: 0.9396 - cost: 7.6855 - val_loss: 0.1643 - val_auc: 0.9826 - val_accuracy: 0.9422 - val_cost: 7.0475\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1633 - auc: 0.9825 - accuracy: 0.9423 - cost: 7.3348 - val_loss: 0.1593 - val_auc: 0.9829 - val_accuracy: 0.9426 - val_cost: 7.4219\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1578 - auc: 0.9836 - accuracy: 0.9442 - cost: 7.0914 - val_loss: 0.1546 - val_auc: 0.9840 - val_accuracy: 0.9471 - val_cost: 6.8262\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1550 - auc: 0.9840 - accuracy: 0.9461 - cost: 6.8587 - val_loss: 0.1531 - val_auc: 0.9843 - val_accuracy: 0.9474 - val_cost: 6.5820\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1505 - auc: 0.9848 - accuracy: 0.9477 - cost: 6.6549 - val_loss: 0.1479 - val_auc: 0.9850 - val_accuracy: 0.9480 - val_cost: 6.6309\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1468 - auc: 0.9854 - accuracy: 0.9489 - cost: 6.5214 - val_loss: 0.1468 - val_auc: 0.9853 - val_accuracy: 0.9488 - val_cost: 6.3607\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1450 - auc: 0.9857 - accuracy: 0.9497 - cost: 6.4242 - val_loss: 0.1442 - val_auc: 0.9857 - val_accuracy: 0.9511 - val_cost: 5.9245\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9863 - accuracy: 0.9519 - cost: 6.1388 - val_loss: 0.1418 - val_auc: 0.9860 - val_accuracy: 0.9515 - val_cost: 6.0938\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9866 - accuracy: 0.9531 - cost: 5.9557 - val_loss: 0.1381 - val_auc: 0.9865 - val_accuracy: 0.9531 - val_cost: 6.1589\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1356 - auc: 0.9873 - accuracy: 0.9538 - cost: 5.8765 - val_loss: 0.1365 - val_auc: 0.9869 - val_accuracy: 0.9538 - val_cost: 6.2891\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1341 - auc: 0.9876 - accuracy: 0.9542 - cost: 5.8348 - val_loss: 0.1360 - val_auc: 0.9869 - val_accuracy: 0.9534 - val_cost: 6.1979\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9880 - accuracy: 0.9564 - cost: 5.5469 - val_loss: 0.1331 - val_auc: 0.9872 - val_accuracy: 0.9560 - val_cost: 5.8431\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9885 - accuracy: 0.9570 - cost: 5.4739 - val_loss: 0.1331 - val_auc: 0.9874 - val_accuracy: 0.9560 - val_cost: 5.6250\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1275 - auc: 0.9885 - accuracy: 0.9578 - cost: 5.3799 - val_loss: 0.1309 - val_auc: 0.9876 - val_accuracy: 0.9569 - val_cost: 5.9408\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1248 - auc: 0.9889 - accuracy: 0.9588 - cost: 5.2512 - val_loss: 0.1280 - val_auc: 0.9880 - val_accuracy: 0.9583 - val_cost: 5.5143\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1223 - auc: 0.9892 - accuracy: 0.9605 - cost: 5.0290 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9599 - val_cost: 5.2279\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1211 - auc: 0.9893 - accuracy: 0.9607 - cost: 5.0061 - val_loss: 0.1256 - val_auc: 0.9881 - val_accuracy: 0.9593 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1195 - auc: 0.9895 - accuracy: 0.9614 - cost: 4.9243 - val_loss: 0.1235 - val_auc: 0.9886 - val_accuracy: 0.9608 - val_cost: 5.2409\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9615 - cost: 4.9109 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9612 - val_cost: 5.0456\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1170 - auc: 0.9900 - accuracy: 0.9626 - cost: 4.7595 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 5.2083\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.1149 - auc: 0.9901 - accuracy: 0.9632 - cost: 4.7147 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9617 - val_cost: 4.9642\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1143 - auc: 0.9903 - accuracy: 0.9636 - cost: 4.6503 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9620 - val_cost: 4.8047\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9642 - cost: 4.5640 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9633 - val_cost: 4.8861\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1105 - auc: 0.9907 - accuracy: 0.9651 - cost: 4.4522 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9626 - val_cost: 4.9609\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1097 - auc: 0.9908 - accuracy: 0.9653 - cost: 4.4271 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9636 - val_cost: 4.9349\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9910 - accuracy: 0.9655 - cost: 4.4062 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9635 - val_cost: 4.7461\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1077 - auc: 0.9911 - accuracy: 0.9665 - cost: 4.2725 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.7103\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9669 - cost: 4.2281 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9649 - val_cost: 4.5573\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1065 - auc: 0.9911 - accuracy: 0.9666 - cost: 4.2665 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9640 - val_cost: 4.8307\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9915 - accuracy: 0.9672 - cost: 4.1932 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9644 - val_cost: 4.7135\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9915 - accuracy: 0.9678 - cost: 4.1166 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9657 - val_cost: 4.3815\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1040 - auc: 0.9915 - accuracy: 0.9680 - cost: 4.0995 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9638 - val_cost: 4.3978\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1024 - auc: 0.9917 - accuracy: 0.9685 - cost: 4.0240 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9662 - val_cost: 4.3197\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9918 - accuracy: 0.9686 - cost: 4.0090 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9661 - val_cost: 4.2025\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9691 - cost: 3.9462 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9669 - val_cost: 4.3522\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1013 - auc: 0.9918 - accuracy: 0.9691 - cost: 3.9572 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9661 - val_cost: 4.5150\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9921 - accuracy: 0.9700 - cost: 3.8218 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9674 - val_cost: 4.3099\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0998 - auc: 0.9919 - accuracy: 0.9697 - cost: 3.8725 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9670 - val_cost: 4.5052\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0982 - auc: 0.9921 - accuracy: 0.9705 - cost: 3.7834 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9669 - val_cost: 4.3132\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0988 - auc: 0.9920 - accuracy: 0.9701 - cost: 3.8159 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 4.1602\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0975 - auc: 0.9921 - accuracy: 0.9708 - cost: 3.7236 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9680 - val_cost: 4.2057\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0971 - auc: 0.9922 - accuracy: 0.9707 - cost: 3.7461 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.2188\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0958 - auc: 0.9924 - accuracy: 0.9709 - cost: 3.7259 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9676 - val_cost: 4.2025\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9923 - accuracy: 0.9715 - cost: 3.6595 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9670 - val_cost: 4.3197\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9924 - accuracy: 0.9713 - cost: 3.6773 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9681 - val_cost: 4.1309\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0949 - auc: 0.9924 - accuracy: 0.9714 - cost: 3.6634 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 4.2090\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0932 - auc: 0.9925 - accuracy: 0.9719 - cost: 3.6013 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9675 - val_cost: 4.2676\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0941 - auc: 0.9926 - accuracy: 0.9720 - cost: 3.5970 - val_loss: 0.1080 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 4.1667\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0935 - auc: 0.9927 - accuracy: 0.9720 - cost: 3.5754 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9685 - val_cost: 4.0951\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9726 - cost: 3.5110 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9676 - val_cost: 4.2578\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9927 - accuracy: 0.9722 - cost: 3.5572 - val_loss: 0.1076 - val_auc: 0.9907 - val_accuracy: 0.9677 - val_cost: 4.2122\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9729 - cost: 3.4790 - val_loss: 0.1082 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.1016\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9728 - cost: 3.4948 - val_loss: 0.1083 - val_auc: 0.9907 - val_accuracy: 0.9678 - val_cost: 4.2090\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9731 - cost: 3.4413 - val_loss: 0.1075 - val_auc: 0.9905 - val_accuracy: 0.9681 - val_cost: 4.1634\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9928 - accuracy: 0.9731 - cost: 3.4447 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.1471\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9927 - accuracy: 0.9732 - cost: 3.4273 - val_loss: 0.1078 - val_auc: 0.9907 - val_accuracy: 0.9691 - val_cost: 3.9323\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9930 - accuracy: 0.9737 - cost: 3.3714 - val_loss: 0.1073 - val_auc: 0.9904 - val_accuracy: 0.9687 - val_cost: 4.1178\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9733 - cost: 3.4298 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9731 - cost: 3.4462 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9691 - val_cost: 4.0039\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9732 - cost: 3.4314 - val_loss: 0.1114 - val_auc: 0.9903 - val_accuracy: 0.9682 - val_cost: 4.0690\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3189 - val_loss: 0.1074 - val_auc: 0.9905 - val_accuracy: 0.9695 - val_cost: 3.8997\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2880 - val_loss: 0.1086 - val_auc: 0.9906 - val_accuracy: 0.9691 - val_cost: 4.1016\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0875 - auc: 0.9932 - accuracy: 0.9740 - cost: 3.3555 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 3.9714\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9739 - cost: 3.3453 - val_loss: 0.1057 - val_auc: 0.9908 - val_accuracy: 0.9696 - val_cost: 3.8770\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9737 - cost: 3.3795 - val_loss: 0.1054 - val_auc: 0.9909 - val_accuracy: 0.9698 - val_cost: 3.8574\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9932 - accuracy: 0.9744 - cost: 3.2861 - val_loss: 0.1065 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 4.0853\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9746 - cost: 3.2702 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9486\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9743 - cost: 3.3043 - val_loss: 0.1061 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.9486\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9751 - cost: 3.2035 - val_loss: 0.1063 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 4.0983\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9752 - cost: 3.1934 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.9909\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9749 - cost: 3.2181 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.8053\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9748 - cost: 3.2311 - val_loss: 0.1063 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.8835\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9753 - cost: 3.1637 - val_loss: 0.1065 - val_auc: 0.9909 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0841 - auc: 0.9936 - accuracy: 0.9751 - cost: 3.2065 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.8216\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2054 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.7760\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0844 - auc: 0.9934 - accuracy: 0.9750 - cost: 3.2063 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.8574\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1464 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.8997\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9934 - accuracy: 0.9756 - cost: 3.1511 - val_loss: 0.1076 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9583\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9755 - cost: 3.1623 - val_loss: 0.1046 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.9453\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9757 - cost: 3.1300 - val_loss: 0.1059 - val_auc: 0.9908 - val_accuracy: 0.9701 - val_cost: 3.8932\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9935 - accuracy: 0.9756 - cost: 3.1342 - val_loss: 0.1051 - val_auc: 0.9907 - val_accuracy: 0.9719 - val_cost: 3.7337\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1282 - val_loss: 0.1047 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8411\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0832 - auc: 0.9936 - accuracy: 0.9756 - cost: 3.1271 - val_loss: 0.1061 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.7467\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0831 - auc: 0.9936 - accuracy: 0.9763 - cost: 3.0459 - val_loss: 0.1060 - val_auc: 0.9908 - val_accuracy: 0.9707 - val_cost: 3.9616\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0985 - val_loss: 0.1056 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.7305\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9756 - cost: 3.1212 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9705 - val_cost: 3.8965\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0827 - auc: 0.9937 - accuracy: 0.9760 - cost: 3.0763 - val_loss: 0.1070 - val_auc: 0.9907 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0208 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9765 - cost: 3.0272 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.8932\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0077 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.9876\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0502 - val_loss: 0.1048 - val_auc: 0.9910 - val_accuracy: 0.9704 - val_cost: 3.8965\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0657 - val_loss: 0.1050 - val_auc: 0.9908 - val_accuracy: 0.9708 - val_cost: 3.8802\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0112 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9698 - val_cost: 3.9811\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9764 - cost: 3.0358 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.8607\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9766 - cost: 3.0102 - val_loss: 0.1085 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.9453\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9763 - cost: 3.0595 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 4.0723\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9762 - cost: 3.0647 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7826\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9768 - cost: 2.9750 - val_loss: 0.1070 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.8997\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9769 - cost: 2.9900 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.9062\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9767 - cost: 2.9953 - val_loss: 0.1084 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.8509\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9768 - cost: 3.0049 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.7891\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9940 - accuracy: 0.9773 - cost: 2.9209 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.8411\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9603 - val_loss: 0.1086 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7728\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9465 - val_loss: 0.1072 - val_auc: 0.9906 - val_accuracy: 0.9709 - val_cost: 4.0430\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9765 - cost: 3.0411 - val_loss: 0.1051 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.8542\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9771 - cost: 2.9537 - val_loss: 0.1095 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8249\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9575 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.8997\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9770 - cost: 2.9525 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9939 - accuracy: 0.9769 - cost: 2.9721 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9681\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9595 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.9421\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9189 - val_loss: 0.1056 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.7207\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9619 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9707 - val_cost: 3.9681\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9248 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6198\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9772 - cost: 2.9389 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.9518\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9773 - cost: 2.9277 - val_loss: 0.1091 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.7923\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9778 - cost: 2.8569 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.8607\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.9147 - val_loss: 0.1071 - val_auc: 0.9908 - val_accuracy: 0.9712 - val_cost: 3.7728\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9349 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.7598\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.9199 - val_loss: 0.1075 - val_auc: 0.9909 - val_accuracy: 0.9712 - val_cost: 3.6816\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9776 - cost: 2.8784 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.8737\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9775 - cost: 2.9072 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 4.0527\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9940 - accuracy: 0.9777 - cost: 2.8779 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.8900\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9298 - val_loss: 0.1081 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.8835\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8986 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9782 - cost: 2.8054 - val_loss: 0.1079 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.7109\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8908 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6719\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9781 - cost: 2.8193 - val_loss: 0.1091 - val_auc: 0.9905 - val_accuracy: 0.9711 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8948 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6654\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9774 - cost: 2.9219 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7598\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8559 - val_loss: 0.1097 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.8737\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9780 - cost: 2.8395 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.9355\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8826 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7923\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.9056 - val_loss: 0.1121 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9774 - cost: 2.8979 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.9167 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8975 - val_loss: 0.1103 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.7826\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.7370\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8292 - val_loss: 0.1073 - val_auc: 0.9906 - val_accuracy: 0.9718 - val_cost: 3.7923\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9783 - cost: 2.8031 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9782 - cost: 2.8143 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.7077\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7885 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9781 - cost: 2.8159 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.7272\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8501 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8306 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.8346\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9780 - cost: 2.8331 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8397 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9716 - val_cost: 3.7858\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7583 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.7598\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9785 - cost: 2.7878 - val_loss: 0.1132 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8184\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8315 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9779 - cost: 2.8438 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.6361\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7337 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.8151\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8187 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.7370\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7946 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.7760\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9786 - cost: 2.7655 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.6589\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7631 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7504 - val_loss: 0.1138 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.4570\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9787 - cost: 2.7435 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7529 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.7760\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9788 - cost: 2.7392 - val_loss: 0.1103 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7391 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8021 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.8672\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9784 - cost: 2.7970 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7630 - val_loss: 0.1110 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7598\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.8026 - val_loss: 0.1103 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.6686\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7676 - val_loss: 0.1103 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.6328\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9784 - cost: 2.7892 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6914\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7476 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.8314\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7688 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.7272\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.8070 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9723 - val_cost: 3.7240\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9786 - cost: 2.7625 - val_loss: 0.1116 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.7402\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7151 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.4440\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7106 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7805 - val_loss: 0.1106 - val_auc: 0.9905 - val_accuracy: 0.9730 - val_cost: 3.5742\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9790 - cost: 2.7181 - val_loss: 0.1132 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.7370\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7085 - val_loss: 0.1118 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7476 - val_loss: 0.1120 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.8118\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9793 - cost: 2.6875 - val_loss: 0.1150 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8835\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7959 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.6426\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.7016 - val_loss: 0.1103 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.9128\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7688 - val_loss: 0.1100 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.7142\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7089 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.9583\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9788 - cost: 2.7542 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.9681\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7292 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4798\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7345 - val_loss: 0.1099 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.6296\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8358 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.7207\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7601 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.7305\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6882 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7465 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.9160\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7825 - val_loss: 0.1136 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7988\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7324 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6751\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6910 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7858\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7339 - val_loss: 0.1141 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5156\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6933 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9844\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7494 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8607\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7261 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9616\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7216 - val_loss: 0.1134 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7695\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.7052 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 4.0462\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7061 - val_loss: 0.1131 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.8281\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7686 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6979\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6948 - val_loss: 0.1136 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9787 - cost: 2.7615 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.7109\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6549 - val_loss: 0.1122 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7246 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.4375\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.7174 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9723 - val_cost: 3.6198\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9796 - cost: 2.6494 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.8835\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7115 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.8151\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7354 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5710\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.7094 - val_loss: 0.1141 - val_auc: 0.9902 - val_accuracy: 0.9721 - val_cost: 3.5156\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6898 - val_loss: 0.1139 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.6914\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9797 - cost: 2.6223 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7923\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6985 - val_loss: 0.1141 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7304 - val_loss: 0.1144 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6515 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.6426\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6578 - val_loss: 0.1159 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6556\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5728 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.6263\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7441 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.6361\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9794 - cost: 2.6621 - val_loss: 0.1133 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.7695\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7021 - val_loss: 0.1157 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.9941\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6881 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.7005 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.9258\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6987 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6621\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9794 - cost: 2.6572 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8932\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.7289 - val_loss: 0.1162 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9453\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6846 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.8477\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6770 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.8639\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6902 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.9583\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6894 - val_loss: 0.1169 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 4.0072\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6269 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.8379\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6514 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.6849\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.7108 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.9323\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6665 - val_loss: 0.1178 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7077\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6426 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.7012\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.6025 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7826\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6841 - val_loss: 0.1168 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7207\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6442 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6491 - val_loss: 0.1168 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7012\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7393 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4701\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6332 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6964 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6393\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6046 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5742\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6826 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.7207\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6661 - val_loss: 0.1181 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6230\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6455 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.9648\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9800 - cost: 2.6028 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.8900\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.7105 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5660 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.9811\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6515 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7826\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6140 - val_loss: 0.1180 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.6057 - val_loss: 0.1166 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.7305\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6643 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.6184 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.7500\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6422 - val_loss: 0.1158 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.7695\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6469 - val_loss: 0.1175 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7630\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1109 - auc: 0.9904 - accuracy: 0.9709 - cost: 3.6656\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:34.631117\n",
            "fold accuracy: 0.9708750247955322 - fold cost: 3.6656250953674316\n",
            "total train/predict time: 0:23:47.793106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_results = fold_results"
      ],
      "metadata": {
        "id": "fszFGfDwmD7r"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "m4_cost = cost_func(y,preds_m4)\n",
        "m4_cost"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11915598-3e5e-4a2b-f39e-9b39c084cfb1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554900"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new4 = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    if m4_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new4[idx] = 1\n",
        "    else:\n",
        "      preds_new4[idx] = 0\n",
        "m4_cost_t = cost_func(y,preds_new4)\n",
        "m4_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7K7DWxmHit",
        "outputId": "33c52f02-206b-433d-9480-f3fa642d1615"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "570050"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "625633cd-7fe8-467e-f2a7-b25f7aa599da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('model4.keras')"
      ],
      "metadata": {
        "id": "ew-ZtZUpzr0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model5 = tf.keras.Sequential()\n",
        "  model5.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model5.add(tf.keras.layers.Dropout(0.2))\n",
        "  model5.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model5.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model5.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model5.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model5.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "8d70c46e-ecb0-42f5-ecab-d423ec4dbced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5265 - auc: 0.8009 - accuracy: 0.7294 - cost: 35.9773 - val_loss: 0.3919 - val_auc: 0.9022 - val_accuracy: 0.8288 - val_cost: 21.9434\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3471 - auc: 0.9236 - accuracy: 0.8525 - cost: 18.7994 - val_loss: 0.3144 - val_auc: 0.9371 - val_accuracy: 0.8675 - val_cost: 16.4290\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3006 - auc: 0.9428 - accuracy: 0.8754 - cost: 15.7681 - val_loss: 0.2883 - val_auc: 0.9483 - val_accuracy: 0.8801 - val_cost: 15.3385\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2716 - auc: 0.9533 - accuracy: 0.8896 - cost: 14.0008 - val_loss: 0.2614 - val_auc: 0.9572 - val_accuracy: 0.8956 - val_cost: 12.6400\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2488 - auc: 0.9609 - accuracy: 0.9010 - cost: 12.5384 - val_loss: 0.2406 - val_auc: 0.9634 - val_accuracy: 0.9064 - val_cost: 11.6211\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2296 - auc: 0.9666 - accuracy: 0.9102 - cost: 11.3726 - val_loss: 0.2253 - val_auc: 0.9687 - val_accuracy: 0.9117 - val_cost: 10.3613\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2133 - auc: 0.9712 - accuracy: 0.9176 - cost: 10.4416 - val_loss: 0.2072 - val_auc: 0.9727 - val_accuracy: 0.9228 - val_cost: 9.3490\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1996 - auc: 0.9746 - accuracy: 0.9240 - cost: 9.6256 - val_loss: 0.1953 - val_auc: 0.9755 - val_accuracy: 0.9285 - val_cost: 8.7533\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1880 - auc: 0.9773 - accuracy: 0.9296 - cost: 8.9326 - val_loss: 0.1863 - val_auc: 0.9776 - val_accuracy: 0.9322 - val_cost: 8.5612\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1793 - auc: 0.9792 - accuracy: 0.9336 - cost: 8.4066 - val_loss: 0.1797 - val_auc: 0.9790 - val_accuracy: 0.9348 - val_cost: 8.2454\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1708 - auc: 0.9810 - accuracy: 0.9366 - cost: 8.0285 - val_loss: 0.1720 - val_auc: 0.9806 - val_accuracy: 0.9389 - val_cost: 7.7734\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1640 - auc: 0.9824 - accuracy: 0.9406 - cost: 7.5507 - val_loss: 0.1663 - val_auc: 0.9817 - val_accuracy: 0.9424 - val_cost: 7.5326\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9427 - cost: 7.2557 - val_loss: 0.1619 - val_auc: 0.9826 - val_accuracy: 0.9427 - val_cost: 7.3568\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9450 - cost: 6.9718 - val_loss: 0.1590 - val_auc: 0.9832 - val_accuracy: 0.9452 - val_cost: 7.1745\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1494 - auc: 0.9851 - accuracy: 0.9465 - cost: 6.7697 - val_loss: 0.1537 - val_auc: 0.9842 - val_accuracy: 0.9473 - val_cost: 6.9336\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1442 - auc: 0.9860 - accuracy: 0.9492 - cost: 6.4565 - val_loss: 0.1517 - val_auc: 0.9844 - val_accuracy: 0.9481 - val_cost: 6.6569\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1413 - auc: 0.9865 - accuracy: 0.9502 - cost: 6.3074 - val_loss: 0.1493 - val_auc: 0.9848 - val_accuracy: 0.9482 - val_cost: 6.6667\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1377 - auc: 0.9870 - accuracy: 0.9525 - cost: 6.0340 - val_loss: 0.1457 - val_auc: 0.9853 - val_accuracy: 0.9507 - val_cost: 6.4128\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9536 - cost: 5.8673 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9503 - val_cost: 6.2142\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1314 - auc: 0.9880 - accuracy: 0.9553 - cost: 5.6627 - val_loss: 0.1407 - val_auc: 0.9859 - val_accuracy: 0.9532 - val_cost: 6.0677\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1284 - auc: 0.9884 - accuracy: 0.9556 - cost: 5.6364 - val_loss: 0.1398 - val_auc: 0.9864 - val_accuracy: 0.9543 - val_cost: 6.3086\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1260 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4017 - val_loss: 0.1366 - val_auc: 0.9866 - val_accuracy: 0.9550 - val_cost: 5.7682\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9890 - accuracy: 0.9581 - cost: 5.3138 - val_loss: 0.1337 - val_auc: 0.9871 - val_accuracy: 0.9560 - val_cost: 5.7357\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1828 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9569 - val_cost: 5.5729\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9605 - cost: 5.0111 - val_loss: 0.1312 - val_auc: 0.9875 - val_accuracy: 0.9579 - val_cost: 5.4915\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9902 - accuracy: 0.9609 - cost: 4.9621 - val_loss: 0.1288 - val_auc: 0.9877 - val_accuracy: 0.9586 - val_cost: 5.4688\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1146 - auc: 0.9903 - accuracy: 0.9621 - cost: 4.8125 - val_loss: 0.1285 - val_auc: 0.9877 - val_accuracy: 0.9592 - val_cost: 5.2995\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7334 - val_loss: 0.1264 - val_auc: 0.9881 - val_accuracy: 0.9609 - val_cost: 5.0879\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9907 - accuracy: 0.9631 - cost: 4.6834 - val_loss: 0.1255 - val_auc: 0.9881 - val_accuracy: 0.9615 - val_cost: 5.0260\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5352 - val_loss: 0.1236 - val_auc: 0.9882 - val_accuracy: 0.9619 - val_cost: 5.0098\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1077 - auc: 0.9910 - accuracy: 0.9648 - cost: 4.4798 - val_loss: 0.1224 - val_auc: 0.9883 - val_accuracy: 0.9624 - val_cost: 4.6191\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1058 - auc: 0.9914 - accuracy: 0.9662 - cost: 4.2873 - val_loss: 0.1211 - val_auc: 0.9885 - val_accuracy: 0.9631 - val_cost: 4.9512\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9659 - cost: 4.3371 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9640 - val_cost: 4.6810\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1902 - val_loss: 0.1199 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5410\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9669 - cost: 4.2149 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9634 - val_cost: 4.6842\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9682 - cost: 4.0414 - val_loss: 0.1169 - val_auc: 0.9892 - val_accuracy: 0.9641 - val_cost: 4.5182\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9684 - cost: 4.0076 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9649 - val_cost: 4.4564\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9922 - accuracy: 0.9689 - cost: 3.9493 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9653 - val_cost: 4.4434\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9199 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.5443\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9697 - cost: 3.8479 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1862\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0944 - auc: 0.9925 - accuracy: 0.9702 - cost: 3.7851 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9662 - val_cost: 4.0202\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9709 - cost: 3.6883 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1569\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9927 - accuracy: 0.9708 - cost: 3.7031 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1895\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6818 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1927\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5782 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1113\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5397 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0983\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.5989 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.1016\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4560 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9583\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4586 - val_loss: 0.1069 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 4.3294\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3216 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9677 - val_cost: 4.3522\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3450 - val_loss: 0.1082 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9735 - cost: 3.3732 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.1471\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3171 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9691 - val_cost: 3.9128\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2743 - val_loss: 0.1056 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9453\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2690 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2166 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2264 - val_loss: 0.1054 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9551\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1474 - val_loss: 0.1052 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1824 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1413 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.6654\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.0602 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7760\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0586 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.9746\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0676 - val_loss: 0.1025 - val_auc: 0.9907 - val_accuracy: 0.9702 - val_cost: 3.8542\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0751 - val_loss: 0.1038 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0590 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.7891\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9388 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.5677\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0461 - val_loss: 0.1042 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0327 - val_loss: 0.1037 - val_auc: 0.9908 - val_accuracy: 0.9701 - val_cost: 3.8574\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9852 - val_loss: 0.1040 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.5677\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9765 - cost: 3.0028 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.8932\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8646 - val_loss: 0.1032 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.6784\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8302 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.9551\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8584 - val_loss: 0.1035 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7012\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8513 - val_loss: 0.1030 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.5189\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8685 - val_loss: 0.1035 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.5579\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8819 - val_loss: 0.1028 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6621\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8536 - val_loss: 0.1034 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.6491\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8528 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7758 - val_loss: 0.1019 - val_auc: 0.9906 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7449 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.5286\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9945 - accuracy: 0.9782 - cost: 2.7784 - val_loss: 0.1024 - val_auc: 0.9907 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7465 - val_loss: 0.1029 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7879 - val_loss: 0.1039 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7213 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.6654\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7474 - val_loss: 0.1031 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.3040\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7245 - val_loss: 0.1023 - val_auc: 0.9907 - val_accuracy: 0.9717 - val_cost: 3.8607\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7945 - val_loss: 0.1023 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.3626\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6946 - val_loss: 0.1019 - val_auc: 0.9908 - val_accuracy: 0.9720 - val_cost: 3.4538\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6753 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.5970\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.6884 - val_loss: 0.1030 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.5905\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6982 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6430 - val_loss: 0.1029 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.6458\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7242 - val_loss: 0.1026 - val_auc: 0.9905 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6858 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.9160\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6769 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9716 - val_cost: 3.6165\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9727 - val_cost: 3.4896\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6517 - val_loss: 0.1050 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6328\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6414 - val_loss: 0.1054 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.5189\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5774 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9726 - val_cost: 3.3073\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6365 - val_loss: 0.1042 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.8346\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6727 - val_loss: 0.1031 - val_auc: 0.9906 - val_accuracy: 0.9724 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.5983 - val_loss: 0.1042 - val_auc: 0.9904 - val_accuracy: 0.9728 - val_cost: 3.4603\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6600 - val_loss: 0.1044 - val_auc: 0.9905 - val_accuracy: 0.9727 - val_cost: 3.5221\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5902 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6553 - val_loss: 0.1042 - val_auc: 0.9905 - val_accuracy: 0.9726 - val_cost: 3.5514\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5626 - val_loss: 0.1046 - val_auc: 0.9907 - val_accuracy: 0.9719 - val_cost: 3.5840\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5181 - val_loss: 0.1031 - val_auc: 0.9904 - val_accuracy: 0.9724 - val_cost: 3.7663\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5690 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9724 - val_cost: 3.5384\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5107 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9725 - val_cost: 3.5645\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5460 - val_loss: 0.1045 - val_auc: 0.9906 - val_accuracy: 0.9734 - val_cost: 3.4961\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5097 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5559 - val_loss: 0.1038 - val_auc: 0.9902 - val_accuracy: 0.9727 - val_cost: 3.5677\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5705 - val_loss: 0.1049 - val_auc: 0.9907 - val_accuracy: 0.9722 - val_cost: 3.5514\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5097 - val_loss: 0.1061 - val_auc: 0.9902 - val_accuracy: 0.9727 - val_cost: 3.3171\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6107 - val_loss: 0.1049 - val_auc: 0.9905 - val_accuracy: 0.9727 - val_cost: 3.4831\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5486 - val_loss: 0.1050 - val_auc: 0.9907 - val_accuracy: 0.9731 - val_cost: 3.4115\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4763 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.2096\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4885 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9724 - val_cost: 3.5612\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4743 - val_loss: 0.1039 - val_auc: 0.9908 - val_accuracy: 0.9728 - val_cost: 3.6589\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4467 - val_loss: 0.1050 - val_auc: 0.9904 - val_accuracy: 0.9733 - val_cost: 3.4408\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4866 - val_loss: 0.1050 - val_auc: 0.9906 - val_accuracy: 0.9723 - val_cost: 3.5449\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4943 - val_loss: 0.1051 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.5417\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5366 - val_loss: 0.1057 - val_auc: 0.9906 - val_accuracy: 0.9732 - val_cost: 3.3887\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4129 - val_loss: 0.1041 - val_auc: 0.9906 - val_accuracy: 0.9730 - val_cost: 3.5091\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5236 - val_loss: 0.1060 - val_auc: 0.9905 - val_accuracy: 0.9728 - val_cost: 3.4147\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4507 - val_loss: 0.1058 - val_auc: 0.9906 - val_accuracy: 0.9734 - val_cost: 3.4115\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4087 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9731 - val_cost: 3.3887\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4828 - val_loss: 0.1056 - val_auc: 0.9901 - val_accuracy: 0.9736 - val_cost: 3.4831\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4578 - val_loss: 0.1060 - val_auc: 0.9900 - val_accuracy: 0.9741 - val_cost: 3.4180\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4741 - val_loss: 0.1055 - val_auc: 0.9904 - val_accuracy: 0.9735 - val_cost: 3.4375\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4705 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9733 - val_cost: 3.4408\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4104 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9741 - val_cost: 3.3626\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4238 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9734 - val_cost: 3.4310\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3419 - val_loss: 0.1075 - val_auc: 0.9900 - val_accuracy: 0.9732 - val_cost: 3.4310\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4006 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9738 - val_cost: 3.3757\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.4180\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4042 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9737 - val_cost: 3.3854\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4106 - val_loss: 0.1086 - val_auc: 0.9897 - val_accuracy: 0.9731 - val_cost: 3.4310\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4304 - val_loss: 0.1065 - val_auc: 0.9900 - val_accuracy: 0.9746 - val_cost: 3.1152\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3873 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.5710\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3331 - val_loss: 0.1081 - val_auc: 0.9897 - val_accuracy: 0.9740 - val_cost: 3.3431\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4176 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9742 - val_cost: 3.3301\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4282 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5872\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4005 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.4570\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3511 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9729 - val_cost: 3.4668\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.3980 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.4538\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3778 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.8086\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3892 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9737 - val_cost: 3.4733\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4062 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3461 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9734 - val_cost: 3.4245\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3834 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.4733\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3653 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9742 - val_cost: 3.2975\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3547 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9732 - val_cost: 3.3984\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3560 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9728 - val_cost: 3.4766\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3001 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9730 - val_cost: 3.4180\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9735 - val_cost: 3.5645\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3382 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9733 - val_cost: 3.5742\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3325 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9735 - val_cost: 3.5547\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3503 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9729 - val_cost: 3.7337\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3584 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9730 - val_cost: 3.8021\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2846 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9738 - val_cost: 3.5026\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3693 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.8249\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3381 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9735 - val_cost: 3.5417\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2816 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9735 - val_cost: 3.4049\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3184 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9737 - val_cost: 3.3398\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3210 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9733 - val_cost: 3.5612\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3349 - val_loss: 0.1106 - val_auc: 0.9894 - val_accuracy: 0.9737 - val_cost: 3.5840\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3204 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9730 - val_cost: 3.8216\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.7988\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2876 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.4668\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2948 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9730 - val_cost: 3.6230\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3014 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9733 - val_cost: 3.4180\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3126 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9734 - val_cost: 3.4668\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2544 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.7500\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2658 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.5221\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3422 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.7240\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3133 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9732 - val_cost: 3.4831\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3389 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.8574\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2871 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.6849\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2671 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.5807\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2524 - val_loss: 0.1139 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.7370\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2741 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9727 - val_cost: 3.4766\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2714 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6361\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2328 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9726 - val_cost: 3.7174\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3254 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.8021\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2730 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.7370\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2692 - val_loss: 0.1137 - val_auc: 0.9892 - val_accuracy: 0.9729 - val_cost: 3.8639\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2804 - val_loss: 0.1132 - val_auc: 0.9890 - val_accuracy: 0.9718 - val_cost: 3.7793\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2540 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9732 - val_cost: 3.4017\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1061 - auc: 0.9908 - accuracy: 0.9705 - cost: 3.6906\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:45.883969\n",
            "fold accuracy: 0.9704999923706055 - fold cost: 3.690624952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 3s 6ms/step - loss: 0.5261 - auc: 0.8016 - accuracy: 0.7315 - cost: 35.7237 - val_loss: 0.3935 - val_auc: 0.9022 - val_accuracy: 0.8303 - val_cost: 22.6302\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3476 - auc: 0.9233 - accuracy: 0.8516 - cost: 18.9104 - val_loss: 0.3148 - val_auc: 0.9371 - val_accuracy: 0.8664 - val_cost: 16.5788\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2988 - auc: 0.9435 - accuracy: 0.8766 - cost: 15.6157 - val_loss: 0.2861 - val_auc: 0.9486 - val_accuracy: 0.8805 - val_cost: 15.2051\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2707 - auc: 0.9537 - accuracy: 0.8893 - cost: 14.0262 - val_loss: 0.2595 - val_auc: 0.9575 - val_accuracy: 0.8971 - val_cost: 12.7441\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2471 - auc: 0.9615 - accuracy: 0.9010 - cost: 12.5469 - val_loss: 0.2404 - val_auc: 0.9637 - val_accuracy: 0.9060 - val_cost: 11.5560\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2281 - auc: 0.9670 - accuracy: 0.9103 - cost: 11.3700 - val_loss: 0.2232 - val_auc: 0.9685 - val_accuracy: 0.9154 - val_cost: 10.8529\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2123 - auc: 0.9713 - accuracy: 0.9179 - cost: 10.3767 - val_loss: 0.2096 - val_auc: 0.9721 - val_accuracy: 0.9197 - val_cost: 10.2897\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1994 - auc: 0.9746 - accuracy: 0.9235 - cost: 9.6699 - val_loss: 0.1974 - val_auc: 0.9753 - val_accuracy: 0.9285 - val_cost: 9.3327\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1878 - auc: 0.9774 - accuracy: 0.9295 - cost: 8.9213 - val_loss: 0.1873 - val_auc: 0.9775 - val_accuracy: 0.9323 - val_cost: 8.7988\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1776 - auc: 0.9796 - accuracy: 0.9350 - cost: 8.2304 - val_loss: 0.1803 - val_auc: 0.9789 - val_accuracy: 0.9358 - val_cost: 8.3724\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1703 - auc: 0.9811 - accuracy: 0.9381 - cost: 7.8498 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9384 - val_cost: 8.1413\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9824 - accuracy: 0.9406 - cost: 7.5259 - val_loss: 0.1686 - val_auc: 0.9812 - val_accuracy: 0.9404 - val_cost: 7.9785\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1573 - auc: 0.9836 - accuracy: 0.9434 - cost: 7.1771 - val_loss: 0.1624 - val_auc: 0.9826 - val_accuracy: 0.9431 - val_cost: 7.2298\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1526 - auc: 0.9845 - accuracy: 0.9457 - cost: 6.8866 - val_loss: 0.1578 - val_auc: 0.9833 - val_accuracy: 0.9456 - val_cost: 7.1810\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1475 - auc: 0.9854 - accuracy: 0.9479 - cost: 6.6080 - val_loss: 0.1540 - val_auc: 0.9841 - val_accuracy: 0.9467 - val_cost: 6.9076\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1445 - auc: 0.9859 - accuracy: 0.9488 - cost: 6.4780 - val_loss: 0.1519 - val_auc: 0.9843 - val_accuracy: 0.9479 - val_cost: 6.8262\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1405 - auc: 0.9865 - accuracy: 0.9514 - cost: 6.1675 - val_loss: 0.1499 - val_auc: 0.9847 - val_accuracy: 0.9477 - val_cost: 6.9271\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9530 - cost: 5.9652 - val_loss: 0.1466 - val_auc: 0.9854 - val_accuracy: 0.9488 - val_cost: 6.4388\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9541 - cost: 5.8325 - val_loss: 0.1461 - val_auc: 0.9855 - val_accuracy: 0.9502 - val_cost: 6.6829\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1316 - auc: 0.9880 - accuracy: 0.9552 - cost: 5.6857 - val_loss: 0.1426 - val_auc: 0.9861 - val_accuracy: 0.9518 - val_cost: 6.0905\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9559 - cost: 5.5883 - val_loss: 0.1414 - val_auc: 0.9861 - val_accuracy: 0.9524 - val_cost: 6.2435\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4363 - val_loss: 0.1394 - val_auc: 0.9866 - val_accuracy: 0.9530 - val_cost: 6.0059\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1237 - auc: 0.9891 - accuracy: 0.9581 - cost: 5.3077 - val_loss: 0.1375 - val_auc: 0.9867 - val_accuracy: 0.9546 - val_cost: 5.9245\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9589 - cost: 5.2076 - val_loss: 0.1371 - val_auc: 0.9868 - val_accuracy: 0.9551 - val_cost: 5.4655\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9598 - cost: 5.1028 - val_loss: 0.1333 - val_auc: 0.9872 - val_accuracy: 0.9574 - val_cost: 5.5827\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9772 - val_loss: 0.1329 - val_auc: 0.9873 - val_accuracy: 0.9572 - val_cost: 5.5176\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1153 - auc: 0.9902 - accuracy: 0.9620 - cost: 4.8306 - val_loss: 0.1321 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.1823\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9626 - cost: 4.7562 - val_loss: 0.1316 - val_auc: 0.9875 - val_accuracy: 0.9577 - val_cost: 5.3353\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9632 - cost: 4.6730 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9585 - val_cost: 5.5859\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9643 - cost: 4.5470 - val_loss: 0.1258 - val_auc: 0.9881 - val_accuracy: 0.9610 - val_cost: 4.9544\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1088 - auc: 0.9911 - accuracy: 0.9646 - cost: 4.5051 - val_loss: 0.1264 - val_auc: 0.9882 - val_accuracy: 0.9597 - val_cost: 5.2018\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4226 - val_loss: 0.1250 - val_auc: 0.9882 - val_accuracy: 0.9612 - val_cost: 4.8470\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1062 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3607 - val_loss: 0.1242 - val_auc: 0.9885 - val_accuracy: 0.9613 - val_cost: 5.0814\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2588 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9616 - val_cost: 4.9577\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9918 - accuracy: 0.9673 - cost: 4.1600 - val_loss: 0.1238 - val_auc: 0.9886 - val_accuracy: 0.9602 - val_cost: 4.7786\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9675 - cost: 4.1246 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9618 - val_cost: 5.0879\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1231 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9627 - val_cost: 4.8665\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0122 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9621 - val_cost: 4.6875\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9345 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9624 - val_cost: 4.8014\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9057 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9637 - val_cost: 4.8047\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9698 - cost: 3.8380 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9638 - val_cost: 4.4987\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9706 - cost: 3.7374 - val_loss: 0.1179 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 4.6257\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6886 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9646 - val_cost: 4.5703\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6916 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9635 - val_cost: 4.3229\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6846 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9653 - val_cost: 4.3555\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6674 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9662 - val_cost: 4.3359\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5928 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9661 - val_cost: 4.1504\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5296 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.1960\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4960 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9644 - val_cost: 4.3066\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4813 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.1178\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9731 - cost: 3.4322 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9662 - val_cost: 4.0755\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9735 - cost: 3.3726 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.2546\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3640 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9674 - val_cost: 3.9323\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2488 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 3.9811\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3278 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9669 - val_cost: 4.1536\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2883 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9676 - val_cost: 4.0592\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9680 - val_cost: 4.0625\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2416 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9678 - val_cost: 3.9876\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1502 - val_loss: 0.1103 - val_auc: 0.9902 - val_accuracy: 0.9672 - val_cost: 4.2741\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9938 - accuracy: 0.9754 - cost: 3.1449 - val_loss: 0.1109 - val_auc: 0.9903 - val_accuracy: 0.9680 - val_cost: 3.8118\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1440 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9675 - val_cost: 3.9616\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1479 - val_loss: 0.1069 - val_auc: 0.9907 - val_accuracy: 0.9678 - val_cost: 3.9876\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0588 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7337\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1112 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.5970\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0115 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9686 - val_cost: 3.8867\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0490 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9684 - val_cost: 3.9160\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0091 - val_loss: 0.1089 - val_auc: 0.9903 - val_accuracy: 0.9676 - val_cost: 3.9290\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0265 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.6296\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9031 - val_loss: 0.1060 - val_auc: 0.9907 - val_accuracy: 0.9693 - val_cost: 3.7988\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9636 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 3.8314\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9984 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 3.8314\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9409 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8944 - val_loss: 0.1055 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 3.8542\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8629 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9696 - val_cost: 3.8086\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8697 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9691 - val_cost: 3.8184\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8383 - val_loss: 0.1081 - val_auc: 0.9905 - val_accuracy: 0.9686 - val_cost: 3.7565\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8835 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.9128\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8417 - val_loss: 0.1068 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.6751\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8565 - val_loss: 0.1069 - val_auc: 0.9905 - val_accuracy: 0.9689 - val_cost: 3.7988\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8179 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.6686\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8539 - val_loss: 0.1041 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8478 - val_loss: 0.1047 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.8249\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7650 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9686 - val_cost: 3.9811\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7703 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.7370\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7696 - val_loss: 0.1051 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.5514\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7812 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9696 - val_cost: 3.7728\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7589 - val_loss: 0.1048 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.6882\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7652 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.6491\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7799 - val_loss: 0.1043 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.7988\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6904 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9694 - val_cost: 3.7370\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6938 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7399 - val_loss: 0.1041 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.6491\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6673 - val_loss: 0.1038 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.7012\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6888 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 4.0072\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6224 - val_loss: 0.1055 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.6914\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6271 - val_loss: 0.1055 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.7988\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6610 - val_loss: 0.1058 - val_auc: 0.9908 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6390 - val_loss: 0.1055 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6966 - val_loss: 0.1082 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.4375\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5479 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.6784\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6139 - val_loss: 0.1062 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5579 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.9095\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5770 - val_loss: 0.1065 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.7174\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5509 - val_loss: 0.1063 - val_auc: 0.9908 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5295 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9691 - val_cost: 3.8249\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5963 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.5677\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5730 - val_loss: 0.1079 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.6947\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6036 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.5057 - val_loss: 0.1051 - val_auc: 0.9909 - val_accuracy: 0.9705 - val_cost: 3.6491\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5287 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6030 - val_loss: 0.1075 - val_auc: 0.9904 - val_accuracy: 0.9696 - val_cost: 3.7012\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4852 - val_loss: 0.1074 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.7142\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5514 - val_loss: 0.1084 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4851 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4758 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.7207\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4822 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9700 - val_cost: 3.7305\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4720 - val_loss: 0.1068 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.8021\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5233 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.7435\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4924 - val_loss: 0.1069 - val_auc: 0.9905 - val_accuracy: 0.9716 - val_cost: 3.4993\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3854 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4473 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.5612\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4470 - val_loss: 0.1084 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.4766\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4979 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.5579\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4481 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.6198\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4502 - val_loss: 0.1071 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6882\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3969 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4292 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3906 - val_loss: 0.1076 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4302 - val_loss: 0.1080 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4582 - val_loss: 0.1068 - val_auc: 0.9905 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4131 - val_loss: 0.1078 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.6556\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4064 - val_loss: 0.1096 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7240\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4512 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9724 - val_cost: 3.4408\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3790 - val_loss: 0.1086 - val_auc: 0.9904 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3949 - val_loss: 0.1099 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3708 - val_loss: 0.1109 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.3138\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4216 - val_loss: 0.1081 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3719 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5514\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4096 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4212 - val_loss: 0.1094 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.3919\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3298 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6230\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3417 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3733 - val_loss: 0.1078 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.3398\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3187 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3787 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.6230\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2960 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.4408\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3533 - val_loss: 0.1093 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5482\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3593 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3440 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9726 - val_cost: 3.4180\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3270 - val_loss: 0.1082 - val_auc: 0.9905 - val_accuracy: 0.9721 - val_cost: 3.4798\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3473 - val_loss: 0.1077 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.4831\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3267 - val_loss: 0.1110 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.5970\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3499 - val_loss: 0.1096 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5905\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3415 - val_loss: 0.1112 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6751\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2918 - val_loss: 0.1124 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.2975\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2716 - val_loss: 0.1107 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.5352\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3068 - val_loss: 0.1107 - val_auc: 0.9905 - val_accuracy: 0.9713 - val_cost: 3.4570\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3423 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3264 - val_loss: 0.1089 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5905\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3625 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.3757\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3025 - val_loss: 0.1092 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.4245\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2849 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2868 - val_loss: 0.1085 - val_auc: 0.9903 - val_accuracy: 0.9721 - val_cost: 3.4961\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3251 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5449\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3203 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9721 - val_cost: 3.4473\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3161 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9720 - val_cost: 3.4538\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2687 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2948 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.5579\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2835 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.4017\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9958 - accuracy: 0.9826 - cost: 2.2366 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3529 - val_loss: 0.1103 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.4375\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2474 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.4993\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2920 - val_loss: 0.1104 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.5905\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2531 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.3626\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2712 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2584 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4049\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3087 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2212 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5677\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2530 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2477 - val_loss: 0.1117 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.4961\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2043 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5775\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1992 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2498 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.5449\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2081 - val_loss: 0.1119 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.4798\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2247 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.4049\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2503 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4147\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2465 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.7012\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2119 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4863\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2219 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.4342\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2293 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6328\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2322 - val_loss: 0.1134 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.6523\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.2083 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2118 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5905\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1999 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9723 - val_cost: 3.4147\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2188 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5807\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1497 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5026\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2236 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4245\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2331 - val_loss: 0.1140 - val_auc: 0.9901 - val_accuracy: 0.9732 - val_cost: 3.2812\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1590 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.3529\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2341 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9728 - val_cost: 3.4505\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1314 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9730 - val_cost: 3.3366\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.1948 - val_loss: 0.1105 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.2845\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1766 - val_loss: 0.1155 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4863\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1779 - val_loss: 0.1144 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.3952\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1746 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1632 - val_loss: 0.1122 - val_auc: 0.9903 - val_accuracy: 0.9731 - val_cost: 3.3594\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2197 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4408\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1555 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9731 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2200 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.2812\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1839 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4245\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1943 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4863\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1530 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9718 - val_cost: 3.5677\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1651 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4570\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1197 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4570\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1937 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5059\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1512 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4115\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1685 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2175 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1369 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.3008\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1575 - val_loss: 0.1130 - val_auc: 0.9903 - val_accuracy: 0.9721 - val_cost: 3.5254\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2444 - val_loss: 0.1151 - val_auc: 0.9895 - val_accuracy: 0.9733 - val_cost: 3.3366\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1194 - val_loss: 0.1173 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6361\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1529 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.5449\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1839 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.3268\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1906 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.1934\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1262 - val_loss: 0.1137 - val_auc: 0.9900 - val_accuracy: 0.9725 - val_cost: 3.3952\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1185 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9728 - val_cost: 3.3822\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1701 - val_loss: 0.1130 - val_auc: 0.9902 - val_accuracy: 0.9725 - val_cost: 3.4961\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1398 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.4766\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1346 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4342\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1198 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.4310\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1505 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4635\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1275 - val_loss: 0.1151 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.6003\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1219 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.3529\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1220 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4701\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1204 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6003\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1663 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.5091\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1364 - val_loss: 0.1152 - val_auc: 0.9899 - val_accuracy: 0.9727 - val_cost: 3.3854\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1189 - val_loss: 0.1152 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1282 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9734 - val_cost: 3.2845\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1348 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0973 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9728 - val_cost: 3.4538\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0517 - val_loss: 0.1161 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4993\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1827 - val_loss: 0.1141 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.4896\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1331 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.5840\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1365 - val_loss: 0.1179 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.4440\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1809 - val_loss: 0.1156 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4766\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1243 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0835 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.3301\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1163 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9723 - val_cost: 3.4049\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0810 - val_loss: 0.1174 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4798\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0646 - val_loss: 0.1155 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1661 - val_loss: 0.1157 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.4570\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1165 - val_loss: 0.1199 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.4180\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0861 - val_loss: 0.1167 - val_auc: 0.9899 - val_accuracy: 0.9725 - val_cost: 3.4180\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9840 - cost: 2.0603 - val_loss: 0.1182 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5124\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1255 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.4310\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.1094 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.4115\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0947 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.6035\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0915 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.3561\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0890 - val_loss: 0.1183 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3008\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0982 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.3822\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0882 - val_loss: 0.1158 - val_auc: 0.9901 - val_accuracy: 0.9731 - val_cost: 3.3594\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1182 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4049\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1255 - val_loss: 0.1156 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.4993\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1150 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5026\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0633 - val_loss: 0.1174 - val_auc: 0.9901 - val_accuracy: 0.9733 - val_cost: 3.3138\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9964 - accuracy: 0.9840 - cost: 2.0557 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9725 - val_cost: 3.4342\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0391 - val_loss: 0.1192 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0738 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.5742\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0941 - val_loss: 0.1172 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4082\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0741 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.4603\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0521 - val_loss: 0.1181 - val_auc: 0.9901 - val_accuracy: 0.9727 - val_cost: 3.4342\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0364 - val_loss: 0.1185 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4766\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1131 - auc: 0.9899 - accuracy: 0.9711 - cost: 3.5812\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.601182\n",
            "fold accuracy: 0.9710624814033508 - fold cost: 3.581249952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5258 - auc: 0.8020 - accuracy: 0.7321 - cost: 35.6462 - val_loss: 0.3906 - val_auc: 0.9027 - val_accuracy: 0.8305 - val_cost: 21.4876\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3465 - auc: 0.9237 - accuracy: 0.8528 - cost: 18.7410 - val_loss: 0.3156 - val_auc: 0.9365 - val_accuracy: 0.8672 - val_cost: 16.1882\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9431 - accuracy: 0.8756 - cost: 15.7371 - val_loss: 0.2858 - val_auc: 0.9482 - val_accuracy: 0.8830 - val_cost: 14.3262\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2713 - auc: 0.9534 - accuracy: 0.8902 - cost: 13.8963 - val_loss: 0.2642 - val_auc: 0.9567 - val_accuracy: 0.8944 - val_cost: 13.6914\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2487 - auc: 0.9609 - accuracy: 0.9010 - cost: 12.5549 - val_loss: 0.2400 - val_auc: 0.9637 - val_accuracy: 0.9085 - val_cost: 11.3184\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2283 - auc: 0.9670 - accuracy: 0.9100 - cost: 11.4013 - val_loss: 0.2229 - val_auc: 0.9685 - val_accuracy: 0.9160 - val_cost: 10.3678\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2116 - auc: 0.9716 - accuracy: 0.9182 - cost: 10.3689 - val_loss: 0.2111 - val_auc: 0.9717 - val_accuracy: 0.9199 - val_cost: 9.7656\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1991 - auc: 0.9746 - accuracy: 0.9241 - cost: 9.5972 - val_loss: 0.1989 - val_auc: 0.9748 - val_accuracy: 0.9267 - val_cost: 9.1439\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1882 - auc: 0.9772 - accuracy: 0.9292 - cost: 8.9770 - val_loss: 0.1901 - val_auc: 0.9767 - val_accuracy: 0.9306 - val_cost: 8.7435\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1802 - auc: 0.9790 - accuracy: 0.9330 - cost: 8.4943 - val_loss: 0.1844 - val_auc: 0.9781 - val_accuracy: 0.9333 - val_cost: 8.6230\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1715 - auc: 0.9809 - accuracy: 0.9371 - cost: 7.9891 - val_loss: 0.1770 - val_auc: 0.9795 - val_accuracy: 0.9360 - val_cost: 8.3431\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1660 - auc: 0.9819 - accuracy: 0.9392 - cost: 7.7193 - val_loss: 0.1733 - val_auc: 0.9807 - val_accuracy: 0.9376 - val_cost: 7.9818\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1609 - auc: 0.9830 - accuracy: 0.9417 - cost: 7.4128 - val_loss: 0.1685 - val_auc: 0.9813 - val_accuracy: 0.9399 - val_cost: 7.7181\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1560 - auc: 0.9839 - accuracy: 0.9438 - cost: 7.1293 - val_loss: 0.1647 - val_auc: 0.9823 - val_accuracy: 0.9408 - val_cost: 7.4447\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1515 - auc: 0.9846 - accuracy: 0.9457 - cost: 6.8799 - val_loss: 0.1610 - val_auc: 0.9829 - val_accuracy: 0.9428 - val_cost: 7.2005\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1475 - auc: 0.9853 - accuracy: 0.9479 - cost: 6.5998 - val_loss: 0.1585 - val_auc: 0.9834 - val_accuracy: 0.9423 - val_cost: 7.7930\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1438 - auc: 0.9859 - accuracy: 0.9494 - cost: 6.4252 - val_loss: 0.1554 - val_auc: 0.9839 - val_accuracy: 0.9441 - val_cost: 7.0508\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1414 - auc: 0.9864 - accuracy: 0.9507 - cost: 6.2508 - val_loss: 0.1522 - val_auc: 0.9844 - val_accuracy: 0.9458 - val_cost: 7.0280\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9517 - cost: 6.1288 - val_loss: 0.1509 - val_auc: 0.9848 - val_accuracy: 0.9461 - val_cost: 6.8424\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1367 - auc: 0.9870 - accuracy: 0.9528 - cost: 5.9839 - val_loss: 0.1480 - val_auc: 0.9852 - val_accuracy: 0.9476 - val_cost: 6.7122\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9877 - accuracy: 0.9534 - cost: 5.9194 - val_loss: 0.1476 - val_auc: 0.9853 - val_accuracy: 0.9487 - val_cost: 6.6829\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1317 - auc: 0.9878 - accuracy: 0.9547 - cost: 5.7568 - val_loss: 0.1447 - val_auc: 0.9857 - val_accuracy: 0.9503 - val_cost: 6.2956\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9882 - accuracy: 0.9562 - cost: 5.5613 - val_loss: 0.1420 - val_auc: 0.9860 - val_accuracy: 0.9523 - val_cost: 5.9831\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9572 - cost: 5.4282 - val_loss: 0.1419 - val_auc: 0.9860 - val_accuracy: 0.9517 - val_cost: 6.2402\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1251 - auc: 0.9888 - accuracy: 0.9575 - cost: 5.4079 - val_loss: 0.1400 - val_auc: 0.9862 - val_accuracy: 0.9526 - val_cost: 6.2077\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9891 - accuracy: 0.9586 - cost: 5.2559 - val_loss: 0.1383 - val_auc: 0.9866 - val_accuracy: 0.9538 - val_cost: 5.9668\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1210 - auc: 0.9894 - accuracy: 0.9593 - cost: 5.1770 - val_loss: 0.1389 - val_auc: 0.9866 - val_accuracy: 0.9536 - val_cost: 6.0807\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9895 - accuracy: 0.9595 - cost: 5.1265 - val_loss: 0.1352 - val_auc: 0.9868 - val_accuracy: 0.9553 - val_cost: 5.8822\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9932 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9547 - val_cost: 5.9993\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9900 - accuracy: 0.9611 - cost: 4.9530 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9545 - val_cost: 5.9473\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1136 - auc: 0.9903 - accuracy: 0.9627 - cost: 4.7330 - val_loss: 0.1308 - val_auc: 0.9876 - val_accuracy: 0.9572 - val_cost: 5.5729\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9905 - accuracy: 0.9633 - cost: 4.6578 - val_loss: 0.1304 - val_auc: 0.9875 - val_accuracy: 0.9562 - val_cost: 5.7292\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6468 - val_loss: 0.1287 - val_auc: 0.9876 - val_accuracy: 0.9587 - val_cost: 5.5143\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1098 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5642 - val_loss: 0.1286 - val_auc: 0.9879 - val_accuracy: 0.9569 - val_cost: 5.6250\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1083 - auc: 0.9911 - accuracy: 0.9645 - cost: 4.5344 - val_loss: 0.1262 - val_auc: 0.9877 - val_accuracy: 0.9592 - val_cost: 5.4427\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3616 - val_loss: 0.1254 - val_auc: 0.9882 - val_accuracy: 0.9598 - val_cost: 5.2507\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9663 - cost: 4.2760 - val_loss: 0.1261 - val_auc: 0.9881 - val_accuracy: 0.9603 - val_cost: 5.0879\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1052 - auc: 0.9913 - accuracy: 0.9663 - cost: 4.2919 - val_loss: 0.1233 - val_auc: 0.9883 - val_accuracy: 0.9603 - val_cost: 5.2148\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9667 - cost: 4.2448 - val_loss: 0.1223 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 5.1497\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9674 - cost: 4.1648 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9614 - val_cost: 5.0553\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9917 - accuracy: 0.9680 - cost: 4.0827 - val_loss: 0.1217 - val_auc: 0.9886 - val_accuracy: 0.9622 - val_cost: 4.9284\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9920 - accuracy: 0.9686 - cost: 4.0092 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9624 - val_cost: 4.5573\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9920 - accuracy: 0.9688 - cost: 3.9746 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9638 - val_cost: 4.6484\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.8659 - val_loss: 0.1188 - val_auc: 0.9888 - val_accuracy: 0.9629 - val_cost: 4.8079\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8452 - val_loss: 0.1182 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.3685\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9700 - cost: 3.8148 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9626 - val_cost: 4.5020\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9703 - cost: 3.7802 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.5020\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9926 - accuracy: 0.9708 - cost: 3.7052 - val_loss: 0.1158 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.5182\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9712 - cost: 3.6673 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9643 - val_cost: 4.5996\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9928 - accuracy: 0.9717 - cost: 3.6110 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.3359\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9719 - cost: 3.5851 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9653 - val_cost: 4.4076\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5284 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9648 - val_cost: 4.2969\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9727 - cost: 3.4738 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9650 - val_cost: 4.4792\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5215 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.0951\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5277 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.3197\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4494 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9657 - val_cost: 4.2122\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4364 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 3.9909\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.3908 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9673 - val_cost: 3.9616\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9736 - cost: 3.3709 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.3783\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3866 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9662 - val_cost: 4.1602\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3389 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.0885\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3441 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.0202\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9741 - cost: 3.3030 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.1276\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2931 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9659 - val_cost: 4.3034\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2337 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9676 - val_cost: 3.9941\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1778 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9666 - val_cost: 4.1211\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2413 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9665 - val_cost: 4.1276\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9938 - accuracy: 0.9756 - cost: 3.1213 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 3.9421\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1883 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9673 - val_cost: 4.0039\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1446 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.0137\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0968 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9669 - val_cost: 3.9290\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.0996 - val_loss: 0.1095 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.0820\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1253 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 3.8997\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0272 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9677 - val_cost: 3.9225\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0475 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.0560\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0370 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9453\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0132 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.8477\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0475 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9030\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0361 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8477\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9425 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9388\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0027 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9681 - val_cost: 3.9258\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9771 - cost: 2.9160 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9095\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9063 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9682 - val_cost: 3.9160\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9180 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.0983\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9679 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8607\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8784 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.7695\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9446 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7305\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8767 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.7305\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8584 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 3.8053\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8603 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9676 - val_cost: 3.9844\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8019 - val_loss: 0.1122 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8676 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.7533\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8689 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 3.9486\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8284 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8216\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7832 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9876\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8544 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.7695\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8393 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8184\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7205 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 3.8672\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7898 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9486\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8367 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9684 - val_cost: 3.9323\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7473 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.7760\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7692 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.7240\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7515 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7728\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6983 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 3.8346\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7175 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9681 - val_cost: 3.9681\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7088 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9388\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7058 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8053\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7383 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8607\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.7598\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6805 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.0625\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7325 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.7826\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6954 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 3.9746\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6637 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.8444\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6069 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8802\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6607 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9676 - val_cost: 3.8997\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7587 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8184\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6536 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6383 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6642 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 3.8542\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6524 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 3.8574\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6236 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.8021\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6231 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7174\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5919 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.8997\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5784 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9682 - val_cost: 3.8184\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6509 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8118\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5688 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7988\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6386 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7630\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6533 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.7956\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6065 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7988\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6589 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6312 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7500\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6039 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.8542\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5997 - val_loss: 0.1133 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.8509\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5557 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5415 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8802\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5788 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.7793\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5717 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.8346\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5204 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9811\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5380 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6751\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5410 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.7435\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5757 - val_loss: 0.1153 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0430\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6228 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9746\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5458 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7826\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5299 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8086\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5562 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 3.8802\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4886 - val_loss: 0.1140 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7337\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5438 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.5102 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9674 - val_cost: 3.9290\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5567 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.8965\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5451 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5054 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5462 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7337\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5402 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9695 - val_cost: 3.7956\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5112 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 3.9128\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8346\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5585 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 3.9388\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4124 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7826\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5163 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8118\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4984 - val_loss: 0.1173 - val_auc: 0.9890 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4475 - val_loss: 0.1171 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.9030\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5166 - val_loss: 0.1176 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.7142\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1158 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.8249\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4658 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.8932\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4856 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.6816\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4792 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7728\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5203 - val_loss: 0.1215 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5154 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.6914\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4452 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.8314\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4524 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6165\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4533 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.7077\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4586 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.7435\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4216 - val_loss: 0.1183 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.8184\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4344 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3496 - val_loss: 0.1173 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5970\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4904 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.5938\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4383 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.8411\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4927 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.7044\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4227 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9673 - val_cost: 3.9974\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4914 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4206 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3730 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8346\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4746 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7533\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4248 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.7467\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4247 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.6556\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4620 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.7337\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3995 - val_loss: 0.1199 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4399 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6719\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4407 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6328\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3958 - val_loss: 0.1202 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.8086\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4050 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9699 - val_cost: 3.7695\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.3952 - val_loss: 0.1216 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.9323\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4287 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.6849\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3361 - val_loss: 0.1212 - val_auc: 0.9885 - val_accuracy: 0.9705 - val_cost: 3.6784\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3713 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.7174\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4241 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9679 - val_cost: 3.8770\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9960 - accuracy: 0.9808 - cost: 2.4540 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4093 - val_loss: 0.1218 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3514 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.7077\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3482 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9680 - val_cost: 3.8672\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3452 - val_loss: 0.1235 - val_auc: 0.9887 - val_accuracy: 0.9693 - val_cost: 3.7142\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3625 - val_loss: 0.1225 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3338 - val_loss: 0.1220 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3867 - val_loss: 0.1236 - val_auc: 0.9885 - val_accuracy: 0.9698 - val_cost: 3.7207\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3664 - val_loss: 0.1225 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 3.8835\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4401 - val_loss: 0.1214 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.7565\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3459 - val_loss: 0.1238 - val_auc: 0.9885 - val_accuracy: 0.9690 - val_cost: 3.8281\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3414 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8477\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4215 - val_loss: 0.1231 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.7760\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3471 - val_loss: 0.1213 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8932\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3816 - val_loss: 0.1218 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6426\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3260 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3527 - val_loss: 0.1211 - val_auc: 0.9885 - val_accuracy: 0.9709 - val_cost: 3.6133\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3528 - val_loss: 0.1230 - val_auc: 0.9884 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3009 - val_loss: 0.1239 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.7240\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3743 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9692 - val_cost: 3.8737\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3452 - val_loss: 0.1244 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.6914\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3349 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.9030\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3123 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3114 - val_loss: 0.1240 - val_auc: 0.9888 - val_accuracy: 0.9689 - val_cost: 3.7402\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3599 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.6849\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3999 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.7630\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2978 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.8184\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3470 - val_loss: 0.1241 - val_auc: 0.9882 - val_accuracy: 0.9686 - val_cost: 3.8053\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3740 - val_loss: 0.1214 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.7500\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3595 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9686 - val_cost: 3.7956\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1008 - auc: 0.9915 - accuracy: 0.9722 - cost: 3.5438\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:08.700796\n",
            "fold accuracy: 0.9721875190734863 - fold cost: 3.543750047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5249 - auc: 0.8029 - accuracy: 0.7321 - cost: 35.5695 - val_loss: 0.3867 - val_auc: 0.9046 - val_accuracy: 0.8326 - val_cost: 21.4388\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3461 - auc: 0.9239 - accuracy: 0.8521 - cost: 18.8091 - val_loss: 0.3120 - val_auc: 0.9382 - val_accuracy: 0.8698 - val_cost: 15.9473\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2984 - auc: 0.9437 - accuracy: 0.8751 - cost: 15.8331 - val_loss: 0.2799 - val_auc: 0.9505 - val_accuracy: 0.8858 - val_cost: 14.0007\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2709 - auc: 0.9537 - accuracy: 0.8895 - cost: 13.9755 - val_loss: 0.2557 - val_auc: 0.9587 - val_accuracy: 0.8967 - val_cost: 13.0208\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9009 - cost: 12.5220 - val_loss: 0.2362 - val_auc: 0.9650 - val_accuracy: 0.9080 - val_cost: 11.1328\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2273 - auc: 0.9675 - accuracy: 0.9114 - cost: 11.2167 - val_loss: 0.2191 - val_auc: 0.9695 - val_accuracy: 0.9156 - val_cost: 10.3158\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2109 - auc: 0.9718 - accuracy: 0.9185 - cost: 10.2994 - val_loss: 0.2057 - val_auc: 0.9733 - val_accuracy: 0.9241 - val_cost: 9.4336\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1978 - auc: 0.9751 - accuracy: 0.9243 - cost: 9.5801 - val_loss: 0.1927 - val_auc: 0.9763 - val_accuracy: 0.9308 - val_cost: 8.4701\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1869 - auc: 0.9777 - accuracy: 0.9295 - cost: 8.9024 - val_loss: 0.1843 - val_auc: 0.9782 - val_accuracy: 0.9342 - val_cost: 7.9590\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1782 - auc: 0.9795 - accuracy: 0.9336 - cost: 8.4084 - val_loss: 0.1772 - val_auc: 0.9796 - val_accuracy: 0.9383 - val_cost: 7.9785\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1704 - auc: 0.9811 - accuracy: 0.9372 - cost: 7.9602 - val_loss: 0.1716 - val_auc: 0.9808 - val_accuracy: 0.9400 - val_cost: 7.3014\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1638 - auc: 0.9825 - accuracy: 0.9395 - cost: 7.6610 - val_loss: 0.1658 - val_auc: 0.9820 - val_accuracy: 0.9421 - val_cost: 7.4577\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1586 - auc: 0.9834 - accuracy: 0.9430 - cost: 7.2252 - val_loss: 0.1618 - val_auc: 0.9826 - val_accuracy: 0.9435 - val_cost: 7.3698\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1537 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9174 - val_loss: 0.1589 - val_auc: 0.9835 - val_accuracy: 0.9446 - val_cost: 6.9303\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1497 - auc: 0.9850 - accuracy: 0.9472 - cost: 6.6974 - val_loss: 0.1565 - val_auc: 0.9840 - val_accuracy: 0.9446 - val_cost: 6.9954\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1453 - auc: 0.9858 - accuracy: 0.9485 - cost: 6.5347 - val_loss: 0.1512 - val_auc: 0.9848 - val_accuracy: 0.9473 - val_cost: 6.8717\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1423 - auc: 0.9863 - accuracy: 0.9495 - cost: 6.4018 - val_loss: 0.1496 - val_auc: 0.9849 - val_accuracy: 0.9484 - val_cost: 6.8327\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9510 - cost: 6.2037 - val_loss: 0.1471 - val_auc: 0.9853 - val_accuracy: 0.9496 - val_cost: 6.9206\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1365 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0092 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9492 - val_cost: 6.7480\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1342 - auc: 0.9876 - accuracy: 0.9539 - cost: 5.8497 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9516 - val_cost: 6.2988\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1320 - auc: 0.9879 - accuracy: 0.9542 - cost: 5.8140 - val_loss: 0.1426 - val_auc: 0.9860 - val_accuracy: 0.9518 - val_cost: 6.3477\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1304 - auc: 0.9881 - accuracy: 0.9558 - cost: 5.5970 - val_loss: 0.1415 - val_auc: 0.9862 - val_accuracy: 0.9522 - val_cost: 5.9635\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1279 - auc: 0.9885 - accuracy: 0.9570 - cost: 5.4547 - val_loss: 0.1401 - val_auc: 0.9863 - val_accuracy: 0.9537 - val_cost: 6.0938\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1259 - auc: 0.9888 - accuracy: 0.9570 - cost: 5.4567 - val_loss: 0.1380 - val_auc: 0.9868 - val_accuracy: 0.9535 - val_cost: 6.0677\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9891 - accuracy: 0.9587 - cost: 5.2547 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9558 - val_cost: 5.9147\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1223 - auc: 0.9893 - accuracy: 0.9591 - cost: 5.2021 - val_loss: 0.1362 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.5794\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9895 - accuracy: 0.9598 - cost: 5.0958 - val_loss: 0.1345 - val_auc: 0.9871 - val_accuracy: 0.9556 - val_cost: 6.0840\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9898 - accuracy: 0.9607 - cost: 4.9781 - val_loss: 0.1343 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.4883\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1169 - auc: 0.9901 - accuracy: 0.9609 - cost: 4.9643 - val_loss: 0.1337 - val_auc: 0.9871 - val_accuracy: 0.9568 - val_cost: 5.3418\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1156 - auc: 0.9902 - accuracy: 0.9614 - cost: 4.9017 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9585 - val_cost: 5.4622\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.7992 - val_loss: 0.1320 - val_auc: 0.9873 - val_accuracy: 0.9577 - val_cost: 5.2507\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1125 - auc: 0.9906 - accuracy: 0.9628 - cost: 4.7253 - val_loss: 0.1297 - val_auc: 0.9877 - val_accuracy: 0.9590 - val_cost: 5.3353\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1116 - auc: 0.9907 - accuracy: 0.9635 - cost: 4.6345 - val_loss: 0.1287 - val_auc: 0.9879 - val_accuracy: 0.9593 - val_cost: 4.9577\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9638 - cost: 4.5845 - val_loss: 0.1282 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 4.9154\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9653 - cost: 4.3951 - val_loss: 0.1270 - val_auc: 0.9877 - val_accuracy: 0.9602 - val_cost: 4.9349\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9913 - accuracy: 0.9651 - cost: 4.4206 - val_loss: 0.1274 - val_auc: 0.9878 - val_accuracy: 0.9599 - val_cost: 5.0293\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1065 - auc: 0.9913 - accuracy: 0.9653 - cost: 4.3962 - val_loss: 0.1255 - val_auc: 0.9881 - val_accuracy: 0.9597 - val_cost: 5.4297\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1046 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3196 - val_loss: 0.1252 - val_auc: 0.9882 - val_accuracy: 0.9613 - val_cost: 4.8568\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2100 - val_loss: 0.1240 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.8177\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9918 - accuracy: 0.9671 - cost: 4.1893 - val_loss: 0.1229 - val_auc: 0.9883 - val_accuracy: 0.9632 - val_cost: 4.6940\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9679 - cost: 4.0708 - val_loss: 0.1232 - val_auc: 0.9882 - val_accuracy: 0.9632 - val_cost: 4.7786\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0553 - val_loss: 0.1222 - val_auc: 0.9883 - val_accuracy: 0.9627 - val_cost: 4.7949\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9899 - val_loss: 0.1226 - val_auc: 0.9883 - val_accuracy: 0.9627 - val_cost: 4.6810\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9894 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9635 - val_cost: 4.8861\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8937 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5182\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9691 - cost: 3.9156 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9633 - val_cost: 4.8242\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9701 - cost: 3.7977 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 5.0488\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9703 - cost: 3.7830 - val_loss: 0.1180 - val_auc: 0.9892 - val_accuracy: 0.9642 - val_cost: 4.6354\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9707 - cost: 3.7256 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.8405\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0933 - auc: 0.9927 - accuracy: 0.9711 - cost: 3.6748 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9654 - val_cost: 4.3197\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6482 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9650 - val_cost: 4.3490\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9712 - cost: 3.6782 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9644 - val_cost: 4.6257\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5831 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9664 - val_cost: 4.4564\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5416 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9660 - val_cost: 4.4596\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5384 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9659 - val_cost: 4.3099\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4542 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9661 - val_cost: 4.2578\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.3979 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.2188\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3441 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.1146\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9737 - cost: 3.3557 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0332\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9736 - cost: 3.3542 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 4.1146\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9743 - cost: 3.2779 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9616\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9746 - cost: 3.2452 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 3.9355\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2895 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 4.2741\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2368 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9673 - val_cost: 4.1602\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2203 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.8574\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1810 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7891\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1331 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 4.0658\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1281 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 4.0234\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1138 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.8509\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0498 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8867\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0732 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9684 - val_cost: 3.9681\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9763 - cost: 3.0294 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9128\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0788 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0238 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.6589\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0799 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.0755\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0374 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9062\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9770 - cost: 2.9347 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 4.1471\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0181 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8118\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9535 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9696 - val_cost: 3.8835\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9776 - cost: 2.8525 - val_loss: 0.1075 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8346\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8525 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.9160\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9273 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.9258\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8627 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.9714\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8932\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8314\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9205 - val_loss: 0.1082 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 4.0267\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8918 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7760\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8311 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9062\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8357 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8216\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7673 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8607\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7778 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8444\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7990 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.7793\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7692 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7337\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7218 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7641 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7826\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7703 - val_loss: 0.1076 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7733 - val_loss: 0.1063 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6751\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6959 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7142\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7426 - val_loss: 0.1079 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7123 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6816\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6803 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7630\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9948 - accuracy: 0.9792 - cost: 2.6611 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7793\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6696 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9388\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6318 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6721 - val_loss: 0.1097 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5872\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9949 - accuracy: 0.9799 - cost: 2.5735 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6035\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6018 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6340 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6431 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8184\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6509 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7858\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5884 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6142 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.7728\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6034 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.7174\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6513 - val_loss: 0.1081 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6849\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5859 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8509\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5739 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5915 - val_loss: 0.1093 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6816\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6232 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7044\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5920 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.5286\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5627 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.5677\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6373 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5872\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5596 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7728\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8444\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5695 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.6393\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5151 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5460 - val_loss: 0.1118 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5215 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4837 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6426\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9953 - accuracy: 0.9808 - cost: 2.4517 - val_loss: 0.1091 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4793 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4622 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.7826\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4900 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.7858\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4568 - val_loss: 0.1097 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.6361\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4601 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6849\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9812 - cost: 2.4051 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.6328\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4313 - val_loss: 0.1104 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4751 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.3952\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4320 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7695\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4684 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.4766\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4303 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7077\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3712 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.5514\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3877 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.4928\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9954 - accuracy: 0.9814 - cost: 2.3758 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7826\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3784 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.6621\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4435 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7565\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3488 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7500\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4288 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.6230\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4540 - val_loss: 0.1122 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.4440\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3765 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6328\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.5417\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.4017 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.5612\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3640 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6296\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3805 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6133\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4161 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3867 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3250 - val_loss: 0.1119 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.6686\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3472 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5579\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3560 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3339 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.4408\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3513 - val_loss: 0.1116 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.7891\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3815 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3150 - val_loss: 0.1120 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3622 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3299 - val_loss: 0.1102 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.5547\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3557 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8477\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3156 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.5938\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3307 - val_loss: 0.1088 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6882\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3335 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6426\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3176 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4733\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.2964 - val_loss: 0.1117 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3278 - val_loss: 0.1121 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.6361\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3472 - val_loss: 0.1136 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6882\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3222 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.4115\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3164 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.4766\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2733 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9725 - val_cost: 3.5449\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3212 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3246 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.4863\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2858 - val_loss: 0.1123 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4310\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3198 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2431 - val_loss: 0.1122 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.7077\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3101 - val_loss: 0.1130 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.6621\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2464 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6589\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2623 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.7109\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2220 - val_loss: 0.1160 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4896\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2927 - val_loss: 0.1133 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.3789\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2967 - val_loss: 0.1118 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2949 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4408\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2491 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.4473\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2777 - val_loss: 0.1151 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.7044\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2502 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7956\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2576 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6686\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2343 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.3757\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2420 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3151 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5970\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2544 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.6393\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2088 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.4342\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2649 - val_loss: 0.1139 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2470 - val_loss: 0.1161 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.4896\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2972 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5059\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2448 - val_loss: 0.1162 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6003\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2728 - val_loss: 0.1180 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.4538\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2267 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4082\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2949 - val_loss: 0.1161 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2365 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1921 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5254\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2053 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6784\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2296 - val_loss: 0.1134 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6165\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2798 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4440\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2042 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4570\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2661 - val_loss: 0.1176 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5905\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1805 - val_loss: 0.1132 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6556\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2654 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2150 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1899 - val_loss: 0.1151 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.4668\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2208 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2112 - val_loss: 0.1133 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.4896\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1957 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.6523\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1727 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2332 - val_loss: 0.1161 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4733\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1721 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.8053\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2350 - val_loss: 0.1187 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.4603\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9961 - accuracy: 0.9833 - cost: 2.1479 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1760 - val_loss: 0.1172 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2110 - val_loss: 0.1188 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2331 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4440\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1757 - val_loss: 0.1189 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1746 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1737 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6914\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1582 - val_loss: 0.1165 - val_auc: 0.9899 - val_accuracy: 0.9724 - val_cost: 3.5775\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9833 - cost: 2.1542 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.3984\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1915 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.4342\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1501 - val_loss: 0.1195 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1819 - val_loss: 0.1170 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5482\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1911 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.6556\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1614 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4668\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2193 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2002 - val_loss: 0.1167 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6491\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5026\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2396 - val_loss: 0.1166 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.5938\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1930 - val_loss: 0.1187 - val_auc: 0.9897 - val_accuracy: 0.9727 - val_cost: 3.3398\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1430 - val_loss: 0.1191 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4375\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1519 - val_loss: 0.1198 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.5449\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2093 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4408\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2125 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.4766\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2136 - val_loss: 0.1168 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4701\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1593 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4538\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1783 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.4310\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.1998 - val_loss: 0.1185 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1689 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6816\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2468 - val_loss: 0.1175 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6361\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1236 - val_loss: 0.1177 - val_auc: 0.9896 - val_accuracy: 0.9723 - val_cost: 3.4082\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2265 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.4115\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1954 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4245\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1534 - val_loss: 0.1202 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5384\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.3431\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1334 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.3691\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2141 - val_loss: 0.1217 - val_auc: 0.9893 - val_accuracy: 0.9725 - val_cost: 3.4017\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9833 - cost: 2.1563 - val_loss: 0.1186 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.3073\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1160 - val_loss: 0.1175 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4212\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1326 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4310\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1183 - val_loss: 0.1195 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.5026\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1126 - val_loss: 0.1188 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.4473\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1581 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4408\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1855 - val_loss: 0.1217 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.4863\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0947 - val_loss: 0.1237 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.3203\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1642 - val_loss: 0.1198 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1854 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9724 - val_cost: 3.2194\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1501 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1154 - val_loss: 0.1212 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.3691\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1321 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4310\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1754 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.4375\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1493 - val_loss: 0.1195 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1459 - val_loss: 0.1186 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5482\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0838 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.5840\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1574 - val_loss: 0.1200 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4766\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0885 - val_loss: 0.1206 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0892 - val_loss: 0.1170 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.5221\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1228 - val_loss: 0.1210 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6263\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1297 - val_loss: 0.1214 - val_auc: 0.9897 - val_accuracy: 0.9725 - val_cost: 3.1934\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1067 - val_loss: 0.1197 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.4212\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1424 - val_loss: 0.1202 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.6296\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1584 - val_loss: 0.1195 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5840\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1143 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.4375\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1131 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.3952\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1084 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.1058 - val_loss: 0.1197 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.4375\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9967 - accuracy: 0.9832 - cost: 2.1489 - val_loss: 0.1210 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6230\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.0991 - val_loss: 0.1245 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.2006 - val_loss: 0.1209 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.4961\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0240 - val_loss: 0.1222 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.4896\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1225 - val_loss: 0.1211 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.5579\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0676 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5059\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0359 - val_loss: 0.1229 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6426\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1665 - val_loss: 0.1220 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1349 - val_loss: 0.1215 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.0901 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4538\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9967 - accuracy: 0.9835 - cost: 2.1262 - val_loss: 0.1207 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1311 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.3984\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0656 - val_loss: 0.1236 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4408\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0768 - val_loss: 0.1236 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1008 - val_loss: 0.1230 - val_auc: 0.9893 - val_accuracy: 0.9726 - val_cost: 3.1868\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0806 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5156\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9967 - accuracy: 0.9834 - cost: 2.1178 - val_loss: 0.1247 - val_auc: 0.9893 - val_accuracy: 0.9716 - val_cost: 3.2910\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0663 - val_loss: 0.1213 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.7174\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0991 - val_loss: 0.1243 - val_auc: 0.9890 - val_accuracy: 0.9718 - val_cost: 3.5026\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9836 - cost: 2.1127 - val_loss: 0.1238 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0653 - val_loss: 0.1221 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4310\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0879 - val_loss: 0.1206 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0861 - val_loss: 0.1269 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.4766\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0305 - val_loss: 0.1231 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.4668\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0870 - val_loss: 0.1212 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.2715\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1540 - val_loss: 0.1229 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.5970\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0784 - val_loss: 0.1232 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0489 - val_loss: 0.1234 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.5319\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0724 - val_loss: 0.1214 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.4928\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0686 - val_loss: 0.1236 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.4603\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0553 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0960 - val_loss: 0.1209 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5352\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0889 - val_loss: 0.1206 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5938\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9967 - accuracy: 0.9842 - cost: 2.0349 - val_loss: 0.1232 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0536 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0314 - val_loss: 0.1212 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5612\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0689 - val_loss: 0.1238 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5417\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0542 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0551 - val_loss: 0.1250 - val_auc: 0.9890 - val_accuracy: 0.9716 - val_cost: 3.3724\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9837 - cost: 2.0885 - val_loss: 0.1223 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5612\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9845 - cost: 1.9917 - val_loss: 0.1220 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1162 - val_loss: 0.1233 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.4277\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0861 - val_loss: 0.1234 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5352\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0683 - val_loss: 0.1254 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.4212\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0926 - val_loss: 0.1239 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.3919\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0547 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0696 - val_loss: 0.1241 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5612\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0905 - val_loss: 0.1236 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.2617\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0543 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0618 - val_loss: 0.1223 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5156\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1071 - val_loss: 0.1244 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.2910\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9969 - accuracy: 0.9839 - cost: 2.0723 - val_loss: 0.1264 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4375\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9841 - cost: 2.0475 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9720 - val_cost: 3.4115\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0503 - val_loss: 0.1197 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0544 - auc: 0.9967 - accuracy: 0.9840 - cost: 2.0551 - val_loss: 0.1230 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4701\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0541 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0316 - val_loss: 0.1226 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0367 - val_loss: 0.1233 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.4505\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0535 - val_loss: 0.1227 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.4342\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0534 - auc: 0.9969 - accuracy: 0.9841 - cost: 2.0339 - val_loss: 0.1257 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0535 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0463 - val_loss: 0.1239 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4082\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0454 - val_loss: 0.1257 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.4766\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0540 - auc: 0.9967 - accuracy: 0.9844 - cost: 1.9982 - val_loss: 0.1233 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5286\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0533 - auc: 0.9968 - accuracy: 0.9843 - cost: 2.0179 - val_loss: 0.1231 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.4831\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0672 - val_loss: 0.1230 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3398\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0537 - auc: 0.9968 - accuracy: 0.9838 - cost: 2.0880 - val_loss: 0.1223 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0747 - val_loss: 0.1267 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.3691\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0645 - val_loss: 0.1231 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4733\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0538 - auc: 0.9968 - accuracy: 0.9839 - cost: 2.0496 - val_loss: 0.1227 - val_auc: 0.9892 - val_accuracy: 0.9722 - val_cost: 3.2357\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0539 - auc: 0.9968 - accuracy: 0.9842 - cost: 2.0346 - val_loss: 0.1217 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.1966\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0545 - auc: 0.9968 - accuracy: 0.9840 - cost: 2.0457 - val_loss: 0.1252 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.3073\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1114 - auc: 0.9894 - accuracy: 0.9723 - cost: 3.5031\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:19.503687\n",
            "fold accuracy: 0.9723125100135803 - fold cost: 3.503124952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5280 - auc: 0.7996 - accuracy: 0.7308 - cost: 35.7990 - val_loss: 0.3931 - val_auc: 0.9017 - val_accuracy: 0.8292 - val_cost: 22.3730\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3484 - auc: 0.9228 - accuracy: 0.8502 - cost: 19.0535 - val_loss: 0.3144 - val_auc: 0.9370 - val_accuracy: 0.8659 - val_cost: 16.6243\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8758 - cost: 15.7348 - val_loss: 0.2836 - val_auc: 0.9490 - val_accuracy: 0.8833 - val_cost: 14.2285\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2718 - auc: 0.9532 - accuracy: 0.8890 - cost: 14.0779 - val_loss: 0.2587 - val_auc: 0.9575 - val_accuracy: 0.8956 - val_cost: 12.8320\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2486 - auc: 0.9610 - accuracy: 0.9005 - cost: 12.5871 - val_loss: 0.2398 - val_auc: 0.9638 - val_accuracy: 0.9062 - val_cost: 11.5104\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2285 - auc: 0.9670 - accuracy: 0.9110 - cost: 11.2494 - val_loss: 0.2207 - val_auc: 0.9692 - val_accuracy: 0.9145 - val_cost: 10.6576\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2118 - auc: 0.9716 - accuracy: 0.9180 - cost: 10.3770 - val_loss: 0.2074 - val_auc: 0.9727 - val_accuracy: 0.9208 - val_cost: 9.7949\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1991 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6775 - val_loss: 0.1958 - val_auc: 0.9755 - val_accuracy: 0.9268 - val_cost: 8.9746\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1882 - auc: 0.9773 - accuracy: 0.9293 - cost: 8.9484 - val_loss: 0.1868 - val_auc: 0.9777 - val_accuracy: 0.9313 - val_cost: 8.5124\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1794 - auc: 0.9793 - accuracy: 0.9336 - cost: 8.4137 - val_loss: 0.1794 - val_auc: 0.9793 - val_accuracy: 0.9349 - val_cost: 8.3268\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1712 - auc: 0.9810 - accuracy: 0.9374 - cost: 7.9323 - val_loss: 0.1728 - val_auc: 0.9807 - val_accuracy: 0.9387 - val_cost: 7.8451\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1643 - auc: 0.9824 - accuracy: 0.9405 - cost: 7.5567 - val_loss: 0.1690 - val_auc: 0.9812 - val_accuracy: 0.9404 - val_cost: 7.5781\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9424 - cost: 7.3219 - val_loss: 0.1633 - val_auc: 0.9824 - val_accuracy: 0.9425 - val_cost: 7.4707\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1531 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9492 - val_loss: 0.1601 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 7.2559\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1493 - auc: 0.9851 - accuracy: 0.9471 - cost: 6.6991 - val_loss: 0.1567 - val_auc: 0.9837 - val_accuracy: 0.9462 - val_cost: 6.9466\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1448 - auc: 0.9858 - accuracy: 0.9482 - cost: 6.5594 - val_loss: 0.1530 - val_auc: 0.9843 - val_accuracy: 0.9469 - val_cost: 6.7871\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1417 - auc: 0.9863 - accuracy: 0.9502 - cost: 6.3180 - val_loss: 0.1493 - val_auc: 0.9850 - val_accuracy: 0.9481 - val_cost: 6.5951\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9870 - accuracy: 0.9518 - cost: 6.1200 - val_loss: 0.1470 - val_auc: 0.9853 - val_accuracy: 0.9484 - val_cost: 6.7676\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9526 - cost: 6.0184 - val_loss: 0.1457 - val_auc: 0.9857 - val_accuracy: 0.9496 - val_cost: 6.2565\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1322 - auc: 0.9879 - accuracy: 0.9546 - cost: 5.7572 - val_loss: 0.1434 - val_auc: 0.9859 - val_accuracy: 0.9508 - val_cost: 6.3542\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1300 - auc: 0.9881 - accuracy: 0.9556 - cost: 5.6365 - val_loss: 0.1410 - val_auc: 0.9863 - val_accuracy: 0.9528 - val_cost: 6.1654\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1268 - auc: 0.9886 - accuracy: 0.9571 - cost: 5.4504 - val_loss: 0.1397 - val_auc: 0.9864 - val_accuracy: 0.9549 - val_cost: 5.8105\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1261 - auc: 0.9887 - accuracy: 0.9577 - cost: 5.3798 - val_loss: 0.1357 - val_auc: 0.9868 - val_accuracy: 0.9552 - val_cost: 5.7650\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1227 - auc: 0.9893 - accuracy: 0.9590 - cost: 5.2123 - val_loss: 0.1346 - val_auc: 0.9871 - val_accuracy: 0.9560 - val_cost: 5.7617\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1198 - auc: 0.9896 - accuracy: 0.9598 - cost: 5.1081 - val_loss: 0.1344 - val_auc: 0.9871 - val_accuracy: 0.9563 - val_cost: 5.5632\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1190 - auc: 0.9896 - accuracy: 0.9603 - cost: 5.0436 - val_loss: 0.1321 - val_auc: 0.9874 - val_accuracy: 0.9578 - val_cost: 5.4069\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1162 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8784 - val_loss: 0.1288 - val_auc: 0.9878 - val_accuracy: 0.9590 - val_cost: 5.2441\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1140 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7879 - val_loss: 0.1294 - val_auc: 0.9880 - val_accuracy: 0.9582 - val_cost: 5.3809\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1130 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7363 - val_loss: 0.1302 - val_auc: 0.9881 - val_accuracy: 0.9587 - val_cost: 4.9609\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1113 - auc: 0.9906 - accuracy: 0.9638 - cost: 4.6048 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9591 - val_cost: 5.1465\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9911 - accuracy: 0.9647 - cost: 4.4835 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9597 - val_cost: 5.0944\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9653 - cost: 4.4144 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.9512\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1052 - auc: 0.9914 - accuracy: 0.9660 - cost: 4.3160 - val_loss: 0.1236 - val_auc: 0.9887 - val_accuracy: 0.9611 - val_cost: 5.0098\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2457 - val_loss: 0.1236 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 5.1660\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2337 - val_loss: 0.1208 - val_auc: 0.9885 - val_accuracy: 0.9632 - val_cost: 4.6680\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9919 - accuracy: 0.9675 - cost: 4.1303 - val_loss: 0.1213 - val_auc: 0.9886 - val_accuracy: 0.9622 - val_cost: 4.6257\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1001 - auc: 0.9920 - accuracy: 0.9681 - cost: 4.0609 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9637 - val_cost: 4.4043\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9686 - cost: 4.0003 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9631 - val_cost: 4.7461\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9691 - cost: 3.9514 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9641 - val_cost: 4.3620\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8479 - val_loss: 0.1168 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.2415\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9926 - accuracy: 0.9702 - cost: 3.7913 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9654 - val_cost: 4.2904\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9700 - cost: 3.8134 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.3034\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7244 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.1471\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9715 - cost: 3.6299 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9653 - val_cost: 4.4368\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9710 - cost: 3.6985 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9658 - val_cost: 4.1569\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6236 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9647 - val_cost: 4.2513\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5440 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9667 - val_cost: 4.1081\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9729 - cost: 3.4638 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9649 - val_cost: 4.3522\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4520 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.0918\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4602 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9667 - val_cost: 4.0788\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4517 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9665 - val_cost: 4.3652\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4940 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.0332\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9736 - cost: 3.3587 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9671 - val_cost: 4.0267\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9747 - cost: 3.2246 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9679 - val_cost: 4.0007\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3523 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9680 - val_cost: 3.8379\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2558 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2329 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9876\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2324 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9388\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2125 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9674 - val_cost: 4.0951\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1837 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.9616\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0967 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9686 - val_cost: 4.0202\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1981 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.7598\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9757 - cost: 3.1134 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9682 - val_cost: 4.0397\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0946 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9682 - val_cost: 4.0690\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0326 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9974\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0888 - val_loss: 0.1059 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 3.8900\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0876 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 4.0039\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9883 - val_loss: 0.1064 - val_auc: 0.9906 - val_accuracy: 0.9682 - val_cost: 4.0072\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9831 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9681 - val_cost: 4.0853\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9542 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.9811\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9901 - val_loss: 0.1064 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9486\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9485 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.9290\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9821 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 4.1634\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9546 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9388\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8605 - val_loss: 0.1059 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.9258\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8862 - val_loss: 0.1067 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 3.9811\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8432 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9676 - val_cost: 4.1243\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9029 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9714\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8270 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9690 - val_cost: 3.8932\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8490 - val_loss: 0.1070 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9160\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8809 - val_loss: 0.1067 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9583\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8724 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9941\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8107 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.8542\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8549 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8932\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8167 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8379\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7964 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7663\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7652 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8118\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6932 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8672\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7397 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7568 - val_loss: 0.1061 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7486 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.7500\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7224 - val_loss: 0.1074 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7305\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7495 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.6654\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6934 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.6361\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7796 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8021\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9947 - accuracy: 0.9791 - cost: 2.6849 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.7891\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9947 - accuracy: 0.9792 - cost: 2.6634 - val_loss: 0.1063 - val_auc: 0.9903 - val_accuracy: 0.9693 - val_cost: 3.8216\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6941 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.6230\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6603 - val_loss: 0.1064 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.6849\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6216 - val_loss: 0.1074 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.6882\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6332 - val_loss: 0.1058 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.5938\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6034 - val_loss: 0.1062 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6328\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6181 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.6751\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5823 - val_loss: 0.1066 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5536 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.9388\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6307 - val_loss: 0.1071 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6311 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.8346\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5973 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5777 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.9062\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5606 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.6719\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5611 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.5612\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5678 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.7565\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5240 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6145 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7695\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5804 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9698 - val_cost: 3.7109\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6046 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7467\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5032 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.7077\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5443 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.5807\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4727 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4808 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6198\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5472 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5074 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4944 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5101 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5124\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.4937 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4975 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5226 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6133\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4758 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.6003\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5126 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6003\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4602 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4910 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6784\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4840 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.6556\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6100\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3952 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4701\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5190 - val_loss: 0.1093 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.5807\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4296 - val_loss: 0.1107 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6328\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4116 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4393 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.4180\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4338 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3546 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.6263\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3856 - val_loss: 0.1122 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.6523\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3461 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.5579\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4369 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4098 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6328\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3770 - val_loss: 0.1130 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6035\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3782 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.3909 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9816 - cost: 2.3637 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7272\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3405 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3907 - val_loss: 0.1117 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6751\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4127 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.5547\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3843 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5026\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5482\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3975 - val_loss: 0.1138 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.4473\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9821 - cost: 2.2952 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7663\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3602 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3634 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.6979\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3220 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3298 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7435\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3499 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3307 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3724 - val_loss: 0.1168 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3040 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7826\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3436 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7012\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3206 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5514\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3294 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7891\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3357 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3114 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7663\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3202 - val_loss: 0.1154 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7142\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2772 - val_loss: 0.1179 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.6198\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3267 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7207\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2686 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2686 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5807\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3099 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9958 - accuracy: 0.9825 - cost: 2.2358 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7077\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2518 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4635\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2997 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.4538\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9825 - cost: 2.2440 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.5124\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3042 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2760 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4993\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1165 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.4928\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2569 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6165\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2740 - val_loss: 0.1163 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.5384\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2795 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2463 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5547\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2511 - val_loss: 0.1192 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.4082\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2471 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2392 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.4245\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2458 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4701\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2954 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.5352\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2480 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2456 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.5775\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2682 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.4928\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9959 - accuracy: 0.9828 - cost: 2.2094 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2924 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2011 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.5905\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2383 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.1984 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2381 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.3724\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2047 - val_loss: 0.1200 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.6556\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2387 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.3561\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1900 - val_loss: 0.1163 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6198\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2115 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.6979\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2314 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1474 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.5872\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2337 - val_loss: 0.1183 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1999 - val_loss: 0.1182 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6165\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1696 - val_loss: 0.1224 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.6426\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1962 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.4961\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2406 - val_loss: 0.1185 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2432 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.3073\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2085 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.3789\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2053 - val_loss: 0.1209 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.4603\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2211 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.3203\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1698 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.3984\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2383 - val_loss: 0.1187 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5775\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0589 - auc: 0.9961 - accuracy: 0.9831 - cost: 2.1576 - val_loss: 0.1203 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6003\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1495 - val_loss: 0.1201 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2198 - val_loss: 0.1191 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5254\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.1973 - val_loss: 0.1212 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.6003\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1971 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.4798\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.2001 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5547\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1222 - val_loss: 0.1217 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6361\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1735 - val_loss: 0.1206 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 3.8509\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2458 - val_loss: 0.1200 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.2780\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2013 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9707 - val_cost: 3.3952\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1655 - val_loss: 0.1196 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5059\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1781 - val_loss: 0.1201 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6133\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1670 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.3919\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2084 - val_loss: 0.1222 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4082\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1237 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2229 - val_loss: 0.1246 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7044\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2169 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.3984\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1486 - val_loss: 0.1211 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.4375\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1817 - val_loss: 0.1219 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1486 - val_loss: 0.1251 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.3919\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1684 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.5547\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9835 - cost: 2.1164 - val_loss: 0.1235 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.4505\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9963 - accuracy: 0.9836 - cost: 2.1056 - val_loss: 0.1219 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.5775\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1499 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5612\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0570 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1392 - val_loss: 0.1226 - val_auc: 0.9891 - val_accuracy: 0.9705 - val_cost: 3.5905\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1423 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.5091\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1478 - val_loss: 0.1226 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.2650\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2147 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.5514\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1066 - val_loss: 0.1220 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1473 - val_loss: 0.1220 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.1868\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1951 - val_loss: 0.1244 - val_auc: 0.9888 - val_accuracy: 0.9716 - val_cost: 3.3464\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1094 - val_loss: 0.1227 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.4277\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2148 - val_loss: 0.1254 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.4115\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1495 - val_loss: 0.1235 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3431\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1847 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1067 - val_loss: 0.1227 - val_auc: 0.9888 - val_accuracy: 0.9702 - val_cost: 3.4733\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1294 - val_loss: 0.1235 - val_auc: 0.9889 - val_accuracy: 0.9714 - val_cost: 3.3626\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1419 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9709 - val_cost: 3.4375\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1610 - val_loss: 0.1227 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.3724\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1446 - val_loss: 0.1247 - val_auc: 0.9888 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1150 - val_loss: 0.1225 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5514\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1410 - val_loss: 0.1252 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1332 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1143 - val_loss: 0.1233 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.3366\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1271 - val_loss: 0.1253 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1241 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.8444\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1550 - val_loss: 0.1248 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.6654\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1818 - val_loss: 0.1222 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.3594\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1040 - val_loss: 0.1208 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0569 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1741 - val_loss: 0.1239 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.4928\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0581 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.6003\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1000 - val_loss: 0.1259 - val_auc: 0.9886 - val_accuracy: 0.9714 - val_cost: 3.3659\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0870 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.6263\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1585 - val_loss: 0.1192 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.5905\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0950 - val_loss: 0.1231 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.0978 - val_loss: 0.1241 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.3366\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1206 - val_loss: 0.1238 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9964 - accuracy: 0.9837 - cost: 2.0903 - val_loss: 0.1248 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4375\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0944 - val_loss: 0.1247 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6165\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0682 - val_loss: 0.1263 - val_auc: 0.9885 - val_accuracy: 0.9717 - val_cost: 3.3040\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0698 - val_loss: 0.1249 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.4147\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9839 - cost: 2.0770 - val_loss: 0.1255 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.3984\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1303 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.7174\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1228 - val_loss: 0.1230 - val_auc: 0.9888 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9837 - cost: 2.0947 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9718 - val_cost: 3.3171\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9965 - accuracy: 0.9840 - cost: 2.0508 - val_loss: 0.1257 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 3.4928\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1182 - val_loss: 0.1258 - val_auc: 0.9885 - val_accuracy: 0.9709 - val_cost: 3.5514\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1402 - val_loss: 0.1255 - val_auc: 0.9887 - val_accuracy: 0.9711 - val_cost: 3.7728\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9839 - cost: 2.0657 - val_loss: 0.1255 - val_auc: 0.9889 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9968 - accuracy: 0.9835 - cost: 2.1069 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0550 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0408 - val_loss: 0.1276 - val_auc: 0.9885 - val_accuracy: 0.9716 - val_cost: 3.2910\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0712 - val_loss: 0.1251 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.7598\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0695 - val_loss: 0.1251 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1000 - val_loss: 0.1260 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.4049\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0845 - val_loss: 0.1270 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.8053\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1034 - val_loss: 0.1241 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0549 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0592 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.6458\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9967 - accuracy: 0.9837 - cost: 2.0944 - val_loss: 0.1256 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.3464\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9843 - cost: 2.0084 - val_loss: 0.1237 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0548 - auc: 0.9967 - accuracy: 0.9841 - cost: 2.0425 - val_loss: 0.1275 - val_auc: 0.9887 - val_accuracy: 0.9713 - val_cost: 3.5807\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1087 - auc: 0.9907 - accuracy: 0.9729 - cost: 3.3125\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:48.238908\n",
            "fold accuracy: 0.9728749990463257 - fold cost: 3.3125\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5248 - auc: 0.8028 - accuracy: 0.7316 - cost: 35.6820 - val_loss: 0.3935 - val_auc: 0.9015 - val_accuracy: 0.8296 - val_cost: 21.7448\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3482 - auc: 0.9230 - accuracy: 0.8514 - cost: 18.8781 - val_loss: 0.3188 - val_auc: 0.9356 - val_accuracy: 0.8639 - val_cost: 16.3346\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3000 - auc: 0.9430 - accuracy: 0.8759 - cost: 15.7019 - val_loss: 0.2867 - val_auc: 0.9481 - val_accuracy: 0.8817 - val_cost: 14.4857\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2710 - auc: 0.9536 - accuracy: 0.8898 - cost: 13.9502 - val_loss: 0.2623 - val_auc: 0.9564 - val_accuracy: 0.8950 - val_cost: 12.6595\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9613 - accuracy: 0.9013 - cost: 12.4837 - val_loss: 0.2422 - val_auc: 0.9630 - val_accuracy: 0.9055 - val_cost: 11.5365\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2291 - auc: 0.9668 - accuracy: 0.9106 - cost: 11.3212 - val_loss: 0.2255 - val_auc: 0.9679 - val_accuracy: 0.9133 - val_cost: 10.6315\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2134 - auc: 0.9711 - accuracy: 0.9175 - cost: 10.4380 - val_loss: 0.2123 - val_auc: 0.9714 - val_accuracy: 0.9203 - val_cost: 9.8438\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2008 - auc: 0.9743 - accuracy: 0.9236 - cost: 9.6841 - val_loss: 0.2010 - val_auc: 0.9743 - val_accuracy: 0.9265 - val_cost: 9.1471\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1893 - auc: 0.9770 - accuracy: 0.9286 - cost: 9.0206 - val_loss: 0.1917 - val_auc: 0.9766 - val_accuracy: 0.9312 - val_cost: 8.4603\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1808 - auc: 0.9789 - accuracy: 0.9324 - cost: 8.5440 - val_loss: 0.1827 - val_auc: 0.9783 - val_accuracy: 0.9347 - val_cost: 8.1055\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1727 - auc: 0.9806 - accuracy: 0.9364 - cost: 8.0657 - val_loss: 0.1762 - val_auc: 0.9797 - val_accuracy: 0.9365 - val_cost: 8.0306\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1660 - auc: 0.9820 - accuracy: 0.9392 - cost: 7.6971 - val_loss: 0.1726 - val_auc: 0.9809 - val_accuracy: 0.9384 - val_cost: 7.4512\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9423 - cost: 7.3040 - val_loss: 0.1654 - val_auc: 0.9820 - val_accuracy: 0.9415 - val_cost: 7.5423\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1550 - auc: 0.9840 - accuracy: 0.9450 - cost: 6.9662 - val_loss: 0.1619 - val_auc: 0.9825 - val_accuracy: 0.9424 - val_cost: 7.1810\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9850 - accuracy: 0.9471 - cost: 6.7105 - val_loss: 0.1574 - val_auc: 0.9834 - val_accuracy: 0.9449 - val_cost: 6.9336\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9493 - cost: 6.4207 - val_loss: 0.1547 - val_auc: 0.9840 - val_accuracy: 0.9458 - val_cost: 6.8978\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1422 - auc: 0.9863 - accuracy: 0.9503 - cost: 6.2907 - val_loss: 0.1516 - val_auc: 0.9845 - val_accuracy: 0.9467 - val_cost: 6.7904\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1397 - auc: 0.9867 - accuracy: 0.9516 - cost: 6.1308 - val_loss: 0.1499 - val_auc: 0.9850 - val_accuracy: 0.9481 - val_cost: 7.0931\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1369 - auc: 0.9871 - accuracy: 0.9525 - cost: 6.0408 - val_loss: 0.1461 - val_auc: 0.9855 - val_accuracy: 0.9480 - val_cost: 6.8392\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9543 - cost: 5.7999 - val_loss: 0.1472 - val_auc: 0.9855 - val_accuracy: 0.9488 - val_cost: 6.2891\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1316 - auc: 0.9879 - accuracy: 0.9550 - cost: 5.6977 - val_loss: 0.1423 - val_auc: 0.9860 - val_accuracy: 0.9509 - val_cost: 6.4616\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9561 - cost: 5.5623 - val_loss: 0.1408 - val_auc: 0.9861 - val_accuracy: 0.9517 - val_cost: 6.3477\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9571 - cost: 5.4491 - val_loss: 0.1381 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 5.9440\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9573 - cost: 5.4224 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9543 - val_cost: 5.8464\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9592 - cost: 5.1739 - val_loss: 0.1356 - val_auc: 0.9871 - val_accuracy: 0.9545 - val_cost: 5.8464\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9896 - accuracy: 0.9599 - cost: 5.0925 - val_loss: 0.1335 - val_auc: 0.9872 - val_accuracy: 0.9551 - val_cost: 5.9505\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9899 - accuracy: 0.9604 - cost: 5.0145 - val_loss: 0.1326 - val_auc: 0.9874 - val_accuracy: 0.9572 - val_cost: 5.4297\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8750 - val_loss: 0.1308 - val_auc: 0.9875 - val_accuracy: 0.9576 - val_cost: 5.5436\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8242 - val_loss: 0.1296 - val_auc: 0.9878 - val_accuracy: 0.9572 - val_cost: 5.3548\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1119 - auc: 0.9906 - accuracy: 0.9639 - cost: 4.5905 - val_loss: 0.1295 - val_auc: 0.9878 - val_accuracy: 0.9582 - val_cost: 5.3320\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5284 - val_loss: 0.1268 - val_auc: 0.9880 - val_accuracy: 0.9592 - val_cost: 5.1823\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9647 - cost: 4.4854 - val_loss: 0.1270 - val_auc: 0.9879 - val_accuracy: 0.9588 - val_cost: 5.2474\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1069 - auc: 0.9912 - accuracy: 0.9652 - cost: 4.4179 - val_loss: 0.1238 - val_auc: 0.9882 - val_accuracy: 0.9603 - val_cost: 5.0163\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1050 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2690 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9605 - val_cost: 5.0163\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9915 - accuracy: 0.9670 - cost: 4.1943 - val_loss: 0.1219 - val_auc: 0.9884 - val_accuracy: 0.9613 - val_cost: 5.0000\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1744 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9622 - val_cost: 4.7070\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9676 - cost: 4.1093 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9628 - val_cost: 4.6810\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0996 - auc: 0.9920 - accuracy: 0.9684 - cost: 4.0186 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9633 - val_cost: 4.5671\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9687 - cost: 3.9932 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9632 - val_cost: 4.6224\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9401 - val_loss: 0.1181 - val_auc: 0.9888 - val_accuracy: 0.9639 - val_cost: 4.5996\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0960 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8766 - val_loss: 0.1162 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.5833\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9922 - accuracy: 0.9695 - cost: 3.9001 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.2578\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7464 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9645 - val_cost: 4.4987\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6980 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3652\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6137 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.2741\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9712 - cost: 3.6792 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1341\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9718 - cost: 3.5994 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 4.1243\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0900 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5219 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.1764\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9930 - accuracy: 0.9722 - cost: 3.5469 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.3327\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9728 - cost: 3.4736 - val_loss: 0.1109 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.0658\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0873 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4343 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0820\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9732 - cost: 3.4213 - val_loss: 0.1095 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.0625\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.4040 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0755\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3722 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.1243\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9743 - cost: 3.2814 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 4.0104\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2657 - val_loss: 0.1079 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0690\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3088 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 4.0365\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9936 - accuracy: 0.9750 - cost: 3.2006 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7988\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9751 - cost: 3.1806 - val_loss: 0.1074 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9421\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9937 - accuracy: 0.9749 - cost: 3.1917 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 4.1081\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1521 - val_loss: 0.1076 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.8411\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9937 - accuracy: 0.9753 - cost: 3.1517 - val_loss: 0.1069 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9941\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9938 - accuracy: 0.9759 - cost: 3.0710 - val_loss: 0.1073 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.8314\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0939 - val_loss: 0.1059 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9909\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9765 - cost: 3.0057 - val_loss: 0.1063 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.7598\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0707 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7435\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0935 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9792 - val_loss: 0.1054 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7435\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9220 - val_loss: 0.1066 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.8542\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9725 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.7500\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9821 - val_loss: 0.1041 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9314 - val_loss: 0.1049 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.9844\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9175 - val_loss: 0.1048 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 4.0007\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9451 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8639\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9044 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.7760\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8611 - val_loss: 0.1052 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.8021\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8643 - val_loss: 0.1055 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8411\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8728 - val_loss: 0.1055 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.7077\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8354 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8375 - val_loss: 0.1051 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.8346\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8414 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7337\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7750 - val_loss: 0.1050 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.9258\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8104 - val_loss: 0.1055 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7663\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7386 - val_loss: 0.1064 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.6198\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7667 - val_loss: 0.1067 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 4.0592\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7917 - val_loss: 0.1061 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.8086\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9946 - accuracy: 0.9785 - cost: 2.7463 - val_loss: 0.1043 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.7337\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7359 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.7565\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.7028 - val_loss: 0.1041 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7219 - val_loss: 0.1051 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8542\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7048 - val_loss: 0.1053 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.6035\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7180 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7216 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6841 - val_loss: 0.1050 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.7044\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7046 - val_loss: 0.1050 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7142\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6601 - val_loss: 0.1044 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.6230\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6248 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6979\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6613 - val_loss: 0.1053 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.7500\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6818 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6849\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6173 - val_loss: 0.1063 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.8704\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6262 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7207\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6339 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6108 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5582 - val_loss: 0.1046 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.6523\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5861 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.5059\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5984 - val_loss: 0.1042 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.9551\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5763 - val_loss: 0.1044 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5949 - val_loss: 0.1039 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.7044\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5362 - val_loss: 0.1052 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.6328\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5766 - val_loss: 0.1039 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.6556\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5134 - val_loss: 0.1058 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7272\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5344 - val_loss: 0.1040 - val_auc: 0.9903 - val_accuracy: 0.9726 - val_cost: 3.5449\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5541 - val_loss: 0.1053 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5938\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5743 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.9714\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5896 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.3431\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5137 - val_loss: 0.1073 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.8867\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9951 - accuracy: 0.9803 - cost: 2.5229 - val_loss: 0.1055 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5281 - val_loss: 0.1060 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.4863\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5503 - val_loss: 0.1069 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.9421\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5325 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9721 - val_cost: 3.5612\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5065 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5254\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4891 - val_loss: 0.1058 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.8314\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4944 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.8281\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4206 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.7891\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5127 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9730 - val_cost: 3.5059\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4426 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4587 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.6816\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4479 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6491\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4383 - val_loss: 0.1064 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 4.0430\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4725 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6230\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4992 - val_loss: 0.1088 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.6621\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4232 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.9876\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9954 - accuracy: 0.9812 - cost: 2.4152 - val_loss: 0.1072 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.9844\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3882 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.9323\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4224 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.8965\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3853 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.9551\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4505 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.3789\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4265 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4538\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4266 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 4.1146\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4503 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4446 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.8477\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3910 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 4.0202\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.4009 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6230\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3685 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.9681\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4114 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9726 - val_cost: 3.7435\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4004 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.9323\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3586 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.9355\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3691 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.8053\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4391 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 4.1276\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4159 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5905\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3734 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3413 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.7565\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3556 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8086\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3804 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.9225\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3455 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.6979\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3581 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6198\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3552 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9723 - val_cost: 3.8574\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3598 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9727 - val_cost: 3.8477\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3290 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.9095\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3398 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 4.0072\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3933 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.8477\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2735 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.9844\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3444 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9719 - val_cost: 3.6198\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3523 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.7435\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2847 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.8672\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1052 - auc: 0.9912 - accuracy: 0.9690 - cost: 3.8531\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:35.150792\n",
            "fold accuracy: 0.968999981880188 - fold cost: 3.8531250953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5245 - auc: 0.8034 - accuracy: 0.7324 - cost: 35.5634 - val_loss: 0.3908 - val_auc: 0.9022 - val_accuracy: 0.8295 - val_cost: 21.8424\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3472 - auc: 0.9235 - accuracy: 0.8508 - cost: 18.9853 - val_loss: 0.3141 - val_auc: 0.9372 - val_accuracy: 0.8643 - val_cost: 16.5885\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9433 - accuracy: 0.8760 - cost: 15.6933 - val_loss: 0.2848 - val_auc: 0.9489 - val_accuracy: 0.8815 - val_cost: 14.2090\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2705 - auc: 0.9538 - accuracy: 0.8899 - cost: 13.9156 - val_loss: 0.2607 - val_auc: 0.9570 - val_accuracy: 0.8947 - val_cost: 12.9688\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2474 - auc: 0.9614 - accuracy: 0.9005 - cost: 12.5905 - val_loss: 0.2423 - val_auc: 0.9629 - val_accuracy: 0.9051 - val_cost: 11.4323\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2282 - auc: 0.9671 - accuracy: 0.9100 - cost: 11.3999 - val_loss: 0.2266 - val_auc: 0.9675 - val_accuracy: 0.9113 - val_cost: 10.7845\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2125 - auc: 0.9714 - accuracy: 0.9180 - cost: 10.3666 - val_loss: 0.2127 - val_auc: 0.9715 - val_accuracy: 0.9203 - val_cost: 9.9382\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1995 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6798 - val_loss: 0.2014 - val_auc: 0.9742 - val_accuracy: 0.9262 - val_cost: 8.9355\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1883 - auc: 0.9773 - accuracy: 0.9291 - cost: 8.9792 - val_loss: 0.1926 - val_auc: 0.9763 - val_accuracy: 0.9317 - val_cost: 8.1706\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1784 - auc: 0.9794 - accuracy: 0.9343 - cost: 8.3300 - val_loss: 0.1849 - val_auc: 0.9779 - val_accuracy: 0.9343 - val_cost: 8.1771\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1714 - auc: 0.9809 - accuracy: 0.9366 - cost: 8.0238 - val_loss: 0.1780 - val_auc: 0.9791 - val_accuracy: 0.9355 - val_cost: 8.2064\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1651 - auc: 0.9821 - accuracy: 0.9394 - cost: 7.6851 - val_loss: 0.1729 - val_auc: 0.9803 - val_accuracy: 0.9393 - val_cost: 7.7539\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9424 - cost: 7.3047 - val_loss: 0.1688 - val_auc: 0.9811 - val_accuracy: 0.9416 - val_cost: 7.3307\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1543 - auc: 0.9842 - accuracy: 0.9447 - cost: 7.0006 - val_loss: 0.1646 - val_auc: 0.9820 - val_accuracy: 0.9424 - val_cost: 6.9661\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1501 - auc: 0.9850 - accuracy: 0.9463 - cost: 6.7975 - val_loss: 0.1607 - val_auc: 0.9826 - val_accuracy: 0.9453 - val_cost: 6.6992\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1455 - auc: 0.9857 - accuracy: 0.9487 - cost: 6.5013 - val_loss: 0.1575 - val_auc: 0.9832 - val_accuracy: 0.9460 - val_cost: 6.6634\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1431 - auc: 0.9861 - accuracy: 0.9499 - cost: 6.3632 - val_loss: 0.1566 - val_auc: 0.9838 - val_accuracy: 0.9457 - val_cost: 6.4648\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9868 - accuracy: 0.9508 - cost: 6.2422 - val_loss: 0.1527 - val_auc: 0.9841 - val_accuracy: 0.9469 - val_cost: 6.4876\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1370 - auc: 0.9871 - accuracy: 0.9521 - cost: 6.0624 - val_loss: 0.1504 - val_auc: 0.9844 - val_accuracy: 0.9491 - val_cost: 6.2272\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1335 - auc: 0.9876 - accuracy: 0.9540 - cost: 5.8269 - val_loss: 0.1489 - val_auc: 0.9848 - val_accuracy: 0.9501 - val_cost: 6.2760\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9881 - accuracy: 0.9550 - cost: 5.7029 - val_loss: 0.1473 - val_auc: 0.9849 - val_accuracy: 0.9504 - val_cost: 6.2305\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9883 - accuracy: 0.9556 - cost: 5.6223 - val_loss: 0.1451 - val_auc: 0.9855 - val_accuracy: 0.9517 - val_cost: 5.8822\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1262 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4365 - val_loss: 0.1434 - val_auc: 0.9857 - val_accuracy: 0.9527 - val_cost: 5.6087\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9890 - accuracy: 0.9568 - cost: 5.4855 - val_loss: 0.1418 - val_auc: 0.9859 - val_accuracy: 0.9531 - val_cost: 5.7292\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1229 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.2637 - val_loss: 0.1405 - val_auc: 0.9859 - val_accuracy: 0.9550 - val_cost: 5.6152\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1204 - auc: 0.9896 - accuracy: 0.9594 - cost: 5.1440 - val_loss: 0.1385 - val_auc: 0.9861 - val_accuracy: 0.9557 - val_cost: 5.5176\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1185 - auc: 0.9899 - accuracy: 0.9602 - cost: 5.0428 - val_loss: 0.1384 - val_auc: 0.9861 - val_accuracy: 0.9563 - val_cost: 5.4915\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1168 - auc: 0.9900 - accuracy: 0.9614 - cost: 4.9026 - val_loss: 0.1343 - val_auc: 0.9867 - val_accuracy: 0.9570 - val_cost: 5.3613\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1151 - auc: 0.9903 - accuracy: 0.9617 - cost: 4.8503 - val_loss: 0.1342 - val_auc: 0.9868 - val_accuracy: 0.9580 - val_cost: 5.2409\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1134 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7107 - val_loss: 0.1323 - val_auc: 0.9872 - val_accuracy: 0.9583 - val_cost: 5.2702\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1125 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6480 - val_loss: 0.1308 - val_auc: 0.9872 - val_accuracy: 0.9595 - val_cost: 4.8893\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1101 - auc: 0.9909 - accuracy: 0.9641 - cost: 4.5555 - val_loss: 0.1307 - val_auc: 0.9872 - val_accuracy: 0.9595 - val_cost: 5.1823\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1090 - auc: 0.9910 - accuracy: 0.9643 - cost: 4.5155 - val_loss: 0.1270 - val_auc: 0.9878 - val_accuracy: 0.9612 - val_cost: 4.9349\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4118 - val_loss: 0.1284 - val_auc: 0.9872 - val_accuracy: 0.9609 - val_cost: 4.8861\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1054 - auc: 0.9915 - accuracy: 0.9656 - cost: 4.3746 - val_loss: 0.1264 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.7982\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1041 - auc: 0.9916 - accuracy: 0.9664 - cost: 4.2689 - val_loss: 0.1262 - val_auc: 0.9877 - val_accuracy: 0.9620 - val_cost: 4.5443\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9919 - accuracy: 0.9668 - cost: 4.2177 - val_loss: 0.1246 - val_auc: 0.9880 - val_accuracy: 0.9610 - val_cost: 4.7070\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1435 - val_loss: 0.1245 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.6224\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1004 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0735 - val_loss: 0.1232 - val_auc: 0.9882 - val_accuracy: 0.9622 - val_cost: 4.5931\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0042 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9642 - val_cost: 4.4076\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9243 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9635 - val_cost: 4.3392\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9187 - val_loss: 0.1204 - val_auc: 0.9885 - val_accuracy: 0.9633 - val_cost: 4.4238\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0966 - auc: 0.9923 - accuracy: 0.9697 - cost: 3.8371 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9647 - val_cost: 4.2904\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9699 - cost: 3.8163 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9639 - val_cost: 4.5215\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7653 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9653 - val_cost: 4.1960\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6889 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9645 - val_cost: 4.3066\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6692 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9655 - val_cost: 4.1276\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6742 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9648 - val_cost: 4.2643\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5918 - val_loss: 0.1163 - val_auc: 0.9888 - val_accuracy: 0.9651 - val_cost: 4.3164\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5189 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9650 - val_cost: 4.1829\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5597 - val_loss: 0.1175 - val_auc: 0.9890 - val_accuracy: 0.9646 - val_cost: 4.1895\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.5067 - val_loss: 0.1161 - val_auc: 0.9888 - val_accuracy: 0.9658 - val_cost: 4.1797\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9932 - accuracy: 0.9731 - cost: 3.4182 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.1341\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9934 - accuracy: 0.9724 - cost: 3.5128 - val_loss: 0.1149 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.1471\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9933 - accuracy: 0.9733 - cost: 3.3962 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9668 - val_cost: 4.0625\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.4005 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9659 - val_cost: 4.0951\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.2995 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9656 - val_cost: 4.2122\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.2951 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9651 - val_cost: 4.2643\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3186 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1602\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.3019 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9258\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2773 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.3066\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2535 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9678 - val_cost: 3.7728\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9744 - cost: 3.2629 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.7044\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9752 - cost: 3.1627 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9258\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1065 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9678 - val_cost: 3.8965\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1601 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0918\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1123 - val_loss: 0.1122 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 3.9062\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0848 - val_loss: 0.1130 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 3.8932\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1104 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9062\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0597 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 3.9779\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1079 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9675 - val_cost: 3.8118\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0266 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 3.8346\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0368 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 4.0234\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0414 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 3.9941\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9978 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9676 - val_cost: 3.9225\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9586 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.8477\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9365 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7891\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9766 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 3.8477\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9000 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.1732\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9172 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.7142\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.7500\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8752 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8900\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8504 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8021\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8852 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.8509\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8249 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9672 - val_cost: 3.9355\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9003 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.1536\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8298 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8108 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.7858\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8246 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9974\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7914 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 3.9616\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8138 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7598\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7584 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.7272\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7562 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7207\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8087 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7826\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7354 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7109\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7153 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6979\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7620 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8770\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7511 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8835\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7302 - val_loss: 0.1125 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.9258\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6924 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.9030\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7394 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8737\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6899 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.7207\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6806 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 3.9160\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7277 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8867\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6896 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6606 - val_loss: 0.1153 - val_auc: 0.9889 - val_accuracy: 0.9688 - val_cost: 3.7077\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6926 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6263\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6606 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6307 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.5840\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6335 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.7760\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6447 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.7793\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6070 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6389 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.5905\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5653 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7012\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6306 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8314\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5963 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7988\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.5972 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8802\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6117 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6070 - val_loss: 0.1121 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6395 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6003\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6013 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6063 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.9453\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5831 - val_loss: 0.1154 - val_auc: 0.9889 - val_accuracy: 0.9696 - val_cost: 3.8835\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6022 - val_loss: 0.1139 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8770\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6008 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8704\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5385 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7272\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5697 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9693 - val_cost: 3.9062\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5153 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8086\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5443 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.7305\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9955 - accuracy: 0.9795 - cost: 2.6248 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5692 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.8281\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5022 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5128 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5592 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9687 - val_cost: 3.9258\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5374 - val_loss: 0.1155 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5674 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8053\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5190 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.9290\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4541 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9225\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5169 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9695 - val_cost: 3.7923\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5038 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.6296\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5079 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.7663\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5156 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4841 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8151\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.4939 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.9030\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4902 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9686 - val_cost: 3.9518\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4553 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8802\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4979 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4897 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9694 - val_cost: 3.9225\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5201 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8639\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4435 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.7012\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4309 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8411\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4683 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5238 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9696 - val_cost: 3.8737\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5087 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4578 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7891\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4259 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.8770\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4782 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4102 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9693 - val_cost: 3.9030\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4156 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.8216\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1058 - auc: 0.9909 - accuracy: 0.9684 - cost: 3.9094\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:32.192342\n",
            "fold accuracy: 0.968375027179718 - fold cost: 3.909374952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5262 - auc: 0.8018 - accuracy: 0.7322 - cost: 35.6144 - val_loss: 0.3912 - val_auc: 0.9032 - val_accuracy: 0.8283 - val_cost: 22.5618\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3475 - auc: 0.9233 - accuracy: 0.8508 - cost: 18.9736 - val_loss: 0.3163 - val_auc: 0.9363 - val_accuracy: 0.8650 - val_cost: 16.9564\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2981 - auc: 0.9437 - accuracy: 0.8762 - cost: 15.6666 - val_loss: 0.2866 - val_auc: 0.9479 - val_accuracy: 0.8798 - val_cost: 15.0618\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2695 - auc: 0.9541 - accuracy: 0.8910 - cost: 13.8050 - val_loss: 0.2597 - val_auc: 0.9574 - val_accuracy: 0.8953 - val_cost: 12.7767\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9617 - accuracy: 0.9010 - cost: 12.5296 - val_loss: 0.2399 - val_auc: 0.9636 - val_accuracy: 0.9072 - val_cost: 11.2044\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2267 - auc: 0.9675 - accuracy: 0.9113 - cost: 11.2259 - val_loss: 0.2239 - val_auc: 0.9681 - val_accuracy: 0.9135 - val_cost: 10.6510\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2117 - auc: 0.9716 - accuracy: 0.9182 - cost: 10.3138 - val_loss: 0.2095 - val_auc: 0.9720 - val_accuracy: 0.9223 - val_cost: 9.3978\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1981 - auc: 0.9750 - accuracy: 0.9245 - cost: 9.5459 - val_loss: 0.1991 - val_auc: 0.9752 - val_accuracy: 0.9253 - val_cost: 8.9518\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1875 - auc: 0.9775 - accuracy: 0.9292 - cost: 8.9565 - val_loss: 0.1875 - val_auc: 0.9775 - val_accuracy: 0.9315 - val_cost: 8.6458\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1785 - auc: 0.9794 - accuracy: 0.9333 - cost: 8.4431 - val_loss: 0.1788 - val_auc: 0.9792 - val_accuracy: 0.9358 - val_cost: 8.1185\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1698 - auc: 0.9812 - accuracy: 0.9373 - cost: 7.9345 - val_loss: 0.1736 - val_auc: 0.9804 - val_accuracy: 0.9374 - val_cost: 7.7214\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1639 - auc: 0.9823 - accuracy: 0.9408 - cost: 7.4764 - val_loss: 0.1674 - val_auc: 0.9815 - val_accuracy: 0.9413 - val_cost: 7.8418\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9434 - cost: 7.1871 - val_loss: 0.1638 - val_auc: 0.9822 - val_accuracy: 0.9427 - val_cost: 7.1322\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1520 - auc: 0.9846 - accuracy: 0.9459 - cost: 6.8526 - val_loss: 0.1587 - val_auc: 0.9831 - val_accuracy: 0.9454 - val_cost: 7.1159\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1490 - auc: 0.9851 - accuracy: 0.9473 - cost: 6.6754 - val_loss: 0.1556 - val_auc: 0.9838 - val_accuracy: 0.9465 - val_cost: 6.9661\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1462 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5529 - val_loss: 0.1517 - val_auc: 0.9846 - val_accuracy: 0.9476 - val_cost: 6.7936\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9509 - cost: 6.2193 - val_loss: 0.1502 - val_auc: 0.9847 - val_accuracy: 0.9485 - val_cost: 6.8652\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9868 - accuracy: 0.9514 - cost: 6.1750 - val_loss: 0.1494 - val_auc: 0.9850 - val_accuracy: 0.9494 - val_cost: 6.5462\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0056 - val_loss: 0.1465 - val_auc: 0.9853 - val_accuracy: 0.9493 - val_cost: 6.3509\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9878 - accuracy: 0.9538 - cost: 5.8510 - val_loss: 0.1435 - val_auc: 0.9859 - val_accuracy: 0.9522 - val_cost: 6.5039\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1306 - auc: 0.9882 - accuracy: 0.9551 - cost: 5.6759 - val_loss: 0.1416 - val_auc: 0.9863 - val_accuracy: 0.9519 - val_cost: 6.4714\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1276 - auc: 0.9885 - accuracy: 0.9561 - cost: 5.5844 - val_loss: 0.1401 - val_auc: 0.9864 - val_accuracy: 0.9536 - val_cost: 5.9505\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.4027 - val_loss: 0.1381 - val_auc: 0.9868 - val_accuracy: 0.9540 - val_cost: 6.1816\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9891 - accuracy: 0.9580 - cost: 5.3253 - val_loss: 0.1391 - val_auc: 0.9866 - val_accuracy: 0.9557 - val_cost: 5.8171\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9895 - accuracy: 0.9587 - cost: 5.2629 - val_loss: 0.1360 - val_auc: 0.9869 - val_accuracy: 0.9549 - val_cost: 5.8887\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1204 - auc: 0.9896 - accuracy: 0.9595 - cost: 5.1546 - val_loss: 0.1349 - val_auc: 0.9870 - val_accuracy: 0.9578 - val_cost: 5.3711\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9898 - accuracy: 0.9605 - cost: 4.9890 - val_loss: 0.1333 - val_auc: 0.9871 - val_accuracy: 0.9567 - val_cost: 5.7910\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1165 - auc: 0.9902 - accuracy: 0.9605 - cost: 5.0109 - val_loss: 0.1326 - val_auc: 0.9872 - val_accuracy: 0.9573 - val_cost: 5.7487\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1151 - auc: 0.9903 - accuracy: 0.9618 - cost: 4.8504 - val_loss: 0.1320 - val_auc: 0.9875 - val_accuracy: 0.9582 - val_cost: 5.2637\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.8054 - val_loss: 0.1304 - val_auc: 0.9876 - val_accuracy: 0.9583 - val_cost: 5.2148\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1117 - auc: 0.9907 - accuracy: 0.9636 - cost: 4.6220 - val_loss: 0.1289 - val_auc: 0.9879 - val_accuracy: 0.9588 - val_cost: 5.1042\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9635 - cost: 4.6151 - val_loss: 0.1262 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 5.0358\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1089 - auc: 0.9911 - accuracy: 0.9648 - cost: 4.4821 - val_loss: 0.1270 - val_auc: 0.9879 - val_accuracy: 0.9606 - val_cost: 4.9089\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1075 - auc: 0.9913 - accuracy: 0.9647 - cost: 4.4845 - val_loss: 0.1268 - val_auc: 0.9882 - val_accuracy: 0.9608 - val_cost: 5.0846\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1060 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3784 - val_loss: 0.1259 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.6191\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9917 - accuracy: 0.9657 - cost: 4.3562 - val_loss: 0.1275 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.5833\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3063 - val_loss: 0.1251 - val_auc: 0.9880 - val_accuracy: 0.9618 - val_cost: 4.7819\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1617 - val_loss: 0.1244 - val_auc: 0.9883 - val_accuracy: 0.9619 - val_cost: 4.5898\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1569 - val_loss: 0.1228 - val_auc: 0.9886 - val_accuracy: 0.9615 - val_cost: 4.8210\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1008 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0776 - val_loss: 0.1206 - val_auc: 0.9883 - val_accuracy: 0.9647 - val_cost: 4.3685\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9924 - accuracy: 0.9683 - cost: 4.0169 - val_loss: 0.1224 - val_auc: 0.9885 - val_accuracy: 0.9623 - val_cost: 4.5703\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9131 - val_loss: 0.1207 - val_auc: 0.9882 - val_accuracy: 0.9641 - val_cost: 4.4368\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9515 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9647 - val_cost: 4.3099\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0960 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8859 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9640 - val_cost: 4.3750\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0946 - auc: 0.9927 - accuracy: 0.9696 - cost: 3.8601 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9649 - val_cost: 4.4564\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9706 - cost: 3.7558 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9647 - val_cost: 4.2318\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7355 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9653 - val_cost: 4.2350\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9712 - cost: 3.6641 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.2546\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9713 - cost: 3.6546 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9657 - val_cost: 4.2480\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6685 - val_loss: 0.1164 - val_auc: 0.9893 - val_accuracy: 0.9656 - val_cost: 4.1732\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5424 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.2155\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9716 - cost: 3.6173 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9652 - val_cost: 4.4434\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5279 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9647 - val_cost: 4.2383\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9933 - accuracy: 0.9724 - cost: 3.5157 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9649 - val_cost: 4.3457\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4399 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9664 - val_cost: 4.3327\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4422 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9664 - val_cost: 4.1276\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3973 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.8835\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3867 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.0853\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3182 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.9225\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2122 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.1341\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2931 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9258\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2282 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 3.9616\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2193 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.1341\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9749 - cost: 3.2040 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.0007\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1670 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9679 - val_cost: 3.9583\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9751 - cost: 3.1838 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 4.0072\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1061 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.7728\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0629 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 3.8607\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0767 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9667 - val_cost: 4.0007\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0766 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.1667\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0653 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9669 - val_cost: 3.9746\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0306 - val_loss: 0.1095 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9876\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0307 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9225\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0175 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9679 - val_cost: 3.9160\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9728 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9674 - val_cost: 4.0072\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9617 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7565\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9609 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9941\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9031 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.1471\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9607 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 3.9518\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9337 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.9779\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8594 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9388\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8463 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.8997\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8697 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9518\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8930 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.1113\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8377 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.1699\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9097 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 4.0853\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8321 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8607\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8594 - val_loss: 0.1088 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9258\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8043 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.9616\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8239 - val_loss: 0.1081 - val_auc: 0.9901 - val_accuracy: 0.9691 - val_cost: 3.8477\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9777 - cost: 2.8502 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 3.9746\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7809 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.6751\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7809 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.1146\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7722 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 4.2188\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7963 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8835\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7740 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.1504\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7589 - val_loss: 0.1083 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 4.1634\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7505 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.9128\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7501 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9648\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7251 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 4.0234\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7819 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 4.0137\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7128 - val_loss: 0.1088 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 4.1634\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6892 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7695\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6598 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 3.9811\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7310 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7598\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.7207\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7215 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.0885\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7312 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8867\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6504 - val_loss: 0.1117 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.7467\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6146 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9616\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6504 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6358 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6327 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6204 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.8704\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5844 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 4.1211\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5969 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9030\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5908 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.9518\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6070 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8737\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5576 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.9518\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5996 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 3.9160\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5912 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 4.0951\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5846 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9128\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5773 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8118\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5450 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 4.0365\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5181 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7956\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6010 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7565\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5402 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.7923\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5155 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5203 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8509\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4826 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7305\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5077 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.8379\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5173 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.7012\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5223 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4593 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6849\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4802 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7923\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5233 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.9323\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5268 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8900\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4502 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8184\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4796 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.9225\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4362 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7793\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4908 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.9746\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4565 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.8184\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4709 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.8900\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4042 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.9876\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4507 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.9128\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4328 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.8411\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4089 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.9290\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4604 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 4.0495\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3962 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 4.0755\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4662 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 4.0625\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4303 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9693 - val_cost: 4.0690\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4412 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 4.0690\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4399 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9225\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4407 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5158 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 4.0397\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 4.0332\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3791 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8477\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3637 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9616\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3609 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4355 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 4.0267\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4453 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.9974\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3819 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.8281\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3401 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7793\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4562 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8086\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4131 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.8314\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3439 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.8281\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3079 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6947\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3285 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8477\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3971 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.9681\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3112 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 4.0234\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3446 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.9714\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3580 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.9974\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3479 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5026\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3502 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7826\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3317 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.8770\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.8607\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8607\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3240 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3257 - val_loss: 0.1130 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8737\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2811 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.9193\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3528 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.8249\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3164 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.8997\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3071 - val_loss: 0.1164 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.3724\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2660 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3415 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7272\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3472 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.6882\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2829 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.9876\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2927 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.8444\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2996 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.8932\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2826 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.9388\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2844 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.8477\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2792 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.9421\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3008 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.8249\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3191 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5547\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2972 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7630\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3033 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.7272\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3234 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7533\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3102 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.8151\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2523 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.4473\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2594 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.9421\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3058 - val_loss: 0.1147 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.8965\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2831 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7402\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7500\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2761 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9704 - val_cost: 3.9323\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2856 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7174\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2630 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2467 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3312 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7630\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2208 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8346\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2198 - val_loss: 0.1168 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9974\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2108 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9698 - val_cost: 3.9876\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.7305\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2502 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.9518\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1638 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.6849\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1924 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.7272\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2502 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2246 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2622 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.8574\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2569 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7207\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1688 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.7988\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2195 - val_loss: 0.1164 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.9030\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1633 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.9974\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1883 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7402\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1985 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6816\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2979 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9704 - val_cost: 3.7142\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2416 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 4.0299\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2238 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7174\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2368 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 4.0560\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2248 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.5286\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2461 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 4.0658\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2607 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7402\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1659 - val_loss: 0.1170 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7565\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1070 - auc: 0.9907 - accuracy: 0.9721 - cost: 3.5219\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:13.533926\n",
            "fold accuracy: 0.9721249938011169 - fold cost: 3.5218749046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5273 - auc: 0.8003 - accuracy: 0.7309 - cost: 35.7981 - val_loss: 0.3946 - val_auc: 0.9016 - val_accuracy: 0.8294 - val_cost: 21.2565\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.3473 - auc: 0.9233 - accuracy: 0.8512 - cost: 18.9520 - val_loss: 0.3152 - val_auc: 0.9375 - val_accuracy: 0.8668 - val_cost: 15.9831\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2982 - auc: 0.9438 - accuracy: 0.8768 - cost: 15.6007 - val_loss: 0.2831 - val_auc: 0.9495 - val_accuracy: 0.8843 - val_cost: 14.0397\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2697 - auc: 0.9541 - accuracy: 0.8899 - cost: 13.9321 - val_loss: 0.2578 - val_auc: 0.9583 - val_accuracy: 0.8972 - val_cost: 12.6074\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2464 - auc: 0.9618 - accuracy: 0.9013 - cost: 12.4921 - val_loss: 0.2394 - val_auc: 0.9639 - val_accuracy: 0.9061 - val_cost: 11.7839\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2274 - auc: 0.9674 - accuracy: 0.9106 - cost: 11.3212 - val_loss: 0.2231 - val_auc: 0.9684 - val_accuracy: 0.9165 - val_cost: 10.3646\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2122 - auc: 0.9714 - accuracy: 0.9178 - cost: 10.3902 - val_loss: 0.2088 - val_auc: 0.9725 - val_accuracy: 0.9224 - val_cost: 9.3001\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1988 - auc: 0.9748 - accuracy: 0.9247 - cost: 9.5071 - val_loss: 0.1968 - val_auc: 0.9752 - val_accuracy: 0.9283 - val_cost: 9.0690\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1872 - auc: 0.9775 - accuracy: 0.9295 - cost: 8.9058 - val_loss: 0.1868 - val_auc: 0.9774 - val_accuracy: 0.9339 - val_cost: 8.1608\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1779 - auc: 0.9796 - accuracy: 0.9341 - cost: 8.3421 - val_loss: 0.1798 - val_auc: 0.9788 - val_accuracy: 0.9364 - val_cost: 7.9264\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1702 - auc: 0.9812 - accuracy: 0.9370 - cost: 7.9742 - val_loss: 0.1734 - val_auc: 0.9801 - val_accuracy: 0.9389 - val_cost: 7.5293\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1636 - auc: 0.9825 - accuracy: 0.9405 - cost: 7.5225 - val_loss: 0.1682 - val_auc: 0.9812 - val_accuracy: 0.9401 - val_cost: 7.3633\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9430 - cost: 7.2140 - val_loss: 0.1652 - val_auc: 0.9819 - val_accuracy: 0.9426 - val_cost: 7.2396\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1538 - auc: 0.9843 - accuracy: 0.9448 - cost: 6.9764 - val_loss: 0.1631 - val_auc: 0.9824 - val_accuracy: 0.9438 - val_cost: 6.5820\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1494 - auc: 0.9851 - accuracy: 0.9468 - cost: 6.7326 - val_loss: 0.1579 - val_auc: 0.9832 - val_accuracy: 0.9449 - val_cost: 6.8913\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1453 - auc: 0.9857 - accuracy: 0.9482 - cost: 6.5632 - val_loss: 0.1553 - val_auc: 0.9835 - val_accuracy: 0.9456 - val_cost: 6.8099\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1416 - auc: 0.9865 - accuracy: 0.9500 - cost: 6.3113 - val_loss: 0.1527 - val_auc: 0.9841 - val_accuracy: 0.9485 - val_cost: 6.3216\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1395 - auc: 0.9867 - accuracy: 0.9514 - cost: 6.1523 - val_loss: 0.1522 - val_auc: 0.9843 - val_accuracy: 0.9491 - val_cost: 6.2663\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1362 - auc: 0.9873 - accuracy: 0.9521 - cost: 6.0703 - val_loss: 0.1498 - val_auc: 0.9846 - val_accuracy: 0.9488 - val_cost: 6.3932\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1344 - auc: 0.9875 - accuracy: 0.9535 - cost: 5.8896 - val_loss: 0.1480 - val_auc: 0.9849 - val_accuracy: 0.9503 - val_cost: 6.1003\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1316 - auc: 0.9880 - accuracy: 0.9542 - cost: 5.7926 - val_loss: 0.1459 - val_auc: 0.9852 - val_accuracy: 0.9522 - val_cost: 5.8561\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9885 - accuracy: 0.9558 - cost: 5.6063 - val_loss: 0.1441 - val_auc: 0.9857 - val_accuracy: 0.9531 - val_cost: 5.6901\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1271 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4930 - val_loss: 0.1438 - val_auc: 0.9858 - val_accuracy: 0.9533 - val_cost: 5.5046\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1244 - auc: 0.9890 - accuracy: 0.9576 - cost: 5.3841 - val_loss: 0.1411 - val_auc: 0.9860 - val_accuracy: 0.9540 - val_cost: 5.5859\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1227 - auc: 0.9892 - accuracy: 0.9589 - cost: 5.2177 - val_loss: 0.1420 - val_auc: 0.9861 - val_accuracy: 0.9540 - val_cost: 5.2441\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2126 - val_loss: 0.1379 - val_auc: 0.9863 - val_accuracy: 0.9563 - val_cost: 5.2995\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9598 - cost: 5.1094 - val_loss: 0.1362 - val_auc: 0.9864 - val_accuracy: 0.9565 - val_cost: 5.2311\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1174 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9853 - val_loss: 0.1351 - val_auc: 0.9867 - val_accuracy: 0.9578 - val_cost: 4.9349\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1159 - auc: 0.9901 - accuracy: 0.9613 - cost: 4.9098 - val_loss: 0.1355 - val_auc: 0.9869 - val_accuracy: 0.9576 - val_cost: 4.8438\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1140 - auc: 0.9905 - accuracy: 0.9620 - cost: 4.8233 - val_loss: 0.1340 - val_auc: 0.9868 - val_accuracy: 0.9592 - val_cost: 4.7624\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1123 - auc: 0.9906 - accuracy: 0.9631 - cost: 4.6876 - val_loss: 0.1318 - val_auc: 0.9870 - val_accuracy: 0.9599 - val_cost: 4.8405\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9642 - cost: 4.5332 - val_loss: 0.1328 - val_auc: 0.9868 - val_accuracy: 0.9590 - val_cost: 4.8145\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9637 - cost: 4.6163 - val_loss: 0.1315 - val_auc: 0.9871 - val_accuracy: 0.9603 - val_cost: 4.6973\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9643 - cost: 4.5463 - val_loss: 0.1292 - val_auc: 0.9875 - val_accuracy: 0.9614 - val_cost: 4.5215\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1064 - auc: 0.9913 - accuracy: 0.9655 - cost: 4.3882 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9608 - val_cost: 4.6419\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9654 - cost: 4.3892 - val_loss: 0.1278 - val_auc: 0.9877 - val_accuracy: 0.9626 - val_cost: 4.3685\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9915 - accuracy: 0.9661 - cost: 4.3088 - val_loss: 0.1275 - val_auc: 0.9877 - val_accuracy: 0.9616 - val_cost: 4.5215\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9664 - cost: 4.2430 - val_loss: 0.1264 - val_auc: 0.9878 - val_accuracy: 0.9623 - val_cost: 4.6224\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1636 - val_loss: 0.1251 - val_auc: 0.9880 - val_accuracy: 0.9631 - val_cost: 4.4141\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9672 - cost: 4.1723 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9622 - val_cost: 4.2936\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9920 - accuracy: 0.9679 - cost: 4.0813 - val_loss: 0.1233 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.5443\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9683 - cost: 4.0134 - val_loss: 0.1231 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.2806\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9689 - cost: 3.9505 - val_loss: 0.1236 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.2025\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9687 - cost: 3.9744 - val_loss: 0.1210 - val_auc: 0.9884 - val_accuracy: 0.9646 - val_cost: 4.2871\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0967 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9153 - val_loss: 0.1204 - val_auc: 0.9884 - val_accuracy: 0.9642 - val_cost: 4.2578\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9426 - val_loss: 0.1207 - val_auc: 0.9883 - val_accuracy: 0.9657 - val_cost: 4.0072\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7751 - val_loss: 0.1207 - val_auc: 0.9883 - val_accuracy: 0.9644 - val_cost: 4.3034\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7476 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9649 - val_cost: 4.0332\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9706 - cost: 3.7372 - val_loss: 0.1202 - val_auc: 0.9884 - val_accuracy: 0.9647 - val_cost: 4.2415\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6901 - val_loss: 0.1196 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2806\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9711 - cost: 3.6781 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.2546\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5636 - val_loss: 0.1203 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.3359\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0896 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5040 - val_loss: 0.1170 - val_auc: 0.9888 - val_accuracy: 0.9667 - val_cost: 3.9876\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5084 - val_loss: 0.1171 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.0169\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4448 - val_loss: 0.1173 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1081\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9727 - cost: 3.4752 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.8997\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4438 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9659 - val_cost: 4.0885\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.3961 - val_loss: 0.1176 - val_auc: 0.9888 - val_accuracy: 0.9654 - val_cost: 3.9648\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.4027 - val_loss: 0.1173 - val_auc: 0.9889 - val_accuracy: 0.9672 - val_cost: 3.7956\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3849 - val_loss: 0.1164 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.0527\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3379 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.0495\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2882 - val_loss: 0.1154 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 4.0169\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9740 - cost: 3.3186 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 3.9681\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9744 - cost: 3.2545 - val_loss: 0.1160 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.0462\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.2124 - val_loss: 0.1158 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 3.7370\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9744 - cost: 3.2549 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 3.9486\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1734 - val_loss: 0.1167 - val_auc: 0.9886 - val_accuracy: 0.9666 - val_cost: 3.8249\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 3.8053\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1804 - val_loss: 0.1159 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 3.8118\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9750 - cost: 3.1866 - val_loss: 0.1155 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 3.8509\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0865 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9672 - val_cost: 3.9714\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1001 - val_loss: 0.1135 - val_auc: 0.9891 - val_accuracy: 0.9683 - val_cost: 3.8477\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0253 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 3.7891\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0408 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.6458\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0406 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9671 - val_cost: 3.8314\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9751 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 3.7142\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0596 - val_loss: 0.1143 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9160\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0355 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.8509\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9181 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.6654\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9619 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 3.8900\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9765 - cost: 3.0025 - val_loss: 0.1127 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.0202\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9277 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.7207\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9023 - val_loss: 0.1135 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 4.0365\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8481 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7533\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9558 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 4.1146\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.8952 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.6296\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8102 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.6523\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8145 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 3.6393\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8667 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.8151\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8075 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.7207\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9778 - cost: 2.8373 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7240\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7963 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6165\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8184 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7337\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8302 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.7174\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8209 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7858\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8205 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.7207\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7315 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9193\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7763 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.5352\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7419 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6458\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7433 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.5352\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7190 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.6621\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7574 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9693 - val_cost: 3.5384\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6720 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7169 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.5677\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6820 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.7305\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7076 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.5579\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7130 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8086\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6990 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6434 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6907 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.6719\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6052 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.5775\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6305 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7272\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6807 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.6165\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6602 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9696 - val_cost: 3.7500\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6530 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.4408\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7448 - val_loss: 0.1164 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.6230\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5844 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6064 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.4310\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6132 - val_loss: 0.1157 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.4961\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6484 - val_loss: 0.1141 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6146 - val_loss: 0.1148 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5547\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.5986 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6251 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.6947\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5628 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.4277\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5571 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.5905\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5593 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.6458\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6216 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.3105\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5312 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5885 - val_loss: 0.1128 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5465 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.4473\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5434 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.3854\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6310 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5726 - val_loss: 0.1167 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.4245\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5307 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5504 - val_loss: 0.1153 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.5319\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5289 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.4212\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5348 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7370\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5135 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5026\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5116 - val_loss: 0.1142 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.4570\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4857 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4017\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4881 - val_loss: 0.1149 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.3887\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4716 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.4245\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5696 - val_loss: 0.1143 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5072 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9720 - val_cost: 3.2780\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5117 - val_loss: 0.1159 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.5514\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4800 - val_loss: 0.1145 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4827 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4841 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.4766\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5297 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.4988 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5221\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4931 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.5645\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4352 - val_loss: 0.1156 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.4505\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4428 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.3073\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4538 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5514\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4292 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4345 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5417\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4629 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.3659\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4365 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.5124\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4179 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.3073\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4458 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5189\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4169 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.4473\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4485 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.5547\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3394 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.2650\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4002 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3851 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6361\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3819 - val_loss: 0.1173 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.3822\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3776 - val_loss: 0.1185 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.7109\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4179 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9704 - val_cost: 3.4082\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4530 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.3008\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3590 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.4766\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3747 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4214 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7012\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4200 - val_loss: 0.1180 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.4766\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4154 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3775 - val_loss: 0.1179 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5156\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4442 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4701\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3451 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6947\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4080 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.3887\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3995 - val_loss: 0.1193 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.2650\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3214 - val_loss: 0.1196 - val_auc: 0.9886 - val_accuracy: 0.9707 - val_cost: 3.5319\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2712 - val_loss: 0.1187 - val_auc: 0.9889 - val_accuracy: 0.9705 - val_cost: 3.4180\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4059 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9713 - val_cost: 3.4180\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3473 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4419 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.7891\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3527 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6914\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3412 - val_loss: 0.1206 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.5807\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3320 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.5970\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3556 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3598 - val_loss: 0.1190 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.5970\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2693 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5319\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3408 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9702 - val_cost: 3.4505\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3706 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9701 - val_cost: 3.6751\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3439 - val_loss: 0.1197 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.5384\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3698 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9704 - val_cost: 3.5319\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3697 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3292 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9702 - val_cost: 3.6100\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3300 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.4082\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3221 - val_loss: 0.1234 - val_auc: 0.9890 - val_accuracy: 0.9700 - val_cost: 3.6882\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3751 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3222 - val_loss: 0.1207 - val_auc: 0.9891 - val_accuracy: 0.9702 - val_cost: 3.6914\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2593 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9711 - val_cost: 3.5026\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3473 - val_loss: 0.1248 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.5970\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2908 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.4668\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3212 - val_loss: 0.1199 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6035\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2844 - val_loss: 0.1215 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.4570\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3029 - val_loss: 0.1212 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.4798\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2916 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.5677\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3025 - val_loss: 0.1210 - val_auc: 0.9889 - val_accuracy: 0.9709 - val_cost: 3.5156\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3541 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9720 - val_cost: 3.3822\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2950 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.5938\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2362 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2477 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2825 - val_loss: 0.1230 - val_auc: 0.9890 - val_accuracy: 0.9707 - val_cost: 3.3789\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1030 - auc: 0.9912 - accuracy: 0.9717 - cost: 3.5469\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:02.685576\n",
            "fold accuracy: 0.9716874957084656 - fold cost: 3.546875\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5223 - auc: 0.8047 - accuracy: 0.7337 - cost: 35.4095 - val_loss: 0.3889 - val_auc: 0.9049 - val_accuracy: 0.8323 - val_cost: 21.1003\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3468 - auc: 0.9235 - accuracy: 0.8515 - cost: 18.8943 - val_loss: 0.3104 - val_auc: 0.9390 - val_accuracy: 0.8694 - val_cost: 16.0840\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8753 - cost: 15.8098 - val_loss: 0.2808 - val_auc: 0.9502 - val_accuracy: 0.8831 - val_cost: 14.4238\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2702 - auc: 0.9538 - accuracy: 0.8901 - cost: 13.9252 - val_loss: 0.2550 - val_auc: 0.9591 - val_accuracy: 0.8976 - val_cost: 12.9427\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2467 - auc: 0.9615 - accuracy: 0.9012 - cost: 12.5477 - val_loss: 0.2354 - val_auc: 0.9648 - val_accuracy: 0.9072 - val_cost: 11.7773\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2293 - auc: 0.9667 - accuracy: 0.9093 - cost: 11.4974 - val_loss: 0.2185 - val_auc: 0.9698 - val_accuracy: 0.9157 - val_cost: 10.2344\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2131 - auc: 0.9712 - accuracy: 0.9175 - cost: 10.4424 - val_loss: 0.2055 - val_auc: 0.9735 - val_accuracy: 0.9218 - val_cost: 9.6712\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2008 - auc: 0.9743 - accuracy: 0.9236 - cost: 9.6655 - val_loss: 0.1941 - val_auc: 0.9761 - val_accuracy: 0.9271 - val_cost: 9.0820\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1889 - auc: 0.9771 - accuracy: 0.9290 - cost: 9.0056 - val_loss: 0.1838 - val_auc: 0.9781 - val_accuracy: 0.9336 - val_cost: 8.3984\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1795 - auc: 0.9792 - accuracy: 0.9332 - cost: 8.4660 - val_loss: 0.1782 - val_auc: 0.9792 - val_accuracy: 0.9348 - val_cost: 8.6165\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1716 - auc: 0.9809 - accuracy: 0.9364 - cost: 8.0521 - val_loss: 0.1698 - val_auc: 0.9811 - val_accuracy: 0.9382 - val_cost: 8.0794\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1656 - auc: 0.9821 - accuracy: 0.9396 - cost: 7.6526 - val_loss: 0.1639 - val_auc: 0.9823 - val_accuracy: 0.9416 - val_cost: 7.4902\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1596 - auc: 0.9831 - accuracy: 0.9421 - cost: 7.3463 - val_loss: 0.1590 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 7.5000\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1548 - auc: 0.9841 - accuracy: 0.9437 - cost: 7.1347 - val_loss: 0.1580 - val_auc: 0.9837 - val_accuracy: 0.9435 - val_cost: 6.9401\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1504 - auc: 0.9848 - accuracy: 0.9464 - cost: 6.8067 - val_loss: 0.1528 - val_auc: 0.9842 - val_accuracy: 0.9459 - val_cost: 7.0150\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1464 - auc: 0.9856 - accuracy: 0.9479 - cost: 6.6059 - val_loss: 0.1493 - val_auc: 0.9848 - val_accuracy: 0.9486 - val_cost: 6.6699\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1426 - auc: 0.9862 - accuracy: 0.9493 - cost: 6.4253 - val_loss: 0.1485 - val_auc: 0.9853 - val_accuracy: 0.9475 - val_cost: 6.6276\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1390 - auc: 0.9868 - accuracy: 0.9517 - cost: 6.1114 - val_loss: 0.1422 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.5853\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1349 - auc: 0.9874 - accuracy: 0.9529 - cost: 5.9860 - val_loss: 0.1409 - val_auc: 0.9863 - val_accuracy: 0.9513 - val_cost: 6.3574\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9877 - accuracy: 0.9539 - cost: 5.8584 - val_loss: 0.1384 - val_auc: 0.9866 - val_accuracy: 0.9520 - val_cost: 6.1328\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1297 - auc: 0.9883 - accuracy: 0.9556 - cost: 5.6441 - val_loss: 0.1372 - val_auc: 0.9868 - val_accuracy: 0.9534 - val_cost: 6.0938\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9569 - cost: 5.4682 - val_loss: 0.1331 - val_auc: 0.9874 - val_accuracy: 0.9558 - val_cost: 5.8171\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9891 - accuracy: 0.9578 - cost: 5.3399 - val_loss: 0.1309 - val_auc: 0.9877 - val_accuracy: 0.9557 - val_cost: 6.2402\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1213 - auc: 0.9895 - accuracy: 0.9594 - cost: 5.1654 - val_loss: 0.1299 - val_auc: 0.9878 - val_accuracy: 0.9567 - val_cost: 6.0091\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9896 - accuracy: 0.9599 - cost: 5.0931 - val_loss: 0.1279 - val_auc: 0.9880 - val_accuracy: 0.9588 - val_cost: 5.3874\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1166 - auc: 0.9901 - accuracy: 0.9610 - cost: 4.9642 - val_loss: 0.1283 - val_auc: 0.9880 - val_accuracy: 0.9581 - val_cost: 5.4460\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9903 - accuracy: 0.9620 - cost: 4.8256 - val_loss: 0.1241 - val_auc: 0.9884 - val_accuracy: 0.9592 - val_cost: 5.5697\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7333 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9608 - val_cost: 5.2669\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9640 - cost: 4.5698 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9622 - val_cost: 5.0358\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9638 - cost: 4.6016 - val_loss: 0.1195 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6484\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4446 - val_loss: 0.1177 - val_auc: 0.9892 - val_accuracy: 0.9631 - val_cost: 5.0456\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3490 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9637 - val_cost: 4.5768\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2439 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9626 - val_cost: 4.8340\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9671 - cost: 4.1831 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.5703\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9918 - accuracy: 0.9672 - cost: 4.1681 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9639 - val_cost: 4.5573\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1008 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9647 - val_cost: 4.3229\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9686 - cost: 3.9784 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9652 - val_cost: 4.3229\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9923 - accuracy: 0.9693 - cost: 3.9083 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9658 - val_cost: 4.2741\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0967 - auc: 0.9923 - accuracy: 0.9694 - cost: 3.8946 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.0885\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0955 - auc: 0.9925 - accuracy: 0.9695 - cost: 3.8716 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9664 - val_cost: 4.5475\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0944 - auc: 0.9926 - accuracy: 0.9704 - cost: 3.7721 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9674 - val_cost: 3.9844\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7673 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9671 - val_cost: 4.1439\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6457 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9669 - val_cost: 4.0332\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6615 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9662 - val_cost: 4.2448\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6195 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9669 - val_cost: 3.9811\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5682 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.2611\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5138 - val_loss: 0.1076 - val_auc: 0.9901 - val_accuracy: 0.9672 - val_cost: 3.9779\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.4864 - val_loss: 0.1052 - val_auc: 0.9904 - val_accuracy: 0.9681 - val_cost: 4.0039\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9932 - accuracy: 0.9727 - cost: 3.4849 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9683 - val_cost: 3.8704\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4715 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9674 - val_cost: 4.1113\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9933 - accuracy: 0.9735 - cost: 3.3631 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 3.9160\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9933 - accuracy: 0.9737 - cost: 3.3583 - val_loss: 0.1049 - val_auc: 0.9904 - val_accuracy: 0.9682 - val_cost: 4.0495\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9936 - accuracy: 0.9733 - cost: 3.3965 - val_loss: 0.1044 - val_auc: 0.9904 - val_accuracy: 0.9682 - val_cost: 3.9388\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9935 - accuracy: 0.9742 - cost: 3.2843 - val_loss: 0.1039 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 4.0788\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9935 - accuracy: 0.9744 - cost: 3.2529 - val_loss: 0.1044 - val_auc: 0.9903 - val_accuracy: 0.9689 - val_cost: 3.8965\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3285 - val_loss: 0.1032 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.6621\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2181 - val_loss: 0.1026 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 4.2578\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9749 - cost: 3.1882 - val_loss: 0.1036 - val_auc: 0.9908 - val_accuracy: 0.9688 - val_cost: 4.1243\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2346 - val_loss: 0.1033 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.7663\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1276 - val_loss: 0.1033 - val_auc: 0.9907 - val_accuracy: 0.9685 - val_cost: 4.2546\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1295 - val_loss: 0.1044 - val_auc: 0.9909 - val_accuracy: 0.9693 - val_cost: 3.7760\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1279 - val_loss: 0.1015 - val_auc: 0.9908 - val_accuracy: 0.9692 - val_cost: 3.8411\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0935 - val_loss: 0.1019 - val_auc: 0.9908 - val_accuracy: 0.9684 - val_cost: 4.2318\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0778 - val_loss: 0.1011 - val_auc: 0.9908 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0487 - val_loss: 0.1039 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0670 - val_loss: 0.1027 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0593 - val_loss: 0.1020 - val_auc: 0.9909 - val_accuracy: 0.9695 - val_cost: 3.7012\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9801 - val_loss: 0.1029 - val_auc: 0.9907 - val_accuracy: 0.9695 - val_cost: 3.8086\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0260 - val_loss: 0.1033 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.6914\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0008 - val_loss: 0.1036 - val_auc: 0.9907 - val_accuracy: 0.9702 - val_cost: 3.8900\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9276 - val_loss: 0.1021 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.7207\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9770 - cost: 2.9336 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.8249\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9353 - val_loss: 0.1065 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.7793\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9399 - val_loss: 0.1032 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.7663\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9689 - val_cost: 4.2415\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8903 - val_loss: 0.1039 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.9779\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9944 - accuracy: 0.9778 - cost: 2.8245 - val_loss: 0.1026 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.9128\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8735 - val_loss: 0.1028 - val_auc: 0.9908 - val_accuracy: 0.9714 - val_cost: 3.8574\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8043 - val_loss: 0.1041 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 4.1309\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8299 - val_loss: 0.1051 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.9583\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8351 - val_loss: 0.1035 - val_auc: 0.9907 - val_accuracy: 0.9710 - val_cost: 3.9323\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7582 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7044\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8038 - val_loss: 0.1042 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8020 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.7272\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7885 - val_loss: 0.1035 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.9225\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7732 - val_loss: 0.1067 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.7305\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7306 - val_loss: 0.1057 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 4.0104\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7982 - val_loss: 0.1031 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.5938\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7223 - val_loss: 0.1039 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.7337\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6637 - val_loss: 0.1065 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 4.0202\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8126 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.5645\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7526 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9698 - val_cost: 3.8770\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7376 - val_loss: 0.1039 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.8965\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6466 - val_loss: 0.1037 - val_auc: 0.9907 - val_accuracy: 0.9709 - val_cost: 3.7402\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6709 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.8997\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6407 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9714 - val_cost: 3.5840\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7020 - val_loss: 0.1036 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7196 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5579\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6412 - val_loss: 0.1044 - val_auc: 0.9906 - val_accuracy: 0.9704 - val_cost: 3.8607\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6303 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.8379\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6834 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.9876\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6439 - val_loss: 0.1066 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7826\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6068 - val_loss: 0.1053 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6092 - val_loss: 0.1055 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.9128\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6152 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6054 - val_loss: 0.1064 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5905\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6178 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5857 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.5988 - val_loss: 0.1051 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.8444\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6519 - val_loss: 0.1075 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9160\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5466 - val_loss: 0.1067 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.9290\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5882 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7826\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6064 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7598\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5355 - val_loss: 0.1060 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6481 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7435\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9952 - accuracy: 0.9807 - cost: 2.4572 - val_loss: 0.1070 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5218 - val_loss: 0.1069 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.9128\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5185 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.7500\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5304 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7598\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5705 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.9779\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4616 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5284 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6263\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5098 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.5938\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4609 - val_loss: 0.1065 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4681 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 4.0495\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4804 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.6621\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4919 - val_loss: 0.1077 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.9355\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5469 - val_loss: 0.1085 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.7826\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5052 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.8021\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4953 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.5059\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4701 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.8151\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4783 - val_loss: 0.1060 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.5710\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4648 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6589\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4233 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.8444\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4558 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.5905\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4276 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9719 - val_cost: 3.7467\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5130 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6068\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4417 - val_loss: 0.1061 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.8021\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3900 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.7988\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3663 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.8607\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4502 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.8314\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3966 - val_loss: 0.1090 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.4408\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3938 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.6361\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4062 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.7240\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4566 - val_loss: 0.1071 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.9290\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4168 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.6816\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4114 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5547\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9818 - cost: 2.3434 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7598\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4186 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.8542\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3765 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.7956\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3830 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9721 - val_cost: 3.6165\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3599 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9720 - val_cost: 3.5482\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9955 - accuracy: 0.9819 - cost: 2.3245 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.9811\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3960 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3671 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.9160\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3227 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 4.0104\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3420 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 4.1146\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3198 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3406 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 4.1178\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3581 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.9648\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3586 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.8509\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3795 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.5612\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3555 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7240\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3486 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.8053\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3270 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7142\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3531 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6719\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3411 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7467\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3659 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.8053\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3809 - val_loss: 0.1130 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7858\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2633 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.9551\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3569 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8477\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5449\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2733 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6068\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3271 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 4.1634\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3067 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.9779\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3407 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 4.0658\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3497 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.7012\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2771 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.9941\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3746 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.9648\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3375 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.7142\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2703 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 4.0430\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2714 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 4.2578\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3142 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 4.1699\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2777 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2564 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 4.0755\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3247 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 4.0983\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3071 - val_loss: 0.1132 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3308 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.9193\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2751 - val_loss: 0.1138 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.9421\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2905 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.4993\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2528 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8021\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1079 - auc: 0.9905 - accuracy: 0.9695 - cost: 3.7594\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:50.850991\n",
            "fold accuracy: 0.9695000052452087 - fold cost: 3.7593750953674316\n",
            "total train/predict time: 0:21:54.263216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m5_results = fold_results"
      ],
      "metadata": {
        "id": "h8ySkCi9mPHh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m5 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "m5_cost = cost_func(y,preds_m5)\n",
        "m5_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrG6or3mRV4",
        "outputId": "b977bd6d-06c2-4571-955d-d88ffe938011"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581950"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new5 = np.zeros(len(y))\n",
        "for i in m5_results.keys():\n",
        "  for j in range(len(m5_results.get(i).get('predictions'))):\n",
        "    idx = m5_results.get(i).get('index')[j]\n",
        "    if m5_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new5[idx] = 1\n",
        "    else:\n",
        "      preds_new5[idx] = 0\n",
        "\n",
        "m5_cost_t = cost_func(y,preds_new5)\n",
        "m5_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGSE-MSmS5Q",
        "outputId": "4365aa00-2d8a-4733-baed-b1e8abd3456b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571900"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhEJqvbmWkK",
        "outputId": "36dc6633-ac03-4551-d7db-81db85649aad"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('model5.keras')"
      ],
      "metadata": {
        "id": "bmq9o4ehJjIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_alt = pd.DataFrame()\n",
        "\n",
        "#one hot encoding categorical variables for model\n",
        "cols = df.columns\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = list((set(cols) - set(num_cols)))\n",
        "\n",
        "#creating dataframe of categorical columns\n",
        "cat_df = df[cat_cols]\n",
        "cat_df = pd.get_dummies(cat_df, columns=cat_df.columns,sparse=True)\n",
        "cat_df\n",
        "\n",
        "y_alt['Volume_high']= cat_df['Volume_high']\n",
        "y_alt['preds_m1']=preds_m1\n",
        "y_alt['preds_m2']=preds_m2\n",
        "y_alt['preds_m3']=preds_m3\n",
        "y_alt['preds_m4']=preds_m4\n",
        "y_alt['preds_m5']=preds_m5\n",
        "\n",
        "y_alt['preds_new4']=preds_new4\n",
        "y_alt['preds_new5']=preds_new5\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OK8IPut_IfuM",
        "outputId": "c11792f6-6b06-41d7-f4f0-733599438ae6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-129-e030d734e541>:26: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1973f4bc-2894-419c-b485-b98c81f96dc5\", \"results.csv\", 5168973)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zPmhthDgm1OQ",
        "outputId": "0d80090e-73e4-41c5-db56-f380f0af98b6"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Volume_high  preds_m1  preds_m2  preds_m3  preds_m4  preds_m5  \\\n",
              "0                 1         0         0       0.0       0.0       0.0   \n",
              "1                 1         1         0       0.0       0.0       0.0   \n",
              "2                 1         0         0       0.0       0.0       0.0   \n",
              "3                 1         1         1       1.0       0.0       0.0   \n",
              "4                 1         1         1       1.0       1.0       1.0   \n",
              "...             ...       ...       ...       ...       ...       ...   \n",
              "159995            1         1         1       1.0       1.0       1.0   \n",
              "159996            1         0         0       0.0       0.0       0.0   \n",
              "159997            1         1         0       0.0       0.0       0.0   \n",
              "159998            1         0         0       0.0       0.0       0.0   \n",
              "159999            1         0         1       1.0       1.0       1.0   \n",
              "\n",
              "        preds_new4  preds_new5  \n",
              "0              0.0         0.0  \n",
              "1              0.0         0.0  \n",
              "2              0.0         0.0  \n",
              "3              0.0         0.0  \n",
              "4              1.0         1.0  \n",
              "...            ...         ...  \n",
              "159995         1.0         1.0  \n",
              "159996         0.0         0.0  \n",
              "159997         0.0         0.0  \n",
              "159998         0.0         0.0  \n",
              "159999         1.0         1.0  \n",
              "\n",
              "[160000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-46857298-dac1-49e6-b3aa-5b98db247ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume_high</th>\n",
              "      <th>preds_m1</th>\n",
              "      <th>preds_m2</th>\n",
              "      <th>preds_m3</th>\n",
              "      <th>preds_m4</th>\n",
              "      <th>preds_m5</th>\n",
              "      <th>preds_new4</th>\n",
              "      <th>preds_new5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160000 rows  8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46857298-dac1-49e6-b3aa-5b98db247ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b94e425e-803c-4530-8112-7ae952694255\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b94e425e-803c-4530-8112-7ae952694255')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b94e425e-803c-4530-8112-7ae952694255 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46857298-dac1-49e6-b3aa-5b98db247ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46857298-dac1-49e6-b3aa-5b98db247ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "OGDgxEMEAh0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix of Results\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m3 = confusion_matrix(y,preds_m3)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_new4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_new5)\n",
        "\n",
        "fig, ax = plt.subplots(1,5,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_m1).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Logistic Regression'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m1:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_m2).plot(ax= ax[1],cmap='Blues', colorbar=False)\n",
        "ax[1].set_title('Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m2:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_m3).plot(ax= ax[2],cmap='Blues', colorbar=False)\n",
        "ax[2].set_title('XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m3_cost:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm_preds_m4).plot(ax= ax[3],cmap='Blues', colorbar=False)\n",
        "ax[3].set_title('Neural Network 1'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m4_cost_t:,}'), fontsize = 12)\n",
        "ax[3].grid(False)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm_preds_m5).plot(ax= ax[4],cmap='Blues', colorbar=False)\n",
        "ax[4].set_title('Neural Network 2'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m5_cost_t:,}'), fontsize = 12)\n",
        "ax[4].grid(False)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hYPzNzlQ36Ct",
        "outputId": "0f8ce5de-cbc6-48ab-bfa9-cbd1eb226eb2"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABlAAAAGSCAYAAACc84zlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC7QElEQVR4nOzdZ1RU1x6G8ZcqoKBib9jBLvbYexeNPbG32E00mkTTjYmJSbyJLfbee+899t57r4iIBVARgbkfCBNnGBQQAzrPby3XvZy6ZyKv+5z/OXvbGAwGgwAAAAAAAAAAAGBkm9gNAAAAAAAAAAAASGoooAAAAAAAAAAAAJihgAIAAAAAAAAAAGCGAgoAAAAAAAAAAIAZCigAAAAAAAAAAABmKKAAAAAAAAAAAACYoYACAAAAAAAAAABghgIKAAAAAAAAAACAGQooAAAAAAAAAAAAZiigIM7atm2rtm3bJtjxqlWrpoEDBybY8SB5eXlp1KhRid0MAPE0cOBAVatWLbGbAQAAgERw8+ZNeXl5acmSJYndlCRl1KhR8vLy0v379xO7KQDeIDLQMjIw8VBAeYstWbJEXl5eOnHiRGI35ZUOHz6sUaNGKTAw8I2ep1q1avLy8jL+8fb2VrNmzbRs2bI3el4Ab6eoHI36U6BAAVWsWFEDBw6Un59fYjcvyTD/nl788/vvvyd28ywaN26cNm3alNjNAPCPAQMGqHDhwrpy5Uq0dRMmTJCXl5e2bt1qXBYaGqqZM2fqww8/VKlSpVSoUCFVqFBB3bt316pVqxQeHm7cNuoi+8U/xYsXV6NGjTRr1iyTbRPL7NmzuQkA/Aei+iyFCxe22Jdr27atGjRokAgtezP27dtnzL2TJ09GWz9w4EAVK1YsXsfevn37O/VQ3uPHjzVy5Eh17txZpUuX5uYs3klkoCky8F/Hjx/XDz/8oPr168vb21tVqlTRJ598YrFvjujsE7sBePtMnjw5zvscOXJEo0ePVuPGjeXm5maybt26dbKxsUmo5il//vzq2LGjJMnf318LFy7UF198odDQULVo0SLBzpOUHT9+XHZ2dondDOCt8fHHHytr1qwKDQ3V0aNHtXTpUh06dEirVq1SsmTJErt5SUbU9/QiT0/PRGrNy40fP161a9dWjRo1ErspACQNGjRIf//9t7777jvNmDHDuPzGjRsaM2aMateurapVq0qS7t+/ry5duujUqVOqUKGCevTooZQpU+revXvavXu3+vfvr2vXrqlXr14m52jQoIEqVaokSQoODtb27ds1ZMgQ3bp1S1988cV/92EtmDt3rlKnTq0mTZokajsAaxEaGqoJEybom2++Seym/GdGjx6tcePGJdjxtm/frtmzZ6tPnz4JdszE9ODBA40ZM0aZM2eWl5eX9u/fn9hNAt4YMvD1vWsZOGnSJB0+fFh16tSRl5eX/P39NXv2bDVp0kTz589Pstf1SQUFFMSZo6Njkj5ehgwZ1KhRI+PPTZo0UfXq1TVt2rT/vIDy5MkTubi4/KfnlMQNXyCOKlWqpMKFC0uSmjdvrtSpU2vixInavHmz6tWrl8itSzpe/J4SUmJlJYD/Tpo0aTRgwAB98803Wrp0qRo3bixJGjx4sOzt7fXVV18Zt/3ss8905swZjRo1SrVq1TI5Trdu3XTixAmLT8sVKFDApA/YqlUrNW/eXKtWrUr0AgqA/1b+/Pm1YMECde3aVRkyZEjs5ujZs2dycHCQre2bGQQkf/782rp1q06dOqWCBQu+kXMkpoToK6ZPn147d+5UunTpdOLECTVr1iyBWgckPWTguyUhMrBDhw76/fffTe7B1qtXTz4+PpowYUKSHVkiqWAILytw+vRpdenSRcWLF1exYsXUvn17HT16NNp2Z8+eVZs2bVSkSBFVqlRJf/31lxYvXiwvLy/dvHnTuJ2lOVBmzpyp+vXrq2jRoipVqpSaNGmilStXSooco+/XX3+VJFWvXt34el3UMS3NgRIYGKihQ4eqWrVqKlSokCpVqqTPP/88XuP8ubu7K1euXLp+/brJ8oiICE2bNk3169dX4cKFVa5cOX377bd69OhRtO1GjRqlChUqqGjRomrbtq0uXrwYrd1Rr0ru379f33//vcqWLavKlSsb12/fvl2tWrWSt7e3ihUrpq5du+rChQsm5/L399egQYNUqVIl41AVPXr0MPn+T5w4oc6dO6tMmTIqUqSIqlWrpkGDBpkcx9IcKLH5exD1GQ4dOqSff/5Z7733nry9vdWrVy/GWIRVKVmypKTIJ6OjhIaGasSIEWrSpIlKlCghb29vtWrVSnv37jXZN2oomcmTJ2v+/PmqUaOGChUqpKZNm+r48ePRzrVp0yY1aNBAhQsXVoMGDbRx40aLbXry5Il++eUXVa5cWYUKFVLt2rU1efJkGQwGk+28vLz0ww8/aO3atapXr56KFCmili1b6ty5c5KkefPmqWbNmipcuLDatm1rki+va8+ePcacK1mypHr06KFLly6ZbBM1buvFixfVv39/lSpVSq1atTKuX758uZo0aaIiRYqodOnS6tevn3x9fU2OcfXqVfXp00fly5dX4cKFValSJfXr109BQUHG7+DJkydaunSp8d8c5toCEl/z5s1VvHhxDRs2TA8ePNDq1au1Y8cO9e3b13hxf+TIEe3cuVMtWrSIVjyJUrhwYTVs2PCV57OxsVHatGllbx/9mbHZs2erfv36xv7W4MGDLQ41u3btWmMmlSlTRgMGDIg2JMar+m/VqlXThQsXtH//fmMmJeR8ggCi69atmyIiIjRx4sRYbR+b/kdMc3eaXx9HDSmzevVq/fHHH6pYsaKKFi2q4OBgPXz4UMOGDZOPj4+KFSum4sWLq0uXLjp79uxrfd42bdooZcqUsR5u5lXXpgMHDtTs2bMlyWR4RElq3LixevfubXI8Hx8feXl5mXyONWvWyMvLy6QvGJdr0piuq83dunVLNWvWVIMGDXTv3r0Yt3N0dFS6dOle/eUA7wAy8OWsMQOLFy8e7QH2HDlyKG/evLp8+XKM+yESb6C84y5cuKDWrVsrefLk6tKli+zt7TV//ny1bdtWs2bNUtGiRSVJfn5+at++vSSpa9eucnFx0cKFC2P1dsiCBQv0448/qnbt2mrXrp2ePXumc+fO6dixY/Lx8VHNmjV19epVrVq1SoMGDVLq1KklRRY2LHn8+LFat26tS5cuqWnTpipQoIAePHigLVu2yM/PL8b9YhIWFiY/Pz+lTJnSZPm3336rpUuXqkmTJsabiLNnz9bp06c1d+5cOTg4SJKGDx+uSZMmqWrVqqpYsaLOnj2rzp0769mzZxbPN3jwYLm7u6tXr1568uSJJGnZsmUaOHCgKlSooAEDBujp06eaO3euWrVqpaVLlxqHxOnTp48uXryoNm3aKEuWLLp//7527dolX19fZc2aVQEBAercubNSp06trl27ys3NTTdv3ozxhmuU2P49iPLjjz/Kzc1NvXv31q1btzR9+nT98MMP+vPPP+P03QNvq1u3bkmSyZCDwcHBWrhwoRo0aKDmzZvr8ePHWrRokbp06aKFCxcqf/78JsdYtWqVHj9+rJYtW8rGxkaTJk1Snz59tGnTJmO+7Ny5U3369FGePHnUv39/PXjwQIMGDVLGjBlNjmUwGNSjRw/t27dPzZo1U/78+bVjxw79+uuv8vPz05dffmmy/cGDB7VlyxZjYWLChAnq3r27unTpojlz5qhVq1Z69OiRJk2apC+//NJkOJ2XCQ4OjlZMjcrk3bt366OPPlLWrFnVu3dvhYSEaNasWfrwww+1ZMmSaEN/ffLJJ8qePbv69etnLAKNHTtWI0aMUN26ddWsWTPdv39fs2bNUuvWrbVs2TK5ubkpNDRUnTt3VmhoqNq0aaO0adPKz89P27ZtU2BgoFxdXfXrr7/q66+/VpEiRYxvHnp4eMTqMwJ4c2xsbPTDDz+ocePG+v7773Xo0CEVKlRIrVu3Nm4TNQ9KbAok5p4+fWrMqMePH+vvv//Wjh071LVrV5PtRo0apdGjR6tcuXL68MMPdeXKFc2dO1cnTpww6QMuWbJEgwYNUuHChfXpp58qICBAM2bM0OHDh42ZJL26//bll19qyJAhcnFxUffu3SVJadOmjfsXCCDWsmbNqkaNGmnBggX66KOPXvoEdmz6H/Hx119/ycHBwdhvcXBw0MWLF7Vp0ybVqVNHWbNm1b179zR//ny1adNGq1evjveT4ilSpFD79u01cuTIVz6BHZtr05YtW+ru3bvatWuX8WHIKCVKlNDq1auNPz98+FAXLlyQra2tDh06pHz58kmK7I+6u7srd+7ckuJ+TWrputrc9evX1b59e6VMmVJTpkyJ870C4F1FBpKBsWEwGHTv3j3lzZs3TvtZJQPeWosXLzZ4enoajh8/HuM2PXv2NBQsWNBw/fp14zI/Pz9DsWLFDK1btzYuGzJkiMHLy8tw+vRp47IHDx4YSpcubfD09DTcuHHDuLxNmzaGNm3aGH/u0aOHoX79+i9t66RJk6IdJ0rVqlUNX3zxhfHnESNGGDw9PQ0bNmyItm1ERMRLz1O1alVDp06dDAEBAYaAgADDuXPnDJ999pnB09PTMHjwYON2Bw4cMHh6ehpWrFhhsv/ff/9tstzf399QoEABQ8+ePU22GzVqlMHT09Ok3VH/PT788ENDWFiYcXlwcLChZMmShq+//trkGP7+/oYSJUoYlz969Mjg6elpmDRpUoyfb+PGja/8b24wGAyenp6GkSNHGn+O7d+DqM/QoUMHk+966NChhvz58xsCAwNfel7gbRP1d3737t2GgIAAg6+vr2HdunWG9957z1CoUCGDr6+vcduwsDDDs2fPTPZ/9OiRoVy5coZBgwYZl924ccPg6elpKF26tOHhw4fG5Zs2bTJ4enoatmzZYlzWqFEjQ/ny5U1+t3bu3Gnw9PQ0VK1a1bgs6nf/r7/+Mjl/nz59DF5eXoZr164Zl3l6ehoKFSpkkrfz5s0zeHp6GsqXL28ICgoyLh8+fHiM2Wzpe7L058XPUrZsWcODBw+My86cOWPIly+f4fPPPzcuGzlypMHT09Pw6aefmpzj5s2bhvz58xvGjh1rsvzcuXOGAgUKGJefPn3a4OnpaVi7du1L2+zt7W2S0QCSjqjsyZ8/v+HkyZMm63r16mXw9PSM1ucICQkx9u8CAgIMjx49Mq6Lyl1Lf7777juTPk1AQIChYMGChk6dOhnCw8ONy2fNmmXw9PQ0LFq0yGAwGAyhoaGGsmXLGho0aGAICQkxbrd161aDp6enYcSIEQaDIXb9N4PBYKhfv75J/xnAm/HiNfL169cNBQoUMAwZMsS4vk2bNibXrrHtfxgM0a9bXzzmi7/fe/fuNXh6ehqqV69uePr0qcm2z549M8kegyEywwoVKmQYPXq0yTJPT0/D4sWLX/p5o861du1aQ2BgoKFUqVKG7t27G9d/8cUXBm9vb+PPsb02NRgMhsGDB5v09aKsXbvW4Onpabh48aLBYDAYNm/ebChUqJChe/fuhr59+xq38/HxMfTq1cv4c1yvSc2vqw2Gf/uRAQEBhosXLxoqVKhgaNq0qUmfOzaOHz8eq+8XeNuQgWRgXCxbtszg6elpWLhwYbz2tyYM4fUOCw8P165du1SjRg1ly5bNuDx9+vRq0KCBDh06pODgYEnSjh075O3tbfIEdapUqeTj4/PK87i5uenOnTsWh6aJjw0bNihfvnyqWbNmtHWxmWx+586dKlu2rMqWLSsfHx/jq4iff/65cZt169bJ1dVV5cuX1/37941/ChYsKBcXF+3bt09S5HA0YWFhJsPLSJGvB8akRYsWJhO47969W4GBgapfv77JuWxtbVW0aFHjuZycnOTg4KD9+/dHG0YsiqurqyRp27Ztev78+Su/Cylufw9e/AwvftclS5ZUeHi48al84F3ToUMH46uxH3/8sZydnTV27FiTN0Hs7OyMb+VFRETo4cOHCgsLU6FChXT69Olox6xXr57Jm2/mw4LdvXtXZ86cUePGjY2/25JUvnx55cmTx+RYf//9t+zs7KIN+dKpUycZDAb9/fffJsvLli1r8sZH1NMstWrVUooUKYzLixQpYtKmV/n22281depUkz/mnyVVqlTG7fPly6dy5cpp+/bt0Y71wQcfmPy8ceNGRUREqG7duiZZmTZtWmXPnt2YlVHt37lzp54+fRqrdgNIWqLeRk6fPn20J96i+iTm4zzPnTvX2L8rW7ZstL6ZJLVs2dKYTaNGjVLr1q01f/58/fzzz8Ztdu/erefPn6tdu3Ym43A3b95cKVKkMObVyZMnFRAQoA8//NBkbrkqVaooV65c2rZtm6TY9d8AJI5s2bKpYcOGWrBgge7evWtxm9j2P+Lj/fffl5OTk8kyR0dHY/aEh4frwYMHcnFxUc6cOS32J+PC1dVV7dq105YtW2I8VmyvTV8mqk974MABSZFPWRcuXFjly5fXwYMHJUUOyX3hwgXjtvG9Jn3xuvpFFy5cUNu2bZUlSxZNmzYt2mgTAMhAS8jAf126dEk//PCDihUrZpybEDFjCK932P379/X06VPlzJkz2rrcuXMrIiJCvr6+yps3r27duiVvb+9o28VmyJOPPvpIu3fvVvPmzZU9e3aVL19eDRo0UIkSJeLV7uvXr8c45nVsFC1aVH379lV4eLguXLigsWPHKjAw0DgcgyRdu3ZNQUFBKlu2rMVjBAQESJJu374tKfr3kCpVqhgDynyYmqtXr0qScYg0c1E3Ax0dHTVgwAANGzZM5cuXV9GiRVWlShW9//77xrFaS5curdq1a2v06NGaNm2aSpcurRo1asjHxyfG4dbi8vcgSubMmU22i3pl09LY4MC74Ntvv1XOnDkVFBSkxYsX68CBAxZ/p5YuXaopU6boypUrJkVM8997ScqUKZPJz1GZEfV7FJUv2bNnj7aveQfy1q1bSp8+vUnxQ5LxdWDz4qb5uaP2Mx8aLKpwE9vf7SJFilicRD7qs8SUMzt37ow28Z2lrDQYDDHmf9QcBtmyZVPHjh01depUrVy5UiVLllS1atXUsGFDk0IUgKTJ19dXI0eOlKenp86fP69JkyapZ8+exvXJkyeXFDnv04u/07Vr15anp6ck6ZdfflFERES0Y2fPnl3lypUz/lyrVi3Z2Nho+vTpatq0qby8vIx5lStXLpN9HR0dlS1bNmOevizXcuXKpUOHDhn3e1X/DUDi6dmzp1asWKEJEybo66+/jrY+tv2P+LDUP4yIiNCMGTM0Z84c3bx5U+Hh4cZ1Lz6EEl/t27fX9OnTNWrUKI0dOzba+them75M2rRplSNHDh08eFAffPCBDh06pDJlyqhkyZIaMmSIbty4oUuXLikiIsJ4TyA+16SWvr8o3bt3V9q0aTV58mTjvxsAoiMDTZGBkfz9/dWtWze5urpqxIgRMRZq8C8KKHhtuXPn1rp167Rt2zbt2LFDGzZs0Jw5c9SrVy99/PHH/3l7UqdObbx4rlixonLlyqVu3bppxowZ6tixo6TI0E6TJo1+//13i8d4nbFTX3xKUZJxbP9ff/3V4oX0i0HVoUMHVatWTZs2bdLOnTs1YsQITZgwQdOnT1eBAgVkY2OjkSNH6ujRo9q6dat27NihL7/8UlOnTtX8+fMTrPP44hOZlj4L8K55sTBQo0YNtWrVSv3799e6deuMv1fLly/XwIEDVaNGDXXu3Flp0qSRnZ2dxo8fb/ENjpg6If/F71FM507MNpkzz8qIiAjZ2Nho4sSJFtv5YvFl4MCBaty4sTZv3qxdu3bpxx9/1Pjx47VgwYJoRSIAScsPP/wgSZo4caJ+/vlnjRs3Tj4+Psan8aIKG+fPnzd5GCdTpkzG4nDKlCn14MGDWJ2vbNmymjVrlg4ePGic/DOhvar/BiDxvPgEtvl8SFLc+h8xCQ8Pt7iv+ZPXkjRu3DiNGDFCTZs21SeffKKUKVPK1tZWQ4cOTZD+mKurq9q3b69Ro0ZZfAI7LtemL1O8eHHt3btXISEhOnXqlHr27ClPT0+5ubnp4MGDunTpklxcXF4rA837ii+qXbu2li5dqpUrV0Z7qxnAv8hAU2SgFBQUpI8++khBQUGaPXt2vOedsTYUUN5h7u7ucnZ21pUrV6Ktu3z5smxtbY0XolmyZNG1a9eibXf9+vVYncvFxUX16tVTvXr1FBoaqj59+mjcuHHq1q2bkiVLFquht6J4eHjowoULsd7+VapUqaLSpUtr3LhxatmypVxcXOTh4aE9e/aoePHiFkM9StSbGNevXzd5ze7BgwexHqYhar80adKYPBUZEw8PD3Xq1EmdOnXS1atX9f7772vKlCkmxR5vb295e3urX79+WrlypQYMGKA1a9aoefPm0Y4Xl78HACI7TZ9++qnatWun2bNnGzua69evV7Zs2TR69GiTTBs5cmS8zhOVL5ay1/z3NUuWLNqzZ4+Cg4NNnoq5fPmycX1iivosMeVM6tSpX9n59vDwkMFgUNasWS0+mWPOy8tLXl5e6tmzpw4fPqwPP/xQc+fOVb9+/eL3IQC8cRs3btSWLVs0aNAgZcyYUV9++aV27typwYMHa9KkSZIi+20TJkzQypUr4/0284vCwsIkRU4qL/2bV5cvXzbp24WGhurmzZvGvtqLuWb+xvKVK1eiva37qv5bXPrCABJWjx49tGLFCk2cODHaurj0P1KmTGnxrd3bt2+b5MnLrF+/XmXKlNHQoUNNlgcGBhqHN3xdUU9gjx49Otrkz3G5Nn1ZbpUsWVJLlizR6tWrFR4eruLFi8vW1lYlSpQw3jwsXry48WZkQl+Tfv7557Kzs9PgwYOVPHnyWA09DlgrMvBf1p6Bz549U/fu3XX16lVNnTo12tDhiBlzoLzD7OzsVL58eW3evFk3b940Lr93755WrVqlEiVKGG/EVahQQUePHtWZM2eM2z18+FArV6585XnMnwB0dHRU7ty5ZTAYjEPcODs7S4qsdL5KrVq1dPbsWW3cuDHauvhWpLt06aKHDx9qwYIFkqS6desqPDxcf/31V7Rtw8LCjP8olC1bVvb29po7d67JNrNnz471uStWrKgUKVJo/PjxFuctuX//viTp6dOnevbsmck6Dw8PJU+eXKGhoZKkR48eRfsOouatidrGXFz+HgCIVKZMGRUpUkTTp083/l5GdX5e/B08duyYjh49Gq9zpE+fXvnz59fSpUtNsnHXrl26ePGiybaVKlVSeHh4tOyZNm2abGxsVKlSpXi1IaFEfZZly5aZdKrPnz+vXbt2qXLlyq88Rq1atWRnZ6fRo0dHyzmDwWD8tyY4ONh4QzSKp6enbG1tTXLQxcWFYQeBJCQ4OFg//vijChQoYJzPKUOGDPrkk0+0Y8cOrV27VpJUokQJlS9fXgsWLNCmTZssHisu/cGtW7dKipyTSZLKlSsnBwcHzZw50+Q4ixYtUlBQkDGvChUqpDRp0mjevHkm2bJ9+3ZdunRJVapUkRS7/psU2Rcmk4DE4eHhoYYNG2r+/Pny9/c3WRfb/ocUeePt2LFjJr/bW7dula+vb6zbYmdnF+08a9eulZ+fX1w+0ktFPYG9efNmk+t7KfbXptK/1/CWsitqXP+JEyfKy8vLOORiiRIltGfPHp08edKkCP4mrkmHDBmi2rVra+DAgdq8eXOc9gWsCRn4L2vOwPDwcPXt21dHjx7ViBEjVKxYsTidz9rxBso7YPHixdqxY0e05e3atVPfvn21e/dutWrVSq1atZKdnZ3mz5+v0NBQffbZZ8Ztu3TpohUrVqhjx45q06aNXFxctHDhQmXKlEkPHz58aeW1c+fOSps2rYoXL640adLo8uXLmjVrlipXrmwMgIIFC0qS/vjjD9WrV08ODg6qWrWqxSeSO3furPXr1+uTTz5R06ZNVbBgQT169EhbtmzR4MGDjRfAcVG5cmV5enpq2rRpat26tUqXLq2WLVtq/PjxOnPmjMqXLy8HBwddvXpV69at01dffaU6deoobdq0ateunaZMmaLu3burYsWKOnfunP7++2+lTp06Vk8TpkiRQt9//70+//xzNWnSRPXq1ZO7u7tu376t7du3q3jx4vr222919epVdejQQXXq1FGePHlkZ2enTZs26d69e6pfv76kyPkX5s6dqxo1asjDw0OPHz/WggULlCJFipfeQI3t3wMA/+rcubM++eQTLVmyRB9++KGqVKmiDRs2qFevXqpSpYpu3rypefPmKU+ePHry5Em8zvHpp5+qW7duatWqlZo2baqHDx9q1qxZyps3r8kxq1WrpjJlyuiPP/7QrVu35OXlpV27dmnz5s1q3759rOaretM+//xzffTRR2rZsqWaNWumkJAQzZo1S66ururdu/cr9/fw8FDfvn01fPhw3bp1SzVq1FDy5Ml18+ZNbdq0SS1atFDnzp21d+9e/fDDD6pTp45y5Mih8PBwLV++XHZ2dqpdu7bxeAULFtSePXs0depUpU+fXlmzZlXRokXf5FcA4CX+/PNP3b17V6NGjTIZHqF169ZatmyZhg4daryo/e2339SlSxf16tVLlSpVUrly5eTm5qZ79+5p9+7dOnDggMV+z+nTp7V8+XJJkW+c7N27V+vXr1exYsVUoUIFSZFPAHbr1k2jR49Wly5dVK1aNV25ckVz5sxR4cKF1bBhQ0mSg4ODBgwYoEGDBqlNmzaqX7++AgICNGPGDGXJkkUdOnSQpFj136TITJo7d67++usvZc+eXe7u7jHOxQcg4XXv3l3Lly/XlStXTMaYj23/Q5KaN2+u9evXq0uXLqpbt66uX7+ulStXxqkfVqVKFY0ZM0aDBg1SsWLFdP78ea1cuTLWT2/HVrt27TRt2jSdPXvW5Jo7ttem0r/X8D/++KMqVKggOzs7Y65lz55d6dKl05UrV4xFcUkqVaqU8c27qBuMURL6mtTW1la//fabevXqpb59+2rChAmvzNVZs2YpMDDQOKH21q1bdefOHUlS27ZtmU8P7ywyMJI1Z+Avv/yiLVu2qGrVqnr48KGxzxylUaNGcW6DNaGA8g4wfzsiSpMmTZQ3b17Nnj1bw4cP1/jx42UwGFSkSBH99ttvJjeSMmXKpBkzZhjHkXd3d1fr1q3l7OysH3/88aVj77Vs2VIrV67U1KlT9eTJE2XMmFFt27Y1mRC0SJEi+uSTTzRv3jzt2LFDERER2rx5s8UCSvLkyTV79myNGjVKGzdu1NKlS5UmTRqVLVv2tcbm69SpkwYOHKiVK1eqSZMm+uGHH1SoUCHNmzdPf/zxh+zs7JQlSxY1bNhQxYsXN+43YMAAOTk5aeHChdqzZ4+8vb01efJktWrVKsaJ2835+Pgoffr0mjBhgiZPnqzQ0FBlyJBBJUuWVJMmTSRFTu5cv3597dmzRytWrJCdnZ1y5cqlP//803hTsHTp0jpx4oTWrFmje/fuydXVVUWKFNHvv//+0n9wYvv3AMC/atWqJQ8PD02ZMkUtWrRQkyZNdO/ePc2fP187d+5Unjx59Ntvv2ndunXav39/vM5RqVIljRgxQn/++aeGDx8uDw8P/fzzz9q8ebPJMW1tbTV27FiNHDlSa9as0ZIlS5QlSxZ9/vnn6tSpU0J95NdSrlw5TZo0SSNHjtTIkSNlb2+vUqVK6bPPPot1h7hr167KkSOHpk2bpjFjxkiKzMby5curWrVqkiKH7qpQoYK2bt0qPz8/OTs7y8vLSxMnTpS3t7fxWAMHDtS3336rP//8UyEhIWrcuDF5BySSkydPas6cOWrVqpWKFCliss7Ozk7ff/+9WrZsqT///FNff/218c2PefPmae3atRo9erRCQkKUOnVqFSpUSL///rvq1asX7TyrVq3SqlWrJEVOepopUyZ17txZvXr1MpnfrU+fPnJ3d9esWbP0888/K2XKlGrRooU+/fRTOTg4GLdr0qSJnJycNHHiRP3+++9ycXFRjRo19NlnnxmHhIhN/02SevXqpdu3b2vSpEl6/PixSpcuTQEF+A9lz55dDRs21NKlS6Oti03/Q4p8cnngwIGaOnWqhg4dqkKFCmncuHEaNmxYrNvRvXt3PX36VCtXrtSaNWtUoEABjR8/XsOHD3/9D/kCNzc3tW/fXqNHj462LjbXplJkX7ht27ZavXq1VqxYIYPBYFIYLlGihNatW2dy7VywYEE5OzsrLCwsWr/rTVyTOjg4aOTIkfroo4/Us2dPTZs27aXHmjJlim7dumX8ecOGDdqwYYMkqWHDhhRQ8M4iA/9lrRl49uxZSZGF46g3tF9EAeXlbAzMCo2X+OmnnzR//nwdOXIk1pMpWYPAwECVKlVKffv2VY8ePRK7OQAAAAAAAACABMYcKDAKCQkx+fnBgwdasWKFSpQoYdXFE/PvRZKmT58uKfKNEAAAAAAAAADAu4chvGDUsmVLlS5dWrlz59a9e/e0ePFiBQcHmwzFZY3WrFmjpUuXqlKlSnJxcdHhw4e1atUqVahQwWRSKAAAAAAAAADAu4MCCowqV66s9evXa8GCBbKxsVGBAgX0008/qVSpUondtETl5eUlOzs745jVadKkUbt27dS3b9/EbhoAAAAAAAAA4A1hDhQAAAAAAAAAAAAzzIECAAAAAAAAAABghgIKAAAAAAAAAACAGQooAAAAAAAAAAAAZiigAAAAAAAAAAAAmKGAAgAAAAAAAAAAYIYCCgAAAAAAAAAAgBkKKAAAAAAAAAAAAGYooAAAAAAAAAAAAJihgAIAAAAAAAAAAGCGAgoAAAAAAAAAAIAZCigAAAAAAAAAAABmKKAAAAAAAAAAAACYoYACAAAAAAAAAABghgIKAAAAAAAAAACAGQooAAAAAAAAAAAAZiigAAAAAAAAAAAAmKGAAgAAAAAAAAAAYIYCCgAAAAAAAAAAgBkKKAAAAAAAAAAAAGYooAAAAAAAAAAAAJihgAIAAAAAAAAAAGCGAgoAAAAAAAAAAIAZCigAAAAAAAAAAABmKKDgrXPz5k21bds2sZsBAImCDARgrcg/AIgZGQnAmpGBeJPsE7sB+G8FBwdr2rRp2rBhg27cuKHw8HB5eHiocuXKateunTJkyJDg55w9e7acnZ3VpEmTBD+2JaNGjdLo0aOjLXd0dNSJEydeub+Xl1eM68qVK6epU6cafx47dqyOHTum48ePKyAgQL1791afPn2i7bdhwwatWbNGJ06c0L1795QxY0ZVrVpVPXv2lJubW4J+ppja379/f3Xt2tVkmZ+fn4YOHapdu3YpIiJCZcqU0Zdffqls2bK9sk3A28gaMvDy5cuaN2+ejh8/rlOnTik0NFSbN29W1qxZ43W8jh07avfu3WrdurW+/fZb43JfX18tXrxY27Zt07Vr12RraytPT0/16NFD5cqVi3acwMBA/fbbb9q4caNCQkJUuHBhDRw4UAULFox1W9asWaPp06fr3Llzsre3V548efTJJ5+obNmyJtstXLhQU6ZM0c2bN5UpUya1bdvWYmeaDIQ1If8Sfv/g4GD99ddfWrdune7evavUqVOrWLFiGjZsmJydnS3u8/XXX2vhwoWqUqWKxo8fH+vPFpv8ow8IxJ81ZGRsrymXLFmiQYMGxXic3377TQ0bNjT+/Lp5cunSJQ0dOlSHDx+Wg4ODKleurEGDBsnd3d24zc2bN1W9enWL+//vf/9T/fr143xMAP8iA+OXgQlx7b169WpNmjRJFy9eVPLkyVWtWjUNGDDAYl5xnZt4KKBYkRs3bqhDhw7y9fVVnTp11LJlSzk4OOjcuXNatGiRNm3apPXr1yf4eefOnavUqVMnWCiGhYUpLCxM4eHhsrOzi3G777//Xi4uLsafX7bti3799ddoy06ePKkZM2aofPnyJsv//PNPpUuXTvnz59fOnTtjPOY333yj9OnTq2HDhsqcObPOnTunWbNmafv27Vq6dKmcnJxi1bbYfqby5curUaNGJssKFChg8vPjx4/Vrl07BQUFqVu3bnJwcNC0adPUpk0bLVu2TKlTp45Vm4C3hbVk4NGjRzVz5kzlyZNHuXPn1pkzZ+J9rg0bNujo0aMW123evFkTJ05UjRo11LhxY4WFhWn58uXq2LGjhg4dqqZNmxq3jYiIUNeuXXXu3Dl17txZqVOn1pw5c9S2bVstWbJEOXLkeGVbRo0apTFjxqh27drG850/f15+fn4m282bN0/fffedateurY4dO+rgwYP68ccf9fTpU5MbiGQgrAn5Fztx2T8oKEht2rTRnTt31LJlS3l4eOj+/fs6dOiQQkNDLRZQTpw4oaVLlypZsmRxalds80+iDwjEh7VkZJRXXVOWKlXK4jXx9OnTdfbsWZPC7evmyZ07d9S6dWu5urqqX79+evLkiaZMmaLz589r4cKFcnR0NNm+QYMGqlSpkskyb2/v1zomYO3IwPhn4Ov2PefMmaPBgwerbNmyGjhwoPz8/DRjxgydPHlSCxcuNOkzcp2byAywCs+fPzc0bNjQULRoUcOBAweirQ8KCjL873//eyPnrl+/vqFNmzavfZzNmzcb6tSpY/Dy8jJ4enoa8uXLZ6hZs6ZhwYIFJtuNHDnS4OnpaQgICHjtc0b58ssvDV5eXgZfX1+T5Tdu3DAYDAZDQECAwdPT0zBy5EiL++/duzfasqVLlxo8PT2jtd+SuHwmT09Pw+DBg1+53YQJEwyenp6GY8eOGZddvHjRkD9/fsPw4cNfuT/wNrGmDHzw4IEhKCjIYDAYDJMmTTJ4enoasyouQkJCDFWrVjWMHj3aYq6cP38+WiY9e/bMUKdOHUOlSpVMlq9evdrg6elpWLt2rXFZQECAoWTJkoZPP/30lW05cuSIwcvLyzB16tSXbvf06VND6dKlDV27djVZ3r9/f4O3t7fh4cOHxmVkIKwF+Rf7/IvL/t99952hZMmShuvXr8fq2BEREYaWLVsaBg0aZKhatWq0nIpJbPPPYKAPCMSHNWXk61wnP3361FCsWDFDx44dTZa/bp589913hiJFihhu3bplXLZr1y6Dp6enYd68ecZlN27cMHh6ehomTZqUYMcEQAbGVkwZ+Dp9z2fPnhlKlixpaN26tSEiIsK4fMuWLQZPT0/DjBkzTM7PdW7iYg4UK7FhwwadPXtW3bt3V8mSJaOtT5Eihfr162eybO3atWrSpImKFCmiMmXKaMCAAdGedPP399egQYNUqVIlFSpUSBUqVFCPHj108+ZNSVK1atV04cIF7d+/X15eXvLy8jJ5vez69eu6fv36K9t/5coVffzxx0qePLm+/vpreXp6aujQoSpXrpyuXLkS437BwcEyGAyvPP7LhIaGasOGDSpVqpQyZsxosi62r+WVKVMm2rIaNWpIiny9OC5i+5lCQkL07NmzGNevX79ehQsXVpEiRYzLcufOrbJly2rt2rVxahOQ1FlTBqZKlUopUqSI9XcTk4kTJ8pgMKhz584W1+fNmzfaa8WOjo6qXLmy7ty5o+DgYOPy9evXK23atKpVq5Zxmbu7u+rWravNmzcrNDT0pW2ZPn260qZNq3bt2slgMOjx48cWt9u3b58ePnyoVq1amSxv3bq1njx5om3btpm0iQyENSD/Yi+2+wcGBmrJkiVq0aKFsmXLptDQ0Ffm2PLly3X+/Plo3/WrxDb/XkQfEIg9a8rIF8X1OnnLli16/PixfHx8TJa/bp5s2LBBVapUUebMmY3LypUrpxw5csS4/5MnT16aufE5JmCtyMDYiSkDX6fveeHCBQUGBqpu3bqysbExLq9atapcXFy0evVq4zKucxMfQ3hZic2bN0tStFf6YxI15l/hwoX16aefKiAgQDNmzNDhw4e1bNky47wdffr00cWLF9WmTRtlyZJF9+/f165du+Tr66usWbPqyy+/1JAhQ+Ti4qLu3btLktKmTWs8T4cOHSRFhtHL7N69W8+fP9eYMWP0/PlzrV+/Xo0bN1bjxo1j3Kd69ep68uSJXFxcVL16dQ0cONDk3LG1fft2BQYGmozzmhDu3bsnSXF6fS62n2np0qWaM2eODAaDcufOrR49epgEfUREhM6dO2cyxE6UwoULa+fOnQoODk6Qm7BAUmCNGfg6bt++rYkTJ2ro0KGxHmIwir+/v5ydnU2Grzlz5owKFCggW1vT5zYKFy6s+fPn68qVKy+df2rPnj0qVqyYZsyYobFjx+rhw4dKly6dunfvrjZt2hi3O336tCSpUKFCJvsXLFhQtra2OnPmjBo1akQGwqqQfwnv0KFDevbsmbJnz66PP/5YmzZtUkREhLy9vfXdd98pf/78JtsHBwfr999/V/fu3ZUuXbo4nSu2+ReFPiAQN9aYkfG5Tl65cqWcnJxUs2ZN47LXzRM/Pz8FBARE67dJUpEiRfT3339HWz569Gj9+uuvsrGxUcGCBdWvXz9VqFDhtY4JWDMyMP4Z+LqiCsGWrrednJx05swZRUREyNbWluvcJIACipW4fPmyXF1dlSlTpldu+/z5c/3+++/y9PTU7NmzjWPulShRQt26ddO0adP08ccfKzAwUEeOHNHnn39u8oRyt27djP+/Ro0a+vPPP5U6depYB7IlUTfdQkJCXjmXiZubm9q0aSNvb285Ojrq4MGDmjNnjk6cOKHFixfHOShWrlwpR0dH1a5dO97tt2TixImys7OL1XHj8pmKFSumunXrKmvWrLp7967mzJmjAQMGKCgoyFitfvjwoUJDQy1exEctu3v3LqGKd4Y1ZWBC+OWXX5Q/f/5oE3K+yrVr17Rx40bVqVPHpJ3+/v4Wn2hKnz69pMi8iamA8ujRIz148ECHDx/W3r171bt3b2XKlElLlizRkCFDZG9vrw8++MB4Hjs7O6VJk8bkGI6OjkqVKpXu3r0riQyEdSH/Et61a9ckScOHD5eHh4eGDRumoKAgjRkzRu3bt9eqVauM+SZJY8aMUbJkyYw3A2IrLvkn0QcE4sOaMjK+18kPHz7Ujh07VKNGDZNtXjdPovplMe0fdXxHR0fZ2tqqQoUKqlGjhjJkyKAbN25o2rRp+uijjzR27FhVqVIlzscEQAa+Tga+ruzZs8vGxkaHDx82KXhcvnxZ9+/flxTZF0ydOjXXuUkABRQrERwcrOTJk8dq25MnTyogIEC9e/c2mbCoSpUqypUrl7Zt26aPP/5YTk5OcnBw0P79+9WsWTOlTJkyzu16VTU5SvXq1fXHH3+oQ4cOql69uh4/fhxj1bR9+/YmP9euXVtFihTRgAEDNGfOHJPJlV4lODhY27ZtU+XKlY2V9ISwcuVKLVq0SF26dInV5Mlx+Uzz5s0z2bZp06Zq2rSp/vjjDzVp0kROTk7GYR0sdRyj/pu/bOgH4G1jTRn4uvbu3asNGzZowYIFcdrv6dOn+uSTT+Tk5KT+/fubrAsJCbGYN1HLXpY3T548kRTZGfzjjz9Ur149SVKdOnXk4+OjsWPHGm8ghoSEyMHBweJxkiVLppCQEJPzkYGwBuRfwosaRsvGxkbTpk0zfr8FChRQy5YtNXv2bONwF1euXNHMmTM1fPjwON+wi0v+SfQBgfiwpoyM73Xy+vXr9fz582hD17xunsRm/6g+ZObMmTV58mSTbRo1aqT69evrl19+MRZQ4nJMAGTg62Tg64oa0nrZsmXKnTu3atasKT8/Pw0ZMkQODg56/vy5MdO4zk18zIFiJVKkSBGrMZOlyKFbJClnzpzR1uXKlcu43tHRUQMGDNDff/+t8uXLq3Xr1po4caL8/f0TruH/SJ8+vRYtWqRSpUpp1apVOnXqlEqXLq3OnTvrwoULr9zfx8dH6dKl0+7du+N03vXr1+vZs2cJGpQHDx7UV199pQoVKsR5HOwXxfYzOTo6qnXr1goMDNTJkycl/RuclsaOjQrTF/9BBN521p6BsRUWFqaffvpJjRo1Mhkz9VXCw8PVr18/Xbx4USNGjFCGDBlM1js5OVnMm6hlL8ubqHUODg4mb+zZ2tqqbt26unPnjvG/iZOTk54/f27xOM+ePTO+Hk0GwpqQfwkvKkuqVq1qctPB29tbWbNm1ZEjR4zLfvrpJxUrVixebzLHJf8soQ8IvJq1Z2RsrilXrlypVKlSqVKlSibLXzdPYrP/y4aSTZUqlZo0aaIrV67ozp07CXJMwNqQgfHPwITwww8/qFKlSho2bJhq1Kih1q1by9PTU1WrVpUkubi4SOI6NymggGIlcuXKpaCgIPn6+ibocTt06KD169fr008/VbJkyTRixAjVq1fPOD5fQvLw8NCvv/6qRYsWqUCBAvrqq6905swZdezYUY8ePXrl/hkzZozVdi9auXKlXF1djeH1us6ePasePXoob968GjlypOztX+8lsNh+pqjXMaO2TZUqlRwdHS3+Axa17MWhJ4C3HRkYO8uWLdOVK1fUsmVL3bx50/hHinzi+ubNm3r69Gm0/b7++mtt27ZNv/zyi8qWLRttfbp06SzmTdSrxi/Lm1SpUilZsmRKlSpVtNeyo15hDgwMNJ4nPDxcAQEBJtuFhobq4cOHxvOQgbAm5F/Ci8oHS+Nlp0mTxphJe/bs0Y4dO9SuXTuTTA0LC1NISIhu3ryp4ODgGM8Tl/yLCX1A4OXIyJdfU96+fVsHDx5U7dq1oz39/Lp5ErUupv2jjv+qtkuRb+ol1DEBa0IGxj8DE4Krq6vGjh2rrVu3atasWdqyZYt+++03+fv7y93d3TgSDte5iY8CipWIKgCsWLHildtmzpxZUuSQA+auXLliXB/Fw8NDnTp10pQpU7Rq1So9f/5cU6ZMMa63sbF5naZblCJFCrVu3Vrff/+9/P39dfjw4ZdubzAYdOvWLbm7u8f6HHfv3tW+fftUq1atBOlkXb9+XV26dJG7u7smTpwY69ckYxKXz3Tjxg1JMm5ra2srT09P49OILzp+/LiyZcvGmIh4p1h7BsaWr6+vnj9/rg8//FDVq1c3/pEiiyvVq1fXrl27TPYZNmyYcTLBBg0aWDxuvnz5dPr0aUVERJgsP378uJydnS0+xRTF1tZW+fPn1/3796M9SRNVgEmdOrUkGSduNs+2kydPKiIiQvny5TMekwyEtSD/El7BggUlRU5WbO7u3bvG/lbUzYjevXubZKqfn5/27t2r6tWra9GiRTGeJy75FxP6gMDLWXtGvuqactWqVTIYDGrYsGG0da+bJxkyZJC7u3uM+0f1214m6kGfqPYnxDEBa0IGxj8DE1LmzJlVqlQpZcmSxfjmcLly5Yzruc5NfBRQrETt2rXl6empcePGmQwrECU4OFh//PGHJKlQoUJKkyaN5s2bZ3Kxtn37dl26dMk4vujTp0+jjZ3n4eGh5MmTm+zn7Owc49Nx169f1/Xr11/Z/piqwWFhYZJMX8ONmmzpRXPmzNH9+/dVsWLFV54rypo1axQREZEgw3f5+/urU6dOsrGx0eTJk+NUyJFi/5ksbRccHKzp06crderUxgt+KfLvxIkTJ3TixAnjssuXL2vv3r2qU6dOnNoHJHXWlIGvo169ehozZky0P5JUuXJljRkzxmRor0mTJmnKlCnq3r17tDFlX1SnTh3du3dPGzZsMC67f/++1q1bp6pVq76ySF23bl2Fh4dr2bJlxmXPnj3TypUrlSdPHuOQYe+9955SpUqluXPnmuw/d+5cOTs7G//bSWQgrAf5l/By5cqlfPnyafPmzSZ9r507d8rX19d4wfvee+9ZzFR3d3cVKlRIY8aMUbVq1V56rtjmH31AIH6sKSPjc528atUqZc6cWSVKlLC4/nXzpFatWtq2bZvJ0+979uzR1atXTfa31HY/Pz8tXrxYXl5eJk9Ux/aYAMjA183AN2H48OEKDw83ub7mOjfx2RgMBkNiNwL/jWvXrqljx47y8/NTnTp1VLx4cTk4OOjChQtatWqV3NzctH79ekkyPk1ctGhR1a9fXwEBAZoxY4bc3d21bNkyubm56cyZM+rQoYPq1KmjPHnyyM7OTps2bdKuXbs0cuRI41jNgwcP1ty5c/Xxxx8re/bscnd3Nw7xEnXR+KoJokaPHq19+/apQYMGSpEihcaPH6/GjRtr/PjxSpEihVasWGEcG7Bo0aKqV6+ePD095ejoqMOHD2v16tXKly+fMVyitG3bVvv379e5c+einbNJkyby9/fX9u3bZWtruda4bNky3b59WyEhIRo/frzKlCmj9957T1LkpHZZsmQx/v+zZ8+qS5cu8vT0NDlG2rRpVb58eePPAwcO1NKlS7V582ZlzZo1Tp9p1KhR2rRpk6pWrarMmTPr7t27WrJkiW7fvq1ff/3VpGoeHBysxo0b6/Hjx+rUqZPs7e01bdo0hYeHa/ny5XEu8gBJnbVkYFBQkGbOnClJOnz4sHbs2KFOnTrJ1dVVbm5uatOmjfG4lvLGEi8vL7Vu3VrffvutcdnGjRvVu3dv5ciRQz179oy2T/ny5Y3D24SHh6tVq1Y6f/68OnfurNSpU2vu3Lm6ffu2Fi1apFy5cr20TSEhIWrWrJmuXr2qtm3bKnPmzFq+fLlOnz6tsWPHqnLlysb9Z8+erR9++EG1a9dWxYoVdfDgQS1btkz9+vVT9+7djduRgbAm5F/s8i8u++/du1edOnWSh4eHPvjgAwUFBWnq1KlKly6dlixZ8tI3jatVq6a8efNq/PjxJstfJ//oAwLxZy0ZGZfrZEk6f/68fHx81LVrV/Xv39/i+eOSJ5auvX19ffX+++/Lzc1N7dq105MnTzR58mRlyJBBixcvNj5kM2jQIF2/fl1ly5ZV+vTpdevWLc2bN0+PHz/W5MmTVaZMmTgfE0AkMjD+Gfi6fc8JEybo/PnzKlq0qOzs7LR582bt3LlTffv2VY8ePUzOxXVu4qKAYmUCAwM1bdo0bdy4UTdu3FBERISyZ8+uqlWrqm3btkqXLp1x2zVr1mjixIm6ePGiXFxcVLFiRX322WfGJ90ePHigUaNGac+ePbpz547s7OyUK1cudezYUXXr1jUe5969e/rqq6904MABPX78WKVLlzYGTGxD8fLly5o9e7Z27dqlO3fu6OnTp0qXLp1KlCih/v37y8PDw7jt119/rSNHjsjX11ehoaHKnDmzatWqpe7du0d7Va1Jkya6e/eudu7cGe18devWVceOHTVw4MAY2xXVCbRkxowZxo6cl5dXjMd48fuQpI8//ljbt2/Xjh07jOMdxvYz7dq1S5MnT9b58+f18OFDOTs7q0iRIurSpYvFeQnu3LmjoUOHateuXYqIiFCZMmU0aNAgZc+ePcb2Am8za8jAmzdvGofdMpclSxaTc1nKG0ssFVBGjRql0aNHx7jPixkoRT4d9Ouvv2rTpk169uyZChcurM8//1yFCxc22S+mNgUEBOi3337T1q1b9eTJE+XPn199+vSx+LTQggULNGXKFN28eVOZMmVS69at1b59+2iviZOBsCbk36vzLy77S9Lu3bs1YsQInTlzRs7OzqpcubI+++wzk+/SkpgKKK+Tf/QBgddjDRkZl+tkKfIp6AkTJmjFihUvvZ6NbZ7EdO194cIF/fLLLzp06JAcHBxUuXJlDRw40GSeqVWrVmnevHm6dOmSAgMD5erqqpIlS6pHjx4mb9jF5ZgA/kUGxi8DX7fvuW3bNo0ZM0aXLl1SRESEvLy81KFDB5Pv6UVc5yYeCih469y8eVODBg0yKTrER3BwsMqUKaMvv/xSrVu3TqDWvb5y5cqpUaNG+uKLLxK7KQCSoITKQClp5k1SbBOApIH8A4CYJWRGJrSkeu0N4N2RlDNQop/3tmMOFFitgwcPKkOGDGrevHliN8XowoULCgkJ0UcffZTYTQHwjkuKeZMU2wTg3ZMUsyYptgkAEkpSvPYGgP8K/by3H2+g4K0TGBioTZs2qUmTJondFAD4z5GBAKwV+QcAMSMjAVgzMhBvEgUUAAAAAAAAAAAAMwzhBQAAAAAAAAAAYIYCCgAAAAAAAAAAgBkKKAAAAAAAAAAAAGbsE7sBb9rzsHDdvPMgsZuBJCZbpjSJ3QQkMXa2ko2NTWI3I8GRgbAke5a0id0EJCFRyfcORiAZCIvIQLzoXc1A8g+WkH8wZ6N3L/8kMhCWkYF4UVz6gO98AeXmnQcq4PN9YjcDScy5zcMTuwlIYjKndJS9XWK3IuGRgbDkwYHRid0EJCGO/2TfO3jtTAbCIjIQL3pXM5D8gyXkH8w52r17+SeRgbCMDMSL4tIHZAgvAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADM2Cd2AyCN+a6NWjV4L8b1Bep9JV//R/9JWzxzZNBPnzbVe0Vz6/nzMG3YdUpf/bFEAQ+DY9yneZ2SmjCkg4KfPFO2yv3/k3Zai+Nnr2vZhoPad/Sibvk9UCo3FxXNn119O9ZVzmzpjNsNHDZXSzccjLZ/zmzptG7aQJNl127d0/CJq7XnyAWFPg9TgbxZ9EmHunqvWJ5o+0dERGjeqr2av2qPrty4K+dkjvLKnVlf9mykfLkzm2x7/fY9jZi6TrsPX9DjJyHKmC6V6lYuqn6d6yXQt4F3XdF82fR1Tx+VLpxTNjY2OnDiir4btUwnz98y2a5qmXxqXLO4ShbKIc8cGXXL74GKNvrO4jEzpHHTwG71VbW0l9KncdOde4+0ZvsJDZ+6Xg8ePTZu9+DA6BjbtXXfWTXp/e/62B4Tb8aZS74aNnGNjp65rrsBgXJ2cpRXrozq06aG6lYqbLLthAXbNXnh37p6K0BpUiVX45rF9WX3BkrunMy4zfmrdzRrxV5t3XtGV2/dU3LnZCqSL5sGda2nYgWymxzvlwmrNWzi2mhtSuZorzu7/nwjnxfW4U3kX86safVd70aqXMpLjo72On72hn4at0o7D10w2a54gexq5VNGJQrmUMG8WeRgb6fUpXpHO55TMgf9+llzlSyUQ1kypJatra2u3vTXrJV7NXnh3woLj0i4LwQWxSX/lm48rL/mbNH5q36ys7NR/lyZ9XG7GqpdoZDJdpdv+Gvw6OXafuCcQkPDVCRfNn3VvYEqlvSMdv5zV+7oq/8t1t5jl+TgYK9a5Qvqp35NlDa16xv93Hj3xTYDP+1QS3UqFVbOrGmVwsVJt/weaMOuUxo+ZX2069W49Nc+al5JnZtXUo4saRTw8LGWbjysoeNW6UlIqHGbvNkzqE3D91T1vfzKkSWtHj99puNnb+jnCZG/k/hvBD95plEzN+nQyas6dPqaHgY+0Zhv26iVT/T7KbHpB0rS71PWRR7v1DX53w/SFx/V1cCu9aMd78JVP01dslMHT17V8XM39Cw0TMeWD5ZH5jRv7PPCOiR2Bsb2PmD/jrVVolAOlSiYXenTuOmXCWs0bOKaN/OlIJrDp65p7up92nnwvK773lfqlMlVqnAOfdW9gfJkz2CybWz7bBERERo1a7OmLN4pv3uPlNsjvfp1qKVmtUuabDNv9X6t3HpUx8/d1MPAJ/LInEZNa5VQ7zbV5ZTM4T/5/ImNAkoSMG3JLm3ff85kmY2k4YM+0HXf+/9Z8SRz+lRaPaGvAoNDNOSvFUrhnEy921RXgTyZVb39b3oeFh5tn+TOjvq+z/sKfvLsP2mjtZk0b6sOn7qiOpWLyitnJvk/CNLsZbvUpPv/NH/0x/LMmcm4raODvX7s38Jkf9fkTiY/+959oJZ9RsrO1ladW1SRs5Ojlqw/oM5fjNe037urVJHcJtt/+dt8rdx8WI1qllSbRuX1JCRUZy7eUsCDIJPtzly8pbaf/qUMaVOqY7PKSu3mott3H+qO/8OE/ULwzirilVVrJ/bTLb+H+nXSWtna2Khzs4paPb6vqnf4TRev3TVu26xOSTWuUVzHz93QnXsx52NyZ0dtmNJfLs6Omrxoh275PVChvFn1UYtKqlgyr6q0/VUGg0GS1O3b6dH2987voR4fVtXWvWfidUy8GTfu3Ffw4xB92KCMMqZNqachoVqx9aha9R+vPwZ9oA5NKkiSvhu1TCNnbFKj6sXU7YMqOnfljibM366zl321eNS/N4dnLtutmSv2qGE1b3VuVlGBj0M0bclO1ew0XItG9FSVMvmitWH4wJYmF992drzQi/h7E/mXJUMqbZjSX+ERBo2auUmPQ0LV2uc9LRndW+/3HKndRy4Zt61ZvqDaNiqnUxdu6+qte8prdgEWxSmZg/LlyqSNu07puu99RUQYVLpITg3t10QlC+bQR99MS7DvBJbFNv8mzN+mL35fpFoVCuq73g317FmY5qzaqw/6jdOMYV3kU81bknTzzgPV6jRcdrY26tO2hpI7OWr2yr1q0nu0lv31scoX//fhmlt+D1S/659yS+Gkb3o2VPDTZxo9a7NOX7ytzdM/k6MDl5WIn7hkYNH8Hjp5/paWbDyk4MfP5Jkzo9q/X061yhdUpda/GAsecemvfd+7kT5pX1PLNh3W+Hnb5JUzo7q2rKx8uTKp2cdjjOdu+345tW1YViu2HNXkRTvkltxJHZpU0MYp/dXsk7+iXc/jzbj/MFi/TlqrrBlTq1DeLNEeCogS236gJP00dpUypHFTEc+s2vxCv9/cgRNXNH5+5N8RzxwZdeL8zQT9bLBOiZ2BcbkP+HVPH92590jHz99UjbIF/tsvChoxY6P2HbusRjWKqWCeLLobEKiJC7arStth2jBlgArkiXzIOS59tiF/rdSf0zeq/fvlVKxAdq35+7g++nqabGykprUiiyhPQp6r1w+zVKpwDnVsWkHpUrvqwIkr+nnCam0/cE4rxn4sGxubRPlO/ktJrqd76dIl/fjjjzpy5IiSJ0+uRo0aqW/fvnJ0dEzspr0xB05c0YETV0yWvVc0l5I7J9OitQcS5BwPDoxWz8EzNXfVvhi3+bRjLbk4J1PVtr/qpt8DSdKh09e0bEwftfJ5T9OX7oq2z4DOdRT8JEQ7D51XvcpFE6St+FeH5pX0+1etTQKuXhVv+XT5XRPmbtHvX7Y2Lre3s1WjmiVeerwJc7coKPipVk7+TLmypZcktaj/nup2HKaf/1qhJeP6Gbdds+2olm44qNGDO6hmhcIxHVIRERH6/Jc5yuWRXjOG97Sa6vObYI35F+Wr7g0U8uy5anUebnwiZsHaAzqw+Ft907Oh2n8xybjtkDEr9cmPcxQWHqF5/+uu/LkzWTxm3UpF5JE5jVr2HasNu04Zlz8IfKwvPqqnQnmzGC98FljI2vLF8yoiIkKLNxyK1zHxZtQqX1C1yhc0WfZRi8qq0naY/pqzVR2aVNCde4/01+wtalmvtMYNbmfcLrdHen3x20Kt/fuE8WntprVL6ouu9ZXC5d+CSBuf91SmxY/6ZeIaiwWURtWLKU2qFG/oE1ova83AN5F/fdvXUkpXF5X74CfjhfeMpbu0f9E3+qlfU1Vt96tx2ymLd2jEjI0KefZcv37WPMYCysPAJ6rVabjJsqlLdiowOERdW1bWV38u1t2AIIv7ImHEJv+kyKeuixfIrnn/6268oG3d8D0VrP+15q7eZyyg/Dl9gx4FPdHueV8pb47I/+7tGpdX6WZD9NUfi7Vt5hfG8/xv6gY9efpMW2d+rmwZ3SVJJQpkV+PeozVn5V7juRF/ZOCrM/DF/x/lwPErmvFrF9WpWFhLNkb22WLbX8uQxk09W1fTvNX71OP7mcbtLl2/q18/b6E6FQtp3Y6TkqTF6w9q2ITVevz037dSZq3cq30LvtbAj+pRQPmPZEjrprNrhypDWjcdOX1N1dr/Fm2buPQDJRnfIgl4GKw8NQdGO16UupUK6+qW3+Sa3EmjZm6iz5+ArDX/pMTNQClu9wGLNPxWN3zvyz1lcl3aNCzhvwy8VM9W1TTxxw4m9wcb1yyu8h8O1Z/TN2rCkPaSYt9nu333ocbM3qIuzSvpt88jH8Zu93451e/2p74dsUzvVy8uOztbOTrYad2kT1WmaC7jeds3Li+PTGkiiyj7z1m8Zn7XJKlHJh89eqT27dvr+fPnGjVqlPr166cFCxbol19+Seym/eea1SmpiIgILVxvOixTi7qltHXG57q943+6vGmYJv/UUVkypEqQc/pU9db6HSeNoSlJ2/ef04Vrfnq/RrFo2+fKlk49Pqyqr/9YwrANb0jxgjmjPdGXI2s65c2RUZev3422fXh4hIIfh8R4vIMnrih/nizG4okkOTs5qlrZgjp14aau3vQ3Lp+2aLuK5PNQzQqFFRERoSdPLb9ltPPgeZ2/cke92taSUzIHPQ0JVTh/H+LM2vPvPe/c2rb/nMnrxH4Bgdp9+KJqVyio5M7/dp7v3HsUq8yJegPr7n3TG3p+9wIlSSHPnse4r6ODvRpW89auwxd1++7DBDkm3hw7O1tlyZBaj4KeSIq8kAgLj1CTWqZF5ab//LzkhaKYd34Pk+KJJLmnSqGy3rl1/uodi+czGAwKDH7K20YJyJoz8E3kX1nv3Dp+7obJU4tPnz3X2r9PyDu/h3K9MAyo//2g18qu674BkqSUKVzifQzEn3n+SVJQcIjSuqcweRrQLYWzkjsnM3nQZc/RSyrilc1YPJEkFydH1a1UWMfO3tClF/qaK7ceVe2KhYwX4pJUpUw+5fFIr2Wbjrypj2c1yMDYZaAlxgxydTYui21/rVSRnHKwtzPpF0gyPjzzYj/i2NkbJsUTSXrw6LH2HL0kzxwZX/1BkSCSOTooQ1q3l24Tl36gpFgPwZU6ZfJoIzzg9Vlz/kmJm4FS3O4D3vC9H5ePhgRWpmiuaPcHc3ukV75cmUyuW2PbZ1uz/bieh4Wrc7OKxmU2Njbq1LSibt99qP3/POjv6GBvUjyJUr9qEUmK8Zr5XZOk3kCZN2+eHj9+rNGjRytVqlSSpPDwcA0ePFjdunVThgyWn4h719jb2er9GsW1//gVk4Dq37G2vuxeX8s2HdHM5buVJnUKdW1RWavH91WlNsMUGPw03ufMlC6l0qdxszh+6+FT11SzXMFoy3/+tKl2HLqgjbtP6/2axeN9bsSNwWDQvQdBJhe7UuSNkRINv9LTkFCldHVW/arFNKCr6Rivoc/DTP5hjRJ1MX3q/E3lyJpOwY9DdPzsDbVqWE7/m7RGM5ft1JOnz5Q1k7v6d6mvelW8jfvuOXxekuToaK8mPf7QqfM35eBgp5rlC+u7T5oqlRs3VGLD2vMvmaO9xRt4T0JClczRQflzZ9bBk1fjdMzdRy4qPDxCv/Rvqq//XKrbdx+qYJ7M6t+ptlZtPaYL1/xi3Ldm+QJK5eaihetM30x5nWMiYT1++kwhz54rMPip1v59Qpv2nFbjGpH/Fj17HiZJcjZ7I87ZKfIC5NjZG688vl9AkNKktPyWSbH3v1fwk2dK7uyoepWL6se+jZU+zcsv5vFy1pyBbyL/HB3t9fCFG+pRnv4ztIN3Pg9dvuEfbX1sONjbyTW5k5ydHOSd30O921TX9dsBunwzfsdD3L0s/ySpfIm8WrHlqCbM36Y6FQsrJPS5JszfrsDgp+r+QRXjdqGhYUrlGr2fFpWVR89eV26P9Lp996H87wfJO79HtG2LF8yujbtPRVuOuCED45aB7imTy97eVrmzpdd3vRsqLCzcZCin2PbXkv1zI+qp2fmjsrJovmyvbH+GNK4KeBTzfKH47yVEPxD/HWvOPylxMzA+9wGRtBgMBvnfD1K+XJGF/Lj02U6cu6nkzo7yymn6EECJgtn/WX9DZb1Nh/l/0d2AyIKcu5WMzJCkCih///23ypYtawxNSapbt66+++477dq1S02aNEm8xv2HqpctoDSpUmjoulXGZdkyptbArvX009hV+t+0Dcblq7Ye0/ZZA9WlWUWT5XGVIW1KSZKfhfG0/e49knuq5HJ0sFfoP52RWuULqup7+VWx1c/xPifiZ8Wmw/K790gfd6htXJYujZu6tKyiAnmzyhBh0I4DZzVnxW6dvXxbM//XU/Z2dpIiJ5U/dOKKgp+EKIXLv0/PHD4ZWVmO+u9//fY9GQwGrd56RPZ2dvqsawO5JnfSjCU79OmPs5TCxUmVSke+onf11j1JUt8fZqhiqXzq9mF1nb10WxPmbpav/0PNHdHbKsZDfF3Wnn8Xr91VycI5ZGtro4iIyKf6HeztVLJQDklSpnSp4nzMc1fuqO/QuRrySWNtnDrAuHzOqr36+Mc5L923eZ1SCnn2XMs3H02wYyJhff3nEk1bEvlKua2tjXyqehtfPY4agmjfscsmEyHvOXJRkuT7ivmZdh+5qAMnrmhAp9omy1O5uuijFpVUqnBOJXO0154jlzRp4d86fPqqtkz/XG4poheoETvWnIFvIv8uXrurst65lcIlmck8de/9cxGUKX3KeLfXp6q3Jg/taPz58Olr6vPDbN4+/Q+9LP8kadiA5rr/8LG++H2Rvvh9kSQpTaoUWvZXH5Uu8u8ThHmyp9eeo5cU9DjE5KnqvUcj58jxvRvZL4zqH0ZdL7woQ9qUevDoiZ6FPlcyR4ZxjS8yMPYZmD6Nq86t+/ca9JbfA330zTSTh1hi21+L2qdM0VwmNx/LFstj8dzmynrnVqnCOfX7lPWx/8B44163H4j/ljXnn5S4GRjX+4BIehasPaDbdx9qULf6kuLWZ7sT8Ejp3N2i3a+L2vdV83GPnLFJrsmdVLOcdcyHk6QKKJcvX1bTpk1Nlrm5uSldunS6fPlyIrXqv9esdkmFPg/T0hderWpQ1Vu2tjZauumw3FMmNy73uxeoS9fvqkJJT2MBxTmZg/HpihelcE5msm94RIQeBT017iP9+7TGi0JCI5c5JXNQ6PMwOdjb6ad+TTV18U6du2Idr2olFZeu++mHUUtUrEB2Na5Vyri8f5f6JtvVr1ZMObKm0x9T1mr99uOqXy3y1csPfcpp657T6jdkpvp1qitnp2Sas2KXTv4z/mVIaOSTD0/+eT39YeATLRj9sYrmj6xAVytXUNVb/6SxszcaCyhRQ3sV9vIwzslSu1IROTs5aPikNdpz+ILKlfi34wrLrD3/Ji/aof8N+kCjvmmtkTM2ydbWRgM61TG+ou/sFL+bMr7+D3Xo1DVt3H1KN3zvq2yx3OrWsooCHj7WtyOWWtzHNbmTapUvqI27T1l8sy8+x0TC6/FhVTWqVkx37j3S0k2HFR4eYezcF82XTSUL5dCIGRuVKV1KVSzpqXNX7qj/sPlysLeL9qTpi/zvB+mjr6cpe+Y0+rhdTZN13T+savJzw2rFVLxgdnX9ZromL9qhfh1qJfwHtRLWnIFvIv+mLN6hupUKa8rQThry10o9CQlV52YVjU+jvc58ZTsOndf7vUYpZQpnVS7lpUKeWeTyiuElkLBeln9S5FPWebKnV+b0qVS7YiEFPw7RX3O3qt3nk7RmYj/jEG6dmlbUuh0n1enLKfqmp49cnCInm416EjXqidiozExmYaJ4J0d747YUUOKPDIx9Bj549ETv9xolJ0cHFfbKKp+qRU3euI8Sm/7a8XM3deDEFX3SrqZ8/R9px8Hz8sqZUcO/aKnQ52HR3mB4UdrUKTTxxw66djtAI2dsTMBvBK/rdfqB+O9Zc/5JiZuBcbkPiKTn/NU7+uzXBSpVOKc+rF9GUtz6bCEhz5XM8eXbxWT41PXatv+cfv+ipVJaeJv5XZSkCiiBgYFyc4s+BEbKlCn16NHLK1/viuTOjqpbubC27D1jMgZibo90srW11eGl31vcLyws3Pj/P25XUwO71ou2za+ft9CvLzyddv12gIo2+k5S7H/JJKlnq6pKkyq5fp6wOo6fDq/D/36gun05Wa7JnTTiu/ays3v5FEYdmlXWiGnrtPvweWMBpXKZ/PqmT2MNn7hajbv/IUnKniWt+naqq98mrJLLP//wJvvnH9KsmdyNxRNJSu6cTFXLFtDKTYcVFh4uezs7Of1zsdygmun4mA2qFdfwSWt0+NRVCiixYO35N3XJTmXJkFp92lZXqwbvSYp8qnnkjE0a0LmOyRPUsVWmSC7N+1931ew03HgzaM324woKDtEXH9XV7BV7LBaBfap5y9nJUQvXHoy2Lr7HRMLzzJHROOb4B/XLqEnv0frw0/HaNG2AbGxsNH1YF3X6cop6D5ktKXKegJ6tqmn34Qu6cC36HFJS5LA4H/Qbp+Anz7R2Ys9oc6NY0rxOKX3z51Jt33+OAsprsOYMfBP5t2n3aX3+6wJ927uR/p4dOSHupet39eNfK/XDJ431OIZ5zWLD/36QcbLkFVuO6tMOtbRkdG+VbDqYSeT/I6/Kvw4DJ8vezlbz/uhu3Kde5SIq0XSwfvxrpab83EmSVLN8QQ37rLl+GL1cldtETgabK1s6fd3TR9+NXGa8IRPbGyyIPzIw9hn4PCzcmEHrd57U3wfOaf3k/rr3IFjrd0ZO+B6X/lr7LyZpytBOGvNtG0mR19V/zdmicsXzKm/29LLExclR8/7orhQuyVT3o7+izY2CxBeffiAShzXnn5S4GRiX+4BIWvzuBapl33FyS+Gs6cM6G+8PxqXP5uTkoGehce/bLdlwSD+NXaW2jcqazJ/yrktSBRRI9atEVo/Nb9zZ2tgqIiJCzT8Zq/CI6EMkPH4hVOet2ae9xy6ZrF82po9GztioLfvOGpeFhPwbhK96zev+w8cKfR4mt+RO6t+pjqYs2iHX5E7G1/2TOyeTjY2ULZO7noaE6t4DxoFNSEHBT/XRoIkKCn6q2X/2svjfyZxTMgelcktufMsoSpv3K6hJ7VI6d9lXDg52yp87ixat3SdJypk18onEqLH806ZyjXbcNKlS6HlYuJ4+DZVrCmel/6ctaVKbjnsY9fPrzM0D6/Lj2JUaNWuT8ufKpMDgEJ2+dFvf9PSRJJOJbGOrQ5Pyuns/KNqYrmv/PqFB3eqrdJGcFosdzeuU1KOgJ8YOaEIcE29ew2re6vfzPF28dld5c2RQ5vSptG7Sp7p0/a78AgKVO1t6ZUjrpvx1v1Qej+g3REKfh6nd5xN16uItLR7ZSwXyZI71ubNkSK0HgY9fvSEQg4TOP0mauPBvzV65VwXzZlHo8zCdOH9TbRuVizxmAt48Wr7lqL7p1VD1KhXRtKW7Euy4iL0X88/B3k6b95zWn19+aLJN6pTJ9V7R3Np33PRp3q4tKqu1z3s6deGWHB3sVdgzq2Yu3y1Jyv3PzeNXDfGROqULb5/gtbxOBu4/fkW+/o/UvE5JY98tLv01X/9HqvvRH8qVLZ0ypHHTpRt3dTcgSKfX/KSLFs7tYG+nGb9+pIJ5sqjpx2N05pJvQnwFSGBx7QcCiSmxMjC29wGRtDwKfqrmn/ylR8FPtGZCP5Nh3uLSZ8uYJqV2Hrwgg8FgMoxX1L6Z0kX/e7F13xn1+H6mapUvqP8N/CAhP1aSl6QKKG5ubgoKiv7k2qNHj5QyZfzHan6bNK9TUkGPQ7T27+Mmy6/c9Jetra2u3Q54ZYBeuxWga7cCoi0/e+WOsVJtztf/0UsnGjpxIXKIp5RuLnJN7qRP2tfUJ+1rRtv2+IoftHrbMbX5bOJL24jYexb6XN2/nqKrN+9p6q/dlCdHxlfvJCn4SYgePHpsMmxbFBfnZCpWMIfx592HL8gpmYOK/7MsQ9qUSufuKr+A6KF7NyBQyRztlfyfJ7ML5s0qKXpA3733z4RSFs6P6Mi/SI+CnmrvsX9v7lQu7aVbfg90/mrcJ2dP5+5m8U0tB/vIOYGi5gZ6UYY0bqpYwlNzVu212FmMzzHx34h6OirwsWnRNrdHeuX+50L57GVf3bkXqA//eborSkREhLp/N0PbD5zX1KGdVL5E3lif12Aw6LpvgIp4ZX3NT2DdyMCEzb8oT0JCdeDElX+PWcpLT0JCte9Ywg2JEfWkG3MAJZ4X8y9qLhpLD1w9Dws3eWs9SnLnZCZzo2w/cE7OyRxUpmjksszpUylt6hQxTjJbOC/597rIwNfLQCdHe5MMik9/7fINf12+4S9J8sqZUZnSpdTcVXtNtrGxsdG4we1UuZSnOn45RbsPX4zdh0OiiU0/EImL/IuUGBkY2/uASDpCnj3Xh5+O06Xrd7V0TG/ly5XJZH1c+myFPLNoxvLdOnfljslxDp68+s960/7dwZNX1fazifLO76GpP3eSvb113ft4+RhA/7FcuXJFG+MwKChI/v7+ypUrVwx7vTvSpEqhyqXzafW2Y9HG5Vy59ZjCwsL1xUd1Le6bOgFuUq/cclS1KxZSlgypjMsqlfJU3uwZtPyf+Vju3Q9S6wETov35+8A5PQ0JVesBE/THa0xmD1Ph4RHqO2Smjp6+qhHftjMpekR5FvpcwU9Coi3/a+ZGGQwGVfxnrpKYHD51RRt3nFCzuqXl+sI/unWreMv37kPtOvhv0e3+o2Bt3n1K7xXLK1vbyPioXr6gHB3stWTdAUW8cLG+cE3kWy0M3xU71p5/ljSuWVwlCubQ2LlbZTAY4rz/pet3lSGNm8oXN70Z3rR2CUnS8XM3ou3TpFYJ2dnZauG66MN3xfeYSFj+96NfYD0PC9e8NfvlnMxBXjkzWdgrskjy3ahlcnFyVMemFUzWff7bQi3deFi/f95CPtW8Yzz3vQfRzz150Q7dexCs6mWtY/K8N4UMNPW6+WdJ6SI55VO1qGYt36PAx9H7Da8S0wMRUW+1HLFwoYaEFZv8y5UtXeS8iRsPm/zdueX3QHuPXlJhr2wvPce+Y5e1cusxtWlUVilf6Bf6VPPW+h0ndfPOA+Oy7fvP6eL1u2pUo5ilQyEOyEBTljLQxcnR4pwkPlW9lTplcpMMep3+mo2NjQb3eV+Pnz7T1MU7Tdb9+llzNalVQgN+XaBVW4/F+/Phv/eyfiASF/kX3X+ZgbG5D4ikITw8Qp2+nKIDx69o6i+dTR5+eVFs+2z1KheRg72dJi/aYVxmMBg0dclOZU6fSmVeOP65K3fUsu9YZcuURvP/6G5x3u13XZJ6A6VSpUoaN26cyRiI69atk62trcqXL5/IrXvzmtQsLgd7O4s37q7euqefxq3Sd70bySOTu1ZvO67gJ8+UPXMa1a9SVNOX7dLoWZtf6/z/m7ZejWoU04qxn2jcvG1K4ZJMfdpU16kLtzR7ZeTTN0+fPdea7cej7Vu/ShEVL5jD4jrE3y/jVmjL7lOqWraAHgY+0fKNh0zWN6pZQv73g9S42/9Uv1ox5coW+XTNzoPntH3fGVUslU/VyxU0bn/L7776/jBT1coVVNrUrrp49Y7mrdojr1yZ1K+z6bw53T6srrXbj6nP4Onq2KyyXJM7ae7KPQoLC9enL2ybzt1N3VvX0Mhp69Rl4ERVL19I5y7d1oI1+9SgWjEVyRf9aQZEZ+35V65Ybn3Wpa627j2r+48eq2ThHGrd4D1t2n1K4+ZtM9m2YJ7MqlOpsCQpZ7a0ckvhrP6dakuSTl24pXU7Il9dnrhwu1r5vKe5/+umiQu264bvfZUvnlfN6pTUlr1ndOjUtWjtaF6nlG7ffaidhy5YbGd8jomE1e/nuQoKDlG54nmUKV0q3Q0I1MJ1B3T+qp9+7NvYOG/JwN8XKST0uQp7ZlVYWLgWrT+oQ6eu6a/v2ypbRnfj8cbO2arJi3aoVOGccnZy1Pw1+03O1+CFiRmL+HyrxjWLq0CezErm6KC9xy5pyYbDKuyZVR2acDH+Oqw5A99E/mXLmFpTfu6sdX+fkF9AoPLlyqSOTSvo1MXbGvLXCpNjZsuYWi3qlZYk4xOIUce86Xtf89cekCS1qFdKHZtU0Jrtx3X1VoBSuCRTtffyq9p7+bX27xPacfD8m/mCYBSb/EvhkkxtfMpqxvLdatRzlBpULargxyGavGiHnj57bjJX03Xf++o0aLLqVCqsDGncdPayr6Yu3qmCeTLrm54NTc79aYfaWr7piBr2GKHuH1RR8JNnGjVrswrkyazWPjzN/brIwFdnYC6PdFo2po+Wbjys81f9ZDAY5J3fQy3qltK1W/dMto1Lf+3n/k3l5OigE+dvyt7eTs1ql1SJgtnV8/uZuun3782n7h9WUZfmlbT/+GU9DQlVi7qlTD7Hqq3H9CSEuVD+CxMWbFdg0FP5+keOgLBuxwndvvtQkvRRy8pKmcI51v1ASZq3Zr9u+t43/vfbfeSSfp+8TpLUol5peWSK3P5R8FNNnL9dkoxvCkxcsF0pXV3k5uqsri0qv/HP/i6y5vyTEj8DY3MfMErLuqWUNZO7XP65eV6uWG5jn3HBmv268cINeyS8r/9corV/n1CdioX04NHjaNetLf/pz8e2z5YlQ2p1/7CqRs3cpOdh4SpeILtWbz+mPUcuacKQf+ddDnocoqZ9xuhh0BP1aVsj2lDnObOmjbGY8y6xMSTUY20J4NGjR6pfv75y5sypbt26yc/PT7/88ot8fHz07bffxuuYV27eUwGf7xO2oW/I+sn9lSNLGuWv95UiIiz/Z2lQtah6fljV+PTYLb8H+vvAOY2fv/2lQ3s9ODBaPQfP1NxV+17ahny5MurHvk31nncuPX8erg27TurrP5dafOLtRWO+a6OG1YopW+X+r/iUScO5zcMTuwmx0vbTv7TfbD6bF53bPFyBwU81ZNRSHTtzTXcDAhUeHqHsWdLKp3pxdWpRxfiapiQ9CnqiQb/O0/Gz1/Uw6IkypE2pupWLqnvrGkrh4hTt+DduB2jY+JXac+SCwsLC5V0gu/p3qR+tKGIwGDR7+S7NXLpTt+7cV1p3V71fq6R6ta1lcv6kLHNKR9nb2bx6wzfkTeSf9PZkYI4safX7Fy1VNF9WpXBx0rXbAZq3ep/GzN6i52bDjXzYoIz++q6txePMWbVXvQbPMv6cJ3t6fdW9gUoWyqH0adx0x/+Rlm8+op/Hr472pl+e7Ol1YNG3Gj17s775c2mMbY3LMZOqBwdGJ3YT4m3xhoOatXyPTl+8rfuPHitFcid558umj1pUVr3KRYzbzVm5V2PnbjUOgVm8QHb171RbFUuavhXX8/uZmrs65n8bjy0fLI/MaSRJn/w4R/uPX9atuw8V8uy5smVyl09Vb/XvVNs4J9jbyPGfmLZNvAi06gx8E/mX0tVZY75toxKFcii1m4t8/R9p2abDGj5lfbTJSMsXz6tV4z+xeMydhy7Ip/sISZHFlY/b1lDJQjmUzt1VYeERunjNTwvWHtCEBduNQ0e9Dd7WDIxt/oWFhWvKkp2atXyPrtyMHJKoWIHs+qxzHZMMfBj4RL1+mKVDJ6/qQeATZUqXUu/XKB5jpp255Kuv/1ysvUcvy8HBTrXKF9KPfRsb5857W72rGfg25J8U+wx0T5lc3/T0UdlieZQlQ2o52Nvqhu8Dbdh1UsOnrNf9R6ZzkcW2v/ZhgzLq8WFV5cyaThERETp8+pqGT1kf7WGaMd+1MU7wbEmRht/qhu/9BPpW3py3Nf9e9LLvOqrfFtt+oCQ16PandsUwHNvKcR+rwj8jKly/HaCijb6zuF22TO46vuKHeH6ixOVo9+7ln0QGxuWaNbb3AVeO+0QVYhjquEG3Edp12PJDiEnJ25yBL8sqyfSzxbbPFhERoT+nb9S0pbvkdy9QubKlU78OtUweEnhZ9knSh/XL6K/vLV+fJHVx6QMmqQKKJF26dElDhgzRkSNHlDx5cjVq1Ej9+vWTo2P8Xg96W0IT/623pYCC/05iF1CkhM8/iQyEZW9zxxEJLyncPJTIQPx3yEC86F3NQPIPlpB/MJfYBRSJPiD+O2QgXhSXPmCSGsJLknLnzq1p06YldjMA4D9H/gGwZmQgAGtGBgKwVuQfgKQuSU0iDwAAAAAAAAAAkBRQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzFBAAQAAAAAAAAAAMEMBBQAAAAAAAAAAwAwFFAAAAAAAAAAAADMUUAAAAAAAAAAAAMxQQAEAAAAAAAAAADBDAQUAAAAAAAAAAMAMBRQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzNjHZqMDBw7E6+ClSpWK134AkJSQgQCsFfkHwJqRgQCsGRkIAJFiVUBp27atbGxsYn1Qg8EgGxsbnTlzJt4NA4CkggwEYK3IPwDWjAwEYM3IQACIFKsCyowZM950OwAgySIDAVgr8g+ANSMDAVgzMhAAIsWqgFK6dOk33Q4ASLLIQADWivwDYM3IQADWjAwEgEivPYn83bt3dfbsWT158iQh2gMAbxUyEIC1Iv8AWDMyEIA1IwMBWJN4F1A2bdqkOnXqqHLlymrcuLGOHTsmSbp//77ef/99bdq0KcEaCQBJDRkIwFqRfwCsGRkIwJqRgQCsUbwKKFu2bFGfPn2UOnVq9erVSwaDwbjO3d1dGTJk0OLFixOskQCQlJCBAKwV+QfAmpGBAKwZGQjAWsWrgDJmzBiVLFlSc+fOVevWraOt9/b21pkzZ167cQCQFJGBAKwV+QfAmpGBAKwZGQjAWsWrgHLhwgXVrVs3xvVp06ZVQEBAvBsFAEkZGQjAWpF/AKwZGQjAmpGBAKxVvAoozs7Oevr0aYzrb9y4oVSpUsW3TQCQpJGBAKwV+QfAmpGBAKwZGQjAWsWrgFKmTBktW7ZMYWFh0db5+/trwYIFqlChwms3DgCSIjIQgLUi/wBYMzIQgDUjAwFYq3gVUPr27as7d+6oWbNmmj9/vmxsbLRz50798ccf8vHxkcFgUK9evRK6rQCQJJCBAKwV+QfAmpGBAKwZGQjAWsWrgJIrVy7NmTNHqVKl0ogRI2QwGDR58mSNHz9enp6emjNnjrJmzZrQbQWAJIEMBGCtyD8A1owMBGDNyEAA1so+vjvmzZtX06ZN06NHj3Tt2jUZDAZly5ZN7u7uCdk+AEiSyEAA1or8A2DNyEAA1owMBGCN4l1AiZIyZUoVKVIkIdoCAG8dMhCAtSL/AFgzMhCANSMDAViTeBdQ7t+/r4kTJ2r79u26deuWJClLliyqXLmyOnfurLRp0yZYIwEgqSEDAVgr8g+ANSMDAVgzMhCANYrXHCgXLlyQj4+Ppk6dKldXV9WpU0d16tSRq6urpk6dqoYNG+r8+fMJ3VYASBLIQADWivwDYM3IQADWjAwEYK3i9QbKDz/8oPDwcC1YsCDaK3vHjx/XRx99pCFDhmjmzJkJ0kgASErIQADWivwDYM3IQADWjAwEYK3i9QbK8ePH1a5dO4vjHRYpUkTt2rXT8ePHX7txAJAUkYEArBX5B8CakYEArBkZCMBaxauAkiZNGiVLlizG9cmSJVOaNGni3SgASMrIQADWivwDYM3IQADWjAwEYK3iVUBp166d5s6dK39//2jr/Pz8NHfuXLVr1+61GwcASREZCMBakX8ArBkZCMCakYEArFWs5kCZOnVqtGUuLi6qVauWatSooezZs0uSrl69qs2bN8vDwyNhWwkAiYgMBGCtyD8A1owMBGDNyEAAiGRjMBgMr9ooX758cT+wjY3OnDkTr0YlpCs376mAz/eJ3QwkMec2D0/sJiCJyZzSUfZ2NhbXkYF41zw4MDqxm4AkxNEu8n9tLUTg25x/EhkIy8hAvOhdzUDyD5aQfzDnaGc5/yQyEO8eMhAvelkf0Fys3kDZvHnz67QHAN5qZCAAa0X+AbBmZCAAa0YGAkCkWBVQsmTJ8qbbAQBJFhkIwFqRfwCsGRkIwJqRgQAQKV6TyAMAAAAAAAAAALzLYvUGiiVnz57VrFmzdPr0aQUFBSkiIsJkvY2NjTZt2vTaDQSApIgMBGCtyD8A1owMBGDNyEAA1iheb6Ds27dPzZs317Zt25Q+fXrduHFD2bJlU/r06XX79m25uLioVKlSCd1WAEgSyEAA1or8A2DNyEAA1owMBGCt4lVAGTlypLJly6Z169Zp6NChkqRu3bpp7ty5mjdvnvz8/FSnTp0EbSgAJBVkIABrRf4BsGZkIABrRgYCsFbxKqCcPn1azZo1U4oUKWRnZydJxtf2ihYtqpYtW2rEiBEJ10oASELIQADWivwDYM3IQADWjAwEYK3iVUCxs7NT8uTJJUlubm6yt7dXQECAcX22bNl06dKlhGkhACQxZCAAa0X+AbBmZCAAa0YGArBW8SqgeHh46OrVq5IiJ4jKlSuXySRR27ZtU9q0aROkgQCQ1JCBAKwV+QfAmpGBAKwZGQjAWsWrgFK5cmWtXr1aYWFhkqSOHTtqw4YNqlWrlmrVqqUtW7aoZcuWCdpQAEgqyEAA1or8A2DNyEAA1owMBGCtbAwGgyGuOz1//lzBwcFKlSqVbGxsJEnLly/Xhg0bZGdnpypVqqhJkyYJ3tj4uHLzngr4fJ/YzUASc27z8MRuApKYzCkdZW9nE6ttyUC87R4cGJ3YTUAS4hg5hLVsYxGBb1P+SWQgLCMD8aJ3NQPJP1hC/sGco13s8k8iA/H2IwPxorj0AeNVQHmbEJqwhAIKzMWlgPI2IQNhCR1HvCguHce3DRkIS8hAvOhdzUDyD5aQfzAXlwLK24QMhCVkIF4Ulz5gvIbwAgAAAAAAAAAAeJfZx2ajdu3axfnANjY2mj59epz3A4CkhgwEYK3IPwDWjAwEYM3IQACIFKsCSnxG+UoqI4Nlz5KWV7QQzZCN5xO7CUhi+lfOIXcXR4vr3uoMzJxGd3aPSOxmIIl5f8K+xG4CkpCprYtKkjKldIq27m3OP0nKniWN7u0bldjNQBJT76/did0EJCGz2heXJGV+xzIwe5Y0CiD/YKbmiJ2J3QQkMfM7l1TmVNHzT3r7M/D+fjIQpshAvGh+55KSFGMGvihWBZSZM2e+XosA4C1GBgKwVuQfAGtGBgKwZmQgAERiDhQAAAAAAAAAAAAzFFAAAAAAAAAAAADMUEABAAAAAAAAAAAwQwEFAAAAAAAAAADADAUUAAAAAAAAAAAAMxRQAAAAAAAAAAAAzNi/zs5+fn46cOCAAgICVLt2bWXMmFHh4eEKCgqSq6ur7OzsEqqdAJDkkIEArBX5B8CakYEArBkZCMDaxKuAYjAY9Msvv2j27NkKCwuTjY2NPD09lTFjRj158kTVqlXTxx9/rA4dOiRwcwEg8ZGBAKwV+QfAmpGBAKwZGQjAWsVrCK9JkyZpxowZ6tSpk6ZOnSqDwWBc5+rqqlq1amnDhg0J1kgASErIQADWivwDYM3IQADWjAwEYK3iVUBZuHCh3n//fX366afKly9ftPVeXl66evXq67YNAJIkMhCAtSL/AFgzMhCANSMDAVireBVQfH19VaxYsRjXOzs7Kzg4ON6NAoCkjAwEYK3IPwDWjAwEYM3IQADWKl4FlDRp0sjX1zfG9adOnVKmTJni3SgASMrIQADWivwDYM3IQADWjAwEYK3iVUCpWbOm5s2bpxs3bhiX2djYSJJ27typpUuXqk6dOgnTQgBIYshAANaK/ANgzchAANaMDARgrWwML876FEtBQUFq3bq1bt68qZIlS2rHjh0qV66cnjx5oqNHjyp//vyaPXu2nJ2d30Sb4yTCIIWGJ3YrkNQM2Xg+sZuAJKZ/5Rxyd3GM1bZvVQZGGBT0LCKxm4EkpuXUg4ndBCQhU1sXlSRlSun0ym3fpvyTpAiDQU+fJ3YrkNT4jNuT2E1AEjKrfXFJUuZ3LAMjDAaFkH8wU3vUrsRuApKY+Z1LKnOqV+ef9PZl4LOwxG4FkppaI8lA/Gt+55KSFKsMjNcbKK6urlqwYIG6dOkiPz8/JUuWTAcOHFBQUJB69eqlOXPmJInABIA3gQwEYK3IPwDWjAwEYM3IQADWKl5voLxNeAMFlvAGCszF5Q2UtwlvoMAS3kDBi+LyBsrbhjdQYAlvoOBFcXkD5W3CGyiwhDdQYC4ub6C8TXgDBZbwBgpe9MbfQAEAAAAAAAAAAHiX2cdnp0GDBr1yGxsbGw0dOjQ+hweAJI0MBGCtyD8A1owMBGDNyEAA1ipeBZR9+/ZFWxYRESF/f3+Fh4fL3d2dcQ8BvLPIQADWivwDYM3IQADWjAwEYK3iVUDZsmWLxeXPnz/X/PnzNX36dE2ZMuW1GgYASRUZCMBakX8ArBkZCMCakYEArFWCzoHi4OCgNm3aqHz58hoyZEhCHhoAkjwyEIC1Iv8AWDMyEIA1IwMBvOveyCTy+fLl04EDB97EoQEgySMDAVgr8g+ANSMDAVgzMhDAu+qNFFB2797NuIcArBYZCMBakX8ArBkZCMCakYEA3lXxmgNl9OjRFpcHBQXpwIEDOn36tLp27fpaDQOApIoMBGCtyD8A1owMBGDNyEAA1ipBCygpU6ZUtmzZNHjwYLVo0eK1GgYASRUZCMBakX8ArBkZCMCakYEArFW8Cihnz55N6HYAwFuDDARgrcg/ANaMDARgzchAANYqznOghISE6Oeff9aWLVveRHsAIEkjAwFYK/IPgDUjAwFYMzIQgDWLcwHFyclJ8+fPV0BAwJtoDwAkaWQgAGtF/gGwZmQgAGtGBgKwZnEuoEhSwYIFdf78+YRuCwC8FchAANaK/ANgzchAANaMDARgreJVQPnyyy+1Zs0aLVy4UGFhYQndJgBI0shAANaK/ANgzchAANaMDARgrWwMBoMhNhseOHBAuXPnlru7u3x8fPTgwQMFBATI0dFRGTJkULJkyUwPbGOjFStWvJFGx0WEQQoNT+xWIKkZspGnJmCqf+UccndxjHH9W5uBEQYFPYtI7GYgiWk59WBiNwFJyNTWRSVJmVI6WVz/tuafJEUYDHr6PLFbgaTGZ9yexG4CkpBZ7YtLkjK/YxkYYTAohPyDmdqjdiV2E5DEzO9cUplTWc4/6e3OwGfUeGCm1kgyEP+a37mkJL00A6PYx/ag7dq102+//aYGDRooVapUSpUqlXLmzBn/VgLAW4QMBGCtyD8A1owMBGDNyEAAiEMBxWAwKOpllZkzZ76xBgFAUkQGArBW5B8Aa0YGArBmZCAAxHMOFAAAAAAAAAAAgHdZnAooNjY2b6odAJDkkYEArBX5B8CakYEArBkZCMDaxXoS+Xz58sUpNG1sbHT69Ol4NyyhMIk8LGESeZh71STyb20GMok8LGASebzoVZPIv635JzGJPCxjEnm86FWTyL+tGcgk8rCESeRh7lWTyL/NGcgk8jDHJPJ40RuZRF6SypUrpxw5csSrUQDwtiMDAVgr8g+ANSMDAVgzMhCAtYtTAeX999+Xj4/Pm2oLACRpZCAAa0X+AbBmZCAAa0YGArB2TCIPAAAAAAAAAABghgIKAAAAAAAAAACAGQooAAAAAAAAAAAAZmI9B8rZs2ffZDsAIEkjAwFYK/IPgDUjAwFYMzIQAHgDBQAAAAAAAAAAIBoKKAAAAAAAAAAAAGYooAAAAAAAAAAAAJihgAIAAAAAAAAAAGCGAgoAAAAAAAAAAIAZCigAAAAAAAAAAABmKKAAAAAAAAAAAACYoYACAAAAAAAAAABghgIKAAAAAAAAAACAGQooAAAAAAAAAAAAZiigAAAAAAAAAAAAmKGAAgAAAAAAAAAAYIYCCgAAAAAAAAAAgBkKKAAAAAAAAAAAAGYooAAAAAAAAAAAAJihgAIAAAAAAAAAAGDGPrEbgEiHT13T3NX7tPPgeV33va/UKZOrVOEc+qp7A+XJnsFk23NX7uir/y3W3mOX5OBgr1rlC+qnfk2UNrWrcZtfJqzWsIlrYzzf2kn99F7R3JKk1KV6x7hdldJeWjqmjyTJ1/+hvhu5XEdOX9Ode49ka2urPB7p1aV5RX1Qv4xsbGxe5ytALOzbekC7Nu5RmvTuat+3zb/Ltx3QpTOX9SjgkUJDn8s1ZQrl9MqpMlVKyiWFS4zHO3P0rNYu2CAHRwf1+b6HcbkhwqDTR87owqlLuuvrr5AnIUqZ2k1eRTxVsmJx2TvEHB23rt7W/AmLJEk9vvpIzsmdE+CTw5odP3dDv09ep/3HLutZ6HN5ZE6jto3KqUuLypKkiIgIzVy+WzOW7daVm/5ycXJUYa9s+rRjbZUqnNN4nF2HL6hp79EWz7F6Qj+VKJTD4rpHQU9UruVPCngYrIk/dpRPNe+E/oiwoFAmV/3oU8Dius+XndL5u8FKn8JRE1oVi/EYG87c1V87rkiSsqV21gclsih32uRK7eKgZ2ERuvHgqZYd89WB6w9jPIadjY3+bFZY2VI7a+rea1p+/I5xXWoXB7Uv46G86ZLL3cVREQaDbj0K0dpTftp64V78Pjjwj52HLuj9niMtrls36VOV/Cfftu49o2WbDuvQqWs6f/WOsmRIrSPLBkfbZ9jENfptUsx9w9UT+qlM0VySpMOnrmru6n06dPKaTl+8pbDwCN3bNyoBPhViq3BmNw17v5DFdf0WH9c5v2BJkp2tjVoWz6LqXumVNoWj7gWHauPZu1pw+KYiDKb72dvaqG1pD1XzSqcUyex0NeCJZuy7riM3Hxm3SWZvq5r50uu9nO7K4e4iJwc7+T56qrWn/bTutF+0Y0pSRrdkalfaQ95ZU8nZ0Vb3gkO141KAZuy7nmDfB6zL4dPXNG/1Pu08dEE3/rk2Llkoh77s3kB5PNKbbLts02H9NWerLlzzk52tjfLnzqw+baqrVoV/f398/R/p+9HLdOT0dd2590h2trbK7ZFOnZtV0gf1Sr/0OrZJn9Havv+cOjerqF8/a/HGPjMsy5Muudq956GCmd3kaGcr30chWnPyjpYd85UklfBIpcqeaZUvg6s83F3kH/xMbacejHacNMkd1aVCDnllSKE0yR0VYZBuPniqFcd9tfHMXYvnrpw3rZoUy6ycaZMrPMKgawFPNG3PNR39JzMd7WzVu2ou5cvgqvSuyWRrY6Pbj0K0/rSfVhz3VbilwARiISoDdxw0zcDI+4P/ZqB76T4xHqNyaS8tHf3vvb7hU9br0KmrOnTqmvzvB+nzLnU1sGu9GPdfsvGQxs3dptMXb8ve3k5eOTPqq+71VamUV8J8SLxSQuWfuWpe6TSojpeehoar4dg90dZXyptWzYplVjZ3F0VEGHQ14InmH7qp/VcfmGzXqlRW5cvoqnwZXZXaxVEz9l7XzHe470cBJYkYMWOj9h27rEY1iqlgniy6GxCoiQu2q0rbYdowZYAK5MksSbrl90D1u/4ptxRO+qZnQwU/fabRszbr9MXb2jz9Mzn+c2O7QVVv5cyaLtp5hvy1Uo+fPlPxAtmNy8YNbhdtu6NnrmvcvG2q+l5+47KAh491++4DNazurawZ3fU8LFzb9p1Vz8GzdOHaXX3bq2FCfy14QdCjIO3bdkAOjg7R1vnduqv0mdIpXxFPOSRz1P2793XiwCldOXdFbfu0srhP6LNQ/b1ul8V1z58/1/rFm5QpW0YVLV1Yzimc5Xv9jvZs3qfrl26oeZcmFi80DBEGbVm5TQ6ODnoe+jxBPjes27Z9Z9Xu8wkq5JlV/TrWUnLnZLp6655u+z80bjN49HKNn7dNzWqXVIfGFfQo+KlmLtulxj1HasX4viZ5J0ldmleSd34Pk2U5sqaNsQ2/Tlyrp89CE/RzIfZWnriji/7BJst8H4VIkh6FhOmPLRej7VMsWypVyZvWeIErSelTOMrZwU5bz9/T/SehSmZvq7I53fVVHS/99fdlbTjrb/H89QtlUNoUjhbXuTnZK21yR+2+cl/+waGyt7VR0Swp9UnV3MqSykmzDtyM78cGjLq2qCxvsxzLme3fPt7iDQe1bNMRFfHKqoxpU8Z4nAZVilrsG/40NrJvWKzAv7m4cfdpzVq+RwXyZFb2LGl16brlm0t485Yfv63zdy1noCR9ViOvKuROo41n7uqCf7C8MriqXRkPpUvhqFHbL5vs92n1PKqQK42WHffV7UchqpEvnQbXz6+By0/p9J0gSVJGNyd1r5hTx24+0tJjt/UkNFzFPVKpd+XcypfBVf8zy9xcaVz0y/uFFPA4VEuO3VZQyHOlS5FM6VIke0PfCKzByBmbtP/4ZTWsXkwF82SWX0CgJi/8W9XaDdP6yf2VP3fktfGEBds1aPgi1SpfUB82aKhnz55r7up9+rD/eE37pbN8qnpLku4/DJbv3YdqWM1bWTOk1vPwcG3bd069f5ili9f89E1Py9exK7ce1cETV/6rjw0zJTxS6QefArrkH6zZ+2/oaWi4MqdyUtoX8qWaVzpV9kyri3cfK+BxzP11N2d7pUuRTDsuBOhu0DPZ29qouEcqfV7LU9lSO2vK7msm27ct46E2ZbJpx4V72nD6ruxtbZQjrYtJnzCZva1yuLto/9UH8gsKkcEgFcjkpu6VcipfxhT6ed35hP9SYBVGzNik/ccuq1H1YiqQJ7PuBgRq0sK/VbXdMK2f0l8F/slAS/fyjpy5rvHztqlqmXwmy38at0oZ0ripsGdWbdl75v/t3Xd8VFX+//F3eq+QCqEECCVAAtJ7U0CKwKooilhWWevqrj9lV2Vtu+6XdYtddMWCCDZQigIWDEgAAek1JISQkEIK6W2S+f0xZMKUhE7YzOv5ePjH3HvmzpmYvLn3fu45p9HP//s73+gf763W5FHxmjGxv6oNNTqQnKnMk4WNvg+XzqXMvzN5ujnr3iHtVF5VY3f/DXERemhEB20+mq+1G1Pl5uKssd1C9dcbYvXcygP6OTnP3PauQe2UV1qlIzml6tvO/vVyc3JVFVCOHTum9957T7t27VJSUpKio6O1cuXKpu7WFfHAjFF698U7zQUQSZp6bW8NvvVv+s+H3+mdF2ZJkv71/lqVlVdq3cInFBUeLEm6pltbTX3odX2yYrPunDZEktS9Uyt179TK4jPSswp0IueU7rhhoMXnTL++n01/Nv6aJCcnJ/3mumvM27p3aqWV8x+1aHffzcN1y2Nv651Pf9JTv5soFxdmhbtc1n/zsyKiwmU0GlVeWm6xb/JtE2zaR7SJ0MpPvlHygaPqEhdjs3/Luq1yd3dXVHRrJe+3vMB2cXHRLbNvUmTbCPO2nn27yz/Qz1xEaduxjfUhtXvrXhUXlqh7n1jtSNx5gd/UcTlyBtpTXFqhh1/4WGMGxeq/f71Lzs62+WIw1OijZRs1cWS8Xv/LTPP2SaPi1f/G57V0zTabAkr/uA7nPIrkQPIJfbjsZ/3h7nGa9+43F/V9cGH2ZxVr09F8u/sqDbVKOJJns31UTIhKqwzamlb/lMz244XaftzypP+bfdn659Tumtwzwm4BJcDTVdN7t9KynSc0o2+Uzf5j+eV6eqXlBcg3+7L11NgYTegerk+22T4BjoaRgfYNiO+gyaMbHmn11P2T9e8/z5Cbq4tu/cPbOpiSabddbKdWirU6N8zINp0b3j7Z8tzwrmlD9MjMMfLydNeT//iMAkoT2nuiWBtTbHNOkjqF+mpYx5b6ZOtxfbz1uCRTBhVVVGtqXKRW7M1Sal6ZJCkm1FcjOoXov4mpWrrzhCTph0M5euuWeN09qK0eX7pXklRQVqUHluxUWkH9uea3+7P16MgOuq5rmBZvS1dmkamA4yTp8TGdlF5Qrjlf71NVTe3l+jE0e+SfpQdmjNQ7L8yyvDYe01tDb3tJ//noO81/znRt/N/PEtSrWxt98s/Z5oe7ZkwaoO6TntGSVb+YCyixnVpp+Vu/t/iMe28arhl/nK93P0vQn2fbXsdWVFZr7ivL9MjMa/XSO6su47eFPd7uLnriuhj9kpqv51cdVEOnUwsSj+lfPxxRTa1RL0zupnYt7M++cDS3TI9/ucdi29e7M/X8pG6aEhepDzYdM5+zdQ330+39ozR/w1Et3XGiwT4WVxr0yGe7Lbat3JOl0kqDpsRH6u31R1VQxkOF54IMtPTAjJF61zoDr+2tITNe0isffqf5z5sy8ObxfW3e+/N223t5krTzq2fVJrKF8k6VqNN1f2rws7fuOap/vLdaL/x+ih6YMeoSfSOcj0udf2e6rV+UyqpqtDO9UIOjW9jsnxIXqYNZxXpm+X7ztjX7s7X4nr66tmuoRQHl9gVblV1cKX9PV305e8B5f8//NVfV3e6kpCQlJCSobdu26tChQ1N354rqHxdtEY6S1KFNqLpER+hwav10ISvW7dTYod3NxRNJGtG/izq2CdVX3+9o9DO+XLtNRqNRN42zDdkzVVZVa/mPOzW4d0e1Cgs6a9/bRAarrKJaVdWGs7bFhUk/mqHD+45oxMRh5/yegCB/SVJlRaXNvoLcU/p14w4NnzDU7k1pF1cXi+JJnY6xpr/L/JwCm33lZRXa+N0mDRozQB6ezb/6fDk4cgbas3TtNp3ML9ac2RPk7Oys0vJK1dZa3pyprqlReWW1QoL9LLa3DPKVs7OTPD1sR1hJUklphQwG+09dnOmZ/yzV+OE9zdPaoGl4ujnL+RxniQzyclP3SH9tPlqg6prGqxe1Rim3tEo+7i5298/sH6WMwgr9ZKdI05ic4kp5uDrL9Vw7DUlkYGOKG8msiJAAubna/x0+my/XbpfRaNSN4/pYbA9t4S8v/i2/ang1kIHdI0z/9iUcsZwycH1SrpydnDSsY/3oyiEdWqim1qhv92Wbt1XXGLX2QI66hfubn6ouqjBYFE/qJKaYCtlRQfVTs/aOClS7Fj76ZNtxVdXUysP13LMalsg/S/16NnBt3D5CSUfrf4eLSysUEuRnMTLe39dLvl4e8mrgHPBMURENX8e+tvB71RqNevA2biA2hVGdQxTs4673E4/JKMnT1Vn24iWvtOqipsrKLqqQh5uzXM+4Jp4aH6mC0iotO1088XQ7v9tm2UWm629fj6vqeeWrGhloqX9DGRgdocOp2Q28y3Qvb8U6+/fy2kTa3iy35+0lPymshZ9+d8sIGY1GlZTZ3k/C5XW58q9VoKemxbfS/A1HVdvA+7zdXXSq3LLwW1ZVo/LqWlUaLO/FZBc71u/GVZXoo0aN0pgxYyRJc+bM0d69e5u4R03LaDTqZH6xukSHS5JO5JzSyfxim6lnJKl3bFt9l7iv0eN9vnqbWoUFaVDvjo22+27jfhUWlzdYaCmvqFJZRZVKyyq18dckfbJis/r2aM+F9mVSW1urH1ckqEefWIWENzzNkNFoVEVZhWpra1WQe0o/r0mUk7OTotq3smn706r1ah3dWtGd2+nwnqRz7ktZsekpRi8fT5t9id9tko+vt3r2667NP/5yzsdEPTLQ0vqth+Xn46msk4W6a857Sk7LkbeXu24c11fPPzJVnh5u8vJwV+/Ytvr0my3q072d+sdFq6ikXP96f60C/bw184ZBNsd99G+fqLSsUi4uzuofF625D95gN1eX/7hD2/akav3iP+l4pv0RELj8HhkeLS93F9XUGrU/q1gfbE5Tcm5pg+2HdGwhF2cnmxuKdTxcneXu4iwfdxf1bRek3lGBFk/S1OkU4qORnUL05+X7JWPjJ6buLk7ycHWRl5uzYiP8NapziA5ll6jqLAUcWCID7Xv4xUXmzBoQ10HPPjJFvexk1oX4cvVW07lhr8bPDdF0HhvVUd6nM3BvZpEWJKYq6aQpA91OPzFfZXVBW3H6dccQH/O2Di19lHGqXOXVloW4urVUolv4KLek4ekfgrxNN6OLKuovquOjTFPGVdfU6pUbe6pTqK+qa2qVmJKvN9anqKSSh6vOFfl3dkajUTlnXBtL0uDenbR83U6981mCxg3proqqar372XoVlZRr9i0jbI5hcR2744gWr9ysvj3a2VzHpmfl65WPvtOrT9/GNW4T6RUVqNJKg1r4uuvZSV0VFeSt8qoafX8wR2+tTznrQzINcXdxlqebs7zcXNSzdYDGdgvTgcxiixF0vaICtT+zSFPiI3VbvygFeLkpr7RKi385rq93247ydHV2kre7izxcnRUT5qcbr2mlrKIKZZyyLUbDPjLw7MwZ2D68wTZ19/JuHNunwTZns37rYfXr2V7zP03QPxesUX5hqcJa+OsPd12ne0+vQYrL63Ll3/3DorUrvVC/pBZoeCf79xZ3pRdqWKeWuiEuQptT8uXu6qwpcRHycXfRsp0Nj8hzBFdVAcXek/CO7LNvt+pEzin9abZpeqbsXNPUI2F25rcOaxmggsIyVVZVy8POmhYHkjO1LylDj9wx5qyLvX++eqs83F11w+h4u/vfXvKTnn9jufn18L6d9frc2+22xcXbvWWPik8VadDdUxptV1ZSpvkvvWd+7Rvgq+tvHqvg0GCLdikHj+pYUppmPnzrefdl64btcvdwV7uYdhbbT2bmavfWvZo6azJ/xxeBn52lo+knZaip1awn/6sZEwfoz7+bqMRfj+i9L9arqLhcb58euvzGX2Zq9jMf6MHnFprf2zayhZa//Xu1bVV/YuDu5qoJI+I0elA3tQjw0eGjWXpr8TpNuf9VrZj/qHp0bm1uW15Zpede+1r33TJcbSJaUEBpAtW1RiWm5Gv78VMqqqhWVKCXpsRF6G+Tu2nO1/t09PS0NNaGd2yh/NIq7ckosrv/rgFtNK5bmCSpptaozan5emdjqk27ewe308aUPB06vVh9YyZ2D9cd/etvaO9KL7RZewBnRwZacndz0aSR8RozqJuCA311+Gim3lj0oybN/o++efcx9exsO63c+TiYkql9R07o4ZlnPzfElWeoNern5DxtPVagoopqtQny1rT4SM2b2l1/XLpXKbmlSj99c65bhJ/FU4DdI0yjkFv61GdXkLe78stsCyR121r4NJxzrs5OmhIXqczCCov1WCIDTKNR5lzXWduPn9Jnv6arfQsf3dy7lUJ83fX4Mm6AnSvy7+w+X71NmSdP6U9nLHr80h9vVF5hif70zy/0p39+IUlqEeirZW88rL492tscY/6nP+mFN1eYXw/rG6PXn7G9jn3mlWXq0bm1pllNgYMrp1Wgl5ydnfTcpG5avS9bCzYeU8/WAZoaHylfD1f9bfWhCzru1F6R+u3gdubXv6ad0svf1a9V4uvhokBvN8VG+is+KkALtxxXTnGlxnYL1UMjO8hQa9SqvVkWxxzSsYWeGl+/3sSh7GK9/F0S07ieBzLw7D5fvU2ZOZYZaNNmzbZG7+WdzamiMuWdKtGWXSnasO2w/t9vx6t1WJA+WblZT778hdxcXczLBuDyuRz5169dkK5pE6jZnzQ+c9GbCSkK8HLTQyM66KERptFgp8qq9cTSvTpwer08R3VVFVBQ73Bqlv7fvM/Ut0d73TqhvySpvNL0xJeHm+3/Nk9307aKSvsFlM9Xb5Wks07fVVRSrrUb9+naQbEK8LM/f95vxvZRr65tlHuqRGs27NXJ/GJVsMDyZVFeVq7E77eo/8h+8vZtfD5DTy9P/ebuKaox1CjnxEkl7Ttis5B7jaFGP63aoJ79uqtF2LkN4ayz5aetSjtyXKMnj5Cnl+XCoOtWJqh9TFu169S2gXcD56+0rFLlFVW6Y+pg/fUPv5EkTRgRp2qDQR99lagn7h2v6KhQ+Xp7KKZ9hK7p3l5D+3RSTl6xXlv4ve6a856+eusRtQj0lST17dHe4mJ67NAemjgqXqNm/p/+9vYKLf73/eZ9ry38XoaaGv3+juuu7JeG2aHsEs3Lrh8ht/XYKSUezdcrN/bQzH5Rev5b2xPHyABPdQzx1de7MxucK3bFniwlHs1XsLe7BkcHy9nJSa4uljePR8W0VNtgL8377txG6G1IztOR3FIFeLqpT5tABXq5yd2VC0FcnH49o9WvZ/30geOH9dCkUb00/LaX9OKbK/TZKw9c1PG/OH1ueDFPKeLyOZBVrANZ9Tm3JbVAPyfn6Y3pcbpzQBvNXXlAW48VKLuoQvcMaqdKQ62O5JSqc5iv7ujfRoaaWosc8nB1tvvEYvXpp64by6z7h7ZX22BvzV253+KGoNfpaW2Sckr08vemvNyYkq9KQ63uGthW8a0DtDOdBWdx8Q6nZumJf5iujW85fW0sSV6e7urYJkyRoYEaO7i7issq9faSdZr15H+1cv6jio4KsTjOb67ro/iubZRXUKK1G/cpJ7/IfI1dZ8O2w1qxbpfWLvjjFflusM/r9CiRFbsz9ebph1J+Ts6Tm4uTJvaI0IebjynjVMV5H3fdoZM6nF2sQC839W8frCBvd4v883IzTYkZ4OWmF785qIQk04jmDUm5euf2XprRL8qmgLIzvVBPLN0jXw9X9YoKVHRLH/NxgEvB3v1Ba0Ul5fpu4z5dO6hbg/fyzqak3PQwRn5hqf771zs17VpTEfmG0fEafOtLennBGgooV8Clzj9XZyfdPyxaK/dkKS2/8ZFxFYYapReUKbekUpuP5svb3UXTerXSXyZ21R8+360Theefu80FV/dXoezcIk1/9G35+3rpw/+7x7ygXd08rpV25mitqDJtszffv9Fo1BdrtqlrhwibheWtrfhxpyoqq3XT+IYvpttEBGtE/y66cWwfvfvinWrXqoWmPPi6yisoolxqG9dulqe3h3oNjDtrWxdXF7Xt2EbRXdprwKh+Gj15pNYu/UEpB4+a22zfuEPlZeUaOOb8Fng6tPuwNn63Sd37dFPcgJ42+06kZWr49UPP65jA2dTl2dQxvS22Tz19Irdtb6oMhhrd9Mib8vf11Et/vFHXD4/TndOG6PNXH1BqRq7eXPRjo5/RvnWIxg7toY2/Jqnm9E2ktMw8vbXoR825b4J8vD0afT+urKyiSm1JLVCPSH+78+wP62gqDK9vYPouScoorNDujCL9lJSrv645LC83Fz01trN5v5ebi2b2i9KyXZnKLT23f9dOllRpd0aRNiTn6d/rkpVdXKnnJnSRuwtP9ePSio4K0bhhPfTz9vrMuhBGo1Ffrt2urh0ibBaWx9Urs6hCm1PzFdcqQM5OpjVM/rLqgIorDHp6XBd9cMc1+uPoTlq87biKKw0qr67/Hak01MrNTiY1NA1Ynd/ER2p8bLg+2pKmbWmnLPbVvecnq8z9KemkJNNCzMDFys4r0q1/mC9/Xy+9/9I9Fou93/3n95SRXaA35s7U5NG9dNukAVr+5iOqqjbor2+vsDlWVESwRvTrot+M7aP5z89Su8iWmvZQ/XWswVCjP/3rC908vq96d+PBsKZUN9f+ukMnLbb/eLAuX/wv6Lg5xZXacbxQ6w7n6u9rDiuzsELzpnWX++nfq7rPra6p1YYzss0oKeFwrkL9PBTiZ3l9cKqsWjuOF2rDkTy9ui5ZW1Lz9fepseapD4GLkZ1bpFseM2XgB3+3zMAzrVi3SxWV1brxLA9NN6bunqObq4tuGNXLvN3Z2VlTr+2tEzmnlJ7FzAyX26XOv9/0ipS/l6s+2px21rbPXN9FIX6e+sd3SdpwJE9r9ufo8S/2yM3ZSXcNcux/FymgXGUKS8p10+/fVGFJmb549QFFhASa99VN3VU3ldeZsnMLFRTgbXf0yeZdKTqemX/W0SeSaVigv6+Xxg7pfs59njy6lzKyC5S448g5vwdnV5B7Snu27lWvgfEqKS5VYUGRCguKZDAYVFtbq8KCIpWXNVz9jWwbIR8/Hx3YaXp6sbKiUlvWbVWPvt1VVVllPl51ZZWMRqMKC4pUVmI7Jc6xpDSt/nytoju305gbbBdRXP/tz4rp3knOLi7mY1aevggpLixWSVGJzXuAcxF+OvNsF4g3vS4sKtPmnck6mJJpk1nRUaHq1C5MW/ecfRqlyLBAVVXXqOz07+28d79VeEiABvXupLTMPKVl5ulknmm4at6pEqVl5tksZo8rJ6+0Sm4uzvKws2j2sI4tlX6qXMm59qf3sicxJU8xob6KDDCt7TSlZ7hcnZ31c3K+Qn3dFerrbp7axtfDVaG+7mddHD4xJV8hvh7qFnFhF/dAY1qFBamq2qCy8gtfuHHL6XNDRp/878ktsczAtIJy3b9kp363eIceX7pHt3+4Tav358jf000nzph/v6CsSsHettN01W3Ls1MwHtM5RHcNbKtVe7O0ZHu6zf6695wqs3yCv27xURZQxsUqKinX9EffUmFxmT77z/2KCKmfyjo1I1c/bDqgcUMtzwGDAnzUP66Dtuw6an04G5NHxSsju0CbdiZLkj795hcdOZajO6cOVtqJPPN/klRSVqm0E3nm80VcXvmn86WggXzx87w0+bLhSK5C/TzVs5XpnK24wqBKQ42KKgw2U3CZP/ss2bY+KVfe7q4aFH1+Mz4A1opKynXz6Qz8/BXLDLT2xeqtp+/lxV7w5wX5e8vTw03BAT42hZqQ09fgp4rO/ToLF+ZS5p+3u4tm9IvSt3uz5e3uojA/D4X5ecjTzUVyksL8PBToZbqPHO7voX7tgrUpxXJ90OJKg/aeKFKsg1/bclZ7FamorNatf3hbyWk5WvbGQ+oSHWGxPzI0UC2DfLXzgG3V8Nd9x9SjU2ub7ZJp+i4nJyfdOK7xi+Ss3EJt2H5YMyYOsFuIaazfklRU4rhDuS6HkqISGY1GrVuZoHUrE2z2v/ePD9RrULxGThzW4DEMBoMqK0w3WCrKK1VdVa1t67dr2/rtdo/XoWu0bpg50bwt83iWli9apbBWYZpw6/VytvO0Q3FhiQ7uOqSDu2yn0/n49SUKiWipmQ/POKfvDJypZ5coJWw9pKyTherYNsy8va6I3CLIVyfzTYWNGjuTDFcbamQ4hye0j2XkydPdTT5epptIGdkFOpqeq/43Pm/Tds7Ln0uSDq156YKHRuPihPl5qtJQqwqrhZA7hfgoMsBTn2w9fl7Hq5u2wcfddDMyxNdDfp6uev3mnjZtb+rVSjf1aqXHvtzT4Bos9o4JXErHMvLk6eF2USPkvlizTU5OTvoNBZT/OeH+nqo01NhkYFpBfbGkT5tAuTg7accZ02cl55aqZ6sAebm5WCwk3znMNM1lSl6pxfEGtAvS70d2VGJKvt5cb/9hhCOnF7O3Xj+l7nVhebXNe4BzVVFZrRl/nK/ktBwtfd322rixc0CDoUY1NTU2262Vm69jTX8/6dkFqjbUaPy9/7Zp++k3v+jTb37RR/N+qwnDzz47AC7O4ZwSXdM2SC193c3rPUn1+XLqEuVL3Tmb9+miiFFS8slSdQ7zk6uzkwxn/H6da7bVFbh9PDgPxIUz3R9sOAPPZLqXl6RbJ/Q/r3t51pydndW9UyvtOJCmqmqD3M9YPiDTfA3O6NLL7VLmn5+Hq7zdXTW9T2tN72N7z/jju/tqY3Kenl15QEGnH6pxsfOwoKuLk93tjoQCylWipqZWd/95gbbuPqpF/5xtMef1mSaNiteSlVuUnlWg1uFBkqSEXw7pSFqO7p8x0qZ9taFGX3+/QwPioxUVHmyz/0xL125Xba1RNzVQaMktKDY/+X2mhV8nysnJSXFdLm4xU1hqGdZCk2+fYLN949pNqqqq1siJwxQQHGBe58TN6h/Kw3uPqLK8UmGtTDeevX287B5vR+IunUjL1IRbxsnHz8e8PS8nX8s+XC7/QD9NmTVJbnbW3pFk95iHdh3WoT1JGnfTtfL19z33Lw2cYfKoXnpt4ff6ZOVmDekTY96+aMUmubo4a1CvTsrOMy0U/tX3v2rUgK7mNrsPHVdyWo5uv2GQeVtuQYlaBln+Pu5LytDan/dq1ICu5sUL59x3vfJPWd5IOpiSqf979xs9eNto9eneTt5eTO11ufl7uqqownLKynbB3urbNlC/Hi+0WeNkWMeWkqT1R/JkT4Cnqwqtjufi5KSRnUJUaajR8dM3H1fuzdKW1ALL93q56oFh0frh0En9klqg7KLKBvsoSWO6hKjWaFRybqnNPuBc2Tvv2ns4Xas37NHogd0ueMHVakONlv+wQ/3jotX6LOeGaDr28qV9C2/1bxekbWmnGlznyd3FWTP7tVFeaZUSkuqnftiYnKcbe7XS+NgwLd15QpJpTuxru4TqYFaxckvqn6rvHuGvJ6+L0d4TRZr33eEGP2vz0XzNHtJe13YJ1fcHc8ztxnY1nXvuYP0TXKCamlrd89T72rrnqD7+x312F4Rv37qlnJ2d9NV3v+rOqYPl5GS6sZORXaBNu5I1IK7+erqh69hFKzbJyclJPTubrmOnXttb3WNspzW844n/6tpB3TRzyiBdE9vuEn1LNCYhKVe39o3SuNgwi7WUxncPk6GmVrvPM18CvFxVWG57zjY+Nky1RqOO5NTPmvDT4Vx1i/DXtV1D9e2+bEmSm4uTRnUOUWpeqXn0XUPngeNjTRl4OJuZGHBhzszARS/fp349bTPwTGe7l3c+pl7bW9v2pmrxqi2aNWWwJFMx54vV29S5fXijo2BwaVzK/DtVXq2/rNhvs31KfKS6Rfjpb98eMo94OVFYrppao4Z3aqmVe+rXemrp667ukf7ae6LoIr7V/z4KKFeJp/+zVN+u36NxQ7uroLBUn37zi8X+6df3kyT94c6x+vr7HZp8/yv63S0jVFJWqdc+/kHdOkbqtkm261r8sGm/8gtLz3H6rq2KCAnQkGs62d3/zwVrtGVXikYP7KbW4UEqKCrTih936tf9x3Tf9OE2i/Th4nj5eKljtw4223/duFOSzPtyTpzUFwuWqXOPTgoOCZaTk5SdkaMDOw/JP8hfvQebnpByc3eze7wj+1PknJ5tsa+qskpL3/9KleWV6jO0t1IOplq8J7BFgCLbRFj040w5J0wX7O1j2snLx+v8vzwgqUfn1rp1Yn8tXrlFhppaDYzvoMQdR7Tix5165I4xCg8JUHhIgIb37azPvvlFJaUVGt6vs7LzirTg8w3y9HDTfTcPNx9v9jMfyNPDTX17tFfLIF8dTs3Swq83ycvTXU89MMncrn+c7e+0v5/p9zi+axuNH247MgGX3uOjO6qqplYHs0tUWF6tqCAvXdclVFWGWi38xXIkprOTNKRDsA5mFyur2P60RvcPbS9vdxftyyxWXmmVgrzdNKxjS0UFeWnBpmOqOD3XbEpemVKsRpeE+pqexkkrKNOWY/XFlZt6RapLmJ92pBfqZEmlfD1cNbB9sGJCfbVyb5ayii58iiXgt0+9L08PN/XrGa2WQb46dDRLC79KlJenu+Y+ONncbl9ShlZv2CNJOpp+UkUl5frngtWSpNhOrTRuaA+L4/64+YDyC0sbnb7reGa+PvvWdC6684BpVFfdMaPCg3Xz6fNSXD5/uq6zKmtqdSCrSKfKqtUm2Fvju4Wp0lCrDzYfO6NdjPJKq5RWUC5vdxdd1yVU4f6e+suqAxZroBzKKdGGI7m6s38bBXq56URhhcZ0DlGYn4deWZdsbhfq66G513eR0WhasHRoR8spaI7mlSn1dEYWlFfr0+3pmtm/jV6Y1E2bUvLVvqW3xnUL00+HTyoph5uHuDDPvLJMqzecvjYuKtNn32612H/z+L5qGeSn2yYN0MKvN2nKg69p4sg4lZRWasGXG1RRWa1HZ11nbv+v99dqy+4UjR7Qtf46dt1O7difpntvrr+OjWkXrph24Xb71CayBSNPrqDkk6X6dl+WxseGy8XZSbszChXXKkDDY0K0eOtxcxGjfUtvDWxvyqnIAE/5uLtqRl9TQSwlt1Sbj5rWa5jRN0qxkf7amlqgnOJK+Xu6akjHluoS7qdlO09YLIy8ak+WxseG6eGRHdQ6yEs5xZUa0yVUYf6eemZ5/Y3I0V1CNbFHuBJT8pRZWCFvN1f1aRuoa9oGaVNKnsWNT+B8PP3Ksvr7gw1k4Jm+WL2t0Xt5kmkU3fHMfJVXmv52Nu04opffM53bTb++n6IiTA/V3Dl1sBZ+vUlPzPtcyWkn1TosSJ99+4uOZ+Xrk3/edym/JhpwKfOv0lCrxBTbdWsGd2ih2jA/i32F5Qat2Z+t67uHa9607tp4JE9e7i6a1DNCHq4uWrLVcjrXMV1CFOrnKU8300NdPVr5mz//+4M5ymnguvx/1VVVQCkvL1dCgmmqooyMDJWUlGj1atMfdL9+/RQc3Hyfkttz2PSLuHrDXq3esNdmf10BpXV4kFbOf1RP/+dLPff6crm5uei6wd314qNT7Q7V+3z1Nrm5umjK6F42+86UlJqtnQeO68EZoxp8ovG6IbE6mp6rRSs2KbegRJ4eburWMVJvzL1dt07sf75fGZeIX4CvOsV21PGUdO3fcVC1NTXyC/RX/MCe6j+ir7y8z7+AUV5WoeJC00Xvz2sSbfZ3693VXEDBpePIGdiQeU9MV6uwIC1Z9Yu+Tdit1uFBev73U3Xf9BHmNh/M+63e+mSdvvr+V63bfEBubq7qHxetJ++93mLqr/HDeujLtds1f8k6FZdWqEWQryYM76k/3jNO7VtTAL7abEkt0PBOLTW5R7i83V1UVG7Q5tQCLdmeblOY6NkqQEHe7vpix4kGj/dzSp7GdA7VuG6h8vN0VXlVrZJzS/XRL2naeuzUBfVxW9ophft7anTnEPl7uqq6xqjU/DK9+lOyfjzc8EL2sI8MtHT98J76Ys02vfXJj/WZNSJO/++34y0eWtl96Lhemr/K4r11r2+Z0M+mgPLF6q2mxUEbOTc8diKvwWMO6t2RAsoVsOlonkbGhGhqXKS83VxUWGFQYkqeFm1NV2ZR/Y2+pJwSjekaqvGxYaoy1GpvZrHmfXfYphAsSS//kKSZ/dpoVEyIfD1cdTSvVM9+c1B7M+ufKAzz9zCvXfLgcNsR8Yu2HjcXUCRp8fZ0FVcaNLlHhO4b0k4FZaaiyifbbNdMQcPIP0t7kxq/Nq67efjyE9MV26mVFi3frBfeNC0a36trG735l5ka1Kujuf21g2OVmpGrRSs3K6+gRB7ubortGKnXnrlNt07gOvZq9cqPycoprtTYbmEa3KGFcoor9WZCipbtrD/f6xTia7Owcd3rtfuzzQWULakFigjw0rjYMAV4uanKUKujeaX6x9rDWnsgx+L9VTW1emLpXt07pJ3GdQuTp5uLkk+W6Omv92lb2ilzu30nihQb4aeRMSEK8nZXTa1RxwvK9db6FH21s+FzUtgiAy3tPcv9wTMLKEnHsrXz4HE9MGNko6OTP16+SRt/rV+3eMP2JG3YniRJGhDfwVxA8fJ019dvPqxnX/tKi5ZvUllFlbrHtNaSf/1Oowd2tXtsXHqXMv/O73OPKOVkqcbFhunuwaZjHcou0by1h7XHagTKuNhwxbWuH5HUKypQvaICJUl7TxQ1uwKKk9FobGhU9hWXnp6u0aNH29330UcfqX//8z+5qTVKVWef/hQO5oXvDjd1F3CV+ePwdnYXV72SLksG1hpVXMmC57A0/f1tTd0FXEXev830RG1EgGeT9uPynAcaxTIMsDbp7U1N3QVcRT6e1VuS6enNpnK58q+C/IOVsa9tbOou4Crz6T19FBnYPM8BK21nWIODu+5VMhD1Pr3HNCL/XDLwqhqB0rp1ax06ZLsQNQA4AjIQgCMjAwE4KvIPgCMjAwFc7S5s9UkAAAAAAAAAAIBmjAIKAAAAAAAAAACAFQooAAAAAAAAAAAAViigAAAAAAAAAAAAWKGAAgAAAAAAAAAAYIUCCgAAAAAAAAAAgBUKKAAAAAAAAAAAAFYooAAAAAAAAAAAAFihgAIAAAAAAAAAAGCFAgoAAAAAAAAAAIAVCigAAAAAAAAAAABWKKAAAAAAAAAAAABYoYACAAAAAAAAAABghQIKAAAAAAAAAACAFQooAAAAAAAAAAAAViigAAAAAAAAAAAAWKGAAgAAAAAAAAAAYIUCCgAAAAAAAAAAgBUKKAAAAAAAAAAAAFYooAAAAAAAAAAAAFihgAIAAAAAAAAAAGCFAgoAAAAAAAAAAIAVCigAAAAAAAAAAABWKKAAAAAAAAAAAABYoYACAAAAAAAAAABghQIKAAAAAAAAAACAFQooAAAAAAAAAAAAViigAAAAAAAAAAAAWKGAAgAAAAAAAAAAYIUCCgAAAAAAAAAAgBUKKAAAAAAAAAAAAFYooAAAAAAAAAAAAFihgAIAAAAAAAAAAGCFAgoAAAAAAAAAAIAVCigAAAAAAAAAAABWKKAAAAAAAAAAAABYoYACAAAAAAAAAABghQIKAAAAAAAAAACAFQooAAAAAAAAAAAAViigAAAAAAAAAAAAWKGAAgAAAAAAAAAAYIUCCgAAAAAAAAAAgBUKKAAAAAAAAAAAAFYooAAAAAAAAAAAAFihgAIAAAAAAAAAAGCFAgoAAAAAAAAAAIAVCigAAAAAAAAAAABWKKAAAAAAAAAAAABYoYACAAAAAAAAAABghQIKAAAAAAAAAACAFQooAAAAAAAAAAAAViigAAAAAAAAAAAAWKGAAgAAAAAAAAAAYIUCCgAAAAAAAAAAgBUKKAAAAAAAAAAAAFYooAAAAAAAAAAAAFihgAIAAAAAAAAAAGCFAgoAAAAAAAAAAIAVJ6PRaGzqTlxORqPUrL8gLsip8qqm7gKuMgGebnJxdmrqblxyRqNRzTvlcSGyiyubugu4ioT4uaumVvJwbX7P1RiNRs4DYSOriAxEvdBmmoHkH+zJKiT/YCnUz12uLs0r/yQyEPaRgThTqJ+7aozndg7Y7AsoAAAAAAAAAAAA56v5lZkBAAAAAAAAAAAuEgUUAAAAAAAAAAAAKxRQAAAAAAAAAAAArFBAAQAAAAAAAAAAsEIBBQAAAAAAAAAAwAoFFAAAAAAAAAAAACsUUAAAAAAAAAAAAKxQQAEAAAAAAAAAALBCAQUAAAAAAAAAAMAKBRQAAAAAAAAAAAArFFAAAAAAAAAAAACsUEABAAAAAAAAAACwQgEFAAAAAAAAAADACgWUZi45OVl33XWX4uPjNXjwYM2bN09VVVVN3S00sWPHjmnu3Lm64YYb1K1bN02cOLGpuwRcFmQgrJF/cCRkIKyRgXAU5B/sIQPhKMhAWCP/Lo5rU3cAl09hYaFmzZqldu3a6bXXXlN2drb+/ve/q6KiQnPnzm3q7qEJJSUlKSEhQXFxcaqtrZXRaGzqLgGXHBkIe8g/OAoyEPaQgXAE5B8aQgbCEZCBsIf8uzgUUJqxJUuWqLS0VK+//roCAwMlSTU1NXruuec0e/ZshYWFNW0H0WRGjRqlMWPGSJLmzJmjvXv3NnGPgEuPDIQ95B8cBRkIe8hAOALyDw0hA+EIyEDYQ/5dHKbwasbWr1+vgQMHmgNTksaPH6/a2lpt3Lix6TqGJufszJ8+mj8yEPaQf3AUZCDsIQPhCMg/NIQMhCMgA2EP+Xdx+Ok1YykpKYqOjrbY5u/vr5CQEKWkpDRRrwDgyiADATgyMhCAoyL/ADgyMhC49CigNGNFRUXy9/e32R4QEKDCwsIm6BEAXDlkIABHRgYCcFTkHwBHRgYClx4FFAAAAAAAAAAAACsUUJoxf39/FRcX22wvLCxUQEBAE/QIAK4cMhCAIyMDATgq8g+AIyMDgUuPAkozFh0dbTO/YXFxsU6ePGkzHyIANDdkIABHRgYCcFTkHwBHRgYClx4FlGZs2LBhSkxMVFFRkXnb6tWr5ezsrMGDBzdhzwDg8iMDATgyMhCAoyL/ADgyMhC49FybugO4fG655RYtXLhQDz74oGbPnq3s7GzNmzdPt9xyi8LCwpq6e2hC5eXlSkhIkCRlZGSopKREq1evliT169dPwcHBTdk94JIgA2EP+QdHQQbCHjIQjoD8Q0PIQDgCMhD2kH8Xx8loNBqbuhO4fJKTk/XCCy9ox44d8vHx0Q033KDHHntM7u7uTd01NKH09HSNHj3a7r6PPvpI/fv3v8I9Ai4PMhDWyD84EjIQ1shAOAryD/aQgXAUZCCskX8XhwIKAAAAAAAAAACAFdZAAQAAAAAAAAAAsEIBBQAAAAAAAAAAwAoFFAAAAAAAAAAAACsUUAAAAAAAAAAAAKxQQAEAAAAAAAAAALBCAQUAAAAAAAAAAMAKBRQAAAAAAAAAAAArFFAAAAAAAAAAAACsUEDBVWHUqFGaM2eO+fWWLVvUuXNnbdmypQl7Zcm6jw3p3LmzXnvttfM+/tKlS9W5c2ft2bPnQrpn12uvvabOnTtfsuMBuDzIQDIQcGRkIBkIOCryj/wDHBkZSAb+r6CAAvMfa91/PXr00NixY/X8888rNze3qbt3XhISEi4osAA4LjIQgCMjAwE4KvIPgCMjA4Fz59rUHcDV45FHHlHr1q1VVVWl7du3a/HixUpISNDKlSvl5eV1RfvSt29f7d69W25ubuf1voSEBC1atEgPP/zwZeoZgOaKDATgyMhAAI6K/APgyMhA4OwooMBs2LBh6tGjhyTppptuUmBgoN5//3398MMPmjhxot33lJWVydvb+5L3xdnZWR4eHpf8uADQEDIQgCMjAwE4KvIPgCMjA4GzYwovNGjAgAGSpPT0dEnSnDlz1KtXL6Wlpenee+9Vr1699Pjjj0uSamtr9cEHH2jChAnq0aOHBg0apLlz56qwsNDimEajUW+++aaGDRumuLg4zZw5U0lJSTaf3dC8h7t27dK9996rvn37Kj4+XpMmTdKHH35o7t+iRYskyWIYYp1L3cdzlZGRoWeffVZjx45Vz5491b9/fz3yyCPmn6u1iooKzZ07V/3791fv3r31xBNP2PRRMlXYZ8yYofj4ePXq1Uv33XffRfUTgCUykAwEHBkZSAYCjor8I/8AR0YGkoGwxQgUNCgtLU2SFBgYaN5mMBh0zz336JprrtGTTz4pT09PSdLcuXO1bNkyTZs2TTNnzlR6eroWLVqk/fv3a/Hixebhd6+88oreeustDR8+XMOHD9e+fft09913q7q6+qz92bhxo2bPnq3Q0FDdcccdatmypZKTk/XTTz9p1qxZmj59unJycrRx40bNmzfP5v1Xoo/27NmzRzt27NCECRMUHh6ujIwMLV68WHfccYdWrVplMyTy+eefl7+/vx566CEdPXpUixcv1okTJ7Rw4UI5OTlJkr766ivNmTNHQ4YM0eOPP67y8nItXrxYM2bM0LJly9S6desL6iuAemQgGQg4MjKQDAQcFflH/gGOjAwkA2GHEQ7vyy+/NMbExBgTExONeXl5xszMTOOqVauM/fr1M/bs2dOYlZVlNBqNxieffNIYExNjfPnlly3ev3XrVmNMTIxx+fLlFtvXr19vsT0vL88YGxtrvO+++4y1tbXmdv/617+MMTExxieffNK8bfPmzcaYmBjj5s2bjUaj0WgwGIyjRo0yjhw50lhYWGjxOWce67nnnjPGxMTYfMfL0ceGxMTEGF999VXz6/Lycps2O3bsMMbExBiXLVtm3lb3/2Hq1KnGqqoq8/Z3333XGBMTY/z++++NRqPRWFJSYuzTp4/x6aeftjjmyZMnjddcc43F9ldffdXuzwNAPTKQDAQcGRlIBgKOivwj/wBHRgaSgTh3TOEFszvvvFMDBw7U8OHD9dhjj8nHx0evv/66wsLCLNrdeuutFq9Xr14tPz8/DR48WPn5+eb/YmNj5e3tbR56l5iYqOrqat1+++3m6qkkzZo166x9279/v9LT03XHHXfI39/fYt+Zx2rIlehjQ+oq85JUXV2tgoICtWnTRv7+/tq/f79N++nTp1ssmHXrrbfK1dVVCQkJ5j4WFRVpwoQJFt/F2dlZcXFxNkMdAZwbMpAMBBwZGUgGAo6K/CP/AEdGBpKBODum8ILZ3Llz1b59e7m4uKhly5Zq3769nJ0ta2yurq4KDw+32Hbs2DEVFxdr4MCBdo+bl5cnSTpx4oQkqV27dhb7g4ODFRAQ0Gjfjh8/LkmKiYk55+9zpfvYkIqKCs2fP19Lly5Vdna2jEajeV9xcbFN+7Zt21q89vHxUUhIiDIyMiRJqampkhoOcl9f3wvqJ+DoyEAyEHBkZCAZCDgq8o/8AxwZGUgG4uwooMCsZ8+e6tGjR6Nt3N3dbYK0trZWLVq00Msvv2z3PcHBwZesjxeqKfv4wgsvaOnSpZo1a5bi4+Pl5+cnJycnPfbYYxYBeq7q3jNv3jyFhITY7HdxcbnoPgOOiAy8PMhA4H8DGXh5kIHA1Y/8uzzIP+B/Axl4eZCBzQsFFFy0Nm3aaNOmTerdu7fFEDVrkZGRkkxV06ioKPP2/Px8FRYWNvoZde0PHz6sQYMGNdiuoSF8V6KPDVmzZo2mTJmiOXPmmLdVVlbarThLpgr5gAEDzK9LS0t18uRJDRs2TFL9z6JFixaN/iwAXBlkYOPIQKB5IwMbRwYCzRf51zjyD2jeyMDGkYHNC2ug4KKNHz9eNTU1evPNN232GQwGFRUVSZIGDRokNzc3ffzxxxbV1g8//PCsnxEbG6vWrVvro48+Mh+vzpnH8vLykiSbNleijw2xVwVeuHChampq7Lb/9NNPVV1dbX69ePFiGQwGc2gOHTpUvr6+mj9/vkW7Ovn5+RfcVwDnjwxsHBkING9kYOPIQKD5Iv8aR/4BzRsZ2DgysHlhBAouWr9+/TR9+nTNnz9fBw4c0ODBg+Xm5qbU1FStXr1aTz31lMaNG6fg4GDdfffdmj9/vmbPnq3hw4dr//79Wr9+vYKCghr9DGdnZz377LO6//77NWXKFE2bNk0hISFKSUnRkSNH9N5770kyhaskvfjiixoyZIhcXFw0YcKEK9LHhowYMUJff/21fH191bFjR+3cuVOJiYkKDAy02766ulp33nmnxo8fr6NHj+qTTz7RNddco9GjR0syzWv47LPP6oknntC0adN0/fXXKzg4WCdOnFBCQoJ69+6tuXPnXlBfAZw/MrBxZCDQvJGBjSMDgeaL/Gsc+Qc0b2Rg48jA5oUCCi6J559/Xt27d9eSJUv073//Wy4uLmrVqpUmT56s3r17m9s9+uijcnd315IlS7Rlyxb17NlTCxYs0OzZs8/6GUOHDtWHH36oN954QwsWLJDRaFRUVJRuvvlmc5vrrrtOM2fO1KpVq7R8+XIZjUZNmDDhivXRnqeeekrOzs5asWKFKisr1bt3b73//vv67W9/a7f93LlztWLFCr366quqrq7WhAkT9PTTT1sMSZw0aZJCQ0P1zjvv6L333lNVVZXCwsLUp08fTZs27YL6CeDCkYENIwOB5o8MbBgZCDRv5F/DyD+g+SMDG0YGNi9OxgtZuQYAAAAAAAAAAKAZYw0UAAAAAAAAAAAAKxRQAAAAAAAAAAAArFBAAQAAAAAAAAAAsEIBBQAAAAAAAAAAwAoFFAAAAAAAAAAAACsUUAAAAAAAAAAAAKxQQAEAAAAAAAAAALBCAQUAAAAAAAAAAMAKBRQAAAAAAAAAAAArFFAAAAAAAAAAAACsUEABAAAAAAAAAACwQgEFAAAAAAAAAADAyv8HXau5Yjw+YyoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembling"
      ],
      "metadata": {
        "id": "lV6Za3-7SvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = (preds_new4+ preds_new5)/2\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = (preds_new4+ preds_new5+preds_new3)/3\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2oJ4cy59VAFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6d6ca436-dadc-4140-d289-01ca8acc04a1"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-55aab6ddcc59>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Combination of Neural Networks and XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpreds_ens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds_new4\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpreds_new5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpreds_new3\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpreds_ens_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcost_ens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcm_preds_ens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_ens_log' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "logR_ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf_ens = GridSearchCV(estimator=logR_ens,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf_ens.fit(y_alt,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "vElSNV8QmkMa",
        "outputId": "084a5601-94fa-4522-fd8f-005daf04d3d5"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          penalty='elasticnet',\n",
              "                                          random_state=807, solver='saga'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         'l1_ratio': [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         'max_iter': [25, 50, 75]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params_ens = lr_clf_ens.best_params_"
      ],
      "metadata": {
        "id": "J6RZiEvlpCh4"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1ens.set_params(**lr_params_ens)\n",
        "model1ens.fit(y_alt,y)\n",
        "skf.get_n_splits(y_alt,y)\n",
        "preds_ens2 = cross_val_predict(model1ens, y_alt,y,cv=skf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAtJAtyrot_t",
        "outputId": "0dd167c2-3701-490a-cca0-eece13db7c16"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "cost_ens_log = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens_log = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n"
      ],
      "metadata": {
        "id": "bca2bRquon1j"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_nn).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Combined Neural Networks'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_nn:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_ens).plot(ax = ax[1],cmap = 'Blues', colorbar=False)\n",
        "ax[1].set_title('Neural Networks and XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_ens_log).plot(ax = ax[2],cmap = 'Blues', colorbar=False)\n",
        "ax[2].set_title('Ensemble from all Predictions'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens_log:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "J71VGqBYU7hF",
        "outputId": "c13436d0-0d5a-4eb6-9fe6-7b6bb128a201"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt['preds_nn']=preds_nn\n",
        "y_alt['preds_ens']=preds_ens\n",
        "y_alt['preds_ens2']=preds_ens2\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "id": "rUY2fsGRwGLf",
        "outputId": "12770681-00e6-4654-aab8-ce8402f6548e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-167-f5d109dfe8d8>:6: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1673cbd2-fc1d-45f3-85ba-6cb65b0f8dab\", \"results.csv\", 6449003)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}