{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "metadata": {
        "id": "T6H6L4bc8YlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97367ff-0693-460a-c35a-321a00a15db7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "#df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "outputId": "fd909fdd-2bed-4565-e7dd-c19bcb669eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "90d30692-d874-4b37-cb13-653ca5dc96d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "9a1355bd-999d-4546-d263-4b3f6130c558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: x24, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "52edb72f-8834-4565-9599-8c186c874772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "5fa862fe-7937-448f-a1bd-39cb0b34aa1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "0f5cfa05-5345-415d-ae1e-dcfdaa6bdb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "1ed160ea-f3fb-4d86-9376-33be4f0d66ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: x30, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "1bc28d2a-97a5-4a88-beb4-74cd30b4799f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "e21babaa-c63d-4bc0-a652-5840ec3ea321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: x32, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "06ce12d3-50a7-445e-e538-d46a37db3ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: x37, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "cee8d38c-68b6-414c-d339-f9d5eaf74913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "d07f5324-da35-48f5-a763-06436d7e76c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f2377dc5-bc77-42b7-9a2f-1cfe080f7f47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2377dc5-bc77-42b7-9a2f-1cfe080f7f47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6664f167-500d-48ea-90d1-031523fe749d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6664f167-500d-48ea-90d1-031523fe749d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6664f167-500d-48ea-90d1-031523fe749d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2377dc5-bc77-42b7-9a2f-1cfe080f7f47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2377dc5-bc77-42b7-9a2f-1cfe080f7f47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "7eb7c54b-1b13-42e8-9264-290058332e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "6fad0968-a875-4a2b-889b-e2b39c0cbc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    95803\n",
              "1    64197\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add y plot"
      ],
      "metadata": {
        "id": "vUXTcWUZIoot"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = lr_clf.best_params_\n",
        "lr_params"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1\n"
      ],
      "metadata": {
        "id": "3katCHeBPQB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)\n"
      ],
      "metadata": {
        "id": "ent8XHdUPayB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[200,250,500],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = rf_clf.best_params_\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost(preds_m2,y)\n",
        "cost_m2\n"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "Fdw5gLOk9oBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC"
      ],
      "metadata": {
        "id": "_6cqxOG75RGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = NuSVC(random_state=807,class_weight='balanced',cache_size = 8192)\n",
        "params = {'nu':[0.0001,0.01, 0.1, 0.25, 0.5, 0.75, 0.99,1],'kernel':['linear','rbf','sigmoid']}\n",
        "svc_clf = GridSearchCV(svc,param_grid=params,cv=skf,n_jobs=-1)"
      ],
      "metadata": {
        "id": "zYBX6GGsPwEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "EjZRywoCP6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_params = svc_clf.best_params_\n",
        "svc_params"
      ],
      "metadata": {
        "id": "yYiNL9AlP98A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NuSVC(random_state=807,class_weight='balanced',cache_size = 2048)\n",
        "model3.set_params(**svc_params)\n",
        "preds_m3 = cross_val_predict(model3,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "_58pwDIoQGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m3 = classification_report(y,preds_m3,output_dict=True)\n",
        "cr_m3"
      ],
      "metadata": {
        "id": "5AVAi2z8QPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m3)"
      ],
      "metadata": {
        "id": "j5nGHzRUQUOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m3 = cost(preds_m3,y)\n",
        "cost_m3"
      ],
      "metadata": {
        "id": "sefhH4BT-Rd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8946dca4-81fe-4bfb-be64-a384b53f9eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cost_m3 \u001b[38;5;241m=\u001b[39m cost(\u001b[43mpreds_m3\u001b[49m,y)\n\u001b[1;32m      2\u001b[0m cost_m3\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_m3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True,start_from_epoch=10)"
      ],
      "metadata": {
        "id": "F7PDvk6faa4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now\n"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy'])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=100,batch_size=128,validation_split=0.2,callbacks=[es])\n",
        "  fold_results.update({i:{'predictions':np.round(model4.predict(X[test_index]).flatten(),0),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "4a98bdb5-27a3-40d2-db96-f664467c9318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 3ms/step - loss: 0.4184 - auc: 0.8842 - accuracy: 0.8048 - val_loss: 0.3038 - val_auc: 0.9420 - val_accuracy: 0.8712\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2839 - auc: 0.9491 - accuracy: 0.8843 - val_loss: 0.2499 - val_auc: 0.9612 - val_accuracy: 0.9000\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.2394 - auc: 0.9638 - accuracy: 0.9071 - val_loss: 0.2145 - val_auc: 0.9713 - val_accuracy: 0.9171\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2110 - auc: 0.9718 - accuracy: 0.9206 - val_loss: 0.1912 - val_auc: 0.9767 - val_accuracy: 0.9284\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1915 - auc: 0.9765 - accuracy: 0.9296 - val_loss: 0.1754 - val_auc: 0.9803 - val_accuracy: 0.9362\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1770 - auc: 0.9796 - accuracy: 0.9370 - val_loss: 0.1627 - val_auc: 0.9825 - val_accuracy: 0.9439\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1666 - auc: 0.9817 - accuracy: 0.9410 - val_loss: 0.1574 - val_auc: 0.9835 - val_accuracy: 0.9450\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1588 - auc: 0.9832 - accuracy: 0.9453 - val_loss: 0.1485 - val_auc: 0.9853 - val_accuracy: 0.9488\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1508 - auc: 0.9847 - accuracy: 0.9475 - val_loss: 0.1420 - val_auc: 0.9861 - val_accuracy: 0.9518\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1453 - auc: 0.9855 - accuracy: 0.9508 - val_loss: 0.1388 - val_auc: 0.9870 - val_accuracy: 0.9522\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1390 - auc: 0.9866 - accuracy: 0.9532 - val_loss: 0.1349 - val_auc: 0.9873 - val_accuracy: 0.9548\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1351 - auc: 0.9873 - accuracy: 0.9546 - val_loss: 0.1301 - val_auc: 0.9879 - val_accuracy: 0.9577\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1305 - auc: 0.9880 - accuracy: 0.9570 - val_loss: 0.1270 - val_auc: 0.9885 - val_accuracy: 0.9587\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1267 - auc: 0.9886 - accuracy: 0.9584 - val_loss: 0.1217 - val_auc: 0.9892 - val_accuracy: 0.9610\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1239 - auc: 0.9888 - accuracy: 0.9597 - val_loss: 0.1207 - val_auc: 0.9892 - val_accuracy: 0.9626\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1202 - auc: 0.9894 - accuracy: 0.9618 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9625\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1179 - auc: 0.9898 - accuracy: 0.9628 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9634\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1148 - auc: 0.9900 - accuracy: 0.9638 - val_loss: 0.1148 - val_auc: 0.9901 - val_accuracy: 0.9640\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9648 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9639\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1104 - auc: 0.9906 - accuracy: 0.9658 - val_loss: 0.1086 - val_auc: 0.9909 - val_accuracy: 0.9669\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1086 - auc: 0.9910 - accuracy: 0.9661 - val_loss: 0.1114 - val_auc: 0.9905 - val_accuracy: 0.9664\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1073 - auc: 0.9909 - accuracy: 0.9675 - val_loss: 0.1085 - val_auc: 0.9908 - val_accuracy: 0.9676\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1042 - auc: 0.9914 - accuracy: 0.9681 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9661\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1039 - auc: 0.9915 - accuracy: 0.9680 - val_loss: 0.1069 - val_auc: 0.9911 - val_accuracy: 0.9672\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1018 - auc: 0.9918 - accuracy: 0.9694 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9680\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0998 - auc: 0.9920 - accuracy: 0.9693 - val_loss: 0.1051 - val_auc: 0.9912 - val_accuracy: 0.9683\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0995 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1065 - val_auc: 0.9910 - val_accuracy: 0.9681\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9698 - val_loss: 0.1090 - val_auc: 0.9906 - val_accuracy: 0.9671\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0986 - auc: 0.9921 - accuracy: 0.9705 - val_loss: 0.1057 - val_auc: 0.9911 - val_accuracy: 0.9691\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9703 - val_loss: 0.1028 - val_auc: 0.9912 - val_accuracy: 0.9701\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0962 - auc: 0.9922 - accuracy: 0.9715 - val_loss: 0.1064 - val_auc: 0.9910 - val_accuracy: 0.9685\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0954 - auc: 0.9923 - accuracy: 0.9716 - val_loss: 0.1058 - val_auc: 0.9909 - val_accuracy: 0.9694\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9714 - val_loss: 0.1046 - val_auc: 0.9912 - val_accuracy: 0.9693\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0931 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1029 - val_auc: 0.9912 - val_accuracy: 0.9695\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0931 - auc: 0.9926 - accuracy: 0.9720 - val_loss: 0.1030 - val_auc: 0.9914 - val_accuracy: 0.9698\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1026 - val_auc: 0.9915 - val_accuracy: 0.9692\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0916 - auc: 0.9929 - accuracy: 0.9728 - val_loss: 0.1054 - val_auc: 0.9912 - val_accuracy: 0.9692\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9731 - val_loss: 0.1052 - val_auc: 0.9914 - val_accuracy: 0.9697\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9732 - val_loss: 0.1049 - val_auc: 0.9912 - val_accuracy: 0.9693\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0910 - auc: 0.9929 - accuracy: 0.9730 - val_loss: 0.1038 - val_auc: 0.9915 - val_accuracy: 0.9691\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9730 - val_loss: 0.1035 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0889 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1044 - val_auc: 0.9914 - val_accuracy: 0.9709\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9734 - val_loss: 0.1033 - val_auc: 0.9912 - val_accuracy: 0.9708\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0901 - auc: 0.9928 - accuracy: 0.9732 - val_loss: 0.1029 - val_auc: 0.9913 - val_accuracy: 0.9700\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9743 - val_loss: 0.1023 - val_auc: 0.9913 - val_accuracy: 0.9703\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - val_loss: 0.1036 - val_auc: 0.9916 - val_accuracy: 0.9696\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0874 - auc: 0.9932 - accuracy: 0.9741 - val_loss: 0.1052 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9742 - val_loss: 0.1042 - val_auc: 0.9911 - val_accuracy: 0.9708\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9739 - val_loss: 0.1057 - val_auc: 0.9911 - val_accuracy: 0.9701\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0860 - auc: 0.9935 - accuracy: 0.9741 - val_loss: 0.1029 - val_auc: 0.9911 - val_accuracy: 0.9708\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9741 - val_loss: 0.1042 - val_auc: 0.9912 - val_accuracy: 0.9710\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9751 - val_loss: 0.1076 - val_auc: 0.9909 - val_accuracy: 0.9699\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0860 - auc: 0.9936 - accuracy: 0.9745 - val_loss: 0.1057 - val_auc: 0.9912 - val_accuracy: 0.9702\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9753 - val_loss: 0.1071 - val_auc: 0.9910 - val_accuracy: 0.9703\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9751 - val_loss: 0.1055 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "fold train/predict time: 0:02:39.365897\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 6s 5ms/step - loss: 0.4116 - auc: 0.8883 - accuracy: 0.8097 - val_loss: 0.3009 - val_auc: 0.9438 - val_accuracy: 0.8728\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2791 - auc: 0.9509 - accuracy: 0.8879 - val_loss: 0.2368 - val_auc: 0.9645 - val_accuracy: 0.9071\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2301 - auc: 0.9667 - accuracy: 0.9116 - val_loss: 0.2046 - val_auc: 0.9733 - val_accuracy: 0.9225\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2030 - auc: 0.9737 - accuracy: 0.9250 - val_loss: 0.1875 - val_auc: 0.9779 - val_accuracy: 0.9310\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1845 - auc: 0.9781 - accuracy: 0.9336 - val_loss: 0.1721 - val_auc: 0.9809 - val_accuracy: 0.9394\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1729 - auc: 0.9805 - accuracy: 0.9388 - val_loss: 0.1614 - val_auc: 0.9829 - val_accuracy: 0.9434\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1634 - auc: 0.9826 - accuracy: 0.9431 - val_loss: 0.1559 - val_auc: 0.9837 - val_accuracy: 0.9459\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1554 - auc: 0.9839 - accuracy: 0.9455 - val_loss: 0.1504 - val_auc: 0.9846 - val_accuracy: 0.9479\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1512 - auc: 0.9847 - accuracy: 0.9483 - val_loss: 0.1445 - val_auc: 0.9857 - val_accuracy: 0.9516\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1452 - auc: 0.9857 - accuracy: 0.9500 - val_loss: 0.1425 - val_auc: 0.9861 - val_accuracy: 0.9509\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1407 - auc: 0.9864 - accuracy: 0.9521 - val_loss: 0.1409 - val_auc: 0.9865 - val_accuracy: 0.9526\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1380 - auc: 0.9868 - accuracy: 0.9538 - val_loss: 0.1369 - val_auc: 0.9867 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9554 - val_loss: 0.1353 - val_auc: 0.9870 - val_accuracy: 0.9551\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9564 - val_loss: 0.1330 - val_auc: 0.9871 - val_accuracy: 0.9568\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1292 - auc: 0.9881 - accuracy: 0.9577 - val_loss: 0.1330 - val_auc: 0.9876 - val_accuracy: 0.9576\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1263 - auc: 0.9886 - accuracy: 0.9585 - val_loss: 0.1302 - val_auc: 0.9878 - val_accuracy: 0.9576\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1236 - auc: 0.9890 - accuracy: 0.9591 - val_loss: 0.1280 - val_auc: 0.9879 - val_accuracy: 0.9579\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1214 - auc: 0.9893 - accuracy: 0.9600 - val_loss: 0.1290 - val_auc: 0.9879 - val_accuracy: 0.9586\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1212 - auc: 0.9892 - accuracy: 0.9606 - val_loss: 0.1286 - val_auc: 0.9878 - val_accuracy: 0.9586\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1191 - auc: 0.9896 - accuracy: 0.9610 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1187 - auc: 0.9896 - accuracy: 0.9618 - val_loss: 0.1263 - val_auc: 0.9881 - val_accuracy: 0.9595\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1154 - auc: 0.9902 - accuracy: 0.9624 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9610\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1153 - auc: 0.9901 - accuracy: 0.9625 - val_loss: 0.1270 - val_auc: 0.9881 - val_accuracy: 0.9604\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1135 - auc: 0.9903 - accuracy: 0.9636 - val_loss: 0.1268 - val_auc: 0.9881 - val_accuracy: 0.9603\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1118 - auc: 0.9905 - accuracy: 0.9637 - val_loss: 0.1245 - val_auc: 0.9884 - val_accuracy: 0.9614\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1114 - auc: 0.9905 - accuracy: 0.9639 - val_loss: 0.1286 - val_auc: 0.9879 - val_accuracy: 0.9607\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1100 - auc: 0.9907 - accuracy: 0.9650 - val_loss: 0.1255 - val_auc: 0.9884 - val_accuracy: 0.9623\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1098 - auc: 0.9909 - accuracy: 0.9647 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9618\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1079 - auc: 0.9912 - accuracy: 0.9646 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9620\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9662 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9622\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9658 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9629\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9915 - accuracy: 0.9655 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9623\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9667 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9621\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1045 - auc: 0.9916 - accuracy: 0.9666 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9633\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1033 - auc: 0.9917 - accuracy: 0.9672 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9640\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9672 - val_loss: 0.1209 - val_auc: 0.9890 - val_accuracy: 0.9637\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1023 - auc: 0.9919 - accuracy: 0.9675 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9638\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1023 - auc: 0.9918 - accuracy: 0.9685 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9631\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1005 - auc: 0.9920 - accuracy: 0.9679 - val_loss: 0.1200 - val_auc: 0.9891 - val_accuracy: 0.9625\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9683 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9641\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0996 - auc: 0.9922 - accuracy: 0.9691 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9639\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9655\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9685 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9646\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9698 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9645\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9695 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9655\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0968 - auc: 0.9925 - accuracy: 0.9694 - val_loss: 0.1219 - val_auc: 0.9890 - val_accuracy: 0.9636\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0974 - auc: 0.9924 - accuracy: 0.9697 - val_loss: 0.1204 - val_auc: 0.9893 - val_accuracy: 0.9639\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9927 - accuracy: 0.9706 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9633\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0969 - auc: 0.9923 - accuracy: 0.9700 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9651\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0948 - auc: 0.9927 - accuracy: 0.9708 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9651\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9711 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9629\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0952 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1183 - val_auc: 0.9892 - val_accuracy: 0.9649\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0935 - auc: 0.9927 - accuracy: 0.9716 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9648\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0932 - auc: 0.9929 - accuracy: 0.9706 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9645\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0943 - auc: 0.9928 - accuracy: 0.9706 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9652\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9714 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9656\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0938 - auc: 0.9928 - accuracy: 0.9712 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9655\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0918 - auc: 0.9930 - accuracy: 0.9715 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9651\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9722 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9650\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9931 - accuracy: 0.9716 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9656\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:10.247254\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4123 - auc: 0.8885 - accuracy: 0.8103 - val_loss: 0.3041 - val_auc: 0.9417 - val_accuracy: 0.8740\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2811 - auc: 0.9503 - accuracy: 0.8870 - val_loss: 0.2455 - val_auc: 0.9624 - val_accuracy: 0.9008\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2355 - auc: 0.9651 - accuracy: 0.9091 - val_loss: 0.2069 - val_auc: 0.9729 - val_accuracy: 0.9221\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2053 - auc: 0.9733 - accuracy: 0.9233 - val_loss: 0.1820 - val_auc: 0.9789 - val_accuracy: 0.9337\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1864 - auc: 0.9777 - accuracy: 0.9315 - val_loss: 0.1670 - val_auc: 0.9819 - val_accuracy: 0.9414\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1732 - auc: 0.9806 - accuracy: 0.9392 - val_loss: 0.1567 - val_auc: 0.9841 - val_accuracy: 0.9460\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1617 - auc: 0.9829 - accuracy: 0.9443 - val_loss: 0.1511 - val_auc: 0.9848 - val_accuracy: 0.9473\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1545 - auc: 0.9840 - accuracy: 0.9471 - val_loss: 0.1430 - val_auc: 0.9866 - val_accuracy: 0.9516\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1460 - auc: 0.9856 - accuracy: 0.9510 - val_loss: 0.1366 - val_auc: 0.9872 - val_accuracy: 0.9539\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1399 - auc: 0.9866 - accuracy: 0.9528 - val_loss: 0.1342 - val_auc: 0.9875 - val_accuracy: 0.9553\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1366 - auc: 0.9870 - accuracy: 0.9556 - val_loss: 0.1288 - val_auc: 0.9883 - val_accuracy: 0.9582\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1308 - auc: 0.9879 - accuracy: 0.9569 - val_loss: 0.1276 - val_auc: 0.9886 - val_accuracy: 0.9589\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 0.1290 - auc: 0.9881 - accuracy: 0.9583 - val_loss: 0.1230 - val_auc: 0.9892 - val_accuracy: 0.9600\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1248 - auc: 0.9887 - accuracy: 0.9599 - val_loss: 0.1238 - val_auc: 0.9890 - val_accuracy: 0.9591\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1230 - auc: 0.9890 - accuracy: 0.9611 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9614\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9614 - val_loss: 0.1209 - val_auc: 0.9895 - val_accuracy: 0.9618\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1178 - auc: 0.9898 - accuracy: 0.9625 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9623\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1155 - auc: 0.9900 - accuracy: 0.9637 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9619\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1125 - auc: 0.9903 - accuracy: 0.9648 - val_loss: 0.1136 - val_auc: 0.9900 - val_accuracy: 0.9644\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1122 - auc: 0.9904 - accuracy: 0.9648 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9626\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1106 - auc: 0.9907 - accuracy: 0.9657 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9631\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1088 - auc: 0.9909 - accuracy: 0.9661 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9647\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1082 - auc: 0.9908 - accuracy: 0.9666 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9647\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1078 - auc: 0.9910 - accuracy: 0.9669 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9646\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9677 - val_loss: 0.1086 - val_auc: 0.9907 - val_accuracy: 0.9664\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1051 - auc: 0.9914 - accuracy: 0.9676 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9660\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9679 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9655\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1024 - auc: 0.9916 - accuracy: 0.9692 - val_loss: 0.1103 - val_auc: 0.9906 - val_accuracy: 0.9652\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1026 - auc: 0.9916 - accuracy: 0.9689 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9672\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1022 - auc: 0.9917 - accuracy: 0.9690 - val_loss: 0.1109 - val_auc: 0.9905 - val_accuracy: 0.9662\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9704 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9679\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0994 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1095 - val_auc: 0.9904 - val_accuracy: 0.9671\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0975 - auc: 0.9923 - accuracy: 0.9711 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9689\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9708 - val_loss: 0.1078 - val_auc: 0.9907 - val_accuracy: 0.9681\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0993 - auc: 0.9920 - accuracy: 0.9703 - val_loss: 0.1075 - val_auc: 0.9908 - val_accuracy: 0.9681\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9709 - val_loss: 0.1052 - val_auc: 0.9910 - val_accuracy: 0.9696\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0960 - auc: 0.9923 - accuracy: 0.9710 - val_loss: 0.1066 - val_auc: 0.9910 - val_accuracy: 0.9700\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9721 - val_loss: 0.1059 - val_auc: 0.9909 - val_accuracy: 0.9685\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9925 - accuracy: 0.9722 - val_loss: 0.1058 - val_auc: 0.9910 - val_accuracy: 0.9686\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0950 - auc: 0.9924 - accuracy: 0.9719 - val_loss: 0.1050 - val_auc: 0.9909 - val_accuracy: 0.9696\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9729 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9688\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9727 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9685\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0938 - auc: 0.9926 - accuracy: 0.9727 - val_loss: 0.1057 - val_auc: 0.9909 - val_accuracy: 0.9691\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1067 - val_auc: 0.9909 - val_accuracy: 0.9698\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9732 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9688\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9737 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9697\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9738 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9688\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0904 - auc: 0.9930 - accuracy: 0.9739 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9687\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9690\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9693\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "fold train/predict time: 0:02:35.521755\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 5s 4ms/step - loss: 0.4119 - auc: 0.8883 - accuracy: 0.8096 - val_loss: 0.2943 - val_auc: 0.9453 - val_accuracy: 0.8757\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2793 - auc: 0.9508 - accuracy: 0.8866 - val_loss: 0.2438 - val_auc: 0.9637 - val_accuracy: 0.9015\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2348 - auc: 0.9652 - accuracy: 0.9089 - val_loss: 0.2119 - val_auc: 0.9717 - val_accuracy: 0.9183\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2091 - auc: 0.9722 - accuracy: 0.9208 - val_loss: 0.1906 - val_auc: 0.9769 - val_accuracy: 0.9281\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1900 - auc: 0.9768 - accuracy: 0.9296 - val_loss: 0.1778 - val_auc: 0.9798 - val_accuracy: 0.9343\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1771 - auc: 0.9798 - accuracy: 0.9358 - val_loss: 0.1677 - val_auc: 0.9817 - val_accuracy: 0.9385\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1686 - auc: 0.9814 - accuracy: 0.9399 - val_loss: 0.1624 - val_auc: 0.9827 - val_accuracy: 0.9420\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.1619 - auc: 0.9827 - accuracy: 0.9430 - val_loss: 0.1573 - val_auc: 0.9836 - val_accuracy: 0.9438\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1568 - auc: 0.9837 - accuracy: 0.9445 - val_loss: 0.1526 - val_auc: 0.9846 - val_accuracy: 0.9472\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1512 - auc: 0.9848 - accuracy: 0.9474 - val_loss: 0.1510 - val_auc: 0.9846 - val_accuracy: 0.9476\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9499 - val_loss: 0.1446 - val_auc: 0.9859 - val_accuracy: 0.9503\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1424 - auc: 0.9862 - accuracy: 0.9513 - val_loss: 0.1421 - val_auc: 0.9861 - val_accuracy: 0.9513\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1393 - auc: 0.9867 - accuracy: 0.9519 - val_loss: 0.1401 - val_auc: 0.9866 - val_accuracy: 0.9526\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9542 - val_loss: 0.1357 - val_auc: 0.9872 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1321 - auc: 0.9879 - accuracy: 0.9557 - val_loss: 0.1344 - val_auc: 0.9875 - val_accuracy: 0.9550\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1308 - auc: 0.9881 - accuracy: 0.9561 - val_loss: 0.1300 - val_auc: 0.9880 - val_accuracy: 0.9583\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1279 - auc: 0.9884 - accuracy: 0.9572 - val_loss: 0.1291 - val_auc: 0.9881 - val_accuracy: 0.9578\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1255 - auc: 0.9889 - accuracy: 0.9586 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9593\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1235 - auc: 0.9890 - accuracy: 0.9597 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9600\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9602 - val_loss: 0.1232 - val_auc: 0.9889 - val_accuracy: 0.9607\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1204 - auc: 0.9895 - accuracy: 0.9607 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9621\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1162 - auc: 0.9901 - accuracy: 0.9625 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9620\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9626 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1132 - auc: 0.9904 - accuracy: 0.9639 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9627\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1133 - auc: 0.9904 - accuracy: 0.9639 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9646 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9643\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9650 - val_loss: 0.1187 - val_auc: 0.9892 - val_accuracy: 0.9639\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1078 - auc: 0.9912 - accuracy: 0.9654 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9635\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1068 - auc: 0.9913 - accuracy: 0.9658 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9646\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1061 - auc: 0.9913 - accuracy: 0.9667 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9643\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9661 - val_loss: 0.1169 - val_auc: 0.9897 - val_accuracy: 0.9648\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9665 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1037 - auc: 0.9916 - accuracy: 0.9676 - val_loss: 0.1166 - val_auc: 0.9896 - val_accuracy: 0.9641\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9681 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9650\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1008 - auc: 0.9921 - accuracy: 0.9682 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9658\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9683 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9652\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1008 - auc: 0.9919 - accuracy: 0.9683 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9650\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9688 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9676\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9689 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9663\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0993 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9651\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9698 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9659\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1177 - val_auc: 0.9892 - val_accuracy: 0.9652\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9688 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9663\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9704 - val_loss: 0.1151 - val_auc: 0.9897 - val_accuracy: 0.9659\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0958 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1155 - val_auc: 0.9899 - val_accuracy: 0.9667\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9665\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9927 - accuracy: 0.9707 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9668\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0957 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9665\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.338100\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4209 - auc: 0.8829 - accuracy: 0.8053 - val_loss: 0.2985 - val_auc: 0.9438 - val_accuracy: 0.8741\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2825 - auc: 0.9494 - accuracy: 0.8863 - val_loss: 0.2437 - val_auc: 0.9629 - val_accuracy: 0.9048\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2371 - auc: 0.9644 - accuracy: 0.9094 - val_loss: 0.2118 - val_auc: 0.9720 - val_accuracy: 0.9195\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2090 - auc: 0.9721 - accuracy: 0.9213 - val_loss: 0.1912 - val_auc: 0.9767 - val_accuracy: 0.9290\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1912 - auc: 0.9764 - accuracy: 0.9299 - val_loss: 0.1774 - val_auc: 0.9796 - val_accuracy: 0.9352\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1786 - auc: 0.9792 - accuracy: 0.9351 - val_loss: 0.1712 - val_auc: 0.9810 - val_accuracy: 0.9394\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1690 - auc: 0.9812 - accuracy: 0.9396 - val_loss: 0.1658 - val_auc: 0.9820 - val_accuracy: 0.9409\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1616 - auc: 0.9826 - accuracy: 0.9427 - val_loss: 0.1561 - val_auc: 0.9836 - val_accuracy: 0.9463\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1545 - auc: 0.9841 - accuracy: 0.9457 - val_loss: 0.1524 - val_auc: 0.9846 - val_accuracy: 0.9473\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1492 - auc: 0.9850 - accuracy: 0.9483 - val_loss: 0.1473 - val_auc: 0.9854 - val_accuracy: 0.9512\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1429 - auc: 0.9860 - accuracy: 0.9511 - val_loss: 0.1442 - val_auc: 0.9859 - val_accuracy: 0.9520\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1388 - auc: 0.9868 - accuracy: 0.9524 - val_loss: 0.1409 - val_auc: 0.9866 - val_accuracy: 0.9527\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1353 - auc: 0.9874 - accuracy: 0.9543 - val_loss: 0.1378 - val_auc: 0.9870 - val_accuracy: 0.9547\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9573 - val_loss: 0.1364 - val_auc: 0.9875 - val_accuracy: 0.9558\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1270 - auc: 0.9886 - accuracy: 0.9575 - val_loss: 0.1362 - val_auc: 0.9874 - val_accuracy: 0.9543\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1248 - auc: 0.9888 - accuracy: 0.9589 - val_loss: 0.1299 - val_auc: 0.9883 - val_accuracy: 0.9574\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1226 - auc: 0.9892 - accuracy: 0.9599 - val_loss: 0.1287 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1201 - auc: 0.9896 - accuracy: 0.9608 - val_loss: 0.1279 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9617 - val_loss: 0.1286 - val_auc: 0.9885 - val_accuracy: 0.9588\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1164 - auc: 0.9900 - accuracy: 0.9625 - val_loss: 0.1326 - val_auc: 0.9882 - val_accuracy: 0.9591\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1141 - auc: 0.9903 - accuracy: 0.9635 - val_loss: 0.1233 - val_auc: 0.9891 - val_accuracy: 0.9611\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1123 - auc: 0.9905 - accuracy: 0.9640 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1112 - auc: 0.9908 - accuracy: 0.9644 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9622\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1113 - auc: 0.9905 - accuracy: 0.9645 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9617\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1076 - auc: 0.9911 - accuracy: 0.9656 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9626\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9661 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9634\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.1060 - auc: 0.9913 - accuracy: 0.9654 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9640\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1052 - auc: 0.9915 - accuracy: 0.9665 - val_loss: 0.1187 - val_auc: 0.9895 - val_accuracy: 0.9638\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1028 - auc: 0.9918 - accuracy: 0.9669 - val_loss: 0.1192 - val_auc: 0.9896 - val_accuracy: 0.9642\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1019 - auc: 0.9919 - accuracy: 0.9677 - val_loss: 0.1226 - val_auc: 0.9891 - val_accuracy: 0.9629\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9680 - val_loss: 0.1188 - val_auc: 0.9896 - val_accuracy: 0.9650\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9690 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9664\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9686 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9652\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9700 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9650\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9924 - accuracy: 0.9692 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9663\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0965 - auc: 0.9926 - accuracy: 0.9699 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9645\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9697 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9669\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0963 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1171 - val_auc: 0.9897 - val_accuracy: 0.9661\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0948 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9656\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0946 - auc: 0.9927 - accuracy: 0.9708 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9658\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9707 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9670\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9706 - val_loss: 0.1169 - val_auc: 0.9899 - val_accuracy: 0.9677\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0935 - auc: 0.9929 - accuracy: 0.9710 - val_loss: 0.1172 - val_auc: 0.9900 - val_accuracy: 0.9670\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0928 - auc: 0.9930 - accuracy: 0.9718 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9657\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0913 - auc: 0.9931 - accuracy: 0.9720 - val_loss: 0.1174 - val_auc: 0.9898 - val_accuracy: 0.9668\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9716 - val_loss: 0.1218 - val_auc: 0.9892 - val_accuracy: 0.9661\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9719 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9675\n",
            "1000/1000 [==============================] - 2s 1ms/step\n",
            "fold train/predict time: 0:02:38.105049\n",
            "total train/predict time: 0:13:40.049858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost(preds_m4,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkQAh6OMjjJp",
        "outputId": "3093b3a9-1d74-473c-ff55-6e1e1d8b05c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "679150"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "bffccd04-49d0-44e0-afac-0d1c25f463aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(preds_m4-y).value_counts()"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "397b6208-91a5-4876-82ba-0a45b43fa562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    152999\n",
              "-1.0      3795\n",
              " 1.0      3206\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crFxa8d68wBQ",
        "outputId": "f5499640-776b-4430-d734-4d2866c6ba56"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.25         10      3       1    1.0\n",
              "1             0.25          3      0       1    0.1\n",
              "2             0.10          3      3       1    0.1\n",
              "3             0.35         10      3       1    0.0\n",
              "4             0.25          3      1       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.25         10      0       1    0.0\n",
              "320           0.25         20      0       1    1.0\n",
              "321           0.10         10      1       2    0.0\n",
              "322           0.25         10      1       3    0.0\n",
              "323           0.25         20      1       1    0.1\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3fc1fb84-2166-4548-a357-c0b744ab3a96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fc1fb84-2166-4548-a357-c0b744ab3a96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4f41c428-470d-4298-b387-ffaa6a7fff13\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f41c428-470d-4298-b387-ffaa6a7fff13')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4f41c428-470d-4298-b387-ffaa6a7fff13 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fc1fb84-2166-4548-a357-c0b744ab3a96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fc1fb84-2166-4548-a357-c0b744ab3a96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference https://xgboost.readthedocs.io/en/stable/tutorials/custom_metric_obj.html\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def cost_obj(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
        "    ''' Root mean squared log error metric.'''\n",
        "    y = dtrain.get_label()\n",
        "\n",
        "    #adjust to reflect customized loss based on project\n",
        "    elements = cost(predt, y)\n",
        "    return 'cost_obj', float(np.sum(elements))"
      ],
      "metadata": {
        "id": "4phrKLGB5kGW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
        "\n",
        "trials = 20\n",
        "best_params = {}\n",
        "i=0\n",
        "\n",
        "for i in range(trials):\n",
        "  #random sampling from paramdf\n",
        "  hyperparams = {'objective': 'binary:hinge',\n",
        "                 'eta': xgb_param['learning_rate'][i],\n",
        "                 'max_depth': xgb_param['max_depth'][i],\n",
        "                 'gamma': xgb_param['gamma'][i],\n",
        "                 'lambda': xgb_param['lambda'][i],\n",
        "                 'alpha': xgb_param['alpha'][i]\n",
        "                 }\n",
        "\n",
        "  print(hyperparams)\n",
        "  out=xgb.cv(params=hyperparams,\n",
        "             num_boost_round=50,\n",
        "             dtrain=dtrain,\n",
        "             nfold=10,\n",
        "             stratified=True,\n",
        "             early_stopping_rounds=5,\n",
        "             verbose_eval=1,\n",
        "             custom_metric= cost_obj\n",
        "             )\n",
        "\n",
        "  index=out.shape[0]-1\n",
        "  result=out.iloc[index,2]\n",
        "  if i< 1:\n",
        "    best_result = result\n",
        "    best_params = hyperparams\n",
        "\n",
        "  if result< best_result:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "      print('result: ' ,result)\n",
        "      print('best result: ' ,best_result)\n",
        "      print('hyperparameters: ' ,hyperparams)\n",
        "      print('best hyperparameters: ' ,best_params)\n",
        "      i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "200d2549-b5a6-4ef2-9423-65b64d514894"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.20036+0.01317\ttrain-cost_obj:3096000.00000+171947.51816\ttest-error:0.21478+0.01163\ttest-cost_obj:372665.00000+15894.88990\n",
            "[3]\ttrain-error:0.14273+0.00238\ttrain-cost_obj:2272685.00000+30614.65376\ttest-error:0.16229+0.00340\ttest-cost_obj:290990.00000+5855.16012\n",
            "[4]\ttrain-error:0.12042+0.00147\ttrain-cost_obj:1971745.00000+21817.86481\ttest-error:0.14119+0.00346\ttest-cost_obj:260185.00000+6307.10116\n",
            "[5]\ttrain-error:0.10637+0.00104\ttrain-cost_obj:1781970.00000+17552.32463\ttest-error:0.12851+0.00245\ttest-cost_obj:242005.00000+5121.54518\n",
            "[6]\ttrain-error:0.09730+0.00109\ttrain-cost_obj:1665175.00000+18289.20788\ttest-error:0.12046+0.00252\ttest-cost_obj:231450.00000+4873.70496\n",
            "[7]\ttrain-error:0.08840+0.00115\ttrain-cost_obj:1538115.00000+19199.16730\ttest-error:0.11148+0.00297\ttest-cost_obj:217415.00000+5812.10160\n",
            "[8]\ttrain-error:0.08271+0.00144\ttrain-cost_obj:1460395.00000+24929.06386\ttest-error:0.10624+0.00326\ttest-cost_obj:209910.00000+6350.03150\n",
            "[9]\ttrain-error:0.07850+0.00141\ttrain-cost_obj:1399915.00000+23461.93779\ttest-error:0.10171+0.00350\ttest-cost_obj:202905.00000+6808.98120\n",
            "[10]\ttrain-error:0.07429+0.00144\ttrain-cost_obj:1334665.00000+26636.12256\ttest-error:0.09792+0.00299\ttest-cost_obj:196805.00000+5908.86833\n",
            "[11]\ttrain-error:0.07025+0.00081\ttrain-cost_obj:1268120.00000+16086.41041\ttest-error:0.09398+0.00278\ttest-cost_obj:189710.00000+5558.00324\n",
            "[12]\ttrain-error:0.06653+0.00104\ttrain-cost_obj:1205280.00000+20962.07528\ttest-error:0.09111+0.00292\ttest-cost_obj:184515.00000+5638.57473\n",
            "[13]\ttrain-error:0.06354+0.00218\ttrain-cost_obj:1154320.00000+41330.35325\ttest-error:0.08829+0.00270\ttest-cost_obj:179170.00000+5232.21750\n",
            "[14]\ttrain-error:0.06049+0.00250\ttrain-cost_obj:1101830.00000+46470.29804\ttest-error:0.08592+0.00287\ttest-cost_obj:174665.00000+5776.93907\n",
            "[15]\ttrain-error:0.05750+0.00274\ttrain-cost_obj:1048990.00000+50765.80936\ttest-error:0.08409+0.00311\ttest-cost_obj:171220.00000+6204.32107\n",
            "[16]\ttrain-error:0.05526+0.00275\ttrain-cost_obj:1009825.00000+50696.65793\ttest-error:0.08242+0.00311\ttest-cost_obj:168015.00000+6203.18668\n",
            "[17]\ttrain-error:0.05329+0.00294\ttrain-cost_obj:974935.00000+53656.81713\ttest-error:0.08148+0.00285\ttest-cost_obj:166285.00000+5746.21832\n",
            "[18]\ttrain-error:0.05113+0.00282\ttrain-cost_obj:936690.00000+51883.06949\ttest-error:0.07984+0.00279\ttest-cost_obj:163025.00000+5681.64809\n",
            "[19]\ttrain-error:0.04948+0.00269\ttrain-cost_obj:906905.00000+49859.56002\ttest-error:0.07885+0.00274\ttest-cost_obj:160915.00000+5792.36782\n",
            "[20]\ttrain-error:0.04810+0.00255\ttrain-cost_obj:881925.00000+47167.37882\ttest-error:0.07807+0.00279\ttest-cost_obj:159400.00000+5850.55553\n",
            "[21]\ttrain-error:0.04689+0.00266\ttrain-cost_obj:860415.00000+49539.13630\ttest-error:0.07734+0.00331\ttest-cost_obj:157975.00000+6884.62962\n",
            "[22]\ttrain-error:0.04548+0.00285\ttrain-cost_obj:834545.00000+52677.83429\ttest-error:0.07642+0.00341\ttest-cost_obj:156160.00000+7084.48304\n",
            "[23]\ttrain-error:0.04409+0.00286\ttrain-cost_obj:809175.00000+53332.89440\ttest-error:0.07556+0.00293\ttest-cost_obj:154480.00000+6210.00000\n",
            "[24]\ttrain-error:0.04278+0.00262\ttrain-cost_obj:785210.00000+48988.26798\ttest-error:0.07495+0.00293\ttest-cost_obj:153315.00000+6292.45779\n",
            "[25]\ttrain-error:0.04164+0.00261\ttrain-cost_obj:765070.00000+48927.34001\ttest-error:0.07457+0.00276\ttest-cost_obj:152530.00000+5852.61480\n",
            "[26]\ttrain-error:0.04053+0.00284\ttrain-cost_obj:744860.00000+52973.38860\ttest-error:0.07376+0.00328\ttest-cost_obj:150895.00000+6744.79244\n",
            "[27]\ttrain-error:0.03958+0.00295\ttrain-cost_obj:727570.00000+55310.23504\ttest-error:0.07331+0.00324\ttest-cost_obj:149940.00000+6762.20378\n",
            "[28]\ttrain-error:0.03851+0.00283\ttrain-cost_obj:708235.00000+52802.32026\ttest-error:0.07350+0.00314\ttest-cost_obj:150390.00000+6463.54392\n",
            "[29]\ttrain-error:0.03745+0.00264\ttrain-cost_obj:688850.00000+49173.15833\ttest-error:0.07328+0.00314\ttest-cost_obj:149970.00000+6534.22528\n",
            "[30]\ttrain-error:0.03668+0.00289\ttrain-cost_obj:674895.00000+53440.51108\ttest-error:0.07319+0.00316\ttest-cost_obj:149665.00000+6469.81646\n",
            "[31]\ttrain-error:0.03600+0.00319\ttrain-cost_obj:662435.00000+59004.18650\ttest-error:0.07302+0.00317\ttest-cost_obj:149320.00000+6536.74996\n",
            "[32]\ttrain-error:0.03520+0.00326\ttrain-cost_obj:648090.00000+60457.26507\ttest-error:0.07294+0.00340\ttest-cost_obj:149185.00000+6987.13282\n",
            "[33]\ttrain-error:0.03450+0.00335\ttrain-cost_obj:635500.00000+62230.08517\ttest-error:0.07289+0.00346\ttest-cost_obj:149060.00000+7064.76468\n",
            "[34]\ttrain-error:0.03391+0.00346\ttrain-cost_obj:624485.00000+64538.20206\ttest-error:0.07282+0.00354\ttest-cost_obj:148920.00000+7279.42992\n",
            "[35]\ttrain-error:0.03311+0.00332\ttrain-cost_obj:609960.00000+61876.00019\ttest-error:0.07271+0.00294\ttest-cost_obj:148700.00000+5920.89520\n",
            "[36]\ttrain-error:0.03251+0.00334\ttrain-cost_obj:599090.00000+62064.64694\ttest-error:0.07236+0.00276\ttest-cost_obj:147975.00000+5551.72271\n",
            "[37]\ttrain-error:0.03188+0.00331\ttrain-cost_obj:587455.00000+61316.52489\ttest-error:0.07229+0.00276\ttest-cost_obj:147910.00000+5592.39662\n",
            "[38]\ttrain-error:0.03112+0.00326\ttrain-cost_obj:573630.00000+60235.97430\ttest-error:0.07190+0.00280\ttest-cost_obj:147280.00000+5775.21428\n",
            "[39]\ttrain-error:0.03024+0.00329\ttrain-cost_obj:557400.00000+60929.46742\ttest-error:0.07182+0.00292\ttest-cost_obj:146980.00000+5953.11683\n",
            "[40]\ttrain-error:0.02958+0.00329\ttrain-cost_obj:545395.00000+61252.90381\ttest-error:0.07198+0.00305\ttest-cost_obj:147275.00000+6301.04158\n",
            "[41]\ttrain-error:0.02876+0.00307\ttrain-cost_obj:530105.00000+56986.37315\ttest-error:0.07171+0.00317\ttest-cost_obj:146745.00000+6479.87075\n",
            "[42]\ttrain-error:0.02831+0.00293\ttrain-cost_obj:521960.00000+54264.88183\ttest-error:0.07174+0.00311\ttest-cost_obj:146795.00000+6389.18813\n",
            "[43]\ttrain-error:0.02779+0.00283\ttrain-cost_obj:512470.00000+52524.06210\ttest-error:0.07162+0.00307\ttest-cost_obj:146560.00000+6247.47149\n",
            "[44]\ttrain-error:0.02720+0.00274\ttrain-cost_obj:501595.00000+50997.57078\ttest-error:0.07150+0.00299\ttest-cost_obj:146215.00000+6076.92562\n",
            "[45]\ttrain-error:0.02687+0.00275\ttrain-cost_obj:495515.00000+51306.74931\ttest-error:0.07157+0.00308\ttest-cost_obj:146445.00000+6237.24498\n",
            "[46]\ttrain-error:0.02652+0.00270\ttrain-cost_obj:489170.00000+50487.28157\ttest-error:0.07174+0.00322\ttest-cost_obj:146790.00000+6480.23148\n",
            "[47]\ttrain-error:0.02606+0.00271\ttrain-cost_obj:480710.00000+50461.08798\ttest-error:0.07156+0.00315\ttest-cost_obj:146385.00000+6335.10260\n",
            "[48]\ttrain-error:0.02566+0.00272\ttrain-cost_obj:473350.00000+50808.26212\ttest-error:0.07141+0.00310\ttest-cost_obj:145955.00000+6215.68379\n",
            "[49]\ttrain-error:0.02530+0.00271\ttrain-cost_obj:466790.00000+50649.46594\ttest-error:0.07148+0.00308\ttest-cost_obj:146115.00000+6160.60265\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.49014+0.03626\ttrain-cost_obj:7241545.00000+460779.85657\ttest-error:0.49144+0.03583\ttest-cost_obj:807020.00000+50422.20344\n",
            "[3]\ttrain-error:0.40456+0.00332\ttrain-cost_obj:6184745.00000+27895.01255\ttest-error:0.40591+0.00437\ttest-cost_obj:689825.00000+6435.96341\n",
            "[4]\ttrain-error:0.33269+0.00158\ttrain-cost_obj:5293910.00000+19132.41752\ttest-error:0.33474+0.00243\ttest-cost_obj:592175.00000+5514.35626\n",
            "[5]\ttrain-error:0.32238+0.00293\ttrain-cost_obj:5200125.00000+26973.44296\ttest-error:0.32408+0.00306\ttest-cost_obj:581130.00000+5459.40473\n",
            "[6]\ttrain-error:0.31455+0.01218\ttrain-cost_obj:5133660.00000+98194.59965\ttest-error:0.31637+0.01209\ttest-cost_obj:573960.00000+11459.27136\n",
            "[7]\ttrain-error:0.27834+0.00128\ttrain-cost_obj:4860745.00000+31586.92332\ttest-error:0.28008+0.00161\ttest-cost_obj:543690.00000+5454.80522\n",
            "[8]\ttrain-error:0.27563+0.00191\ttrain-cost_obj:4840935.00000+29739.15811\ttest-error:0.27724+0.00221\ttest-cost_obj:541215.00000+5709.81830\n",
            "[9]\ttrain-error:0.27481+0.00163\ttrain-cost_obj:4841525.00000+35483.94179\ttest-error:0.27654+0.00258\ttest-cost_obj:541445.00000+6513.27299\n",
            "[10]\ttrain-error:0.27085+0.00332\ttrain-cost_obj:4790805.00000+54375.88827\ttest-error:0.27308+0.00405\ttest-cost_obj:536700.00000+7620.49867\n",
            "[11]\ttrain-error:0.26608+0.00372\ttrain-cost_obj:4725000.00000+67262.47096\ttest-error:0.26753+0.00425\ttest-cost_obj:528065.00000+8390.68084\n",
            "[12]\ttrain-error:0.26044+0.00519\ttrain-cost_obj:4637215.00000+90750.53457\ttest-error:0.26249+0.00557\ttest-cost_obj:519330.00000+10978.25578\n",
            "[13]\ttrain-error:0.25467+0.00493\ttrain-cost_obj:4551375.00000+90573.29698\ttest-error:0.25648+0.00615\ttest-cost_obj:509285.00000+12146.79073\n",
            "[14]\ttrain-error:0.25200+0.00499\ttrain-cost_obj:4513510.00000+85547.73463\ttest-error:0.25413+0.00567\ttest-cost_obj:505795.00000+10772.42893\n",
            "[15]\ttrain-error:0.24777+0.00505\ttrain-cost_obj:4446865.00000+89261.10309\ttest-error:0.25041+0.00498\ttest-cost_obj:499455.00000+9785.38323\n",
            "[16]\ttrain-error:0.24391+0.00425\ttrain-cost_obj:4388270.00000+75750.75313\ttest-error:0.24624+0.00409\ttest-cost_obj:492225.00000+8044.35361\n",
            "[17]\ttrain-error:0.24180+0.00421\ttrain-cost_obj:4355390.00000+76098.39946\ttest-error:0.24415+0.00415\ttest-cost_obj:488520.00000+8406.64023\n",
            "[18]\ttrain-error:0.23832+0.00426\ttrain-cost_obj:4294000.00000+76454.72843\ttest-error:0.24076+0.00420\ttest-cost_obj:482090.00000+8766.63561\n",
            "[19]\ttrain-error:0.23518+0.00462\ttrain-cost_obj:4241675.00000+78965.24631\ttest-error:0.23774+0.00439\ttest-cost_obj:476550.00000+8598.63361\n",
            "[20]\ttrain-error:0.23195+0.00453\ttrain-cost_obj:4190180.00000+78159.16837\ttest-error:0.23461+0.00471\ttest-cost_obj:470980.00000+9279.66055\n",
            "[21]\ttrain-error:0.22835+0.00492\ttrain-cost_obj:4129405.00000+88513.40139\ttest-error:0.23116+0.00467\ttest-cost_obj:464425.00000+9104.20919\n",
            "[22]\ttrain-error:0.22514+0.00511\ttrain-cost_obj:4073720.00000+88483.40861\ttest-error:0.22809+0.00495\ttest-cost_obj:458590.00000+9559.25729\n",
            "[23]\ttrain-error:0.22189+0.00468\ttrain-cost_obj:4018610.00000+81935.87371\ttest-error:0.22503+0.00492\ttest-cost_obj:453020.00000+9653.68323\n",
            "[24]\ttrain-error:0.21881+0.00390\ttrain-cost_obj:3966760.00000+70653.09547\ttest-error:0.22154+0.00445\ttest-cost_obj:446385.00000+9123.98076\n",
            "[25]\ttrain-error:0.21612+0.00377\ttrain-cost_obj:3920430.00000+66732.78879\ttest-error:0.21870+0.00461\ttest-cost_obj:441010.00000+9184.38349\n",
            "[26]\ttrain-error:0.21350+0.00400\ttrain-cost_obj:3875320.00000+71717.50553\ttest-error:0.21647+0.00443\ttest-cost_obj:436850.00000+8775.47720\n",
            "[27]\ttrain-error:0.21138+0.00398\ttrain-cost_obj:3838865.00000+72224.48010\ttest-error:0.21451+0.00461\ttest-cost_obj:433080.00000+9357.51570\n",
            "[28]\ttrain-error:0.20901+0.00415\ttrain-cost_obj:3797715.00000+75719.38012\ttest-error:0.21274+0.00520\ttest-cost_obj:429710.00000+10543.54779\n",
            "[29]\ttrain-error:0.20748+0.00391\ttrain-cost_obj:3770540.00000+71658.91710\ttest-error:0.21133+0.00514\ttest-cost_obj:426965.00000+10363.15710\n",
            "[30]\ttrain-error:0.20544+0.00400\ttrain-cost_obj:3735980.00000+74190.51220\ttest-error:0.20882+0.00507\ttest-cost_obj:422210.00000+10245.09151\n",
            "[31]\ttrain-error:0.20271+0.00325\ttrain-cost_obj:3688375.00000+61124.93865\ttest-error:0.20592+0.00416\ttest-cost_obj:416570.00000+8489.38160\n",
            "[32]\ttrain-error:0.20083+0.00338\ttrain-cost_obj:3656500.00000+64645.74619\ttest-error:0.20423+0.00399\ttest-cost_obj:413280.00000+8096.64128\n",
            "[33]\ttrain-error:0.19900+0.00324\ttrain-cost_obj:3624565.00000+62895.58430\ttest-error:0.20254+0.00418\ttest-cost_obj:409995.00000+8540.12441\n",
            "[34]\ttrain-error:0.19688+0.00305\ttrain-cost_obj:3587325.00000+58186.05610\ttest-error:0.20033+0.00433\ttest-cost_obj:405600.00000+8619.33872\n",
            "[35]\ttrain-error:0.19501+0.00296\ttrain-cost_obj:3555515.00000+56709.54086\ttest-error:0.19853+0.00392\ttest-cost_obj:402290.00000+7928.07669\n",
            "[36]\ttrain-error:0.19348+0.00295\ttrain-cost_obj:3530350.00000+56095.03543\ttest-error:0.19709+0.00380\ttest-cost_obj:399690.00000+7735.69001\n",
            "[37]\ttrain-error:0.19169+0.00263\ttrain-cost_obj:3499415.00000+50783.24551\ttest-error:0.19529+0.00374\ttest-cost_obj:396175.00000+7735.05818\n",
            "[38]\ttrain-error:0.19018+0.00244\ttrain-cost_obj:3473185.00000+48640.07633\ttest-error:0.19375+0.00421\ttest-cost_obj:393250.00000+8942.37105\n",
            "[39]\ttrain-error:0.18893+0.00234\ttrain-cost_obj:3451795.00000+47122.33786\ttest-error:0.19262+0.00423\ttest-cost_obj:391150.00000+9007.99645\n",
            "[40]\ttrain-error:0.18725+0.00216\ttrain-cost_obj:3423355.00000+45219.25171\ttest-error:0.19103+0.00449\ttest-cost_obj:387965.00000+9490.41754\n",
            "[41]\ttrain-error:0.18589+0.00245\ttrain-cost_obj:3399965.00000+50476.94053\ttest-error:0.18964+0.00476\ttest-cost_obj:385335.00000+10130.12956\n",
            "[42]\ttrain-error:0.18433+0.00244\ttrain-cost_obj:3372730.00000+48362.99308\ttest-error:0.18816+0.00477\ttest-cost_obj:382520.00000+10034.81938\n",
            "[43]\ttrain-error:0.18324+0.00253\ttrain-cost_obj:3353530.00000+50074.35571\ttest-error:0.18704+0.00505\ttest-cost_obj:380330.00000+10534.94661\n",
            "[44]\ttrain-error:0.18195+0.00234\ttrain-cost_obj:3330370.00000+46150.90573\ttest-error:0.18586+0.00490\ttest-cost_obj:378125.00000+10159.97662\n",
            "[45]\ttrain-error:0.18053+0.00216\ttrain-cost_obj:3305400.00000+43755.13684\ttest-error:0.18438+0.00509\ttest-cost_obj:375210.00000+10577.49498\n",
            "[46]\ttrain-error:0.17947+0.00224\ttrain-cost_obj:3286805.00000+45484.02164\ttest-error:0.18303+0.00504\ttest-cost_obj:372580.00000+10562.20148\n",
            "[47]\ttrain-error:0.17822+0.00247\ttrain-cost_obj:3264615.00000+48996.16847\ttest-error:0.18194+0.00517\ttest-cost_obj:370475.00000+10625.37646\n",
            "[48]\ttrain-error:0.17688+0.00200\ttrain-cost_obj:3241465.00000+39883.46807\ttest-error:0.18038+0.00524\ttest-cost_obj:367560.00000+10595.39523\n",
            "[49]\ttrain-error:0.17538+0.00170\ttrain-cost_obj:3214725.00000+34275.49598\ttest-error:0.17917+0.00511\ttest-cost_obj:365080.00000+10412.23319\n",
            "{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[3]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[4]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.21779+0.01099\ttrain-cost_obj:3315485.00000+144261.25615\ttest-error:0.23234+0.01000\ttest-cost_obj:397230.00000+14661.04021\n",
            "[2]\ttrain-error:0.13271+0.00200\ttrain-cost_obj:2107335.00000+29639.29866\ttest-error:0.15652+0.00244\ttest-cost_obj:280340.00000+5017.40969\n",
            "[3]\ttrain-error:0.10821+0.00207\ttrain-cost_obj:1786825.00000+34562.40190\ttest-error:0.13217+0.00212\ttest-cost_obj:245555.00000+5016.69463\n",
            "[4]\ttrain-error:0.09453+0.00201\ttrain-cost_obj:1608740.00000+32848.79602\ttest-error:0.11932+0.00258\ttest-cost_obj:228265.00000+6039.04173\n",
            "[5]\ttrain-error:0.08393+0.00211\ttrain-cost_obj:1464415.00000+38067.91333\ttest-error:0.10823+0.00315\ttest-cost_obj:211960.00000+6979.21199\n",
            "[6]\ttrain-error:0.07690+0.00242\ttrain-cost_obj:1364195.00000+45247.89194\ttest-error:0.10131+0.00302\ttest-cost_obj:201500.00000+6550.22900\n",
            "[7]\ttrain-error:0.07257+0.00221\ttrain-cost_obj:1300650.00000+41255.56932\ttest-error:0.09726+0.00244\ttest-cost_obj:195245.00000+5533.64482\n",
            "[8]\ttrain-error:0.06862+0.00212\ttrain-cost_obj:1237540.00000+38451.66316\ttest-error:0.09336+0.00356\ttest-cost_obj:188515.00000+7338.22356\n",
            "[9]\ttrain-error:0.06370+0.00186\ttrain-cost_obj:1153490.00000+32523.12101\ttest-error:0.08929+0.00313\ttest-cost_obj:180820.00000+6443.06604\n",
            "[10]\ttrain-error:0.05952+0.00276\ttrain-cost_obj:1080790.00000+50193.13100\ttest-error:0.08628+0.00359\ttest-cost_obj:175180.00000+7391.89421\n",
            "[11]\ttrain-error:0.05594+0.00275\ttrain-cost_obj:1017825.00000+48915.98026\ttest-error:0.08378+0.00304\ttest-cost_obj:170260.00000+6158.03540\n",
            "[12]\ttrain-error:0.05369+0.00261\ttrain-cost_obj:978535.00000+46149.95152\ttest-error:0.08215+0.00269\ttest-cost_obj:167110.00000+5295.12984\n",
            "[13]\ttrain-error:0.05140+0.00283\ttrain-cost_obj:938235.00000+50179.01479\ttest-error:0.08052+0.00276\ttest-cost_obj:163795.00000+5569.44566\n",
            "[14]\ttrain-error:0.04936+0.00273\ttrain-cost_obj:901980.00000+48591.56408\ttest-error:0.07955+0.00254\ttest-cost_obj:161860.00000+5340.73029\n",
            "[15]\ttrain-error:0.04774+0.00241\ttrain-cost_obj:872540.00000+42251.57275\ttest-error:0.07879+0.00255\ttest-cost_obj:160485.00000+5013.18512\n",
            "[16]\ttrain-error:0.04593+0.00161\ttrain-cost_obj:839830.00000+28258.47837\ttest-error:0.07792+0.00266\ttest-cost_obj:158735.00000+5554.54994\n",
            "[17]\ttrain-error:0.04436+0.00188\ttrain-cost_obj:811540.00000+33212.42087\ttest-error:0.07754+0.00271\ttest-cost_obj:157940.00000+5475.75566\n",
            "[18]\ttrain-error:0.04288+0.00228\ttrain-cost_obj:784920.00000+40902.72729\ttest-error:0.07674+0.00269\ttest-cost_obj:156345.00000+5379.28666\n",
            "[19]\ttrain-error:0.04168+0.00249\ttrain-cost_obj:763135.00000+45307.57139\ttest-error:0.07649+0.00240\ttest-cost_obj:155950.00000+4721.75815\n",
            "[20]\ttrain-error:0.04062+0.00274\ttrain-cost_obj:743940.00000+50084.73220\ttest-error:0.07615+0.00225\ttest-cost_obj:155250.00000+4289.69696\n",
            "[21]\ttrain-error:0.03948+0.00288\ttrain-cost_obj:723490.00000+52836.44481\ttest-error:0.07571+0.00224\ttest-cost_obj:154360.00000+4278.94847\n",
            "[22]\ttrain-error:0.03848+0.00267\ttrain-cost_obj:705335.00000+48773.32288\ttest-error:0.07542+0.00220\ttest-cost_obj:153745.00000+4204.54813\n",
            "[23]\ttrain-error:0.03755+0.00257\ttrain-cost_obj:688380.00000+46979.35291\ttest-error:0.07516+0.00198\ttest-cost_obj:153200.00000+3747.93276\n",
            "[24]\ttrain-error:0.03685+0.00268\ttrain-cost_obj:675735.00000+49325.39939\ttest-error:0.07503+0.00177\ttest-cost_obj:152960.00000+3407.47707\n",
            "[25]\ttrain-error:0.03612+0.00272\ttrain-cost_obj:662305.00000+49567.54709\ttest-error:0.07513+0.00209\ttest-cost_obj:153185.00000+3778.89203\n",
            "[26]\ttrain-error:0.03550+0.00288\ttrain-cost_obj:650990.00000+52151.19749\ttest-error:0.07526+0.00218\ttest-cost_obj:153425.00000+4172.78384\n",
            "[27]\ttrain-error:0.03466+0.00210\ttrain-cost_obj:635295.00000+37872.47318\ttest-error:0.07484+0.00197\ttest-cost_obj:152530.00000+3904.94558\n",
            "[28]\ttrain-error:0.03402+0.00195\ttrain-cost_obj:623905.00000+34840.29599\ttest-error:0.07507+0.00230\ttest-cost_obj:152950.00000+4538.28161\n",
            "[29]\ttrain-error:0.03341+0.00191\ttrain-cost_obj:612550.00000+34426.14559\ttest-error:0.07479+0.00262\ttest-cost_obj:152405.00000+5256.73140\n",
            "[30]\ttrain-error:0.03281+0.00203\ttrain-cost_obj:601525.00000+36839.32851\ttest-error:0.07501+0.00254\ttest-cost_obj:152825.00000+5287.30792\n",
            "[31]\ttrain-error:0.03214+0.00198\ttrain-cost_obj:589715.00000+35366.51700\ttest-error:0.07495+0.00289\ttest-cost_obj:152630.00000+6074.01021\n",
            "[32]\ttrain-error:0.03163+0.00206\ttrain-cost_obj:580290.00000+36850.37178\ttest-error:0.07469+0.00276\ttest-cost_obj:152060.00000+5699.99123\n",
            "[33]\ttrain-error:0.03118+0.00214\ttrain-cost_obj:572015.00000+38286.39478\ttest-error:0.07465+0.00295\ttest-cost_obj:152020.00000+5975.41630\n",
            "[34]\ttrain-error:0.03069+0.00196\ttrain-cost_obj:563170.00000+34924.54151\ttest-error:0.07449+0.00320\ttest-cost_obj:151705.00000+6522.74674\n",
            "[35]\ttrain-error:0.03014+0.00218\ttrain-cost_obj:552820.00000+39242.60567\ttest-error:0.07424+0.00306\ttest-cost_obj:151255.00000+6351.51360\n",
            "[36]\ttrain-error:0.02970+0.00228\ttrain-cost_obj:544765.00000+41167.77289\ttest-error:0.07446+0.00308\ttest-cost_obj:151605.00000+6351.43488\n",
            "[37]\ttrain-error:0.02925+0.00233\ttrain-cost_obj:536590.00000+42016.72762\ttest-error:0.07439+0.00303\ttest-cost_obj:151505.00000+6335.39462\n",
            "[38]\ttrain-error:0.02865+0.00234\ttrain-cost_obj:525580.00000+42484.09232\ttest-error:0.07454+0.00312\ttest-cost_obj:151675.00000+6358.03625\n",
            "[39]\ttrain-error:0.02836+0.00222\ttrain-cost_obj:520300.00000+40204.85045\ttest-error:0.07474+0.00306\ttest-cost_obj:152245.00000+6207.51359\n",
            "[40]\ttrain-error:0.02805+0.00215\ttrain-cost_obj:514565.00000+39225.95474\ttest-error:0.07484+0.00314\ttest-cost_obj:152345.00000+6477.32391\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 3, 'gamma': 1, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.49014+0.03626\ttrain-cost_obj:7241545.00000+460779.85657\ttest-error:0.49144+0.03583\ttest-cost_obj:807020.00000+50422.20344\n",
            "[3]\ttrain-error:0.40456+0.00332\ttrain-cost_obj:6184745.00000+27895.01255\ttest-error:0.40591+0.00437\ttest-cost_obj:689825.00000+6435.96341\n",
            "[4]\ttrain-error:0.33269+0.00158\ttrain-cost_obj:5293910.00000+19132.41752\ttest-error:0.33474+0.00243\ttest-cost_obj:592175.00000+5514.35626\n",
            "[5]\ttrain-error:0.32238+0.00293\ttrain-cost_obj:5200125.00000+26973.44296\ttest-error:0.32408+0.00306\ttest-cost_obj:581130.00000+5459.40473\n",
            "[6]\ttrain-error:0.31455+0.01218\ttrain-cost_obj:5133660.00000+98194.59965\ttest-error:0.31637+0.01209\ttest-cost_obj:573960.00000+11459.27136\n",
            "[7]\ttrain-error:0.27834+0.00128\ttrain-cost_obj:4860745.00000+31586.92332\ttest-error:0.28008+0.00161\ttest-cost_obj:543690.00000+5454.80522\n",
            "[8]\ttrain-error:0.27563+0.00191\ttrain-cost_obj:4840935.00000+29739.15811\ttest-error:0.27724+0.00221\ttest-cost_obj:541215.00000+5709.81830\n",
            "[9]\ttrain-error:0.27481+0.00163\ttrain-cost_obj:4841525.00000+35483.94179\ttest-error:0.27654+0.00258\ttest-cost_obj:541445.00000+6513.27299\n",
            "[10]\ttrain-error:0.27085+0.00332\ttrain-cost_obj:4790805.00000+54375.88827\ttest-error:0.27308+0.00405\ttest-cost_obj:536700.00000+7620.49867\n",
            "[11]\ttrain-error:0.26608+0.00372\ttrain-cost_obj:4725000.00000+67262.47096\ttest-error:0.26753+0.00425\ttest-cost_obj:528065.00000+8390.68084\n",
            "[12]\ttrain-error:0.26044+0.00519\ttrain-cost_obj:4637215.00000+90750.53457\ttest-error:0.26249+0.00557\ttest-cost_obj:519330.00000+10978.25578\n",
            "[13]\ttrain-error:0.25467+0.00493\ttrain-cost_obj:4551375.00000+90573.29698\ttest-error:0.25648+0.00615\ttest-cost_obj:509285.00000+12146.79073\n",
            "[14]\ttrain-error:0.25200+0.00499\ttrain-cost_obj:4513510.00000+85547.73463\ttest-error:0.25413+0.00567\ttest-cost_obj:505795.00000+10772.42893\n",
            "[15]\ttrain-error:0.24777+0.00505\ttrain-cost_obj:4446865.00000+89261.10309\ttest-error:0.25041+0.00498\ttest-cost_obj:499455.00000+9785.38323\n",
            "[16]\ttrain-error:0.24391+0.00425\ttrain-cost_obj:4388270.00000+75750.75313\ttest-error:0.24624+0.00409\ttest-cost_obj:492225.00000+8044.35361\n",
            "[17]\ttrain-error:0.24180+0.00421\ttrain-cost_obj:4355390.00000+76098.39946\ttest-error:0.24415+0.00415\ttest-cost_obj:488520.00000+8406.64023\n",
            "[18]\ttrain-error:0.23832+0.00426\ttrain-cost_obj:4294000.00000+76454.72843\ttest-error:0.24076+0.00420\ttest-cost_obj:482090.00000+8766.63561\n",
            "[19]\ttrain-error:0.23518+0.00462\ttrain-cost_obj:4241675.00000+78965.24631\ttest-error:0.23774+0.00439\ttest-cost_obj:476550.00000+8598.63361\n",
            "[20]\ttrain-error:0.23195+0.00453\ttrain-cost_obj:4190180.00000+78159.16837\ttest-error:0.23461+0.00471\ttest-cost_obj:470980.00000+9279.66055\n",
            "[21]\ttrain-error:0.22835+0.00492\ttrain-cost_obj:4129405.00000+88513.40139\ttest-error:0.23116+0.00467\ttest-cost_obj:464425.00000+9104.20919\n",
            "[22]\ttrain-error:0.22514+0.00511\ttrain-cost_obj:4073720.00000+88483.40861\ttest-error:0.22809+0.00495\ttest-cost_obj:458590.00000+9559.25729\n",
            "[23]\ttrain-error:0.22189+0.00468\ttrain-cost_obj:4018610.00000+81935.87371\ttest-error:0.22503+0.00492\ttest-cost_obj:453020.00000+9653.68323\n",
            "[24]\ttrain-error:0.21881+0.00390\ttrain-cost_obj:3966760.00000+70653.09547\ttest-error:0.22154+0.00445\ttest-cost_obj:446385.00000+9123.98076\n",
            "[25]\ttrain-error:0.21612+0.00377\ttrain-cost_obj:3920430.00000+66732.78879\ttest-error:0.21870+0.00461\ttest-cost_obj:441010.00000+9184.38349\n",
            "[26]\ttrain-error:0.21350+0.00400\ttrain-cost_obj:3875320.00000+71717.50553\ttest-error:0.21647+0.00443\ttest-cost_obj:436850.00000+8775.47720\n",
            "[27]\ttrain-error:0.21138+0.00398\ttrain-cost_obj:3838865.00000+72224.48010\ttest-error:0.21451+0.00461\ttest-cost_obj:433080.00000+9357.51570\n",
            "[28]\ttrain-error:0.20901+0.00415\ttrain-cost_obj:3797715.00000+75719.38012\ttest-error:0.21274+0.00520\ttest-cost_obj:429710.00000+10543.54779\n",
            "[29]\ttrain-error:0.20748+0.00391\ttrain-cost_obj:3770540.00000+71658.91710\ttest-error:0.21133+0.00514\ttest-cost_obj:426965.00000+10363.15710\n",
            "[30]\ttrain-error:0.20544+0.00400\ttrain-cost_obj:3735980.00000+74190.51220\ttest-error:0.20882+0.00507\ttest-cost_obj:422210.00000+10245.09151\n",
            "[31]\ttrain-error:0.20271+0.00325\ttrain-cost_obj:3688375.00000+61124.93865\ttest-error:0.20592+0.00416\ttest-cost_obj:416570.00000+8489.38160\n",
            "[32]\ttrain-error:0.20083+0.00338\ttrain-cost_obj:3656500.00000+64645.74619\ttest-error:0.20423+0.00399\ttest-cost_obj:413280.00000+8096.64128\n",
            "[33]\ttrain-error:0.19900+0.00324\ttrain-cost_obj:3624565.00000+62895.58430\ttest-error:0.20254+0.00418\ttest-cost_obj:409995.00000+8540.12441\n",
            "[34]\ttrain-error:0.19688+0.00305\ttrain-cost_obj:3587325.00000+58186.05610\ttest-error:0.20033+0.00433\ttest-cost_obj:405600.00000+8619.33872\n",
            "[35]\ttrain-error:0.19501+0.00296\ttrain-cost_obj:3555515.00000+56709.54086\ttest-error:0.19853+0.00392\ttest-cost_obj:402290.00000+7928.07669\n",
            "[36]\ttrain-error:0.19348+0.00295\ttrain-cost_obj:3530350.00000+56095.03543\ttest-error:0.19709+0.00380\ttest-cost_obj:399690.00000+7735.69001\n",
            "[37]\ttrain-error:0.19169+0.00263\ttrain-cost_obj:3499415.00000+50783.24551\ttest-error:0.19529+0.00374\ttest-cost_obj:396175.00000+7735.05818\n",
            "[38]\ttrain-error:0.19018+0.00244\ttrain-cost_obj:3473185.00000+48640.07633\ttest-error:0.19375+0.00421\ttest-cost_obj:393250.00000+8942.37105\n",
            "[39]\ttrain-error:0.18893+0.00234\ttrain-cost_obj:3451795.00000+47122.33786\ttest-error:0.19262+0.00423\ttest-cost_obj:391150.00000+9007.99645\n",
            "[40]\ttrain-error:0.18725+0.00216\ttrain-cost_obj:3423355.00000+45219.25171\ttest-error:0.19103+0.00449\ttest-cost_obj:387965.00000+9490.41754\n",
            "[41]\ttrain-error:0.18589+0.00245\ttrain-cost_obj:3399965.00000+50476.94053\ttest-error:0.18964+0.00476\ttest-cost_obj:385335.00000+10130.12956\n",
            "[42]\ttrain-error:0.18433+0.00244\ttrain-cost_obj:3372730.00000+48362.99308\ttest-error:0.18816+0.00477\ttest-cost_obj:382520.00000+10034.81938\n",
            "[43]\ttrain-error:0.18324+0.00253\ttrain-cost_obj:3353530.00000+50074.35571\ttest-error:0.18704+0.00505\ttest-cost_obj:380330.00000+10534.94661\n",
            "[44]\ttrain-error:0.18195+0.00234\ttrain-cost_obj:3330370.00000+46150.90573\ttest-error:0.18586+0.00490\ttest-cost_obj:378125.00000+10159.97662\n",
            "[45]\ttrain-error:0.18053+0.00216\ttrain-cost_obj:3305400.00000+43755.13684\ttest-error:0.18438+0.00509\ttest-cost_obj:375210.00000+10577.49498\n",
            "[46]\ttrain-error:0.17947+0.00224\ttrain-cost_obj:3286805.00000+45484.02164\ttest-error:0.18303+0.00504\ttest-cost_obj:372580.00000+10562.20148\n",
            "[47]\ttrain-error:0.17822+0.00247\ttrain-cost_obj:3264615.00000+48996.16847\ttest-error:0.18194+0.00517\ttest-cost_obj:370475.00000+10625.37646\n",
            "[48]\ttrain-error:0.17688+0.00200\ttrain-cost_obj:3241465.00000+39883.46807\ttest-error:0.18038+0.00524\ttest-cost_obj:367560.00000+10595.39523\n",
            "[49]\ttrain-error:0.17538+0.00170\ttrain-cost_obj:3214725.00000+34275.49598\ttest-error:0.17917+0.00511\ttest-cost_obj:365080.00000+10412.23319\n",
            "{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'gamma': 1, 'lambda': 1, 'alpha': 0.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[3]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[4]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[5]\ttrain-error:0.53893+0.00375\ttrain-cost_obj:7799840.00000+50132.74279\ttest-error:0.53985+0.00472\ttest-cost_obj:868370.00000+7078.99004\n",
            "[6]\ttrain-error:0.46098+0.01800\ttrain-cost_obj:6740925.00000+247594.91640\ttest-error:0.46305+0.01764\ttest-cost_obj:752910.00000+26434.87091\n",
            "[7]\ttrain-error:0.38339+0.01308\ttrain-cost_obj:5700500.00000+172909.21028\ttest-error:0.38468+0.01130\ttest-cost_obj:636075.00000+16175.83460\n",
            "[8]\ttrain-error:0.31143+0.00862\ttrain-cost_obj:4788740.00000+109628.23496\ttest-error:0.31376+0.00814\ttest-cost_obj:536895.00000+11288.27821\n",
            "[9]\ttrain-error:0.27069+0.00437\ttrain-cost_obj:4295885.00000+59006.10159\ttest-error:0.27343+0.00476\ttest-cost_obj:482840.00000+7195.37351\n",
            "[10]\ttrain-error:0.25882+0.00391\ttrain-cost_obj:4153715.00000+57791.85950\ttest-error:0.26277+0.00415\ttest-cost_obj:469275.00000+6430.91168\n",
            "[11]\ttrain-error:0.25121+0.00243\ttrain-cost_obj:4064940.00000+42207.36192\ttest-error:0.25449+0.00314\ttest-cost_obj:458010.00000+5656.18246\n",
            "[12]\ttrain-error:0.24567+0.00254\ttrain-cost_obj:4002110.00000+46084.30752\ttest-error:0.24862+0.00342\ttest-cost_obj:450470.00000+7096.76687\n",
            "[13]\ttrain-error:0.24224+0.00257\ttrain-cost_obj:3962380.00000+43044.80921\ttest-error:0.24528+0.00391\ttest-cost_obj:446305.00000+7855.45829\n",
            "[14]\ttrain-error:0.23829+0.00226\ttrain-cost_obj:3912705.00000+36042.42951\ttest-error:0.24154+0.00351\ttest-cost_obj:441125.00000+7002.50848\n",
            "[15]\ttrain-error:0.23541+0.00266\ttrain-cost_obj:3881270.00000+39668.08667\ttest-error:0.23874+0.00405\ttest-cost_obj:437770.00000+7817.19899\n",
            "[16]\ttrain-error:0.23224+0.00310\ttrain-cost_obj:3842180.00000+44587.66758\ttest-error:0.23575+0.00457\ttest-cost_obj:433730.00000+8766.53295\n",
            "[17]\ttrain-error:0.22886+0.00351\ttrain-cost_obj:3804120.00000+47270.79542\ttest-error:0.23229+0.00470\ttest-cost_obj:429300.00000+8983.40136\n",
            "[18]\ttrain-error:0.22598+0.00376\ttrain-cost_obj:3771130.00000+46910.45832\ttest-error:0.22970+0.00490\ttest-cost_obj:426260.00000+8974.45820\n",
            "[19]\ttrain-error:0.22292+0.00407\ttrain-cost_obj:3740200.00000+50741.18643\ttest-error:0.22659+0.00508\ttest-cost_obj:422725.00000+8969.45511\n",
            "[20]\ttrain-error:0.21908+0.00367\ttrain-cost_obj:3696350.00000+44373.73097\ttest-error:0.22282+0.00503\ttest-cost_obj:417950.00000+9066.72488\n",
            "[21]\ttrain-error:0.21655+0.00342\ttrain-cost_obj:3670535.00000+39136.39004\ttest-error:0.22049+0.00545\ttest-cost_obj:415615.00000+9640.35917\n",
            "[22]\ttrain-error:0.21325+0.00307\ttrain-cost_obj:3631595.00000+35499.52429\ttest-error:0.21738+0.00524\ttest-cost_obj:411880.00000+9568.83483\n",
            "[23]\ttrain-error:0.21007+0.00280\ttrain-cost_obj:3593430.00000+32062.05078\ttest-error:0.21425+0.00531\ttest-cost_obj:407645.00000+9693.10193\n",
            "[24]\ttrain-error:0.20689+0.00313\ttrain-cost_obj:3553895.00000+37692.78081\ttest-error:0.21111+0.00556\ttest-cost_obj:403295.00000+9974.02752\n",
            "[25]\ttrain-error:0.20400+0.00333\ttrain-cost_obj:3515615.00000+39931.62938\ttest-error:0.20789+0.00578\ttest-cost_obj:398365.00000+10334.86938\n",
            "[26]\ttrain-error:0.20118+0.00329\ttrain-cost_obj:3476685.00000+39267.88160\ttest-error:0.20542+0.00584\ttest-cost_obj:394735.00000+10424.73141\n",
            "[27]\ttrain-error:0.19833+0.00352\ttrain-cost_obj:3437675.00000+42947.68475\ttest-error:0.20282+0.00610\ttest-cost_obj:390745.00000+10858.87770\n",
            "[28]\ttrain-error:0.19577+0.00354\ttrain-cost_obj:3401955.00000+42998.93284\ttest-error:0.20064+0.00612\ttest-cost_obj:387470.00000+10912.70361\n",
            "[29]\ttrain-error:0.19337+0.00383\ttrain-cost_obj:3369130.00000+48409.85540\ttest-error:0.19824+0.00644\ttest-cost_obj:383815.00000+11664.56279\n",
            "[30]\ttrain-error:0.19099+0.00358\ttrain-cost_obj:3336030.00000+44792.15445\ttest-error:0.19574+0.00585\ttest-cost_obj:380070.00000+10710.09337\n",
            "[31]\ttrain-error:0.18825+0.00331\ttrain-cost_obj:3296610.00000+41016.26994\ttest-error:0.19327+0.00610\ttest-cost_obj:376085.00000+11188.45499\n",
            "[32]\ttrain-error:0.18580+0.00347\ttrain-cost_obj:3261595.00000+45330.14698\ttest-error:0.19082+0.00614\ttest-cost_obj:372245.00000+11374.78461\n",
            "[33]\ttrain-error:0.18317+0.00356\ttrain-cost_obj:3222890.00000+47922.37891\ttest-error:0.18838+0.00628\ttest-cost_obj:368225.00000+11788.96200\n",
            "[34]\ttrain-error:0.18081+0.00347\ttrain-cost_obj:3188300.00000+46391.23301\ttest-error:0.18606+0.00597\ttest-cost_obj:364500.00000+11172.53328\n",
            "[35]\ttrain-error:0.17880+0.00346\ttrain-cost_obj:3158940.00000+45438.09965\ttest-error:0.18386+0.00609\ttest-cost_obj:361045.00000+11280.76793\n",
            "[36]\ttrain-error:0.17653+0.00309\ttrain-cost_obj:3125690.00000+41335.91538\ttest-error:0.18143+0.00576\ttest-cost_obj:357015.00000+11006.95348\n",
            "[37]\ttrain-error:0.17435+0.00311\ttrain-cost_obj:3093145.00000+41976.49015\ttest-error:0.17924+0.00587\ttest-cost_obj:353305.00000+11260.91582\n",
            "[38]\ttrain-error:0.17250+0.00308\ttrain-cost_obj:3065930.00000+44807.12667\ttest-error:0.17720+0.00561\ttest-cost_obj:349960.00000+10866.73364\n",
            "[39]\ttrain-error:0.17085+0.00319\ttrain-cost_obj:3042010.00000+48030.56735\ttest-error:0.17554+0.00598\ttest-cost_obj:347260.00000+11632.81565\n",
            "[40]\ttrain-error:0.16935+0.00328\ttrain-cost_obj:3020020.00000+49801.01505\ttest-error:0.17399+0.00611\ttest-cost_obj:344840.00000+11814.11867\n",
            "[41]\ttrain-error:0.16775+0.00309\ttrain-cost_obj:2996550.00000+46443.71325\ttest-error:0.17260+0.00605\ttest-cost_obj:342740.00000+11747.08049\n",
            "[42]\ttrain-error:0.16649+0.00331\ttrain-cost_obj:2978175.00000+50185.17336\ttest-error:0.17149+0.00598\ttest-cost_obj:340930.00000+11548.70556\n",
            "[43]\ttrain-error:0.16495+0.00300\ttrain-cost_obj:2955110.00000+44152.41669\ttest-error:0.17007+0.00561\ttest-cost_obj:338465.00000+10848.13463\n",
            "[44]\ttrain-error:0.16338+0.00280\ttrain-cost_obj:2931210.00000+43903.32448\ttest-error:0.16858+0.00575\ttest-cost_obj:336060.00000+11233.60583\n",
            "[45]\ttrain-error:0.16186+0.00292\ttrain-cost_obj:2907630.00000+47842.66506\ttest-error:0.16708+0.00600\ttest-cost_obj:333515.00000+11752.21362\n",
            "[46]\ttrain-error:0.16018+0.00309\ttrain-cost_obj:2881600.00000+49982.80704\ttest-error:0.16528+0.00629\ttest-cost_obj:330400.00000+12286.06935\n",
            "[47]\ttrain-error:0.15850+0.00287\ttrain-cost_obj:2855325.00000+46199.53057\ttest-error:0.16341+0.00601\ttest-cost_obj:327100.00000+11834.25114\n",
            "[48]\ttrain-error:0.15715+0.00282\ttrain-cost_obj:2834395.00000+44628.01502\ttest-error:0.16244+0.00606\ttest-cost_obj:325585.00000+11957.21644\n",
            "[49]\ttrain-error:0.15587+0.00307\ttrain-cost_obj:2814400.00000+50462.74864\ttest-error:0.16084+0.00630\ttest-cost_obj:322710.00000+12498.23588\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 2, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.05604+0.00133\ttrain-cost_obj:869220.00000+16892.14610\ttest-error:0.14350+0.00232\ttest-cost_obj:269795.00000+4816.71309\n",
            "[2]\ttrain-error:0.01446+0.00085\ttrain-cost_obj:247010.00000+13322.45848\ttest-error:0.13503+0.00181\ttest-cost_obj:258565.00000+3521.93484\n",
            "[3]\ttrain-error:0.01118+0.00052\ttrain-cost_obj:200005.00000+9298.42594\ttest-error:0.12429+0.00172\ttest-cost_obj:238805.00000+3233.06743\n",
            "[4]\ttrain-error:0.00976+0.00035\ttrain-cost_obj:180780.00000+6559.88567\ttest-error:0.11091+0.00209\ttest-cost_obj:221450.00000+4182.10473\n",
            "[5]\ttrain-error:0.00657+0.00023\ttrain-cost_obj:122605.00000+4001.02799\ttest-error:0.10171+0.00163\ttest-cost_obj:204680.00000+3282.54474\n",
            "[6]\ttrain-error:0.00466+0.00013\ttrain-cost_obj:90830.00000+2621.56442\ttest-error:0.09816+0.00241\ttest-cost_obj:201450.00000+4708.66223\n",
            "[7]\ttrain-error:0.00324+0.00021\ttrain-cost_obj:61385.00000+3814.84272\ttest-error:0.09760+0.00207\ttest-cost_obj:195860.00000+3972.45516\n",
            "[8]\ttrain-error:0.00249+0.00015\ttrain-cost_obj:49600.00000+3003.33148\ttest-error:0.09639+0.00234\ttest-cost_obj:198890.00000+4581.20072\n",
            "[9]\ttrain-error:0.00167+0.00015\ttrain-cost_obj:31950.00000+2823.82719\ttest-error:0.09612+0.00202\ttest-cost_obj:193085.00000+3665.04093\n",
            "[10]\ttrain-error:0.00137+0.00012\ttrain-cost_obj:27705.00000+2470.67299\ttest-error:0.09614+0.00231\ttest-cost_obj:199085.00000+4592.55103\n",
            "[11]\ttrain-error:0.00094+0.00009\ttrain-cost_obj:18155.00000+1802.00583\ttest-error:0.09559+0.00217\ttest-cost_obj:191800.00000+4369.15324\n",
            "[12]\ttrain-error:0.00087+0.00008\ttrain-cost_obj:17815.00000+1754.28760\ttest-error:0.09604+0.00201\ttest-cost_obj:199080.00000+4085.41308\n",
            "[13]\ttrain-error:0.00062+0.00008\ttrain-cost_obj:12020.00000+1544.37690\ttest-error:0.09644+0.00241\ttest-cost_obj:193515.00000+4530.23454\n",
            "[14]\ttrain-error:0.00060+0.00008\ttrain-cost_obj:12190.00000+1731.01127\ttest-error:0.09620+0.00256\ttest-cost_obj:199095.00000+4847.90934\n",
            "[15]\ttrain-error:0.00043+0.00008\ttrain-cost_obj:8315.00000+1600.00781\ttest-error:0.09688+0.00307\ttest-cost_obj:194270.00000+5894.11571\n",
            "{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[3]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[4]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[5]\ttrain-error:0.28897+0.01801\ttrain-cost_obj:4270795.00000+249297.50144\ttest-error:0.29964+0.01721\ttest-cost_obj:495920.00000+26026.40198\n",
            "[6]\ttrain-error:0.21500+0.01296\ttrain-cost_obj:3210130.00000+181182.40284\ttest-error:0.23102+0.01121\ttest-cost_obj:387305.00000+17262.00235\n",
            "[7]\ttrain-error:0.16875+0.00231\ttrain-cost_obj:2563100.00000+32097.06373\ttest-error:0.18718+0.00301\ttest-cost_obj:320080.00000+5239.66602\n",
            "[8]\ttrain-error:0.14710+0.00190\ttrain-cost_obj:2260535.00000+24930.46379\ttest-error:0.16736+0.00284\ttest-cost_obj:289920.00000+5312.91822\n",
            "[9]\ttrain-error:0.13347+0.00137\ttrain-cost_obj:2074955.00000+16649.75150\ttest-error:0.15460+0.00293\ttest-cost_obj:271240.00000+5690.94895\n",
            "[10]\ttrain-error:0.12267+0.00163\ttrain-cost_obj:1929090.00000+22311.83318\ttest-error:0.14454+0.00340\ttest-cost_obj:256780.00000+6333.60877\n",
            "[11]\ttrain-error:0.11513+0.00118\ttrain-cost_obj:1829220.00000+18539.40668\ttest-error:0.13710+0.00298\ttest-cost_obj:246020.00000+5589.01601\n",
            "[12]\ttrain-error:0.10894+0.00100\ttrain-cost_obj:1747455.00000+17160.25131\ttest-error:0.13102+0.00243\ttest-cost_obj:237400.00000+4797.18668\n",
            "[13]\ttrain-error:0.10395+0.00094\ttrain-cost_obj:1682565.00000+15546.19005\ttest-error:0.12626+0.00276\ttest-cost_obj:230590.00000+5433.72800\n",
            "[14]\ttrain-error:0.09979+0.00092\ttrain-cost_obj:1628795.00000+14829.64008\ttest-error:0.12221+0.00279\ttest-cost_obj:225325.00000+5683.67179\n",
            "[15]\ttrain-error:0.09599+0.00083\ttrain-cost_obj:1579340.00000+13247.24122\ttest-error:0.11856+0.00273\ttest-cost_obj:220315.00000+5795.94902\n",
            "[16]\ttrain-error:0.09249+0.00097\ttrain-cost_obj:1533355.00000+15976.09855\ttest-error:0.11541+0.00303\ttest-cost_obj:216285.00000+6207.77939\n",
            "[17]\ttrain-error:0.08852+0.00111\ttrain-cost_obj:1478910.00000+18273.42059\ttest-error:0.11123+0.00268\ttest-cost_obj:210050.00000+5558.28211\n",
            "[18]\ttrain-error:0.08528+0.00137\ttrain-cost_obj:1434655.00000+22362.02641\ttest-error:0.10826+0.00293\ttest-cost_obj:205900.00000+6031.12759\n",
            "[19]\ttrain-error:0.08232+0.00147\ttrain-cost_obj:1395195.00000+24307.42119\ttest-error:0.10541+0.00296\ttest-cost_obj:201770.00000+5961.13244\n",
            "[20]\ttrain-error:0.07933+0.00137\ttrain-cost_obj:1352450.00000+22756.81217\ttest-error:0.10244+0.00252\ttest-cost_obj:197340.00000+5385.85184\n",
            "[21]\ttrain-error:0.07681+0.00135\ttrain-cost_obj:1317070.00000+23595.23469\ttest-error:0.09987+0.00218\ttest-cost_obj:193405.00000+4767.46526\n",
            "[22]\ttrain-error:0.07452+0.00118\ttrain-cost_obj:1284080.00000+20709.91550\ttest-error:0.09778+0.00212\ttest-cost_obj:190280.00000+4487.15946\n",
            "[23]\ttrain-error:0.07233+0.00102\ttrain-cost_obj:1252000.00000+17309.28941\ttest-error:0.09554+0.00234\ttest-cost_obj:186670.00000+4951.22207\n",
            "[24]\ttrain-error:0.07019+0.00095\ttrain-cost_obj:1220200.00000+16563.30281\ttest-error:0.09356+0.00247\ttest-cost_obj:183575.00000+5144.52379\n",
            "[25]\ttrain-error:0.06806+0.00108\ttrain-cost_obj:1187550.00000+19137.17586\ttest-error:0.09150+0.00265\ttest-cost_obj:180115.00000+5577.54650\n",
            "[26]\ttrain-error:0.06602+0.00120\ttrain-cost_obj:1155840.00000+20914.98028\ttest-error:0.08976+0.00271\ttest-cost_obj:177185.00000+5700.70390\n",
            "[27]\ttrain-error:0.06405+0.00115\ttrain-cost_obj:1124475.00000+19888.81910\ttest-error:0.08829+0.00267\ttest-cost_obj:174765.00000+5647.78939\n",
            "[28]\ttrain-error:0.06227+0.00117\ttrain-cost_obj:1096075.00000+20476.30643\ttest-error:0.08676+0.00286\ttest-cost_obj:172145.00000+6006.51521\n",
            "[29]\ttrain-error:0.06058+0.00100\ttrain-cost_obj:1068705.00000+17502.37770\ttest-error:0.08558+0.00274\ttest-cost_obj:170210.00000+5690.02636\n",
            "[30]\ttrain-error:0.05874+0.00100\ttrain-cost_obj:1038380.00000+17213.35528\ttest-error:0.08401+0.00263\ttest-cost_obj:167405.00000+5504.65485\n",
            "[31]\ttrain-error:0.05705+0.00115\ttrain-cost_obj:1010665.00000+19875.06038\ttest-error:0.08284+0.00237\ttest-cost_obj:165375.00000+4972.88900\n",
            "[32]\ttrain-error:0.05538+0.00110\ttrain-cost_obj:983075.00000+19117.58680\ttest-error:0.08154+0.00225\ttest-cost_obj:163095.00000+4775.27224\n",
            "[33]\ttrain-error:0.05387+0.00121\ttrain-cost_obj:957765.00000+21044.47730\ttest-error:0.08023+0.00249\ttest-cost_obj:160675.00000+5235.89773\n",
            "[34]\ttrain-error:0.05248+0.00112\ttrain-cost_obj:934425.00000+19437.27411\ttest-error:0.07940+0.00254\ttest-cost_obj:159255.00000+5274.15633\n",
            "[35]\ttrain-error:0.05122+0.00108\ttrain-cost_obj:913655.00000+18610.68846\ttest-error:0.07859+0.00253\ttest-cost_obj:157790.00000+5221.00565\n",
            "[36]\ttrain-error:0.04997+0.00123\ttrain-cost_obj:892290.00000+21386.00945\ttest-error:0.07777+0.00245\ttest-cost_obj:156415.00000+5112.24266\n",
            "[37]\ttrain-error:0.04887+0.00124\ttrain-cost_obj:874175.00000+21141.58521\ttest-error:0.07706+0.00239\ttest-cost_obj:155195.00000+4978.67703\n",
            "[38]\ttrain-error:0.04769+0.00117\ttrain-cost_obj:854050.00000+19752.08850\ttest-error:0.07610+0.00227\ttest-cost_obj:153235.00000+4683.37752\n",
            "[39]\ttrain-error:0.04677+0.00109\ttrain-cost_obj:838410.00000+18203.04645\ttest-error:0.07555+0.00234\ttest-cost_obj:152325.00000+4974.34669\n",
            "[40]\ttrain-error:0.04577+0.00099\ttrain-cost_obj:821145.00000+16906.38119\ttest-error:0.07489+0.00232\ttest-cost_obj:151155.00000+4945.32355\n",
            "[41]\ttrain-error:0.04488+0.00097\ttrain-cost_obj:805820.00000+16384.96567\ttest-error:0.07440+0.00234\ttest-cost_obj:150335.00000+4971.32025\n",
            "[42]\ttrain-error:0.04397+0.00098\ttrain-cost_obj:789955.00000+17155.96762\ttest-error:0.07367+0.00228\ttest-cost_obj:148920.00000+4849.95876\n",
            "[43]\ttrain-error:0.04316+0.00102\ttrain-cost_obj:776015.00000+18347.50732\ttest-error:0.07339+0.00215\ttest-cost_obj:148475.00000+4581.98920\n",
            "[44]\ttrain-error:0.04239+0.00120\ttrain-cost_obj:762855.00000+22074.96829\ttest-error:0.07297+0.00232\ttest-cost_obj:147640.00000+5006.38592\n",
            "[45]\ttrain-error:0.04164+0.00123\ttrain-cost_obj:749735.00000+22577.96548\ttest-error:0.07266+0.00236\ttest-cost_obj:147085.00000+5119.03555\n",
            "[46]\ttrain-error:0.04089+0.00102\ttrain-cost_obj:736745.00000+19045.39905\ttest-error:0.07212+0.00231\ttest-cost_obj:146100.00000+5033.28918\n",
            "[47]\ttrain-error:0.04020+0.00107\ttrain-cost_obj:724590.00000+20128.60899\ttest-error:0.07172+0.00251\ttest-cost_obj:145390.00000+5464.32979\n",
            "[48]\ttrain-error:0.03955+0.00097\ttrain-cost_obj:713200.00000+18616.09519\ttest-error:0.07168+0.00240\ttest-cost_obj:145390.00000+5178.45537\n",
            "[49]\ttrain-error:0.03871+0.00098\ttrain-cost_obj:698450.00000+18699.89305\ttest-error:0.07140+0.00247\ttest-cost_obj:144865.00000+5307.26153\n",
            "result:  0.07139999999999999\n",
            "best result:  0.07139999999999999\n",
            "hyperparameters:  {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1}\n",
            "best hyperparameters:  {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1}\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.49014+0.03626\ttrain-cost_obj:7241545.00000+460779.85657\ttest-error:0.49144+0.03583\ttest-cost_obj:807020.00000+50422.20344\n",
            "[3]\ttrain-error:0.40456+0.00332\ttrain-cost_obj:6184745.00000+27895.01255\ttest-error:0.40591+0.00437\ttest-cost_obj:689825.00000+6435.96341\n",
            "[4]\ttrain-error:0.33269+0.00158\ttrain-cost_obj:5293910.00000+19132.41752\ttest-error:0.33474+0.00243\ttest-cost_obj:592175.00000+5514.35626\n",
            "[5]\ttrain-error:0.32238+0.00293\ttrain-cost_obj:5200125.00000+26973.44296\ttest-error:0.32408+0.00306\ttest-cost_obj:581130.00000+5459.40473\n",
            "[6]\ttrain-error:0.31453+0.01218\ttrain-cost_obj:5133060.00000+98059.68285\ttest-error:0.31640+0.01210\ttest-cost_obj:573975.00000+11469.94442\n",
            "[7]\ttrain-error:0.27835+0.00128\ttrain-cost_obj:4860795.00000+31655.29537\ttest-error:0.28010+0.00161\ttest-cost_obj:543715.00000+5446.97393\n",
            "[8]\ttrain-error:0.27571+0.00193\ttrain-cost_obj:4841530.00000+29674.05601\ttest-error:0.27734+0.00215\ttest-cost_obj:541315.00000+5590.44050\n",
            "[9]\ttrain-error:0.27480+0.00164\ttrain-cost_obj:4841890.00000+35242.62902\ttest-error:0.27653+0.00266\ttest-cost_obj:541460.00000+6635.84207\n",
            "[10]\ttrain-error:0.27094+0.00318\ttrain-cost_obj:4791965.00000+53078.74834\ttest-error:0.27313+0.00402\ttest-cost_obj:536765.00000+7597.53414\n",
            "[11]\ttrain-error:0.26610+0.00363\ttrain-cost_obj:4722220.00000+64490.75980\ttest-error:0.26763+0.00412\ttest-cost_obj:527830.00000+8090.12361\n",
            "[12]\ttrain-error:0.26063+0.00517\ttrain-cost_obj:4640895.00000+91742.25431\ttest-error:0.26271+0.00559\ttest-cost_obj:519795.00000+11195.45555\n",
            "[13]\ttrain-error:0.25555+0.00522\ttrain-cost_obj:4569130.00000+99324.57954\ttest-error:0.25731+0.00655\ttest-cost_obj:511215.00000+13296.69226\n",
            "[14]\ttrain-error:0.25198+0.00486\ttrain-cost_obj:4516020.00000+80306.95860\ttest-error:0.25403+0.00609\ttest-cost_obj:505960.00000+11396.33274\n",
            "[15]\ttrain-error:0.24728+0.00377\ttrain-cost_obj:4442665.00000+70592.41124\ttest-error:0.24959+0.00490\ttest-cost_obj:498335.00000+9942.98874\n",
            "[16]\ttrain-error:0.24401+0.00366\ttrain-cost_obj:4392515.00000+67104.19529\ttest-error:0.24609+0.00362\ttest-cost_obj:492350.00000+7158.35177\n",
            "[17]\ttrain-error:0.24132+0.00335\ttrain-cost_obj:4348320.00000+61059.32853\ttest-error:0.24376+0.00405\ttest-cost_obj:488120.00000+8094.51049\n",
            "[18]\ttrain-error:0.23767+0.00447\ttrain-cost_obj:4286555.00000+78779.65934\ttest-error:0.24019+0.00397\ttest-cost_obj:481430.00000+7933.98387\n",
            "[19]\ttrain-error:0.23466+0.00449\ttrain-cost_obj:4238010.00000+75666.07166\ttest-error:0.23753+0.00389\ttest-cost_obj:476825.00000+6818.69672\n",
            "[20]\ttrain-error:0.23146+0.00466\ttrain-cost_obj:4184920.00000+77248.44076\ttest-error:0.23418+0.00439\ttest-cost_obj:470525.00000+7761.80552\n",
            "[21]\ttrain-error:0.22796+0.00424\ttrain-cost_obj:4125455.00000+71587.92304\ttest-error:0.23069+0.00419\ttest-cost_obj:463840.00000+6996.34905\n",
            "[22]\ttrain-error:0.22530+0.00445\ttrain-cost_obj:4079250.00000+77328.02209\ttest-error:0.22810+0.00427\ttest-cost_obj:458930.00000+7747.87713\n",
            "[23]\ttrain-error:0.22246+0.00470\ttrain-cost_obj:4030855.00000+81609.38809\ttest-error:0.22517+0.00417\ttest-cost_obj:453380.00000+7869.82211\n",
            "[24]\ttrain-error:0.21978+0.00415\ttrain-cost_obj:3984830.00000+71860.26092\ttest-error:0.22221+0.00410\ttest-cost_obj:447855.00000+7850.84231\n",
            "[25]\ttrain-error:0.21710+0.00381\ttrain-cost_obj:3937910.00000+67891.55249\ttest-error:0.21966+0.00379\ttest-cost_obj:442935.00000+7314.33695\n",
            "[26]\ttrain-error:0.21410+0.00393\ttrain-cost_obj:3886140.00000+70246.73587\ttest-error:0.21691+0.00392\ttest-cost_obj:437605.00000+7652.82464\n",
            "[27]\ttrain-error:0.21168+0.00396\ttrain-cost_obj:3844105.00000+69421.80655\ttest-error:0.21441+0.00346\ttest-cost_obj:432785.00000+6536.43825\n",
            "[28]\ttrain-error:0.20925+0.00389\ttrain-cost_obj:3801670.00000+66558.09192\ttest-error:0.21221+0.00327\ttest-cost_obj:428525.00000+6103.86148\n",
            "[29]\ttrain-error:0.20665+0.00398\ttrain-cost_obj:3756980.00000+67758.01133\ttest-error:0.20921+0.00340\ttest-cost_obj:422820.00000+6577.01300\n",
            "[30]\ttrain-error:0.20445+0.00421\ttrain-cost_obj:3717565.00000+70628.66291\ttest-error:0.20707+0.00335\ttest-cost_obj:418605.00000+6167.51368\n",
            "[31]\ttrain-error:0.20253+0.00404\ttrain-cost_obj:3684045.00000+69082.01086\ttest-error:0.20524+0.00280\ttest-cost_obj:414945.00000+5065.83902\n",
            "[32]\ttrain-error:0.20049+0.00395\ttrain-cost_obj:3648580.00000+66207.31531\ttest-error:0.20316+0.00321\ttest-cost_obj:410905.00000+5591.97863\n",
            "[33]\ttrain-error:0.19861+0.00371\ttrain-cost_obj:3615555.00000+62042.67664\ttest-error:0.20124+0.00292\ttest-cost_obj:407165.00000+5106.46894\n",
            "[34]\ttrain-error:0.19703+0.00341\ttrain-cost_obj:3588895.00000+58158.67283\ttest-error:0.19944+0.00277\ttest-cost_obj:403910.00000+4909.06305\n",
            "[35]\ttrain-error:0.19507+0.00338\ttrain-cost_obj:3555815.00000+58891.28989\ttest-error:0.19755+0.00227\ttest-cost_obj:400325.00000+3832.63943\n",
            "[36]\ttrain-error:0.19342+0.00345\ttrain-cost_obj:3527485.00000+61977.80671\ttest-error:0.19625+0.00224\ttest-cost_obj:397930.00000+4003.32362\n",
            "[37]\ttrain-error:0.19129+0.00377\ttrain-cost_obj:3490820.00000+67860.73312\ttest-error:0.19417+0.00273\ttest-cost_obj:393800.00000+5231.01329\n",
            "[38]\ttrain-error:0.18988+0.00357\ttrain-cost_obj:3466865.00000+63700.98920\ttest-error:0.19312+0.00251\ttest-cost_obj:391830.00000+4774.21198\n",
            "[39]\ttrain-error:0.18843+0.00351\ttrain-cost_obj:3441175.00000+62335.37619\ttest-error:0.19178+0.00273\ttest-cost_obj:389075.00000+5234.08301\n",
            "[40]\ttrain-error:0.18654+0.00328\ttrain-cost_obj:3408315.00000+59143.84182\ttest-error:0.19011+0.00273\ttest-cost_obj:385750.00000+5262.84144\n",
            "[41]\ttrain-error:0.18550+0.00333\ttrain-cost_obj:3389670.00000+61525.36144\ttest-error:0.18913+0.00289\ttest-cost_obj:383825.00000+5699.26530\n",
            "[42]\ttrain-error:0.18436+0.00311\ttrain-cost_obj:3369450.00000+57320.66817\ttest-error:0.18786+0.00279\ttest-cost_obj:381370.00000+5300.05660\n",
            "[43]\ttrain-error:0.18302+0.00297\ttrain-cost_obj:3345500.00000+55033.98950\ttest-error:0.18665+0.00272\ttest-cost_obj:378920.00000+5206.92808\n",
            "[44]\ttrain-error:0.18148+0.00264\ttrain-cost_obj:3318480.00000+48829.42351\ttest-error:0.18508+0.00288\ttest-cost_obj:375905.00000+5505.06358\n",
            "[45]\ttrain-error:0.18028+0.00280\ttrain-cost_obj:3297435.00000+51545.62566\ttest-error:0.18394+0.00287\ttest-cost_obj:373575.00000+5779.15435\n",
            "[46]\ttrain-error:0.17919+0.00289\ttrain-cost_obj:3278260.00000+53228.74130\ttest-error:0.18256+0.00273\ttest-cost_obj:370900.00000+5362.88169\n",
            "[47]\ttrain-error:0.17797+0.00276\ttrain-cost_obj:3256985.00000+51010.16590\ttest-error:0.18151+0.00330\ttest-cost_obj:368900.00000+6610.59755\n",
            "[48]\ttrain-error:0.17694+0.00306\ttrain-cost_obj:3238390.00000+56777.60034\ttest-error:0.18049+0.00321\ttest-cost_obj:366900.00000+6408.39293\n",
            "[49]\ttrain-error:0.17568+0.00314\ttrain-cost_obj:3215950.00000+56812.66144\ttest-error:0.17966+0.00336\ttest-cost_obj:365255.00000+6821.30669\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 10, 'gamma': 0, 'lambda': 2, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.21672+0.01056\ttrain-cost_obj:3303550.00000+138513.62929\ttest-error:0.23069+0.00903\ttest-cost_obj:394720.00000+12630.50276\n",
            "[2]\ttrain-error:0.13391+0.00212\ttrain-cost_obj:2126775.00000+28055.72357\ttest-error:0.15703+0.00345\ttest-cost_obj:280880.00000+5850.90591\n",
            "[3]\ttrain-error:0.10942+0.00137\ttrain-cost_obj:1804430.00000+19173.04358\ttest-error:0.13308+0.00299\ttest-cost_obj:247045.00000+5689.70342\n",
            "[4]\ttrain-error:0.09503+0.00141\ttrain-cost_obj:1617420.00000+21380.03976\ttest-error:0.11952+0.00343\ttest-cost_obj:228715.00000+6612.33884\n",
            "[5]\ttrain-error:0.08405+0.00156\ttrain-cost_obj:1465095.00000+26565.82814\ttest-error:0.10854+0.00260\ttest-cost_obj:212515.00000+5395.64871\n",
            "[6]\ttrain-error:0.07700+0.00183\ttrain-cost_obj:1365710.00000+32711.68599\ttest-error:0.10149+0.00268\ttest-cost_obj:202040.00000+5750.46955\n",
            "[7]\ttrain-error:0.07167+0.00226\ttrain-cost_obj:1284535.00000+37883.03743\ttest-error:0.09667+0.00189\ttest-cost_obj:194180.00000+4143.62160\n",
            "[8]\ttrain-error:0.06637+0.00209\ttrain-cost_obj:1197430.00000+35412.13916\ttest-error:0.09193+0.00267\ttest-cost_obj:185435.00000+5660.39089\n",
            "[9]\ttrain-error:0.06285+0.00229\ttrain-cost_obj:1138395.00000+37896.72446\ttest-error:0.08897+0.00294\ttest-cost_obj:180200.00000+6181.74733\n",
            "[10]\ttrain-error:0.05913+0.00246\ttrain-cost_obj:1075260.00000+41255.03484\ttest-error:0.08598+0.00322\ttest-cost_obj:174655.00000+6730.61847\n",
            "[11]\ttrain-error:0.05597+0.00246\ttrain-cost_obj:1020610.00000+41892.28330\ttest-error:0.08361+0.00314\ttest-cost_obj:170180.00000+6443.33764\n",
            "[12]\ttrain-error:0.05352+0.00229\ttrain-cost_obj:977835.00000+39825.56371\ttest-error:0.08198+0.00287\ttest-cost_obj:167030.00000+5862.72974\n",
            "[13]\ttrain-error:0.05140+0.00223\ttrain-cost_obj:940185.00000+39566.85513\ttest-error:0.08057+0.00274\ttest-cost_obj:164340.00000+5557.37348\n",
            "[14]\ttrain-error:0.04968+0.00248\ttrain-cost_obj:909780.00000+44564.98738\ttest-error:0.07952+0.00235\ttest-cost_obj:162325.00000+4786.45224\n",
            "[15]\ttrain-error:0.04813+0.00273\ttrain-cost_obj:881950.00000+49330.46726\ttest-error:0.07873+0.00212\ttest-cost_obj:160745.00000+4242.72613\n",
            "[16]\ttrain-error:0.04639+0.00305\ttrain-cost_obj:850940.00000+54872.91135\ttest-error:0.07775+0.00222\ttest-cost_obj:158825.00000+4517.14788\n",
            "[17]\ttrain-error:0.04511+0.00322\ttrain-cost_obj:827800.00000+57819.36959\ttest-error:0.07754+0.00207\ttest-cost_obj:158205.00000+4059.03006\n",
            "[18]\ttrain-error:0.04370+0.00293\ttrain-cost_obj:802115.00000+53071.30133\ttest-error:0.07699+0.00184\ttest-cost_obj:157115.00000+3617.11556\n",
            "[19]\ttrain-error:0.04265+0.00279\ttrain-cost_obj:783050.00000+50488.05304\ttest-error:0.07677+0.00240\ttest-cost_obj:156795.00000+4700.66219\n",
            "[20]\ttrain-error:0.04121+0.00292\ttrain-cost_obj:757150.00000+52853.08884\ttest-error:0.07611+0.00274\ttest-cost_obj:155395.00000+5649.88717\n",
            "[21]\ttrain-error:0.04016+0.00286\ttrain-cost_obj:738425.00000+51713.73246\ttest-error:0.07564+0.00253\ttest-cost_obj:154515.00000+5279.53833\n",
            "[22]\ttrain-error:0.03889+0.00263\ttrain-cost_obj:715470.00000+47532.53202\ttest-error:0.07547+0.00250\ttest-cost_obj:154200.00000+5204.61334\n",
            "[23]\ttrain-error:0.03781+0.00257\ttrain-cost_obj:695785.00000+46314.79272\ttest-error:0.07497+0.00245\ttest-cost_obj:153215.00000+4887.43542\n",
            "[24]\ttrain-error:0.03655+0.00259\ttrain-cost_obj:673155.00000+46846.78457\ttest-error:0.07456+0.00201\ttest-cost_obj:152350.00000+4144.27316\n",
            "[25]\ttrain-error:0.03542+0.00226\ttrain-cost_obj:652655.00000+41328.06220\ttest-error:0.07476+0.00222\ttest-cost_obj:152635.00000+4597.99141\n",
            "[26]\ttrain-error:0.03458+0.00211\ttrain-cost_obj:637190.00000+38744.92096\ttest-error:0.07483+0.00240\ttest-cost_obj:152740.00000+4988.17602\n",
            "[27]\ttrain-error:0.03344+0.00208\ttrain-cost_obj:616220.00000+38103.43292\ttest-error:0.07466+0.00259\ttest-cost_obj:152325.00000+5462.38272\n",
            "[28]\ttrain-error:0.03290+0.00214\ttrain-cost_obj:606380.00000+38764.32767\ttest-error:0.07480+0.00292\ttest-cost_obj:152655.00000+6077.14777\n",
            "[29]\ttrain-error:0.03222+0.00227\ttrain-cost_obj:593850.00000+41042.56936\ttest-error:0.07476+0.00312\ttest-cost_obj:152530.00000+6522.77548\n",
            "[30]\ttrain-error:0.03158+0.00246\ttrain-cost_obj:581940.00000+44601.05268\ttest-error:0.07478+0.00313\ttest-cost_obj:152530.00000+6558.20860\n",
            "[31]\ttrain-error:0.03100+0.00259\ttrain-cost_obj:571515.00000+46998.79280\ttest-error:0.07489+0.00287\ttest-cost_obj:152735.00000+6206.24887\n",
            "[32]\ttrain-error:0.03033+0.00270\ttrain-cost_obj:559310.00000+48776.25857\ttest-error:0.07460+0.00306\ttest-cost_obj:152125.00000+6538.05208\n",
            "[33]\ttrain-error:0.02961+0.00272\ttrain-cost_obj:545850.00000+48968.47455\ttest-error:0.07463+0.00297\ttest-cost_obj:152135.00000+6457.09106\n",
            "[34]\ttrain-error:0.02913+0.00283\ttrain-cost_obj:537225.00000+50931.06739\ttest-error:0.07481+0.00313\ttest-cost_obj:152560.00000+6632.07358\n",
            "[35]\ttrain-error:0.02850+0.00298\ttrain-cost_obj:525595.00000+53775.27522\ttest-error:0.07454+0.00314\ttest-cost_obj:152075.00000+6576.21662\n",
            "[36]\ttrain-error:0.02792+0.00329\ttrain-cost_obj:515180.00000+59685.33404\ttest-error:0.07456+0.00307\ttest-cost_obj:152155.00000+6446.10154\n",
            "[37]\ttrain-error:0.02753+0.00335\ttrain-cost_obj:508065.00000+60872.33382\ttest-error:0.07452+0.00294\ttest-cost_obj:152065.00000+6245.88064\n",
            "[38]\ttrain-error:0.02704+0.00344\ttrain-cost_obj:498960.00000+62478.78760\ttest-error:0.07477+0.00271\ttest-cost_obj:152620.00000+5825.04077\n",
            "[39]\ttrain-error:0.02659+0.00344\ttrain-cost_obj:490555.00000+62661.79638\ttest-error:0.07481+0.00248\ttest-cost_obj:152605.00000+5404.23214\n",
            "[40]\ttrain-error:0.02617+0.00357\ttrain-cost_obj:483070.00000+64843.01119\ttest-error:0.07483+0.00257\ttest-cost_obj:152640.00000+5523.39569\n",
            "[41]\ttrain-error:0.02594+0.00360\ttrain-cost_obj:478700.00000+65247.40991\ttest-error:0.07489+0.00259\ttest-cost_obj:152730.00000+5464.25658\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 2, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.39254+0.00743\ttrain-cost_obj:5895770.00000+97664.47973\ttest-error:0.39410+0.00788\ttest-cost_obj:658295.00000+12007.98588\n",
            "[3]\ttrain-error:0.26979+0.00320\ttrain-cost_obj:4347775.00000+27843.27791\ttest-error:0.27193+0.00394\ttest-cost_obj:487520.00000+5420.84864\n",
            "[4]\ttrain-error:0.24714+0.00202\ttrain-cost_obj:4048150.00000+35280.90844\ttest-error:0.25068+0.00317\ttest-cost_obj:456615.00000+6004.20894\n",
            "[5]\ttrain-error:0.23577+0.00298\ttrain-cost_obj:3923385.00000+39166.07620\ttest-error:0.23896+0.00417\ttest-cost_obj:442080.00000+6912.64060\n",
            "[6]\ttrain-error:0.22617+0.00220\ttrain-cost_obj:3813775.00000+29149.42752\ttest-error:0.23007+0.00265\ttest-cost_obj:431290.00000+3941.81430\n",
            "[7]\ttrain-error:0.21884+0.00306\ttrain-cost_obj:3724420.00000+41127.69262\ttest-error:0.22247+0.00458\ttest-cost_obj:420915.00000+8089.50091\n",
            "[8]\ttrain-error:0.21071+0.00235\ttrain-cost_obj:3637660.00000+26214.08782\ttest-error:0.21442+0.00322\ttest-cost_obj:411320.00000+5151.75698\n",
            "[9]\ttrain-error:0.20305+0.00217\ttrain-cost_obj:3543055.00000+30645.62326\ttest-error:0.20679+0.00355\ttest-cost_obj:400950.00000+6217.59600\n",
            "[10]\ttrain-error:0.19562+0.00248\ttrain-cost_obj:3445565.00000+38618.99177\ttest-error:0.19991+0.00472\ttest-cost_obj:391150.00000+8856.21251\n",
            "[11]\ttrain-error:0.18889+0.00319\ttrain-cost_obj:3350930.00000+51935.34057\ttest-error:0.19336+0.00548\ttest-cost_obj:381155.00000+10305.49489\n",
            "[12]\ttrain-error:0.18254+0.00201\ttrain-cost_obj:3258735.00000+35072.55373\ttest-error:0.18698+0.00407\ttest-cost_obj:370870.00000+7670.66490\n",
            "[13]\ttrain-error:0.17799+0.00245\ttrain-cost_obj:3194075.00000+41977.62053\ttest-error:0.18257+0.00501\ttest-cost_obj:363970.00000+9569.67084\n",
            "[14]\ttrain-error:0.17333+0.00294\ttrain-cost_obj:3125070.00000+48179.59734\ttest-error:0.17824+0.00503\ttest-cost_obj:356935.00000+9152.02300\n",
            "[15]\ttrain-error:0.16799+0.00270\ttrain-cost_obj:3041125.00000+44057.54334\ttest-error:0.17301+0.00499\ttest-cost_obj:347670.00000+9266.12648\n",
            "[16]\ttrain-error:0.16400+0.00234\ttrain-cost_obj:2979760.00000+41216.61558\ttest-error:0.16934+0.00501\ttest-cost_obj:341530.00000+9777.83718\n",
            "[17]\ttrain-error:0.16032+0.00229\ttrain-cost_obj:2922175.00000+37071.38553\ttest-error:0.16575+0.00492\ttest-cost_obj:335390.00000+9326.48916\n",
            "[18]\ttrain-error:0.15666+0.00219\ttrain-cost_obj:2862780.00000+38567.94135\ttest-error:0.16237+0.00508\ttest-cost_obj:329385.00000+9596.04215\n",
            "[19]\ttrain-error:0.15406+0.00221\ttrain-cost_obj:2821830.00000+38081.85395\ttest-error:0.15981+0.00477\ttest-cost_obj:324890.00000+9075.34572\n",
            "[20]\ttrain-error:0.15182+0.00182\ttrain-cost_obj:2786160.00000+31844.15017\ttest-error:0.15774+0.00421\ttest-cost_obj:321300.00000+7767.30326\n",
            "[21]\ttrain-error:0.14881+0.00220\ttrain-cost_obj:2735250.00000+37714.21483\ttest-error:0.15482+0.00416\ttest-cost_obj:315915.00000+7702.37139\n",
            "[22]\ttrain-error:0.14610+0.00264\ttrain-cost_obj:2689655.00000+45449.84296\ttest-error:0.15195+0.00477\ttest-cost_obj:310535.00000+8972.82146\n",
            "[23]\ttrain-error:0.14371+0.00218\ttrain-cost_obj:2648590.00000+38682.29440\ttest-error:0.14945+0.00449\ttest-cost_obj:305835.00000+8755.42832\n",
            "[24]\ttrain-error:0.14189+0.00213\ttrain-cost_obj:2617250.00000+37045.70825\ttest-error:0.14762+0.00425\ttest-cost_obj:302385.00000+8167.03894\n",
            "[25]\ttrain-error:0.13972+0.00203\ttrain-cost_obj:2579755.00000+34076.90163\ttest-error:0.14558+0.00406\ttest-cost_obj:298430.00000+7874.20472\n",
            "[26]\ttrain-error:0.13811+0.00228\ttrain-cost_obj:2551385.00000+39342.98572\ttest-error:0.14416+0.00439\ttest-cost_obj:295585.00000+8500.17794\n",
            "[27]\ttrain-error:0.13613+0.00220\ttrain-cost_obj:2515595.00000+39165.14681\ttest-error:0.14243+0.00403\ttest-cost_obj:292135.00000+7873.62845\n",
            "[28]\ttrain-error:0.13463+0.00220\ttrain-cost_obj:2488990.00000+38717.59161\ttest-error:0.14100+0.00414\ttest-cost_obj:289330.00000+8010.28089\n",
            "[29]\ttrain-error:0.13279+0.00219\ttrain-cost_obj:2455835.00000+39372.15418\ttest-error:0.13939+0.00394\ttest-cost_obj:286085.00000+7711.55140\n",
            "[30]\ttrain-error:0.13110+0.00229\ttrain-cost_obj:2425280.00000+39549.62200\ttest-error:0.13756+0.00355\ttest-cost_obj:282525.00000+6847.85550\n",
            "[31]\ttrain-error:0.12920+0.00239\ttrain-cost_obj:2391255.00000+40675.70190\ttest-error:0.13553+0.00347\ttest-cost_obj:278445.00000+6665.07502\n",
            "[32]\ttrain-error:0.12758+0.00260\ttrain-cost_obj:2361980.00000+44575.76247\ttest-error:0.13402+0.00393\ttest-cost_obj:275430.00000+7653.11048\n",
            "[33]\ttrain-error:0.12586+0.00297\ttrain-cost_obj:2330835.00000+51701.37353\ttest-error:0.13205+0.00366\ttest-cost_obj:271490.00000+7114.34466\n",
            "[34]\ttrain-error:0.12424+0.00265\ttrain-cost_obj:2301420.00000+48023.01115\ttest-error:0.13035+0.00312\ttest-cost_obj:268010.00000+6093.80013\n",
            "[35]\ttrain-error:0.12250+0.00258\ttrain-cost_obj:2269510.00000+47950.82794\ttest-error:0.12879+0.00322\ttest-cost_obj:264840.00000+6320.23734\n",
            "[36]\ttrain-error:0.12124+0.00287\ttrain-cost_obj:2246375.00000+52992.09021\ttest-error:0.12746+0.00291\ttest-cost_obj:262125.00000+5699.00211\n",
            "[37]\ttrain-error:0.11993+0.00295\ttrain-cost_obj:2222085.00000+54976.16324\ttest-error:0.12648+0.00283\ttest-cost_obj:260050.00000+5479.55290\n",
            "[38]\ttrain-error:0.11870+0.00275\ttrain-cost_obj:2199200.00000+51115.53580\ttest-error:0.12531+0.00309\ttest-cost_obj:257635.00000+6077.00790\n",
            "[39]\ttrain-error:0.11712+0.00274\ttrain-cost_obj:2169845.00000+50487.52049\ttest-error:0.12399+0.00334\ttest-cost_obj:254970.00000+6529.44102\n",
            "[40]\ttrain-error:0.11574+0.00277\ttrain-cost_obj:2144360.00000+50701.68538\ttest-error:0.12265+0.00349\ttest-cost_obj:252200.00000+6818.32091\n",
            "[41]\ttrain-error:0.11458+0.00296\ttrain-cost_obj:2122675.00000+54453.63739\ttest-error:0.12144+0.00417\ttest-cost_obj:249690.00000+8279.57728\n",
            "[42]\ttrain-error:0.11315+0.00287\ttrain-cost_obj:2096380.00000+52390.04295\ttest-error:0.11990+0.00405\ttest-cost_obj:246530.00000+8004.75484\n",
            "[43]\ttrain-error:0.11162+0.00287\ttrain-cost_obj:2068090.00000+52795.84169\ttest-error:0.11878+0.00382\ttest-cost_obj:244215.00000+7502.20134\n",
            "[44]\ttrain-error:0.11027+0.00277\ttrain-cost_obj:2042965.00000+50899.94131\ttest-error:0.11771+0.00393\ttest-cost_obj:241905.00000+7734.54750\n",
            "[45]\ttrain-error:0.10928+0.00292\ttrain-cost_obj:2024165.00000+54385.46704\ttest-error:0.11669+0.00389\ttest-cost_obj:239765.00000+7756.12822\n",
            "[46]\ttrain-error:0.10783+0.00284\ttrain-cost_obj:1997560.00000+52886.13145\ttest-error:0.11504+0.00332\ttest-cost_obj:236380.00000+6583.28186\n",
            "[47]\ttrain-error:0.10664+0.00319\ttrain-cost_obj:1975280.00000+59076.68406\ttest-error:0.11404+0.00330\ttest-cost_obj:234290.00000+6411.73923\n",
            "[48]\ttrain-error:0.10531+0.00305\ttrain-cost_obj:1951240.00000+57838.13534\ttest-error:0.11295+0.00328\ttest-cost_obj:232065.00000+6487.79816\n",
            "[49]\ttrain-error:0.10415+0.00291\ttrain-cost_obj:1929500.00000+55305.32524\ttest-error:0.11184+0.00346\ttest-cost_obj:229670.00000+7033.64059\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 20, 'gamma': 3, 'lambda': 3, 'alpha': 0.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.06320+0.00162\ttrain-cost_obj:1017935.00000+24138.26889\ttest-error:0.13528+0.00226\ttest-cost_obj:256385.00000+4589.71949\n",
            "[3]\ttrain-error:0.03736+0.00075\ttrain-cost_obj:629230.00000+10833.60974\ttest-error:0.12555+0.00161\ttest-cost_obj:241750.00000+3314.28725\n",
            "[4]\ttrain-error:0.02871+0.00054\ttrain-cost_obj:489030.00000+8719.61008\ttest-error:0.11947+0.00141\ttest-cost_obj:230510.00000+3045.55414\n",
            "[5]\ttrain-error:0.02385+0.00043\ttrain-cost_obj:418785.00000+7348.19876\ttest-error:0.11377+0.00208\ttest-cost_obj:222275.00000+4391.42631\n",
            "[6]\ttrain-error:0.02038+0.00034\ttrain-cost_obj:361945.00000+6447.10982\ttest-error:0.10669+0.00221\ttest-cost_obj:211450.00000+4632.49393\n",
            "[7]\ttrain-error:0.01763+0.00069\ttrain-cost_obj:315210.00000+12310.23558\ttest-error:0.09990+0.00200\ttest-cost_obj:200195.00000+3954.64600\n",
            "[8]\ttrain-error:0.01351+0.00090\ttrain-cost_obj:246155.00000+15276.21435\ttest-error:0.09384+0.00208\ttest-cost_obj:190090.00000+4533.08945\n",
            "[9]\ttrain-error:0.01093+0.00090\ttrain-cost_obj:201340.00000+15611.24274\ttest-error:0.09153+0.00157\ttest-cost_obj:185720.00000+3180.73891\n",
            "[10]\ttrain-error:0.00843+0.00071\ttrain-cost_obj:157580.00000+12666.69254\ttest-error:0.08958+0.00193\ttest-cost_obj:182420.00000+4007.00636\n",
            "[11]\ttrain-error:0.00682+0.00060\ttrain-cost_obj:128595.00000+10933.46811\ttest-error:0.08845+0.00189\ttest-cost_obj:180210.00000+3953.90946\n",
            "[12]\ttrain-error:0.00532+0.00047\ttrain-cost_obj:101050.00000+8554.91087\ttest-error:0.08774+0.00196\ttest-cost_obj:179080.00000+4024.81055\n",
            "[13]\ttrain-error:0.00405+0.00036\ttrain-cost_obj:77560.00000+6794.54929\ttest-error:0.08722+0.00203\ttest-cost_obj:178105.00000+4210.84611\n",
            "[14]\ttrain-error:0.00300+0.00030\ttrain-cost_obj:58000.00000+5736.50591\ttest-error:0.08694+0.00227\ttest-cost_obj:177510.00000+4761.92188\n",
            "[15]\ttrain-error:0.00225+0.00022\ttrain-cost_obj:43920.00000+4128.81339\ttest-error:0.08686+0.00208\ttest-cost_obj:177430.00000+4536.19885\n",
            "[16]\ttrain-error:0.00170+0.00017\ttrain-cost_obj:33225.00000+3367.80715\ttest-error:0.08684+0.00193\ttest-cost_obj:177245.00000+4203.12086\n",
            "[17]\ttrain-error:0.00128+0.00019\ttrain-cost_obj:25205.00000+3689.00054\ttest-error:0.08694+0.00217\ttest-cost_obj:177460.00000+4654.12720\n",
            "[18]\ttrain-error:0.00094+0.00015\ttrain-cost_obj:18610.00000+2916.83047\ttest-error:0.08704+0.00229\ttest-cost_obj:177655.00000+4791.78724\n",
            "[19]\ttrain-error:0.00067+0.00010\ttrain-cost_obj:13285.00000+1862.66610\ttest-error:0.08704+0.00212\ttest-cost_obj:177685.00000+4763.08986\n",
            "[20]\ttrain-error:0.00049+0.00007\ttrain-cost_obj:9730.00000+1454.68210\ttest-error:0.08780+0.00219\ttest-cost_obj:179475.00000+4800.95043\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.46492+0.00633\ttrain-cost_obj:6823980.00000+82561.82592\ttest-error:0.46621+0.00614\ttest-cost_obj:760920.00000+9069.29435\n",
            "[2]\ttrain-error:0.26185+0.00345\ttrain-cost_obj:4232565.00000+35898.53096\ttest-error:0.26415+0.00457\ttest-cost_obj:474860.00000+7122.98393\n",
            "[3]\ttrain-error:0.23630+0.00287\ttrain-cost_obj:3918655.00000+41700.60821\ttest-error:0.23912+0.00379\ttest-cost_obj:440845.00000+6737.15259\n",
            "[4]\ttrain-error:0.22393+0.00268\ttrain-cost_obj:3780640.00000+36043.70819\ttest-error:0.22689+0.00487\ttest-cost_obj:425875.00000+8726.48984\n",
            "[5]\ttrain-error:0.21441+0.00206\ttrain-cost_obj:3678810.00000+17949.44010\ttest-error:0.21755+0.00466\ttest-cost_obj:415175.00000+7563.10948\n",
            "[6]\ttrain-error:0.20322+0.00250\ttrain-cost_obj:3546385.00000+32546.46717\ttest-error:0.20676+0.00427\ttest-cost_obj:401220.00000+7051.88627\n",
            "[7]\ttrain-error:0.19279+0.00237\ttrain-cost_obj:3411150.00000+43767.41368\ttest-error:0.19678+0.00434\ttest-cost_obj:386815.00000+8178.93789\n",
            "[8]\ttrain-error:0.18551+0.00231\ttrain-cost_obj:3309305.00000+47728.35871\ttest-error:0.19011+0.00399\ttest-cost_obj:376790.00000+8127.87795\n",
            "[9]\ttrain-error:0.17789+0.00310\ttrain-cost_obj:3195020.00000+54873.75602\ttest-error:0.18304+0.00513\ttest-cost_obj:365250.00000+10131.78168\n",
            "[10]\ttrain-error:0.17100+0.00331\ttrain-cost_obj:3088585.00000+60049.75874\ttest-error:0.17609+0.00519\ttest-cost_obj:353280.00000+10062.01272\n",
            "[11]\ttrain-error:0.16627+0.00389\ttrain-cost_obj:3017815.00000+73792.35750\ttest-error:0.17119+0.00598\ttest-cost_obj:345280.00000+11959.03842\n",
            "[12]\ttrain-error:0.16171+0.00351\ttrain-cost_obj:2946070.00000+66357.76594\ttest-error:0.16661+0.00650\ttest-cost_obj:337270.00000+12775.37084\n",
            "[13]\ttrain-error:0.15653+0.00382\ttrain-cost_obj:2861075.00000+71805.48813\ttest-error:0.16216+0.00599\ttest-cost_obj:329260.00000+12090.69477\n",
            "[14]\ttrain-error:0.15226+0.00304\ttrain-cost_obj:2790905.00000+55771.51804\ttest-error:0.15808+0.00538\ttest-cost_obj:321830.00000+10924.79290\n",
            "[15]\ttrain-error:0.14866+0.00397\ttrain-cost_obj:2730445.00000+72429.88489\ttest-error:0.15448+0.00549\ttest-cost_obj:315160.00000+11228.77553\n",
            "[16]\ttrain-error:0.14507+0.00388\ttrain-cost_obj:2669460.00000+71210.58138\ttest-error:0.15085+0.00609\ttest-cost_obj:308340.00000+12692.76960\n",
            "[17]\ttrain-error:0.14149+0.00366\ttrain-cost_obj:2607560.00000+68711.85051\ttest-error:0.14769+0.00634\ttest-cost_obj:302345.00000+13175.95253\n",
            "[18]\ttrain-error:0.13874+0.00298\ttrain-cost_obj:2559455.00000+55539.88409\ttest-error:0.14517+0.00610\ttest-cost_obj:297425.00000+12641.82048\n",
            "[19]\ttrain-error:0.13521+0.00311\ttrain-cost_obj:2497150.00000+57636.95863\ttest-error:0.14172+0.00677\ttest-cost_obj:290595.00000+14040.59205\n",
            "[20]\ttrain-error:0.13270+0.00248\ttrain-cost_obj:2453290.00000+46005.24318\ttest-error:0.13914+0.00637\ttest-cost_obj:285525.00000+13029.37546\n",
            "[21]\ttrain-error:0.12992+0.00253\ttrain-cost_obj:2403585.00000+45904.72225\ttest-error:0.13633+0.00615\ttest-cost_obj:279965.00000+12573.00779\n",
            "[22]\ttrain-error:0.12777+0.00315\ttrain-cost_obj:2365015.00000+57532.61705\ttest-error:0.13388+0.00571\ttest-cost_obj:275000.00000+11696.26009\n",
            "[23]\ttrain-error:0.12529+0.00227\ttrain-cost_obj:2319845.00000+41028.04803\ttest-error:0.13176+0.00530\ttest-cost_obj:270840.00000+11057.75294\n",
            "[24]\ttrain-error:0.12347+0.00251\ttrain-cost_obj:2286330.00000+44625.40308\ttest-error:0.13014+0.00462\ttest-cost_obj:267645.00000+9634.11776\n",
            "[25]\ttrain-error:0.12211+0.00267\ttrain-cost_obj:2261200.00000+46019.20251\ttest-error:0.12869+0.00457\ttest-cost_obj:264770.00000+9470.53853\n",
            "[26]\ttrain-error:0.11990+0.00248\ttrain-cost_obj:2220780.00000+43278.77771\ttest-error:0.12679+0.00402\ttest-cost_obj:260890.00000+8481.41498\n",
            "[27]\ttrain-error:0.11808+0.00224\ttrain-cost_obj:2187530.00000+40405.31029\ttest-error:0.12517+0.00416\ttest-cost_obj:257610.00000+8762.78495\n",
            "[28]\ttrain-error:0.11615+0.00200\ttrain-cost_obj:2151690.00000+37145.95402\ttest-error:0.12346+0.00387\ttest-cost_obj:254060.00000+8120.36945\n",
            "[29]\ttrain-error:0.11376+0.00186\ttrain-cost_obj:2107585.00000+35349.23655\ttest-error:0.12116+0.00433\ttest-cost_obj:249470.00000+9035.04842\n",
            "[30]\ttrain-error:0.11184+0.00207\ttrain-cost_obj:2072265.00000+39541.80098\ttest-error:0.11929+0.00434\ttest-cost_obj:245675.00000+9128.94435\n",
            "[31]\ttrain-error:0.10956+0.00200\ttrain-cost_obj:2029840.00000+38465.47023\ttest-error:0.11716+0.00438\ttest-cost_obj:241220.00000+9299.62902\n",
            "[32]\ttrain-error:0.10784+0.00138\ttrain-cost_obj:1997465.00000+26194.16968\ttest-error:0.11539+0.00409\ttest-cost_obj:237445.00000+8705.26996\n",
            "[33]\ttrain-error:0.10642+0.00125\ttrain-cost_obj:1970650.00000+22588.21595\ttest-error:0.11392+0.00413\ttest-cost_obj:234395.00000+8634.68152\n",
            "[34]\ttrain-error:0.10478+0.00153\ttrain-cost_obj:1940055.00000+26238.23022\ttest-error:0.11221+0.00443\ttest-cost_obj:230830.00000+9218.27533\n",
            "[35]\ttrain-error:0.10361+0.00146\ttrain-cost_obj:1918200.00000+26207.83280\ttest-error:0.11138+0.00425\ttest-cost_obj:228970.00000+8947.46333\n",
            "[36]\ttrain-error:0.10222+0.00187\ttrain-cost_obj:1892660.00000+32966.89855\ttest-error:0.10982+0.00430\ttest-cost_obj:225560.00000+8960.07254\n",
            "[37]\ttrain-error:0.10125+0.00178\ttrain-cost_obj:1874200.00000+31093.13429\ttest-error:0.10900+0.00422\ttest-cost_obj:223805.00000+8843.99372\n",
            "[38]\ttrain-error:0.10001+0.00161\ttrain-cost_obj:1851150.00000+28006.06184\ttest-error:0.10768+0.00371\ttest-cost_obj:221110.00000+7714.26601\n",
            "[39]\ttrain-error:0.09849+0.00158\ttrain-cost_obj:1822620.00000+26410.61529\ttest-error:0.10639+0.00403\ttest-cost_obj:218445.00000+8423.87826\n",
            "[40]\ttrain-error:0.09757+0.00176\ttrain-cost_obj:1805410.00000+29979.74149\ttest-error:0.10551+0.00427\ttest-cost_obj:216610.00000+8939.37358\n",
            "[41]\ttrain-error:0.09676+0.00186\ttrain-cost_obj:1789995.00000+32158.76591\ttest-error:0.10464+0.00416\ttest-cost_obj:214715.00000+8730.26489\n",
            "[42]\ttrain-error:0.09600+0.00188\ttrain-cost_obj:1775870.00000+32746.97085\ttest-error:0.10411+0.00407\ttest-cost_obj:213450.00000+8506.93834\n",
            "[43]\ttrain-error:0.09509+0.00197\ttrain-cost_obj:1758590.00000+34376.90213\ttest-error:0.10322+0.00406\ttest-cost_obj:211690.00000+8459.16071\n",
            "[44]\ttrain-error:0.09425+0.00176\ttrain-cost_obj:1743005.00000+31832.22777\ttest-error:0.10271+0.00376\ttest-cost_obj:210615.00000+7797.85387\n",
            "[45]\ttrain-error:0.09318+0.00187\ttrain-cost_obj:1723375.00000+35414.04559\ttest-error:0.10180+0.00416\ttest-cost_obj:208735.00000+8635.65429\n",
            "[46]\ttrain-error:0.09225+0.00211\ttrain-cost_obj:1705820.00000+39962.83398\ttest-error:0.10109+0.00433\ttest-cost_obj:207235.00000+9058.14689\n",
            "[47]\ttrain-error:0.09131+0.00206\ttrain-cost_obj:1688660.00000+39494.56798\ttest-error:0.10017+0.00416\ttest-cost_obj:205240.00000+8731.80394\n",
            "[48]\ttrain-error:0.09012+0.00238\ttrain-cost_obj:1666200.00000+45726.46936\ttest-error:0.09901+0.00402\ttest-cost_obj:202940.00000+8382.47577\n",
            "[49]\ttrain-error:0.08953+0.00251\ttrain-cost_obj:1655180.00000+48390.50113\ttest-error:0.09881+0.00406\ttest-cost_obj:202525.00000+8529.30976\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 20, 'gamma': 3, 'lambda': 2, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.08066+0.00151\ttrain-cost_obj:1284260.00000+20835.19618\ttest-error:0.13838+0.00273\ttest-cost_obj:257140.00000+4943.26815\n",
            "[2]\ttrain-error:0.04578+0.00074\ttrain-cost_obj:747485.00000+12557.13044\ttest-error:0.12557+0.00271\ttest-cost_obj:236075.00000+5567.01221\n",
            "[3]\ttrain-error:0.03261+0.00040\ttrain-cost_obj:561270.00000+8235.17456\ttest-error:0.11063+0.00275\ttest-cost_obj:213275.00000+5401.30771\n",
            "[4]\ttrain-error:0.02690+0.00028\ttrain-cost_obj:479290.00000+6238.70179\ttest-error:0.10097+0.00210\ttest-cost_obj:199505.00000+3739.81617\n",
            "[5]\ttrain-error:0.02029+0.00055\ttrain-cost_obj:369635.00000+10071.52049\ttest-error:0.09046+0.00218\ttest-cost_obj:182980.00000+4401.03397\n",
            "[6]\ttrain-error:0.01628+0.00052\ttrain-cost_obj:303305.00000+9755.52279\ttest-error:0.08626+0.00166\ttest-cost_obj:175830.00000+3368.39724\n",
            "[7]\ttrain-error:0.01295+0.00054\ttrain-cost_obj:241490.00000+10477.35176\ttest-error:0.08374+0.00155\ttest-cost_obj:170480.00000+2970.11784\n",
            "[8]\ttrain-error:0.01015+0.00054\ttrain-cost_obj:192230.00000+10530.27065\ttest-error:0.08327+0.00130\ttest-cost_obj:170555.00000+2705.77623\n",
            "[9]\ttrain-error:0.00801+0.00057\ttrain-cost_obj:151910.00000+11080.92505\ttest-error:0.08262+0.00192\ttest-cost_obj:168625.00000+3715.59215\n",
            "[10]\ttrain-error:0.00626+0.00042\ttrain-cost_obj:119685.00000+7766.85425\ttest-error:0.08269+0.00152\ttest-cost_obj:169535.00000+3066.43523\n",
            "[11]\ttrain-error:0.00482+0.00046\ttrain-cost_obj:92415.00000+8944.74846\ttest-error:0.08258+0.00127\ttest-cost_obj:168590.00000+2627.52735\n",
            "[12]\ttrain-error:0.00380+0.00037\ttrain-cost_obj:73225.00000+7162.65488\ttest-error:0.08371+0.00144\ttest-cost_obj:171270.00000+3090.00000\n",
            "[13]\ttrain-error:0.00291+0.00026\ttrain-cost_obj:56225.00000+5264.84805\ttest-error:0.08456+0.00124\ttest-cost_obj:172635.00000+2704.16808\n",
            "[14]\ttrain-error:0.00222+0.00018\ttrain-cost_obj:42965.00000+3670.01703\ttest-error:0.08481+0.00131\ttest-cost_obj:173135.00000+2831.70002\n",
            "[15]\ttrain-error:0.00169+0.00017\ttrain-cost_obj:32980.00000+3504.79671\ttest-error:0.08614+0.00159\ttest-cost_obj:175525.00000+3300.70068\n",
            "[16]\ttrain-error:0.00132+0.00011\ttrain-cost_obj:25730.00000+2235.08389\ttest-error:0.08638+0.00157\ttest-cost_obj:176650.00000+3600.06944\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.21739+0.01091\ttrain-cost_obj:3309520.00000+143229.35837\ttest-error:0.23228+0.00981\ttest-cost_obj:397240.00000+14361.14202\n",
            "[2]\ttrain-error:0.13229+0.00198\ttrain-cost_obj:2101525.00000+29119.72055\ttest-error:0.15573+0.00261\ttest-cost_obj:278915.00000+4768.75508\n",
            "[3]\ttrain-error:0.10802+0.00232\ttrain-cost_obj:1782685.00000+41545.23468\ttest-error:0.13242+0.00196\ttest-cost_obj:246020.00000+4652.32200\n",
            "[4]\ttrain-error:0.09369+0.00248\ttrain-cost_obj:1594505.00000+43800.13955\ttest-error:0.11827+0.00236\ttest-cost_obj:226450.00000+4739.14549\n",
            "[5]\ttrain-error:0.08302+0.00221\ttrain-cost_obj:1448930.00000+40785.45206\ttest-error:0.10817+0.00329\ttest-cost_obj:212115.00000+6411.16409\n",
            "[6]\ttrain-error:0.07604+0.00205\ttrain-cost_obj:1351505.00000+38787.38487\ttest-error:0.10101+0.00309\ttest-cost_obj:201185.00000+6513.14248\n",
            "[7]\ttrain-error:0.07063+0.00242\ttrain-cost_obj:1268335.00000+45025.14325\ttest-error:0.09656+0.00297\ttest-cost_obj:194115.00000+6267.69695\n",
            "[8]\ttrain-error:0.06597+0.00271\ttrain-cost_obj:1191530.00000+50422.23319\ttest-error:0.09221+0.00368\ttest-cost_obj:186345.00000+7904.69639\n",
            "[9]\ttrain-error:0.06194+0.00236\ttrain-cost_obj:1123415.00000+42703.16762\ttest-error:0.08866+0.00360\ttest-cost_obj:179740.00000+7500.79329\n",
            "[10]\ttrain-error:0.05883+0.00234\ttrain-cost_obj:1070515.00000+42367.15149\ttest-error:0.08626+0.00375\ttest-cost_obj:175330.00000+7823.59253\n",
            "[11]\ttrain-error:0.05573+0.00219\ttrain-cost_obj:1016040.00000+39083.53106\ttest-error:0.08412+0.00367\ttest-cost_obj:171375.00000+7538.80793\n",
            "[12]\ttrain-error:0.05338+0.00273\ttrain-cost_obj:974475.00000+47868.78550\ttest-error:0.08249+0.00393\ttest-cost_obj:168165.00000+8085.23500\n",
            "[13]\ttrain-error:0.05112+0.00267\ttrain-cost_obj:934365.00000+47391.62927\ttest-error:0.08065+0.00390\ttest-cost_obj:164400.00000+8080.74873\n",
            "[14]\ttrain-error:0.04900+0.00199\ttrain-cost_obj:895975.00000+34058.78925\ttest-error:0.07960+0.00323\ttest-cost_obj:162410.00000+6681.27233\n",
            "[15]\ttrain-error:0.04762+0.00178\ttrain-cost_obj:871335.00000+31567.68165\ttest-error:0.07891+0.00298\ttest-cost_obj:161055.00000+6227.61792\n",
            "[16]\ttrain-error:0.04574+0.00199\ttrain-cost_obj:837725.00000+35667.10144\ttest-error:0.07800+0.00280\ttest-cost_obj:159070.00000+5764.85906\n",
            "[17]\ttrain-error:0.04432+0.00205\ttrain-cost_obj:812055.00000+36741.83209\ttest-error:0.07726+0.00271\ttest-cost_obj:157530.00000+5514.80734\n",
            "[18]\ttrain-error:0.04282+0.00228\ttrain-cost_obj:785140.00000+41009.50378\ttest-error:0.07707+0.00305\ttest-cost_obj:157170.00000+6114.29473\n",
            "[19]\ttrain-error:0.04190+0.00257\ttrain-cost_obj:768225.00000+46527.17620\ttest-error:0.07697+0.00305\ttest-cost_obj:156895.00000+6146.88742\n",
            "[20]\ttrain-error:0.04096+0.00233\ttrain-cost_obj:751330.00000+42185.54966\ttest-error:0.07686+0.00299\ttest-cost_obj:156830.00000+6195.28853\n",
            "[21]\ttrain-error:0.03985+0.00217\ttrain-cost_obj:731245.00000+39350.94948\ttest-error:0.07658+0.00300\ttest-cost_obj:156270.00000+6181.31054\n",
            "[22]\ttrain-error:0.03910+0.00205\ttrain-cost_obj:717725.00000+36932.76492\ttest-error:0.07646+0.00273\ttest-cost_obj:155970.00000+5757.26498\n",
            "[23]\ttrain-error:0.03840+0.00187\ttrain-cost_obj:704770.00000+33521.17391\ttest-error:0.07636+0.00273\ttest-cost_obj:155955.00000+5684.60421\n",
            "[24]\ttrain-error:0.03772+0.00188\ttrain-cost_obj:692455.00000+33885.16969\ttest-error:0.07632+0.00299\ttest-cost_obj:155800.00000+6298.13464\n",
            "[25]\ttrain-error:0.03718+0.00195\ttrain-cost_obj:682625.00000+35285.96924\ttest-error:0.07619+0.00280\ttest-cost_obj:155610.00000+5861.64653\n",
            "[26]\ttrain-error:0.03643+0.00185\ttrain-cost_obj:668875.00000+33499.12872\ttest-error:0.07601+0.00239\ttest-cost_obj:155150.00000+4993.64596\n",
            "[27]\ttrain-error:0.03561+0.00186\ttrain-cost_obj:654065.00000+33873.95792\ttest-error:0.07583+0.00254\ttest-cost_obj:154720.00000+5275.18720\n",
            "[28]\ttrain-error:0.03505+0.00182\ttrain-cost_obj:643935.00000+33115.86516\ttest-error:0.07581+0.00226\ttest-cost_obj:154730.00000+4743.79595\n",
            "[29]\ttrain-error:0.03453+0.00167\ttrain-cost_obj:634365.00000+30623.02279\ttest-error:0.07564+0.00217\ttest-cost_obj:154350.00000+4611.45313\n",
            "[30]\ttrain-error:0.03391+0.00184\ttrain-cost_obj:622950.00000+34008.73417\ttest-error:0.07566+0.00199\ttest-cost_obj:154495.00000+4313.31949\n",
            "[31]\ttrain-error:0.03325+0.00182\ttrain-cost_obj:611265.00000+33923.64257\ttest-error:0.07560+0.00223\ttest-cost_obj:154280.00000+4787.28524\n",
            "[32]\ttrain-error:0.03265+0.00203\ttrain-cost_obj:600360.00000+37441.11243\ttest-error:0.07519+0.00194\ttest-cost_obj:153370.00000+4168.22504\n",
            "[33]\ttrain-error:0.03212+0.00249\ttrain-cost_obj:590295.00000+45913.78578\ttest-error:0.07541+0.00227\ttest-cost_obj:153780.00000+4859.43412\n",
            "[34]\ttrain-error:0.03170+0.00247\ttrain-cost_obj:582545.00000+45483.91172\ttest-error:0.07562+0.00188\ttest-cost_obj:154280.00000+4031.76140\n",
            "[35]\ttrain-error:0.03132+0.00236\ttrain-cost_obj:575765.00000+43603.16531\ttest-error:0.07560+0.00190\ttest-cost_obj:154200.00000+4152.58955\n",
            "[36]\ttrain-error:0.03098+0.00244\ttrain-cost_obj:569790.00000+44909.96437\ttest-error:0.07602+0.00175\ttest-cost_obj:155125.00000+3752.01612\n",
            "[37]\ttrain-error:0.03076+0.00252\ttrain-cost_obj:565775.00000+46252.70938\ttest-error:0.07621+0.00189\ttest-cost_obj:155545.00000+4002.96453\n",
            "{'objective': 'binary:hinge', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 3, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.05988+0.00072\ttrain-cost_obj:935250.00000+10644.85791\ttest-error:0.14141+0.00264\ttest-cost_obj:265415.00000+5134.83447\n",
            "[3]\ttrain-error:0.02934+0.00081\ttrain-cost_obj:485405.00000+12971.82427\ttest-error:0.13061+0.00248\ttest-cost_obj:250900.00000+4804.37301\n",
            "[4]\ttrain-error:0.01851+0.00061\ttrain-cost_obj:318170.00000+10402.86499\ttest-error:0.12458+0.00214\ttest-cost_obj:239470.00000+4309.82598\n",
            "[5]\ttrain-error:0.01370+0.00055\ttrain-cost_obj:249260.00000+9897.14100\ttest-error:0.11703+0.00225\ttest-cost_obj:228665.00000+4738.35678\n",
            "[6]\ttrain-error:0.01190+0.00040\ttrain-cost_obj:218775.00000+7862.67289\ttest-error:0.10942+0.00205\ttest-cost_obj:216905.00000+4367.40484\n",
            "[7]\ttrain-error:0.01041+0.00042\ttrain-cost_obj:190490.00000+8753.62211\ttest-error:0.10241+0.00211\ttest-cost_obj:205160.00000+4210.33253\n",
            "[8]\ttrain-error:0.00772+0.00058\ttrain-cost_obj:144045.00000+10482.44843\ttest-error:0.09726+0.00201\ttest-cost_obj:197135.00000+3954.93679\n",
            "[9]\ttrain-error:0.00583+0.00048\ttrain-cost_obj:110635.00000+9012.21532\ttest-error:0.09422+0.00244\ttest-cost_obj:191015.00000+4860.40379\n",
            "[10]\ttrain-error:0.00418+0.00037\ttrain-cost_obj:80890.00000+6904.52026\ttest-error:0.09227+0.00209\ttest-cost_obj:187925.00000+4275.99404\n",
            "[11]\ttrain-error:0.00309+0.00032\ttrain-cost_obj:60400.00000+6049.13217\ttest-error:0.09136+0.00278\ttest-cost_obj:186045.00000+5450.34173\n",
            "[12]\ttrain-error:0.00219+0.00021\ttrain-cost_obj:43505.00000+4059.09165\ttest-error:0.09076+0.00174\ttest-cost_obj:185160.00000+3391.15025\n",
            "[13]\ttrain-error:0.00153+0.00019\ttrain-cost_obj:30830.00000+3776.25476\ttest-error:0.09018+0.00251\ttest-cost_obj:184030.00000+5196.93179\n",
            "[14]\ttrain-error:0.00103+0.00017\ttrain-cost_obj:21050.00000+3511.12518\ttest-error:0.09049+0.00243\ttest-cost_obj:184885.00000+4796.98082\n",
            "[15]\ttrain-error:0.00066+0.00014\ttrain-cost_obj:13665.00000+2700.00463\ttest-error:0.08986+0.00234\ttest-cost_obj:183460.00000+4922.99705\n",
            "[16]\ttrain-error:0.00038+0.00011\ttrain-cost_obj:7895.00000+2175.94232\ttest-error:0.08990+0.00183\ttest-cost_obj:183780.00000+3526.20192\n",
            "[17]\ttrain-error:0.00022+0.00008\ttrain-cost_obj:4590.00000+1643.44151\ttest-error:0.08959+0.00106\ttest-cost_obj:183135.00000+2244.88864\n",
            "[18]\ttrain-error:0.00013+0.00004\ttrain-cost_obj:2645.00000+712.19730\ttest-error:0.08998+0.00169\ttest-cost_obj:183950.00000+3290.44070\n",
            "[19]\ttrain-error:0.00008+0.00003\ttrain-cost_obj:1600.00000+633.64028\ttest-error:0.09007+0.00139\ttest-cost_obj:184175.00000+2884.98267\n",
            "[20]\ttrain-error:0.00005+0.00002\ttrain-cost_obj:965.00000+417.16304\ttest-error:0.09029+0.00172\ttest-cost_obj:184580.00000+3538.65794\n",
            "[21]\ttrain-error:0.00003+0.00001\ttrain-cost_obj:575.00000+234.78714\ttest-error:0.09083+0.00182\ttest-cost_obj:185710.00000+3796.49839\n",
            "[22]\ttrain-error:0.00002+0.00001\ttrain-cost_obj:345.00000+179.51323\ttest-error:0.09076+0.00220\ttest-cost_obj:185370.00000+4566.73844\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 20, 'gamma': 0, 'lambda': 1, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.05660+0.00146\ttrain-cost_obj:885080.00000+18881.31616\ttest-error:0.14228+0.00315\ttest-cost_obj:268185.00000+5867.58255\n",
            "[2]\ttrain-error:0.02474+0.00068\ttrain-cost_obj:404720.00000+12022.52469\ttest-error:0.13357+0.00255\ttest-cost_obj:254645.00000+4865.56523\n",
            "[3]\ttrain-error:0.01536+0.00062\ttrain-cost_obj:271980.00000+11536.53327\ttest-error:0.11788+0.00238\ttest-cost_obj:228455.00000+5024.11435\n",
            "[4]\ttrain-error:0.01239+0.00041\ttrain-cost_obj:229035.00000+7720.17001\ttest-error:0.10817+0.00296\ttest-cost_obj:215605.00000+6032.26533\n",
            "[5]\ttrain-error:0.00875+0.00037\ttrain-cost_obj:163075.00000+7224.13490\ttest-error:0.09831+0.00214\ttest-cost_obj:198345.00000+4750.76047\n",
            "[6]\ttrain-error:0.00632+0.00028\ttrain-cost_obj:121945.00000+5416.47718\ttest-error:0.09392+0.00252\ttest-cost_obj:192160.00000+5363.85123\n",
            "[7]\ttrain-error:0.00441+0.00027\ttrain-cost_obj:84070.00000+5242.33726\ttest-error:0.09333+0.00237\ttest-cost_obj:188120.00000+5145.73610\n",
            "[8]\ttrain-error:0.00329+0.00020\ttrain-cost_obj:64955.00000+3897.33563\ttest-error:0.09191+0.00244\ttest-cost_obj:189040.00000+5234.44362\n",
            "[9]\ttrain-error:0.00220+0.00012\ttrain-cost_obj:42665.00000+2240.65281\ttest-error:0.09148+0.00272\ttest-cost_obj:184365.00000+5582.83306\n",
            "[10]\ttrain-error:0.00169+0.00012\ttrain-cost_obj:33900.00000+2283.52797\ttest-error:0.09156+0.00338\ttest-cost_obj:188560.00000+6840.02193\n",
            "[11]\ttrain-error:0.00114+0.00009\ttrain-cost_obj:22210.00000+1727.10741\ttest-error:0.09176+0.00319\ttest-cost_obj:184735.00000+6405.42934\n",
            "[12]\ttrain-error:0.00093+0.00010\ttrain-cost_obj:18830.00000+2147.46362\ttest-error:0.09166+0.00325\ttest-cost_obj:188805.00000+6569.26366\n",
            "[13]\ttrain-error:0.00064+0.00008\ttrain-cost_obj:12515.00000+1617.25848\ttest-error:0.09174+0.00317\ttest-cost_obj:184740.00000+6333.43509\n",
            "[14]\ttrain-error:0.00054+0.00011\ttrain-cost_obj:10970.00000+2176.25826\ttest-error:0.09226+0.00329\ttest-cost_obj:190065.00000+6619.82062\n",
            "{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 3, 'alpha': 1.0}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[3]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[4]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "{'objective': 'binary:hinge', 'eta': 0.35, 'max_depth': 5, 'gamma': 0, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.46491+0.00632\ttrain-cost_obj:6823830.00000+82474.03591\ttest-error:0.46621+0.00613\ttest-cost_obj:760940.00000+9070.49613\n",
            "[2]\ttrain-error:0.26184+0.00344\ttrain-cost_obj:4232705.00000+35889.90422\ttest-error:0.26413+0.00456\ttest-cost_obj:474880.00000+7109.89451\n",
            "[3]\ttrain-error:0.23631+0.00286\ttrain-cost_obj:3919005.00000+41673.91540\ttest-error:0.23908+0.00378\ttest-cost_obj:440805.00000+6727.79496\n",
            "[4]\ttrain-error:0.22415+0.00220\ttrain-cost_obj:3785710.00000+29827.07495\ttest-error:0.22706+0.00457\ttest-cost_obj:426310.00000+8392.96729\n",
            "[5]\ttrain-error:0.21423+0.00218\ttrain-cost_obj:3676810.00000+21135.50094\ttest-error:0.21736+0.00462\ttest-cost_obj:414915.00000+7479.64070\n",
            "[6]\ttrain-error:0.20345+0.00239\ttrain-cost_obj:3546575.00000+34591.82888\ttest-error:0.20738+0.00444\ttest-cost_obj:402015.00000+7888.15726\n",
            "[7]\ttrain-error:0.19202+0.00265\ttrain-cost_obj:3396460.00000+42154.99852\ttest-error:0.19697+0.00466\ttest-cost_obj:387025.00000+8912.80680\n",
            "[8]\ttrain-error:0.18428+0.00286\ttrain-cost_obj:3285625.00000+46644.64198\ttest-error:0.18880+0.00452\ttest-cost_obj:374120.00000+8504.79865\n",
            "[9]\ttrain-error:0.17727+0.00183\ttrain-cost_obj:3184160.00000+27390.14239\ttest-error:0.18228+0.00481\ttest-cost_obj:363870.00000+9005.08745\n",
            "[10]\ttrain-error:0.17128+0.00236\ttrain-cost_obj:3093815.00000+41551.33602\ttest-error:0.17651+0.00512\ttest-cost_obj:354245.00000+9814.59245\n",
            "[11]\ttrain-error:0.16615+0.00263\ttrain-cost_obj:3015535.00000+49052.66583\ttest-error:0.17162+0.00477\ttest-cost_obj:346115.00000+9227.59584\n",
            "[12]\ttrain-error:0.16084+0.00301\ttrain-cost_obj:2930480.00000+57704.34646\ttest-error:0.16639+0.00540\ttest-cost_obj:336595.00000+10537.79982\n",
            "[13]\ttrain-error:0.15588+0.00360\ttrain-cost_obj:2849780.00000+65396.84702\ttest-error:0.16128+0.00554\ttest-cost_obj:327270.00000+10925.98279\n",
            "[14]\ttrain-error:0.15215+0.00285\ttrain-cost_obj:2789320.00000+52524.78558\ttest-error:0.15788+0.00502\ttest-cost_obj:321320.00000+9993.47787\n",
            "[15]\ttrain-error:0.14893+0.00290\ttrain-cost_obj:2736275.00000+52492.03868\ttest-error:0.15484+0.00467\ttest-cost_obj:315920.00000+9491.08002\n",
            "[16]\ttrain-error:0.14476+0.00307\ttrain-cost_obj:2664530.00000+56799.56514\ttest-error:0.15061+0.00489\ttest-cost_obj:307705.00000+9603.68289\n",
            "[17]\ttrain-error:0.14134+0.00303\ttrain-cost_obj:2605780.00000+55143.93530\ttest-error:0.14736+0.00459\ttest-cost_obj:301735.00000+8761.73641\n",
            "[18]\ttrain-error:0.13844+0.00304\ttrain-cost_obj:2555090.00000+55443.26740\ttest-error:0.14449+0.00490\ttest-cost_obj:296015.00000+9548.63996\n",
            "[19]\ttrain-error:0.13558+0.00304\ttrain-cost_obj:2505635.00000+56301.74087\ttest-error:0.14214+0.00546\ttest-cost_obj:291555.00000+10715.60661\n",
            "[20]\ttrain-error:0.13322+0.00285\ttrain-cost_obj:2463785.00000+51967.42754\ttest-error:0.13981+0.00524\ttest-cost_obj:287070.00000+10560.73388\n",
            "[21]\ttrain-error:0.13005+0.00296\ttrain-cost_obj:2406345.00000+53722.56253\ttest-error:0.13706+0.00501\ttest-cost_obj:281460.00000+10075.83247\n",
            "[22]\ttrain-error:0.12755+0.00310\ttrain-cost_obj:2361270.00000+54925.65521\ttest-error:0.13441+0.00529\ttest-cost_obj:276265.00000+10611.03317\n",
            "[23]\ttrain-error:0.12508+0.00288\ttrain-cost_obj:2316215.00000+51720.43141\ttest-error:0.13164+0.00447\ttest-cost_obj:270510.00000+8931.65158\n",
            "[24]\ttrain-error:0.12289+0.00299\ttrain-cost_obj:2276020.00000+54398.10291\ttest-error:0.12949+0.00443\ttest-cost_obj:266100.00000+8981.84280\n",
            "[25]\ttrain-error:0.12028+0.00271\ttrain-cost_obj:2228520.00000+51808.46552\ttest-error:0.12701+0.00416\ttest-cost_obj:260995.00000+8402.51302\n",
            "[26]\ttrain-error:0.11865+0.00266\ttrain-cost_obj:2198010.00000+51378.98306\ttest-error:0.12531+0.00437\ttest-cost_obj:257535.00000+8793.20903\n",
            "[27]\ttrain-error:0.11716+0.00281\ttrain-cost_obj:2170065.00000+54163.50732\ttest-error:0.12397+0.00435\ttest-cost_obj:254845.00000+8759.03676\n",
            "[28]\ttrain-error:0.11541+0.00271\ttrain-cost_obj:2137980.00000+52221.80675\ttest-error:0.12224+0.00465\ttest-cost_obj:251450.00000+9292.90052\n",
            "[29]\ttrain-error:0.11363+0.00285\ttrain-cost_obj:2105250.00000+54912.12070\ttest-error:0.12027+0.00469\ttest-cost_obj:247400.00000+9387.99766\n",
            "[30]\ttrain-error:0.11214+0.00302\ttrain-cost_obj:2077315.00000+57125.62932\ttest-error:0.11909+0.00499\ttest-cost_obj:244975.00000+10023.12950\n",
            "[31]\ttrain-error:0.11058+0.00269\ttrain-cost_obj:2048430.00000+50731.71690\ttest-error:0.11786+0.00465\ttest-cost_obj:242390.00000+9296.23042\n",
            "[32]\ttrain-error:0.10877+0.00235\ttrain-cost_obj:2015330.00000+44920.19702\ttest-error:0.11569+0.00408\ttest-cost_obj:238035.00000+8203.81161\n",
            "[33]\ttrain-error:0.10715+0.00212\ttrain-cost_obj:1985990.00000+40811.74341\ttest-error:0.11430+0.00295\ttest-cost_obj:235195.00000+5819.59835\n",
            "[34]\ttrain-error:0.10588+0.00237\ttrain-cost_obj:1962660.00000+45421.87138\ttest-error:0.11347+0.00330\ttest-cost_obj:233580.00000+6530.09188\n",
            "[35]\ttrain-error:0.10454+0.00225\ttrain-cost_obj:1937890.00000+44038.45365\ttest-error:0.11194+0.00313\ttest-cost_obj:230350.00000+6454.18469\n",
            "[36]\ttrain-error:0.10323+0.00255\ttrain-cost_obj:1913105.00000+49438.33760\ttest-error:0.11079+0.00295\ttest-cost_obj:227990.00000+6159.53732\n",
            "[37]\ttrain-error:0.10195+0.00244\ttrain-cost_obj:1888895.00000+46907.36323\ttest-error:0.10954+0.00304\ttest-cost_obj:225290.00000+6170.64826\n",
            "[38]\ttrain-error:0.10006+0.00266\ttrain-cost_obj:1854015.00000+51488.33387\ttest-error:0.10739+0.00346\ttest-cost_obj:220795.00000+7321.21745\n",
            "[39]\ttrain-error:0.09874+0.00258\ttrain-cost_obj:1829240.00000+49420.75374\ttest-error:0.10612+0.00334\ttest-cost_obj:218070.00000+6980.30085\n",
            "[40]\ttrain-error:0.09742+0.00255\ttrain-cost_obj:1804145.00000+49005.21630\ttest-error:0.10512+0.00380\ttest-cost_obj:215945.00000+7825.07029\n",
            "[41]\ttrain-error:0.09605+0.00238\ttrain-cost_obj:1778535.00000+45177.51127\ttest-error:0.10406+0.00363\ttest-cost_obj:213805.00000+7548.16037\n",
            "[42]\ttrain-error:0.09477+0.00208\ttrain-cost_obj:1754380.00000+38454.13632\ttest-error:0.10274+0.00348\ttest-cost_obj:211055.00000+7154.35008\n",
            "[43]\ttrain-error:0.09363+0.00209\ttrain-cost_obj:1732890.00000+39344.90945\ttest-error:0.10161+0.00355\ttest-cost_obj:208790.00000+7207.00354\n",
            "[44]\ttrain-error:0.09252+0.00192\ttrain-cost_obj:1712090.00000+36147.97228\ttest-error:0.10046+0.00318\ttest-cost_obj:206405.00000+6546.92485\n",
            "[45]\ttrain-error:0.09166+0.00203\ttrain-cost_obj:1695825.00000+38006.38269\ttest-error:0.10008+0.00310\ttest-cost_obj:205585.00000+6442.01250\n",
            "[46]\ttrain-error:0.09080+0.00189\ttrain-cost_obj:1679600.00000+34941.46534\ttest-error:0.09922+0.00332\ttest-cost_obj:203800.00000+6861.96036\n",
            "[47]\ttrain-error:0.08983+0.00164\ttrain-cost_obj:1661235.00000+29758.88985\ttest-error:0.09848+0.00280\ttest-cost_obj:202225.00000+5862.47601\n",
            "[48]\ttrain-error:0.08929+0.00179\ttrain-cost_obj:1650595.00000+32811.84580\ttest-error:0.09798+0.00273\ttest-cost_obj:201200.00000+5683.04496\n",
            "[49]\ttrain-error:0.08856+0.00202\ttrain-cost_obj:1637090.00000+37175.08440\ttest-error:0.09759+0.00243\ttest-cost_obj:200410.00000+4966.12525\n",
            "{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 20, 'gamma': 3, 'lambda': 1, 'alpha': 0.1}\n",
            "[0]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[1]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[2]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[3]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[4]\ttrain-error:0.59877+0.00000\ttrain-cost_obj:8622270.00000+45.82576\ttest-error:0.59877+0.00003\ttest-cost_obj:958030.00000+45.82576\n",
            "[5]\ttrain-error:0.07339+0.00180\ttrain-cost_obj:1122085.00000+25326.46886\ttest-error:0.14763+0.00298\ttest-cost_obj:271695.00000+5579.80510\n",
            "[6]\ttrain-error:0.03998+0.00126\ttrain-cost_obj:621200.00000+18092.22209\ttest-error:0.13321+0.00200\ttest-cost_obj:247720.00000+4190.11933\n",
            "[7]\ttrain-error:0.02955+0.00069\ttrain-cost_obj:466795.00000+10159.48941\ttest-error:0.12522+0.00175\ttest-cost_obj:235025.00000+3568.28040\n",
            "[8]\ttrain-error:0.02261+0.00037\ttrain-cost_obj:364140.00000+5345.59632\ttest-error:0.12146+0.00163\ttest-cost_obj:229980.00000+3342.69352\n",
            "[9]\ttrain-error:0.01937+0.00028\ttrain-cost_obj:313645.00000+4103.19692\ttest-error:0.11959+0.00192\ttest-cost_obj:227315.00000+3893.33084\n",
            "[10]\ttrain-error:0.01757+0.00031\ttrain-cost_obj:287105.00000+5014.15247\ttest-error:0.11873+0.00209\ttest-cost_obj:226875.00000+4338.33205\n",
            "[11]\ttrain-error:0.01500+0.00028\ttrain-cost_obj:247895.00000+4659.79882\ttest-error:0.11724+0.00204\ttest-cost_obj:225280.00000+4163.96446\n",
            "[12]\ttrain-error:0.01358+0.00034\ttrain-cost_obj:227050.00000+5872.30789\ttest-error:0.11578+0.00227\ttest-cost_obj:223780.00000+4762.46785\n",
            "[13]\ttrain-error:0.01240+0.00037\ttrain-cost_obj:209040.00000+6565.16565\ttest-error:0.11423+0.00214\ttest-cost_obj:221835.00000+4349.02575\n",
            "[14]\ttrain-error:0.01136+0.00030\ttrain-cost_obj:193900.00000+5379.82342\ttest-error:0.11154+0.00237\ttest-cost_obj:218295.00000+5009.71307\n",
            "[15]\ttrain-error:0.01040+0.00028\ttrain-cost_obj:179335.00000+4992.99760\ttest-error:0.10798+0.00249\ttest-cost_obj:213330.00000+5115.13441\n",
            "[16]\ttrain-error:0.00920+0.00030\ttrain-cost_obj:160180.00000+5260.95048\ttest-error:0.10392+0.00219\ttest-cost_obj:207145.00000+4517.21430\n",
            "[17]\ttrain-error:0.00789+0.00032\ttrain-cost_obj:139790.00000+5729.34551\ttest-error:0.09983+0.00207\ttest-cost_obj:200640.00000+4233.54461\n",
            "[18]\ttrain-error:0.00669+0.00025\ttrain-cost_obj:120330.00000+4923.93136\ttest-error:0.09750+0.00227\ttest-cost_obj:196710.00000+4612.90581\n",
            "[19]\ttrain-error:0.00599+0.00031\ttrain-cost_obj:108890.00000+5884.50508\ttest-error:0.09524+0.00231\ttest-cost_obj:192960.00000+4778.74461\n",
            "[20]\ttrain-error:0.00521+0.00043\ttrain-cost_obj:95770.00000+7904.34058\ttest-error:0.09412+0.00220\ttest-cost_obj:190960.00000+4530.49666\n",
            "[21]\ttrain-error:0.00456+0.00055\ttrain-cost_obj:84810.00000+10067.36808\ttest-error:0.09337+0.00225\ttest-cost_obj:189815.00000+4766.13313\n",
            "[22]\ttrain-error:0.00395+0.00042\ttrain-cost_obj:74330.00000+7689.51234\ttest-error:0.09229+0.00179\ttest-cost_obj:187770.00000+3705.28002\n",
            "[23]\ttrain-error:0.00337+0.00043\ttrain-cost_obj:64105.00000+8000.45155\ttest-error:0.09157+0.00234\ttest-cost_obj:186600.00000+4880.62496\n",
            "[24]\ttrain-error:0.00284+0.00038\ttrain-cost_obj:54630.00000+7212.91203\ttest-error:0.09073+0.00198\ttest-cost_obj:185110.00000+3942.44848\n",
            "[25]\ttrain-error:0.00242+0.00033\ttrain-cost_obj:47195.00000+6244.45554\ttest-error:0.09001+0.00245\ttest-cost_obj:183890.00000+4887.88298\n",
            "[26]\ttrain-error:0.00205+0.00032\ttrain-cost_obj:40255.00000+6076.57181\ttest-error:0.08954+0.00227\ttest-cost_obj:183050.00000+4556.25943\n",
            "[27]\ttrain-error:0.00173+0.00029\ttrain-cost_obj:34395.00000+5660.01104\ttest-error:0.08891+0.00237\ttest-cost_obj:181895.00000+4778.04615\n",
            "[28]\ttrain-error:0.00144+0.00025\ttrain-cost_obj:29015.00000+4815.34267\ttest-error:0.08850+0.00222\ttest-cost_obj:181130.00000+4441.63258\n",
            "[29]\ttrain-error:0.00118+0.00019\ttrain-cost_obj:23985.00000+3812.81064\ttest-error:0.08866+0.00243\ttest-cost_obj:181615.00000+4889.53219\n",
            "[30]\ttrain-error:0.00097+0.00018\ttrain-cost_obj:19805.00000+3575.92296\ttest-error:0.08791+0.00235\ttest-cost_obj:180210.00000+4824.56216\n",
            "[31]\ttrain-error:0.00076+0.00014\ttrain-cost_obj:15680.00000+2925.50850\ttest-error:0.08778+0.00285\ttest-cost_obj:179815.00000+5769.23088\n",
            "[32]\ttrain-error:0.00059+0.00011\ttrain-cost_obj:12300.00000+2243.88057\ttest-error:0.08760+0.00261\ttest-cost_obj:179660.00000+5340.96433\n",
            "[33]\ttrain-error:0.00045+0.00009\ttrain-cost_obj:9455.00000+1794.63785\ttest-error:0.08731+0.00259\ttest-cost_obj:179000.00000+5205.57394\n",
            "[34]\ttrain-error:0.00032+0.00007\ttrain-cost_obj:6775.00000+1522.04632\ttest-error:0.08707+0.00255\ttest-cost_obj:178640.00000+5293.80770\n",
            "[35]\ttrain-error:0.00024+0.00006\ttrain-cost_obj:5070.00000+1274.00942\ttest-error:0.08693+0.00262\ttest-cost_obj:178360.00000+5180.86865\n",
            "[36]\ttrain-error:0.00018+0.00005\ttrain-cost_obj:3810.00000+1144.29017\ttest-error:0.08692+0.00254\ttest-cost_obj:178340.00000+5031.34177\n",
            "[37]\ttrain-error:0.00014+0.00004\ttrain-cost_obj:2880.00000+953.99161\ttest-error:0.08643+0.00275\ttest-cost_obj:177370.00000+5424.26032\n",
            "[38]\ttrain-error:0.00009+0.00005\ttrain-cost_obj:1980.00000+956.86990\ttest-error:0.08643+0.00244\ttest-cost_obj:177475.00000+4843.56532\n",
            "[39]\ttrain-error:0.00006+0.00003\ttrain-cost_obj:1355.00000+635.78691\ttest-error:0.08633+0.00280\ttest-cost_obj:177085.00000+5472.57024\n",
            "[40]\ttrain-error:0.00005+0.00002\ttrain-cost_obj:1020.00000+493.05172\ttest-error:0.08627+0.00249\ttest-cost_obj:177305.00000+4778.25543\n",
            "[41]\ttrain-error:0.00003+0.00002\ttrain-cost_obj:625.00000+353.02266\ttest-error:0.08599+0.00252\ttest-cost_obj:176655.00000+4796.32411\n",
            "[42]\ttrain-error:0.00002+0.00001\ttrain-cost_obj:435.00000+318.62988\ttest-error:0.08576+0.00247\ttest-cost_obj:176325.00000+4783.47416\n",
            "[43]\ttrain-error:0.00001+0.00001\ttrain-cost_obj:240.00000+238.53721\ttest-error:0.08594+0.00246\ttest-cost_obj:176640.00000+4715.38970\n",
            "[44]\ttrain-error:0.00001+0.00001\ttrain-cost_obj:185.00000+159.76545\ttest-error:0.08587+0.00261\ttest-cost_obj:176500.00000+5108.66910\n",
            "[45]\ttrain-error:0.00000+0.00001\ttrain-cost_obj:95.00000+108.28204\ttest-error:0.08594+0.00261\ttest-cost_obj:176490.00000+4982.45923\n",
            "[46]\ttrain-error:0.00000+0.00000\ttrain-cost_obj:15.00000+45.00000\ttest-error:0.08587+0.00255\ttest-cost_obj:176355.00000+4806.11329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXJEj4W_8T-H",
        "outputId": "0609f2f5-6f37-4810-c288-bed63097e3a6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:hinge',\n",
              " 'eta': 0.1,\n",
              " 'max_depth': 10,\n",
              " 'gamma': 1,\n",
              " 'lambda': 1,\n",
              " 'alpha': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = { 'eta':0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'objective': 'binary:hinge'}\n",
        "\n",
        "XGBModel = xgb.XGBClassifier(params=hyperparams, early_stopping_rounds=5)"
      ],
      "metadata": {
        "id": "1WsS7wIP8Y1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}