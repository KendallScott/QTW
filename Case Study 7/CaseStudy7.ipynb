{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "#df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d9a704-a571-4abc-9a9a-ea7df483874d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42536833-24d2-4e05-90e0-9d57669d6067"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "16a967a7-5ed6-47ae-caaa-ddb32410c0a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "1954fd06-e8d2-40c4-ccf1-880e3ef8b0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: x24, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "09d36f54-7ee1-44f7-f9c2-9ce747f4e6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "a0efa5c4-713c-4818-d2cb-320c007e429e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: x29, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "4a36c65b-a230-4d50-b37a-ae90eb95a868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3, figsize = (25, 5))\n",
        "plt.subplots_adjust(wspace=.18,hspace=1)\n",
        "fig.subplots_adjust(top = .96)\n",
        "sns.set(rc={'figure.figsize':(5.5,6)})\n",
        "sns.countplot(x = 'x29', data = df, hue = 'y', ax = axes[0]);\n",
        "sns.countplot(x = 'x30', data = df, hue = 'y', ax = axes[1]);\n",
        "sns.countplot(x = 'x24', data = df, hue = 'y', ax = axes[2]);\n",
        "\n",
        "fig.suptitle('Count plots for categorical features')"
      ],
      "metadata": {
        "id": "lCaK4Zy0zbuh",
        "outputId": "cb10f066-442b-4b3a-d17c-7df4df7bdc55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Count plots for categorical features')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "346dfad2-0185-4168-8496-d7934e4da77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: x30, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "b0997e5c-7a7b-4a9c-ea83-b9dd64a89ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "1bcc3381-b6b1-4a4c-a6f3-d276d4d17156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: x32, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "76474cff-c3ba-4151-bc2a-c9ff5df37deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: x37, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "0214f17a-5d14-44ed-fa7d-1c4af833df50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "c42b6e99-2a8a-4400-89d0-9aeff372dcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-81588e7b-6ef5-4ad9-9237-5c79a0a73040\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81588e7b-6ef5-4ad9-9237-5c79a0a73040')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6dce488e-1979-40c0-8008-b0655edbef8b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6dce488e-1979-40c0-8008-b0655edbef8b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6dce488e-1979-40c0-8008-b0655edbef8b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81588e7b-6ef5-4ad9-9237-5c79a0a73040 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81588e7b-6ef5-4ad9-9237-5c79a0a73040');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24', 'x29', 'y']].groupby(['x24', 'x29']).mean()"
      ],
      "metadata": {
        "id": "ZDFgT6AhXMgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#created categorical variable for high/low volume based on month/continent\n",
        "conditions = [\n",
        "    (df['x24'] == 'america'),\n",
        "    (df['x24'] =='asia') & (df['x29'] == 'Jan'),\n",
        "    (df['x24'] =='asia') & (df['x29'] != 'Jan'),\n",
        "    (df['x24'] =='euorpe')\n",
        "    ]\n",
        "\n",
        "values = ['low', 'low', 'high', 'high']\n",
        "df['Volume'] = np.select(conditions, values)\n",
        "df[['Volume', 'y']].groupby(['Volume']).count()"
      ],
      "metadata": {
        "id": "Ul1CRi4b4kGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ccd670f2-3444-470f-d4db-9af8cd07cb85"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y\n",
              "Volume        \n",
              "high    155522\n",
              "low       4478"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fe943036-4b94-4dc0-acc8-e0c87ddcc7a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>155522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>4478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe943036-4b94-4dc0-acc8-e0c87ddcc7a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1038722a-cb2b-4232-8c4b-fc4050fab785\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1038722a-cb2b-4232-8c4b-fc4050fab785')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1038722a-cb2b-4232-8c4b-fc4050fab785 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe943036-4b94-4dc0-acc8-e0c87ddcc7a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe943036-4b94-4dc0-acc8-e0c87ddcc7a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "539c08a3-642d-486a-c5fa-95619aa2aa75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1zPG-Q7z7U3",
        "outputId": "1b97fe4b-8997-4c2f-d7f9-23b3d6234e34"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 69)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "8619f934-20b3-4743-e7aa-a834eda54161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    95803\n",
              "1    64197\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost_func(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratifiedkfold by high/lower volume created category\n",
        "#in order to get an equal distribution of the 0s during high volume time and 1s during low, replace with binary imediately after\n",
        "\n",
        "y=df[['Volume', 'y']].astype(str).apply(\"-\".join, axis=1)\n",
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)\n",
        "y = df['y'].values.flatten()"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "#params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "#lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "#lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lr_params = lr_clf.best_params_\n",
        "lr_params ={'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1"
      ],
      "metadata": {
        "id": "3katCHeBPQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e023ad78-614b-46e4-b81f-add9c9acf5ea"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7707427436265313,\n",
              "  'recall': 0.7289646462010584,\n",
              "  'f1-score': 0.7492717782558083,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.625796224239804,\n",
              "  'recall': 0.6764179011480287,\n",
              "  'f1-score': 0.6501231407247711,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.70788125,\n",
              " 'macro avg': {'precision': 0.6982694839331676,\n",
              "  'recall': 0.7026912736745435,\n",
              "  'f1-score': 0.6996974594902896,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.7125856704698453,\n",
              "  'recall': 0.70788125,\n",
              "  'f1-score': 0.7094902464834333,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)"
      ],
      "metadata": {
        "id": "ent8XHdUPayB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "ed15d045-3373-4f21-f504-56bc2134268f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x780ac7aeb400>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost_func(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005b96e0-d254-4027-e210-e0ac0738e07d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5712550"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "#params = {'n_estimators':[100, 200],'max_features':['sqrt','log2',20]}\n",
        "#rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "12f4caae-9c96-47f7-87f9-ac547e74cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_features': ['sqrt', 'log2', 20],\n",
              "                         'n_estimators': [100, 200]})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rf_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jhHtsE6rFk",
        "outputId": "268d129a-e1f6-430c-d247-a7a524d48ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {'max_features': 20, 'n_estimators': 200}\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cee27a5-b28e-465c-959a-620a1c24807e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "a32d2502-44c6-49a7-e7e4-7a9cd05f69d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-c2093db50b55>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m807\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds_m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = pd.read_csv(\"/content/rf_results.csv\")\n",
        "preds_m2 = preds_m2['0']\n",
        "preds_m2"
      ],
      "metadata": {
        "id": "PFByIS7pi7fR"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m2 = preds_m2['0']"
      ],
      "metadata": {
        "id": "dczRs5VZjHoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54673c27-df35-40e1-d493-124d37a7b23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.9305797512457967,\n",
              "  'recall': 0.9590305105268102,\n",
              "  'f1-score': 0.9445909476443828,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.9359371939674871,\n",
              "  'recall': 0.8932348863654065,\n",
              "  'f1-score': 0.914087594149763,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.93263125,\n",
              " 'macro avg': {'precision': 0.933258472606642,\n",
              "  'recall': 0.9261326984461083,\n",
              "  'f1-score': 0.9293392708970729,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.932729324685824,\n",
              "  'recall': 0.93263125,\n",
              "  'f1-score': 0.9323520489925445,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2 ,cmap='Blues', colorbar=False)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "731e7f6d-c320-4471-b575-fd35b9e270dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a32ac3c1300>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost_func(preds_m2,y)\n",
        "cost_m2"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf1d5c8-5c2c-4093-fab2-f393e43112ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1420600"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crFxa8d68wBQ",
        "outputId": "b15aaf95-050b-41cc-d058-d3734fb23abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.10         20      3       1    0.0\n",
              "1             0.25         20      1       3    0.0\n",
              "2             0.35         20      1       3    0.0\n",
              "3             0.35          3      0       2    0.0\n",
              "4             0.25          5      3       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.25         20      0       3    0.1\n",
              "320           0.10          3      1       2    1.0\n",
              "321           0.25         10      3       2    1.0\n",
              "322           0.25          5      1       1    0.0\n",
              "323           0.25          3      0       3    0.1\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c3d091ef-80fa-4745-8f71-54c43ba7eb27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows  5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d091ef-80fa-4745-8f71-54c43ba7eb27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b1b1a599-f754-46e9-a83e-11693c67c937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1b1a599-f754-46e9-a83e-11693c67c937')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b1b1a599-f754-46e9-a83e-11693c67c937 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "\n",
        "trials = 30\n",
        "best_params = {}\n",
        "i=0\n",
        "\n",
        "for i in range(trials):\n",
        "  #random sampling from paramdf\n",
        "  hyperparams = {'objective': 'binary:logistic',\n",
        "                 'eta': xgb_param['learning_rate'][i],\n",
        "                 'max_depth': xgb_param['max_depth'][i],\n",
        "                 'gamma': xgb_param['gamma'][i],\n",
        "                 'lambda': xgb_param['lambda'][i],\n",
        "                 'alpha': xgb_param['alpha'][i],\n",
        "                 'eval_metric': 'aucpr'\n",
        "                 }\n",
        "\n",
        "  print(hyperparams)\n",
        "  out=xgb.cv(params=hyperparams,\n",
        "             num_boost_round=20,\n",
        "             dtrain=dtrain,\n",
        "             nfold=5,\n",
        "             stratified=True,\n",
        "             early_stopping_rounds=3,\n",
        "             verbose_eval=1\n",
        "             )\n",
        "\n",
        "  index=out.shape[0]-1\n",
        "  result=out.iloc[index,2]\n",
        "  if i< 1.1:\n",
        "    best_result = result\n",
        "    best_params = hyperparams\n",
        "\n",
        "  if result> best_result:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "      print('result: ' ,result)\n",
        "      print('best result: ' ,best_result)\n",
        "      print('hyperparameters: ' ,hyperparams)\n",
        "      print('best hyperparameters: ' ,best_params)\n",
        "      i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "35897351-2785-4c1d-d03a-faa23ff501af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73761+0.00208\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74850+0.00132\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75308+0.00284\ttest-aucpr:0.74841+0.00202\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00501\n",
            "[8]\ttrain-aucpr:0.78353+0.00227\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00160\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00166\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81465+0.00377\ttest-aucpr:0.80908+0.00378\n",
            "[14]\ttrain-aucpr:0.81993+0.00351\ttest-aucpr:0.81426+0.00372\n",
            "[15]\ttrain-aucpr:0.82332+0.00361\ttest-aucpr:0.81784+0.00370\n",
            "[16]\ttrain-aucpr:0.82662+0.00381\ttest-aucpr:0.82082+0.00337\n",
            "[17]\ttrain-aucpr:0.83062+0.00327\ttest-aucpr:0.82481+0.00400\n",
            "[18]\ttrain-aucpr:0.83598+0.00418\ttest-aucpr:0.83030+0.00522\n",
            "[19]\ttrain-aucpr:0.83916+0.00467\ttest-aucpr:0.83345+0.00572\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00235\ttest-aucpr:0.75927+0.00435\n",
            "[1]\ttrain-aucpr:0.81318+0.00225\ttest-aucpr:0.80539+0.00334\n",
            "[2]\ttrain-aucpr:0.83318+0.00295\ttest-aucpr:0.82591+0.00336\n",
            "[3]\ttrain-aucpr:0.84939+0.00145\ttest-aucpr:0.84225+0.00267\n",
            "[4]\ttrain-aucpr:0.85931+0.00101\ttest-aucpr:0.85189+0.00276\n",
            "[5]\ttrain-aucpr:0.86673+0.00230\ttest-aucpr:0.85947+0.00362\n",
            "[6]\ttrain-aucpr:0.87432+0.00233\ttest-aucpr:0.86671+0.00337\n",
            "[7]\ttrain-aucpr:0.88360+0.00369\ttest-aucpr:0.87603+0.00496\n",
            "[8]\ttrain-aucpr:0.89029+0.00271\ttest-aucpr:0.88296+0.00332\n",
            "[9]\ttrain-aucpr:0.89450+0.00311\ttest-aucpr:0.88709+0.00372\n",
            "[10]\ttrain-aucpr:0.89871+0.00108\ttest-aucpr:0.89103+0.00216\n",
            "[11]\ttrain-aucpr:0.90387+0.00182\ttest-aucpr:0.89611+0.00226\n",
            "[12]\ttrain-aucpr:0.90796+0.00308\ttest-aucpr:0.90005+0.00332\n",
            "[13]\ttrain-aucpr:0.91089+0.00251\ttest-aucpr:0.90283+0.00223\n",
            "[14]\ttrain-aucpr:0.91468+0.00190\ttest-aucpr:0.90639+0.00206\n",
            "[15]\ttrain-aucpr:0.91783+0.00235\ttest-aucpr:0.90934+0.00278\n",
            "[16]\ttrain-aucpr:0.91965+0.00216\ttest-aucpr:0.91114+0.00209\n",
            "[17]\ttrain-aucpr:0.92165+0.00265\ttest-aucpr:0.91322+0.00278\n",
            "[18]\ttrain-aucpr:0.92351+0.00273\ttest-aucpr:0.91509+0.00272\n",
            "[19]\ttrain-aucpr:0.92562+0.00328\ttest-aucpr:0.91723+0.00321\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90560+0.00136\ttest-aucpr:0.87281+0.00246\n",
            "[1]\ttrain-aucpr:0.93138+0.00371\ttest-aucpr:0.90324+0.00377\n",
            "[2]\ttrain-aucpr:0.94181+0.00295\ttest-aucpr:0.91546+0.00261\n",
            "[3]\ttrain-aucpr:0.94852+0.00280\ttest-aucpr:0.92354+0.00318\n",
            "[4]\ttrain-aucpr:0.95339+0.00224\ttest-aucpr:0.92893+0.00228\n",
            "[5]\ttrain-aucpr:0.95770+0.00096\ttest-aucpr:0.93427+0.00122\n",
            "[6]\ttrain-aucpr:0.96061+0.00112\ttest-aucpr:0.93722+0.00081\n",
            "[7]\ttrain-aucpr:0.96275+0.00110\ttest-aucpr:0.93929+0.00083\n",
            "[8]\ttrain-aucpr:0.96501+0.00076\ttest-aucpr:0.94173+0.00098\n",
            "[9]\ttrain-aucpr:0.96701+0.00047\ttest-aucpr:0.94391+0.00050\n",
            "[10]\ttrain-aucpr:0.96869+0.00022\ttest-aucpr:0.94571+0.00087\n",
            "[11]\ttrain-aucpr:0.97022+0.00020\ttest-aucpr:0.94726+0.00064\n",
            "[12]\ttrain-aucpr:0.97141+0.00024\ttest-aucpr:0.94847+0.00048\n",
            "[13]\ttrain-aucpr:0.97253+0.00035\ttest-aucpr:0.94970+0.00024\n",
            "[14]\ttrain-aucpr:0.97353+0.00022\ttest-aucpr:0.95084+0.00033\n",
            "[15]\ttrain-aucpr:0.97467+0.00022\ttest-aucpr:0.95221+0.00034\n",
            "[16]\ttrain-aucpr:0.97580+0.00040\ttest-aucpr:0.95340+0.00038\n",
            "[17]\ttrain-aucpr:0.97659+0.00038\ttest-aucpr:0.95420+0.00039\n",
            "[18]\ttrain-aucpr:0.97736+0.00026\ttest-aucpr:0.95502+0.00038\n",
            "[19]\ttrain-aucpr:0.97818+0.00021\ttest-aucpr:0.95586+0.00038\n",
            "result:  0.9558574813295282\n",
            "best result:  0.9558574813295282\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68916+0.00516\ttest-aucpr:0.68605+0.00458\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71815+0.00233\ttest-aucpr:0.71444+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74144+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74512+0.00232\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74908+0.00173\ttest-aucpr:0.74434+0.00441\n",
            "[9]\ttrain-aucpr:0.75073+0.00079\ttest-aucpr:0.74618+0.00414\n",
            "[10]\ttrain-aucpr:0.75240+0.00215\ttest-aucpr:0.74759+0.00479\n",
            "[11]\ttrain-aucpr:0.75616+0.00265\ttest-aucpr:0.75156+0.00445\n",
            "[12]\ttrain-aucpr:0.75850+0.00161\ttest-aucpr:0.75370+0.00417\n",
            "[13]\ttrain-aucpr:0.76290+0.00245\ttest-aucpr:0.75780+0.00201\n",
            "[14]\ttrain-aucpr:0.76493+0.00215\ttest-aucpr:0.76010+0.00309\n",
            "[15]\ttrain-aucpr:0.76779+0.00324\ttest-aucpr:0.76279+0.00328\n",
            "[16]\ttrain-aucpr:0.77002+0.00213\ttest-aucpr:0.76497+0.00301\n",
            "[17]\ttrain-aucpr:0.77335+0.00251\ttest-aucpr:0.76821+0.00227\n",
            "[18]\ttrain-aucpr:0.77641+0.00283\ttest-aucpr:0.77114+0.00366\n",
            "[19]\ttrain-aucpr:0.78056+0.00281\ttest-aucpr:0.77480+0.00361\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94669+0.00203\ttest-aucpr:0.88450+0.00314\n",
            "[1]\ttrain-aucpr:0.96495+0.00291\ttest-aucpr:0.90774+0.00501\n",
            "[2]\ttrain-aucpr:0.97536+0.00234\ttest-aucpr:0.92202+0.00414\n",
            "[3]\ttrain-aucpr:0.98032+0.00163\ttest-aucpr:0.93012+0.00276\n",
            "[4]\ttrain-aucpr:0.98418+0.00137\ttest-aucpr:0.93630+0.00233\n",
            "[5]\ttrain-aucpr:0.98717+0.00084\ttest-aucpr:0.94131+0.00210\n",
            "[6]\ttrain-aucpr:0.98915+0.00069\ttest-aucpr:0.94423+0.00167\n",
            "[7]\ttrain-aucpr:0.99068+0.00046\ttest-aucpr:0.94685+0.00141\n",
            "[8]\ttrain-aucpr:0.99197+0.00040\ttest-aucpr:0.94973+0.00114\n",
            "[9]\ttrain-aucpr:0.99287+0.00039\ttest-aucpr:0.95147+0.00103\n",
            "[10]\ttrain-aucpr:0.99371+0.00029\ttest-aucpr:0.95323+0.00086\n",
            "[11]\ttrain-aucpr:0.99441+0.00025\ttest-aucpr:0.95485+0.00099\n",
            "[12]\ttrain-aucpr:0.99495+0.00024\ttest-aucpr:0.95595+0.00082\n",
            "[13]\ttrain-aucpr:0.99545+0.00025\ttest-aucpr:0.95708+0.00062\n",
            "[14]\ttrain-aucpr:0.99591+0.00014\ttest-aucpr:0.95810+0.00051\n",
            "[15]\ttrain-aucpr:0.99630+0.00016\ttest-aucpr:0.95899+0.00044\n",
            "[16]\ttrain-aucpr:0.99667+0.00015\ttest-aucpr:0.96003+0.00033\n",
            "[17]\ttrain-aucpr:0.99693+0.00014\ttest-aucpr:0.96072+0.00034\n",
            "[18]\ttrain-aucpr:0.99719+0.00012\ttest-aucpr:0.96160+0.00054\n",
            "[19]\ttrain-aucpr:0.99744+0.00010\ttest-aucpr:0.96219+0.00056\n",
            "result:  0.9621872731832992\n",
            "best result:  0.9621872731832992\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95555+0.00089\ttest-aucpr:0.88733+0.00278\n",
            "[1]\ttrain-aucpr:0.97987+0.00160\ttest-aucpr:0.91923+0.00264\n",
            "[2]\ttrain-aucpr:0.98830+0.00110\ttest-aucpr:0.93501+0.00291\n",
            "[3]\ttrain-aucpr:0.99182+0.00061\ttest-aucpr:0.94304+0.00234\n",
            "[4]\ttrain-aucpr:0.99392+0.00043\ttest-aucpr:0.94862+0.00150\n",
            "[5]\ttrain-aucpr:0.99538+0.00020\ttest-aucpr:0.95260+0.00105\n",
            "[6]\ttrain-aucpr:0.99631+0.00019\ttest-aucpr:0.95589+0.00121\n",
            "[7]\ttrain-aucpr:0.99709+0.00013\ttest-aucpr:0.95838+0.00098\n",
            "[8]\ttrain-aucpr:0.99762+0.00009\ttest-aucpr:0.96050+0.00092\n",
            "[9]\ttrain-aucpr:0.99804+0.00010\ttest-aucpr:0.96232+0.00086\n",
            "[10]\ttrain-aucpr:0.99837+0.00010\ttest-aucpr:0.96367+0.00061\n",
            "[11]\ttrain-aucpr:0.99866+0.00007\ttest-aucpr:0.96515+0.00070\n",
            "[12]\ttrain-aucpr:0.99888+0.00006\ttest-aucpr:0.96616+0.00060\n",
            "[13]\ttrain-aucpr:0.99906+0.00005\ttest-aucpr:0.96717+0.00058\n",
            "[14]\ttrain-aucpr:0.99920+0.00004\ttest-aucpr:0.96818+0.00077\n",
            "[15]\ttrain-aucpr:0.99932+0.00004\ttest-aucpr:0.96891+0.00079\n",
            "[16]\ttrain-aucpr:0.99941+0.00004\ttest-aucpr:0.96963+0.00084\n",
            "[17]\ttrain-aucpr:0.99949+0.00003\ttest-aucpr:0.97036+0.00089\n",
            "[18]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.97084+0.00094\n",
            "[19]\ttrain-aucpr:0.99962+0.00002\ttest-aucpr:0.97134+0.00099\n",
            "result:  0.9713368907046164\n",
            "best result:  0.9713368907046164\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00754\ttest-aucpr:0.71973+0.01007\n",
            "[3]\ttrain-aucpr:0.73763+0.00209\ttest-aucpr:0.73403+0.00556\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75306+0.00284\ttest-aucpr:0.74839+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75896+0.00563\n",
            "[7]\ttrain-aucpr:0.77440+0.00388\ttest-aucpr:0.76927+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77828+0.00214\n",
            "[9]\ttrain-aucpr:0.79097+0.00270\ttest-aucpr:0.78570+0.00044\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79890+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00373\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00393\n",
            "[15]\ttrain-aucpr:0.82372+0.00387\ttest-aucpr:0.81764+0.00323\n",
            "[16]\ttrain-aucpr:0.82728+0.00452\ttest-aucpr:0.82121+0.00374\n",
            "[17]\ttrain-aucpr:0.83238+0.00400\ttest-aucpr:0.82622+0.00430\n",
            "[18]\ttrain-aucpr:0.83627+0.00462\ttest-aucpr:0.83022+0.00562\n",
            "[19]\ttrain-aucpr:0.83893+0.00416\ttest-aucpr:0.83280+0.00508\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95752+0.00066\ttest-aucpr:0.88951+0.00308\n",
            "[1]\ttrain-aucpr:0.98161+0.00142\ttest-aucpr:0.91862+0.00349\n",
            "[2]\ttrain-aucpr:0.98959+0.00056\ttest-aucpr:0.93323+0.00072\n",
            "[3]\ttrain-aucpr:0.99333+0.00038\ttest-aucpr:0.94294+0.00132\n",
            "[4]\ttrain-aucpr:0.99539+0.00007\ttest-aucpr:0.94884+0.00132\n",
            "[5]\ttrain-aucpr:0.99661+0.00009\ttest-aucpr:0.95324+0.00085\n",
            "[6]\ttrain-aucpr:0.99741+0.00007\ttest-aucpr:0.95635+0.00081\n",
            "[7]\ttrain-aucpr:0.99804+0.00008\ttest-aucpr:0.95861+0.00074\n",
            "[8]\ttrain-aucpr:0.99847+0.00005\ttest-aucpr:0.96095+0.00071\n",
            "[9]\ttrain-aucpr:0.99878+0.00003\ttest-aucpr:0.96255+0.00080\n",
            "[10]\ttrain-aucpr:0.99904+0.00005\ttest-aucpr:0.96405+0.00047\n",
            "[11]\ttrain-aucpr:0.99925+0.00001\ttest-aucpr:0.96533+0.00057\n",
            "[12]\ttrain-aucpr:0.99941+0.00001\ttest-aucpr:0.96634+0.00042\n",
            "[13]\ttrain-aucpr:0.99953+0.00002\ttest-aucpr:0.96736+0.00042\n",
            "[14]\ttrain-aucpr:0.99963+0.00002\ttest-aucpr:0.96824+0.00051\n",
            "[15]\ttrain-aucpr:0.99970+0.00002\ttest-aucpr:0.96896+0.00047\n",
            "[16]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96960+0.00051\n",
            "[17]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97020+0.00048\n",
            "[18]\ttrain-aucpr:0.99984+0.00001\ttest-aucpr:0.97081+0.00037\n",
            "[19]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.97130+0.00041\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.68945+0.00533\ttest-aucpr:0.68631+0.00481\n",
            "[2]\ttrain-aucpr:0.70779+0.00228\ttest-aucpr:0.70469+0.00584\n",
            "[3]\ttrain-aucpr:0.71829+0.00226\ttest-aucpr:0.71451+0.00574\n",
            "[4]\ttrain-aucpr:0.72944+0.00515\ttest-aucpr:0.72491+0.00992\n",
            "[5]\ttrain-aucpr:0.73478+0.00406\ttest-aucpr:0.73042+0.00908\n",
            "[6]\ttrain-aucpr:0.74147+0.00198\ttest-aucpr:0.73732+0.00612\n",
            "[7]\ttrain-aucpr:0.74517+0.00230\ttest-aucpr:0.74083+0.00550\n",
            "[8]\ttrain-aucpr:0.74914+0.00175\ttest-aucpr:0.74438+0.00441\n",
            "[9]\ttrain-aucpr:0.75080+0.00085\ttest-aucpr:0.74623+0.00417\n",
            "[10]\ttrain-aucpr:0.75245+0.00215\ttest-aucpr:0.74762+0.00479\n",
            "[11]\ttrain-aucpr:0.75622+0.00268\ttest-aucpr:0.75159+0.00444\n",
            "[12]\ttrain-aucpr:0.75858+0.00165\ttest-aucpr:0.75371+0.00411\n",
            "[13]\ttrain-aucpr:0.76305+0.00231\ttest-aucpr:0.75788+0.00194\n",
            "[14]\ttrain-aucpr:0.76508+0.00199\ttest-aucpr:0.76020+0.00303\n",
            "[15]\ttrain-aucpr:0.76758+0.00364\ttest-aucpr:0.76262+0.00341\n",
            "[16]\ttrain-aucpr:0.76989+0.00242\ttest-aucpr:0.76480+0.00301\n",
            "[17]\ttrain-aucpr:0.77372+0.00206\ttest-aucpr:0.76851+0.00204\n",
            "[18]\ttrain-aucpr:0.77671+0.00247\ttest-aucpr:0.77134+0.00347\n",
            "[19]\ttrain-aucpr:0.78047+0.00316\ttest-aucpr:0.77465+0.00370\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00403\n",
            "[1]\ttrain-aucpr:0.81349+0.00249\ttest-aucpr:0.80541+0.00348\n",
            "[2]\ttrain-aucpr:0.83384+0.00283\ttest-aucpr:0.82622+0.00343\n",
            "[3]\ttrain-aucpr:0.84957+0.00175\ttest-aucpr:0.84230+0.00258\n",
            "[4]\ttrain-aucpr:0.85957+0.00124\ttest-aucpr:0.85205+0.00262\n",
            "[5]\ttrain-aucpr:0.86772+0.00294\ttest-aucpr:0.86016+0.00411\n",
            "[6]\ttrain-aucpr:0.87563+0.00216\ttest-aucpr:0.86792+0.00401\n",
            "[7]\ttrain-aucpr:0.88307+0.00263\ttest-aucpr:0.87529+0.00418\n",
            "[8]\ttrain-aucpr:0.88884+0.00110\ttest-aucpr:0.88119+0.00137\n",
            "[9]\ttrain-aucpr:0.89481+0.00136\ttest-aucpr:0.88704+0.00242\n",
            "[10]\ttrain-aucpr:0.89810+0.00080\ttest-aucpr:0.89005+0.00161\n",
            "[11]\ttrain-aucpr:0.90183+0.00033\ttest-aucpr:0.89373+0.00146\n",
            "[12]\ttrain-aucpr:0.90700+0.00128\ttest-aucpr:0.89889+0.00060\n",
            "[13]\ttrain-aucpr:0.91026+0.00239\ttest-aucpr:0.90216+0.00215\n",
            "[14]\ttrain-aucpr:0.91400+0.00227\ttest-aucpr:0.90591+0.00184\n",
            "[15]\ttrain-aucpr:0.91630+0.00253\ttest-aucpr:0.90810+0.00227\n",
            "[16]\ttrain-aucpr:0.91886+0.00255\ttest-aucpr:0.91071+0.00266\n",
            "[17]\ttrain-aucpr:0.92122+0.00209\ttest-aucpr:0.91296+0.00211\n",
            "[18]\ttrain-aucpr:0.92320+0.00226\ttest-aucpr:0.91482+0.00221\n",
            "[19]\ttrain-aucpr:0.92519+0.00272\ttest-aucpr:0.91667+0.00267\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.69996+0.00178\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72428+0.00732\ttest-aucpr:0.71979+0.01005\n",
            "[3]\ttrain-aucpr:0.73812+0.00237\ttest-aucpr:0.73389+0.00550\n",
            "[4]\ttrain-aucpr:0.74914+0.00187\ttest-aucpr:0.74508+0.00522\n",
            "[5]\ttrain-aucpr:0.75370+0.00235\ttest-aucpr:0.74899+0.00137\n",
            "[6]\ttrain-aucpr:0.76480+0.00353\ttest-aucpr:0.75970+0.00542\n",
            "[7]\ttrain-aucpr:0.77330+0.00225\ttest-aucpr:0.76828+0.00398\n",
            "[8]\ttrain-aucpr:0.78143+0.00403\ttest-aucpr:0.77629+0.00409\n",
            "[9]\ttrain-aucpr:0.78920+0.00341\ttest-aucpr:0.78401+0.00238\n",
            "[10]\ttrain-aucpr:0.79564+0.00400\ttest-aucpr:0.79041+0.00363\n",
            "[11]\ttrain-aucpr:0.80268+0.00379\ttest-aucpr:0.79778+0.00413\n",
            "[12]\ttrain-aucpr:0.80901+0.00186\ttest-aucpr:0.80386+0.00164\n",
            "[13]\ttrain-aucpr:0.81633+0.00264\ttest-aucpr:0.81099+0.00205\n",
            "[14]\ttrain-aucpr:0.82101+0.00283\ttest-aucpr:0.81542+0.00336\n",
            "[15]\ttrain-aucpr:0.82425+0.00309\ttest-aucpr:0.81874+0.00328\n",
            "[16]\ttrain-aucpr:0.82800+0.00388\ttest-aucpr:0.82251+0.00443\n",
            "[17]\ttrain-aucpr:0.83153+0.00326\ttest-aucpr:0.82601+0.00497\n",
            "[18]\ttrain-aucpr:0.83714+0.00166\ttest-aucpr:0.83188+0.00329\n",
            "[19]\ttrain-aucpr:0.83971+0.00204\ttest-aucpr:0.83441+0.00379\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73762+0.00207\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74851+0.00130\ttest-aucpr:0.74450+0.00514\n",
            "[5]\ttrain-aucpr:0.75307+0.00283\ttest-aucpr:0.74840+0.00201\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00502\n",
            "[8]\ttrain-aucpr:0.78353+0.00228\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00161\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00167\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81445+0.00354\ttest-aucpr:0.80886+0.00372\n",
            "[14]\ttrain-aucpr:0.81982+0.00349\ttest-aucpr:0.81398+0.00393\n",
            "[15]\ttrain-aucpr:0.82378+0.00386\ttest-aucpr:0.81770+0.00322\n",
            "[16]\ttrain-aucpr:0.82735+0.00451\ttest-aucpr:0.82128+0.00374\n",
            "[17]\ttrain-aucpr:0.83244+0.00400\ttest-aucpr:0.82628+0.00430\n",
            "[18]\ttrain-aucpr:0.83634+0.00463\ttest-aucpr:0.83028+0.00562\n",
            "[19]\ttrain-aucpr:0.83899+0.00417\ttest-aucpr:0.83285+0.00509\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90143+0.00174\ttest-aucpr:0.87209+0.00410\n",
            "[1]\ttrain-aucpr:0.93481+0.00131\ttest-aucpr:0.90821+0.00184\n",
            "[2]\ttrain-aucpr:0.94936+0.00095\ttest-aucpr:0.92508+0.00082\n",
            "[3]\ttrain-aucpr:0.95746+0.00102\ttest-aucpr:0.93383+0.00131\n",
            "[4]\ttrain-aucpr:0.96245+0.00090\ttest-aucpr:0.93935+0.00062\n",
            "[5]\ttrain-aucpr:0.96621+0.00108\ttest-aucpr:0.94336+0.00079\n",
            "[6]\ttrain-aucpr:0.96954+0.00123\ttest-aucpr:0.94693+0.00100\n",
            "[7]\ttrain-aucpr:0.97212+0.00130\ttest-aucpr:0.94966+0.00105\n",
            "[8]\ttrain-aucpr:0.97436+0.00095\ttest-aucpr:0.95238+0.00065\n",
            "[9]\ttrain-aucpr:0.97658+0.00079\ttest-aucpr:0.95482+0.00055\n",
            "[10]\ttrain-aucpr:0.97821+0.00052\ttest-aucpr:0.95685+0.00037\n",
            "[11]\ttrain-aucpr:0.97939+0.00044\ttest-aucpr:0.95822+0.00038\n",
            "[12]\ttrain-aucpr:0.98029+0.00047\ttest-aucpr:0.95936+0.00071\n",
            "[13]\ttrain-aucpr:0.98130+0.00051\ttest-aucpr:0.96064+0.00049\n",
            "[14]\ttrain-aucpr:0.98255+0.00043\ttest-aucpr:0.96222+0.00027\n",
            "[15]\ttrain-aucpr:0.98318+0.00046\ttest-aucpr:0.96309+0.00020\n",
            "[16]\ttrain-aucpr:0.98392+0.00052\ttest-aucpr:0.96400+0.00053\n",
            "[17]\ttrain-aucpr:0.98439+0.00054\ttest-aucpr:0.96476+0.00050\n",
            "[18]\ttrain-aucpr:0.98489+0.00075\ttest-aucpr:0.96538+0.00043\n",
            "[19]\ttrain-aucpr:0.98532+0.00061\ttest-aucpr:0.96596+0.00042\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90107+0.00181\ttest-aucpr:0.87201+0.00406\n",
            "[1]\ttrain-aucpr:0.92761+0.00399\ttest-aucpr:0.90065+0.00401\n",
            "[2]\ttrain-aucpr:0.93951+0.00295\ttest-aucpr:0.91439+0.00244\n",
            "[3]\ttrain-aucpr:0.94586+0.00238\ttest-aucpr:0.92160+0.00217\n",
            "[4]\ttrain-aucpr:0.95245+0.00125\ttest-aucpr:0.92944+0.00152\n",
            "[5]\ttrain-aucpr:0.95588+0.00136\ttest-aucpr:0.93315+0.00114\n",
            "[6]\ttrain-aucpr:0.95862+0.00086\ttest-aucpr:0.93630+0.00085\n",
            "[7]\ttrain-aucpr:0.96064+0.00092\ttest-aucpr:0.93849+0.00088\n",
            "[8]\ttrain-aucpr:0.96290+0.00077\ttest-aucpr:0.94087+0.00073\n",
            "[9]\ttrain-aucpr:0.96449+0.00072\ttest-aucpr:0.94249+0.00027\n",
            "[10]\ttrain-aucpr:0.96624+0.00031\ttest-aucpr:0.94429+0.00045\n",
            "[11]\ttrain-aucpr:0.96761+0.00043\ttest-aucpr:0.94576+0.00045\n",
            "[12]\ttrain-aucpr:0.96890+0.00046\ttest-aucpr:0.94701+0.00049\n",
            "[13]\ttrain-aucpr:0.97039+0.00061\ttest-aucpr:0.94880+0.00062\n",
            "[14]\ttrain-aucpr:0.97154+0.00062\ttest-aucpr:0.95004+0.00067\n",
            "[15]\ttrain-aucpr:0.97263+0.00084\ttest-aucpr:0.95115+0.00068\n",
            "[16]\ttrain-aucpr:0.97373+0.00100\ttest-aucpr:0.95239+0.00095\n",
            "[17]\ttrain-aucpr:0.97459+0.00088\ttest-aucpr:0.95338+0.00108\n",
            "[18]\ttrain-aucpr:0.97543+0.00085\ttest-aucpr:0.95435+0.00087\n",
            "[19]\ttrain-aucpr:0.97630+0.00102\ttest-aucpr:0.95526+0.00108\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00755\ttest-aucpr:0.71973+0.01008\n",
            "[3]\ttrain-aucpr:0.73762+0.00208\ttest-aucpr:0.73402+0.00557\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74448+0.00515\n",
            "[5]\ttrain-aucpr:0.75305+0.00284\ttest-aucpr:0.74838+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75895+0.00563\n",
            "[7]\ttrain-aucpr:0.77439+0.00388\ttest-aucpr:0.76926+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77827+0.00214\n",
            "[9]\ttrain-aucpr:0.79096+0.00271\ttest-aucpr:0.78570+0.00045\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79889+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00372\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00392\n",
            "[15]\ttrain-aucpr:0.82411+0.00447\ttest-aucpr:0.81813+0.00418\n",
            "[16]\ttrain-aucpr:0.82775+0.00520\ttest-aucpr:0.82170+0.00470\n",
            "[17]\ttrain-aucpr:0.83303+0.00484\ttest-aucpr:0.82689+0.00525\n",
            "[18]\ttrain-aucpr:0.83699+0.00510\ttest-aucpr:0.83099+0.00622\n",
            "[19]\ttrain-aucpr:0.83933+0.00456\ttest-aucpr:0.83319+0.00548\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96995+0.00060\ttest-aucpr:0.89124+0.00327\n",
            "[1]\ttrain-aucpr:0.98800+0.00114\ttest-aucpr:0.91813+0.00197\n",
            "[2]\ttrain-aucpr:0.99404+0.00072\ttest-aucpr:0.93402+0.00240\n",
            "[3]\ttrain-aucpr:0.99648+0.00043\ttest-aucpr:0.94225+0.00277\n",
            "[4]\ttrain-aucpr:0.99777+0.00018\ttest-aucpr:0.94829+0.00208\n",
            "[5]\ttrain-aucpr:0.99853+0.00011\ttest-aucpr:0.95284+0.00202\n",
            "[6]\ttrain-aucpr:0.99897+0.00009\ttest-aucpr:0.95597+0.00165\n",
            "[7]\ttrain-aucpr:0.99924+0.00008\ttest-aucpr:0.95835+0.00148\n",
            "[8]\ttrain-aucpr:0.99945+0.00005\ttest-aucpr:0.96022+0.00134\n",
            "[9]\ttrain-aucpr:0.99961+0.00006\ttest-aucpr:0.96192+0.00110\n",
            "[10]\ttrain-aucpr:0.99970+0.00005\ttest-aucpr:0.96339+0.00106\n",
            "[11]\ttrain-aucpr:0.99979+0.00003\ttest-aucpr:0.96457+0.00105\n",
            "[12]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.96563+0.00095\n",
            "[13]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.96666+0.00111\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96772+0.00087\n",
            "[15]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96842+0.00079\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.96922+0.00078\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.96981+0.00091\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97035+0.00095\n",
            "[19]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97082+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00402\n",
            "[1]\ttrain-aucpr:0.79887+0.00361\ttest-aucpr:0.79184+0.00372\n",
            "[2]\ttrain-aucpr:0.81831+0.00312\ttest-aucpr:0.81134+0.00402\n",
            "[3]\ttrain-aucpr:0.82970+0.00179\ttest-aucpr:0.82294+0.00487\n",
            "[4]\ttrain-aucpr:0.83700+0.00306\ttest-aucpr:0.83006+0.00456\n",
            "[5]\ttrain-aucpr:0.84354+0.00213\ttest-aucpr:0.83694+0.00378\n",
            "[6]\ttrain-aucpr:0.84714+0.00189\ttest-aucpr:0.84010+0.00377\n",
            "[7]\ttrain-aucpr:0.85265+0.00180\ttest-aucpr:0.84523+0.00248\n",
            "[8]\ttrain-aucpr:0.85632+0.00130\ttest-aucpr:0.84904+0.00272\n",
            "[9]\ttrain-aucpr:0.86071+0.00142\ttest-aucpr:0.85347+0.00328\n",
            "[10]\ttrain-aucpr:0.86405+0.00092\ttest-aucpr:0.85671+0.00278\n",
            "[11]\ttrain-aucpr:0.86777+0.00084\ttest-aucpr:0.86032+0.00215\n",
            "[12]\ttrain-aucpr:0.87107+0.00076\ttest-aucpr:0.86358+0.00222\n",
            "[13]\ttrain-aucpr:0.87356+0.00068\ttest-aucpr:0.86599+0.00242\n",
            "[14]\ttrain-aucpr:0.87669+0.00070\ttest-aucpr:0.86923+0.00258\n",
            "[15]\ttrain-aucpr:0.87924+0.00058\ttest-aucpr:0.87175+0.00216\n",
            "[16]\ttrain-aucpr:0.88214+0.00103\ttest-aucpr:0.87452+0.00221\n",
            "[17]\ttrain-aucpr:0.88479+0.00100\ttest-aucpr:0.87706+0.00226\n",
            "[18]\ttrain-aucpr:0.88692+0.00113\ttest-aucpr:0.87919+0.00265\n",
            "[19]\ttrain-aucpr:0.89032+0.00092\ttest-aucpr:0.88262+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90648+0.00131\ttest-aucpr:0.87250+0.00255\n",
            "[1]\ttrain-aucpr:0.93227+0.00376\ttest-aucpr:0.90315+0.00362\n",
            "[2]\ttrain-aucpr:0.94224+0.00211\ttest-aucpr:0.91512+0.00145\n",
            "[3]\ttrain-aucpr:0.94845+0.00199\ttest-aucpr:0.92203+0.00166\n",
            "[4]\ttrain-aucpr:0.95365+0.00173\ttest-aucpr:0.92839+0.00185\n",
            "[5]\ttrain-aucpr:0.95819+0.00062\ttest-aucpr:0.93349+0.00071\n",
            "[6]\ttrain-aucpr:0.96129+0.00099\ttest-aucpr:0.93693+0.00075\n",
            "[7]\ttrain-aucpr:0.96351+0.00087\ttest-aucpr:0.93913+0.00053\n",
            "[8]\ttrain-aucpr:0.96553+0.00085\ttest-aucpr:0.94118+0.00069\n",
            "[9]\ttrain-aucpr:0.96761+0.00101\ttest-aucpr:0.94329+0.00088\n",
            "[10]\ttrain-aucpr:0.96913+0.00080\ttest-aucpr:0.94480+0.00058\n",
            "[11]\ttrain-aucpr:0.97052+0.00081\ttest-aucpr:0.94627+0.00069\n",
            "[12]\ttrain-aucpr:0.97201+0.00057\ttest-aucpr:0.94783+0.00054\n",
            "[13]\ttrain-aucpr:0.97308+0.00060\ttest-aucpr:0.94886+0.00061\n",
            "[14]\ttrain-aucpr:0.97422+0.00055\ttest-aucpr:0.95007+0.00057\n",
            "[15]\ttrain-aucpr:0.97536+0.00053\ttest-aucpr:0.95115+0.00067\n",
            "[16]\ttrain-aucpr:0.97624+0.00042\ttest-aucpr:0.95221+0.00063\n",
            "[17]\ttrain-aucpr:0.97729+0.00049\ttest-aucpr:0.95323+0.00072\n",
            "[18]\ttrain-aucpr:0.97820+0.00044\ttest-aucpr:0.95427+0.00081\n",
            "[19]\ttrain-aucpr:0.97899+0.00050\ttest-aucpr:0.95510+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75887+0.00420\n",
            "[1]\ttrain-aucpr:0.81337+0.00230\ttest-aucpr:0.80537+0.00343\n",
            "[2]\ttrain-aucpr:0.83328+0.00309\ttest-aucpr:0.82599+0.00338\n",
            "[3]\ttrain-aucpr:0.84947+0.00147\ttest-aucpr:0.84236+0.00255\n",
            "[4]\ttrain-aucpr:0.85936+0.00094\ttest-aucpr:0.85202+0.00250\n",
            "[5]\ttrain-aucpr:0.86762+0.00275\ttest-aucpr:0.86011+0.00398\n",
            "[6]\ttrain-aucpr:0.87499+0.00138\ttest-aucpr:0.86730+0.00306\n",
            "[7]\ttrain-aucpr:0.88209+0.00234\ttest-aucpr:0.87446+0.00337\n",
            "[8]\ttrain-aucpr:0.88837+0.00227\ttest-aucpr:0.88052+0.00217\n",
            "[9]\ttrain-aucpr:0.89361+0.00226\ttest-aucpr:0.88577+0.00276\n",
            "[10]\ttrain-aucpr:0.89709+0.00179\ttest-aucpr:0.88897+0.00235\n",
            "[11]\ttrain-aucpr:0.90149+0.00180\ttest-aucpr:0.89335+0.00287\n",
            "[12]\ttrain-aucpr:0.90548+0.00101\ttest-aucpr:0.89725+0.00195\n",
            "[13]\ttrain-aucpr:0.90933+0.00136\ttest-aucpr:0.90113+0.00241\n",
            "[14]\ttrain-aucpr:0.91240+0.00122\ttest-aucpr:0.90415+0.00211\n",
            "[15]\ttrain-aucpr:0.91515+0.00106\ttest-aucpr:0.90709+0.00146\n",
            "[16]\ttrain-aucpr:0.91742+0.00093\ttest-aucpr:0.90934+0.00074\n",
            "[17]\ttrain-aucpr:0.91991+0.00190\ttest-aucpr:0.91169+0.00258\n",
            "[18]\ttrain-aucpr:0.92227+0.00253\ttest-aucpr:0.91407+0.00346\n",
            "[19]\ttrain-aucpr:0.92493+0.00176\ttest-aucpr:0.91673+0.00257\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.81329+0.00228\ttest-aucpr:0.80537+0.00332\n",
            "[2]\ttrain-aucpr:0.83322+0.00300\ttest-aucpr:0.82593+0.00336\n",
            "[3]\ttrain-aucpr:0.84949+0.00146\ttest-aucpr:0.84230+0.00261\n",
            "[4]\ttrain-aucpr:0.85945+0.00091\ttest-aucpr:0.85195+0.00265\n",
            "[5]\ttrain-aucpr:0.86692+0.00230\ttest-aucpr:0.85960+0.00352\n",
            "[6]\ttrain-aucpr:0.87440+0.00160\ttest-aucpr:0.86668+0.00273\n",
            "[7]\ttrain-aucpr:0.88236+0.00259\ttest-aucpr:0.87460+0.00358\n",
            "[8]\ttrain-aucpr:0.88904+0.00102\ttest-aucpr:0.88132+0.00140\n",
            "[9]\ttrain-aucpr:0.89339+0.00155\ttest-aucpr:0.88553+0.00096\n",
            "[10]\ttrain-aucpr:0.89747+0.00144\ttest-aucpr:0.88909+0.00035\n",
            "[11]\ttrain-aucpr:0.90172+0.00147\ttest-aucpr:0.89324+0.00101\n",
            "[12]\ttrain-aucpr:0.90622+0.00147\ttest-aucpr:0.89768+0.00166\n",
            "[13]\ttrain-aucpr:0.90929+0.00095\ttest-aucpr:0.90087+0.00141\n",
            "[14]\ttrain-aucpr:0.91321+0.00120\ttest-aucpr:0.90473+0.00176\n",
            "[15]\ttrain-aucpr:0.91442+0.00125\ttest-aucpr:0.90591+0.00146\n",
            "[16]\ttrain-aucpr:0.91721+0.00164\ttest-aucpr:0.90866+0.00221\n",
            "[17]\ttrain-aucpr:0.91923+0.00122\ttest-aucpr:0.91073+0.00159\n",
            "[18]\ttrain-aucpr:0.92139+0.00105\ttest-aucpr:0.91275+0.00176\n",
            "[19]\ttrain-aucpr:0.92425+0.00164\ttest-aucpr:0.91547+0.00245\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89849+0.00177\ttest-aucpr:0.87056+0.00377\n",
            "[1]\ttrain-aucpr:0.93193+0.00123\ttest-aucpr:0.90645+0.00169\n",
            "[2]\ttrain-aucpr:0.94755+0.00104\ttest-aucpr:0.92373+0.00150\n",
            "[3]\ttrain-aucpr:0.95520+0.00059\ttest-aucpr:0.93160+0.00064\n",
            "[4]\ttrain-aucpr:0.96071+0.00090\ttest-aucpr:0.93729+0.00133\n",
            "[5]\ttrain-aucpr:0.96499+0.00070\ttest-aucpr:0.94206+0.00123\n",
            "[6]\ttrain-aucpr:0.96854+0.00088\ttest-aucpr:0.94574+0.00152\n",
            "[7]\ttrain-aucpr:0.97151+0.00058\ttest-aucpr:0.94880+0.00119\n",
            "[8]\ttrain-aucpr:0.97394+0.00070\ttest-aucpr:0.95135+0.00139\n",
            "[9]\ttrain-aucpr:0.97615+0.00045\ttest-aucpr:0.95399+0.00116\n",
            "[10]\ttrain-aucpr:0.97832+0.00037\ttest-aucpr:0.95645+0.00075\n",
            "[11]\ttrain-aucpr:0.97989+0.00039\ttest-aucpr:0.95818+0.00089\n",
            "[12]\ttrain-aucpr:0.98078+0.00026\ttest-aucpr:0.95929+0.00091\n",
            "[13]\ttrain-aucpr:0.98195+0.00048\ttest-aucpr:0.96090+0.00116\n",
            "[14]\ttrain-aucpr:0.98258+0.00058\ttest-aucpr:0.96176+0.00131\n",
            "[15]\ttrain-aucpr:0.98339+0.00061\ttest-aucpr:0.96265+0.00120\n",
            "[16]\ttrain-aucpr:0.98418+0.00073\ttest-aucpr:0.96355+0.00134\n",
            "[17]\ttrain-aucpr:0.98478+0.00075\ttest-aucpr:0.96423+0.00111\n",
            "[18]\ttrain-aucpr:0.98530+0.00067\ttest-aucpr:0.96492+0.00109\n",
            "[19]\ttrain-aucpr:0.98581+0.00087\ttest-aucpr:0.96544+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90305+0.00167\ttest-aucpr:0.87212+0.00414\n",
            "[1]\ttrain-aucpr:0.93640+0.00176\ttest-aucpr:0.90820+0.00217\n",
            "[2]\ttrain-aucpr:0.95121+0.00103\ttest-aucpr:0.92526+0.00195\n",
            "[3]\ttrain-aucpr:0.95965+0.00132\ttest-aucpr:0.93387+0.00168\n",
            "[4]\ttrain-aucpr:0.96405+0.00153\ttest-aucpr:0.93858+0.00170\n",
            "[5]\ttrain-aucpr:0.96849+0.00128\ttest-aucpr:0.94290+0.00118\n",
            "[6]\ttrain-aucpr:0.97222+0.00117\ttest-aucpr:0.94680+0.00126\n",
            "[7]\ttrain-aucpr:0.97505+0.00130\ttest-aucpr:0.94980+0.00143\n",
            "[8]\ttrain-aucpr:0.97770+0.00099\ttest-aucpr:0.95274+0.00096\n",
            "[9]\ttrain-aucpr:0.97967+0.00112\ttest-aucpr:0.95493+0.00126\n",
            "[10]\ttrain-aucpr:0.98132+0.00109\ttest-aucpr:0.95688+0.00152\n",
            "[11]\ttrain-aucpr:0.98311+0.00078\ttest-aucpr:0.95913+0.00084\n",
            "[12]\ttrain-aucpr:0.98395+0.00060\ttest-aucpr:0.96028+0.00083\n",
            "[13]\ttrain-aucpr:0.98502+0.00041\ttest-aucpr:0.96144+0.00070\n",
            "[14]\ttrain-aucpr:0.98573+0.00061\ttest-aucpr:0.96227+0.00103\n",
            "[15]\ttrain-aucpr:0.98654+0.00060\ttest-aucpr:0.96336+0.00119\n",
            "[16]\ttrain-aucpr:0.98711+0.00074\ttest-aucpr:0.96418+0.00105\n",
            "[17]\ttrain-aucpr:0.98769+0.00039\ttest-aucpr:0.96486+0.00093\n",
            "[18]\ttrain-aucpr:0.98833+0.00033\ttest-aucpr:0.96551+0.00101\n",
            "[19]\ttrain-aucpr:0.98875+0.00046\ttest-aucpr:0.96602+0.00107\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70763+0.00244\ttest-aucpr:0.70463+0.00584\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73731+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74079+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00173\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75075+0.00079\ttest-aucpr:0.74620+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74760+0.00479\n",
            "[11]\ttrain-aucpr:0.75618+0.00265\ttest-aucpr:0.75157+0.00444\n",
            "[12]\ttrain-aucpr:0.75853+0.00161\ttest-aucpr:0.75369+0.00411\n",
            "[13]\ttrain-aucpr:0.76292+0.00245\ttest-aucpr:0.75780+0.00197\n",
            "[14]\ttrain-aucpr:0.76496+0.00215\ttest-aucpr:0.76011+0.00306\n",
            "[15]\ttrain-aucpr:0.76782+0.00325\ttest-aucpr:0.76280+0.00325\n",
            "[16]\ttrain-aucpr:0.77006+0.00213\ttest-aucpr:0.76498+0.00299\n",
            "[17]\ttrain-aucpr:0.77340+0.00251\ttest-aucpr:0.76823+0.00224\n",
            "[18]\ttrain-aucpr:0.77646+0.00284\ttest-aucpr:0.77114+0.00363\n",
            "[19]\ttrain-aucpr:0.78061+0.00282\ttest-aucpr:0.77482+0.00358\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89869+0.00174\ttest-aucpr:0.87054+0.00378\n",
            "[1]\ttrain-aucpr:0.93221+0.00151\ttest-aucpr:0.90655+0.00175\n",
            "[2]\ttrain-aucpr:0.94847+0.00128\ttest-aucpr:0.92439+0.00122\n",
            "[3]\ttrain-aucpr:0.95545+0.00099\ttest-aucpr:0.93159+0.00098\n",
            "[4]\ttrain-aucpr:0.96087+0.00136\ttest-aucpr:0.93693+0.00165\n",
            "[5]\ttrain-aucpr:0.96482+0.00103\ttest-aucpr:0.94152+0.00102\n",
            "[6]\ttrain-aucpr:0.96890+0.00035\ttest-aucpr:0.94608+0.00079\n",
            "[7]\ttrain-aucpr:0.97211+0.00055\ttest-aucpr:0.94953+0.00104\n",
            "[8]\ttrain-aucpr:0.97421+0.00047\ttest-aucpr:0.95171+0.00110\n",
            "[9]\ttrain-aucpr:0.97655+0.00073\ttest-aucpr:0.95413+0.00107\n",
            "[10]\ttrain-aucpr:0.97834+0.00080\ttest-aucpr:0.95619+0.00091\n",
            "[11]\ttrain-aucpr:0.97995+0.00083\ttest-aucpr:0.95788+0.00092\n",
            "[12]\ttrain-aucpr:0.98132+0.00041\ttest-aucpr:0.95939+0.00059\n",
            "[13]\ttrain-aucpr:0.98210+0.00050\ttest-aucpr:0.96042+0.00041\n",
            "[14]\ttrain-aucpr:0.98291+0.00029\ttest-aucpr:0.96147+0.00041\n",
            "[15]\ttrain-aucpr:0.98385+0.00040\ttest-aucpr:0.96264+0.00058\n",
            "[16]\ttrain-aucpr:0.98435+0.00029\ttest-aucpr:0.96326+0.00061\n",
            "[17]\ttrain-aucpr:0.98538+0.00039\ttest-aucpr:0.96453+0.00039\n",
            "[18]\ttrain-aucpr:0.98589+0.00026\ttest-aucpr:0.96519+0.00044\n",
            "[19]\ttrain-aucpr:0.98640+0.00040\ttest-aucpr:0.96565+0.00039\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75886+0.00421\n",
            "[1]\ttrain-aucpr:0.79813+0.00424\ttest-aucpr:0.79127+0.00391\n",
            "[2]\ttrain-aucpr:0.81796+0.00286\ttest-aucpr:0.81121+0.00397\n",
            "[3]\ttrain-aucpr:0.82899+0.00115\ttest-aucpr:0.82236+0.00436\n",
            "[4]\ttrain-aucpr:0.83654+0.00304\ttest-aucpr:0.82981+0.00439\n",
            "[5]\ttrain-aucpr:0.84330+0.00201\ttest-aucpr:0.83689+0.00376\n",
            "[6]\ttrain-aucpr:0.84729+0.00198\ttest-aucpr:0.84033+0.00403\n",
            "[7]\ttrain-aucpr:0.85277+0.00198\ttest-aucpr:0.84548+0.00243\n",
            "[8]\ttrain-aucpr:0.85683+0.00174\ttest-aucpr:0.84967+0.00322\n",
            "[9]\ttrain-aucpr:0.86067+0.00139\ttest-aucpr:0.85345+0.00318\n",
            "[10]\ttrain-aucpr:0.86454+0.00093\ttest-aucpr:0.85746+0.00260\n",
            "[11]\ttrain-aucpr:0.86742+0.00127\ttest-aucpr:0.86016+0.00288\n",
            "[12]\ttrain-aucpr:0.87021+0.00102\ttest-aucpr:0.86290+0.00295\n",
            "[13]\ttrain-aucpr:0.87331+0.00072\ttest-aucpr:0.86599+0.00267\n",
            "[14]\ttrain-aucpr:0.87622+0.00084\ttest-aucpr:0.86906+0.00260\n",
            "[15]\ttrain-aucpr:0.87910+0.00068\ttest-aucpr:0.87181+0.00249\n",
            "[16]\ttrain-aucpr:0.88170+0.00080\ttest-aucpr:0.87431+0.00248\n",
            "[17]\ttrain-aucpr:0.88430+0.00055\ttest-aucpr:0.87661+0.00221\n",
            "[18]\ttrain-aucpr:0.88698+0.00147\ttest-aucpr:0.87933+0.00311\n",
            "[19]\ttrain-aucpr:0.88954+0.00129\ttest-aucpr:0.88184+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90627+0.00135\ttest-aucpr:0.87263+0.00253\n",
            "[1]\ttrain-aucpr:0.93801+0.00154\ttest-aucpr:0.90831+0.00187\n",
            "[2]\ttrain-aucpr:0.95256+0.00107\ttest-aucpr:0.92557+0.00231\n",
            "[3]\ttrain-aucpr:0.95948+0.00160\ttest-aucpr:0.93293+0.00203\n",
            "[4]\ttrain-aucpr:0.96529+0.00061\ttest-aucpr:0.93917+0.00055\n",
            "[5]\ttrain-aucpr:0.96986+0.00122\ttest-aucpr:0.94438+0.00087\n",
            "[6]\ttrain-aucpr:0.97279+0.00092\ttest-aucpr:0.94755+0.00095\n",
            "[7]\ttrain-aucpr:0.97572+0.00101\ttest-aucpr:0.95070+0.00101\n",
            "[8]\ttrain-aucpr:0.97791+0.00105\ttest-aucpr:0.95308+0.00078\n",
            "[9]\ttrain-aucpr:0.98033+0.00082\ttest-aucpr:0.95589+0.00064\n",
            "[10]\ttrain-aucpr:0.98231+0.00070\ttest-aucpr:0.95785+0.00077\n",
            "[11]\ttrain-aucpr:0.98357+0.00065\ttest-aucpr:0.95941+0.00082\n",
            "[12]\ttrain-aucpr:0.98467+0.00040\ttest-aucpr:0.96085+0.00075\n",
            "[13]\ttrain-aucpr:0.98563+0.00033\ttest-aucpr:0.96189+0.00089\n",
            "[14]\ttrain-aucpr:0.98628+0.00032\ttest-aucpr:0.96274+0.00083\n",
            "[15]\ttrain-aucpr:0.98689+0.00035\ttest-aucpr:0.96344+0.00072\n",
            "[16]\ttrain-aucpr:0.98750+0.00048\ttest-aucpr:0.96415+0.00064\n",
            "[17]\ttrain-aucpr:0.98818+0.00063\ttest-aucpr:0.96501+0.00067\n",
            "[18]\ttrain-aucpr:0.98885+0.00057\ttest-aucpr:0.96576+0.00079\n",
            "[19]\ttrain-aucpr:0.98941+0.00084\ttest-aucpr:0.96626+0.00092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "xXJEj4W_8T-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69863b78-b66d-45ff-bb28-49504e4cb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:logistic',\n",
              " 'eta': 0.25,\n",
              " 'max_depth': 20,\n",
              " 'gamma': 1,\n",
              " 'lambda': 1,\n",
              " 'alpha': 1.0,\n",
              " 'eval_metric': 'aucpr'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aucpr_params = {'objective': 'binary:logistic',\n",
        "         'eta': 0.25,\n",
        "         'max_depth': 20,\n",
        "         'gamma': 1,\n",
        "         'lambda': 1,\n",
        "         'alpha': 1.0,\n",
        "         'eval_metric': 'aucpr'}"
      ],
      "metadata": {
        "id": "_RjSFnb1SXl7"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "    dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "    dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    tr=xgb.train(params=aucpr_params,\n",
        "                 num_boost_round=222,\n",
        "                 dtrain=dtrain,\n",
        "                 verbose_eval=1,\n",
        "                 evals=evallist,\n",
        "                 early_stopping_rounds = 3\n",
        "             )\n",
        "\n",
        "    preds_XGB = np.round(tr.predict(dtest), 0)\n",
        "\n",
        "    classification_report(y[test_index],np.round(preds_XGB, 0),output_dict=True)\n",
        "    fold_results.update({i:{'predictions':preds_XGB,'index':test_index,'y_true':y[test_index]}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQFpdGo4cZNV",
        "outputId": "3ab537d6-803e-4834-8273-985213842f06"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-aucpr:0.95959\teval-aucpr:0.89759\n",
            "[1]\ttrain-aucpr:0.98119\teval-aucpr:0.93133\n",
            "[2]\ttrain-aucpr:0.98777\teval-aucpr:0.93999\n",
            "[3]\ttrain-aucpr:0.99178\teval-aucpr:0.94840\n",
            "[4]\ttrain-aucpr:0.99375\teval-aucpr:0.95154\n",
            "[5]\ttrain-aucpr:0.99507\teval-aucpr:0.95507\n",
            "[6]\ttrain-aucpr:0.99611\teval-aucpr:0.95924\n",
            "[7]\ttrain-aucpr:0.99678\teval-aucpr:0.96071\n",
            "[8]\ttrain-aucpr:0.99724\teval-aucpr:0.96271\n",
            "[9]\ttrain-aucpr:0.99786\teval-aucpr:0.96437\n",
            "[10]\ttrain-aucpr:0.99815\teval-aucpr:0.96569\n",
            "[11]\ttrain-aucpr:0.99847\teval-aucpr:0.96755\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96863\n",
            "[13]\ttrain-aucpr:0.99891\teval-aucpr:0.96901\n",
            "[14]\ttrain-aucpr:0.99905\teval-aucpr:0.97010\n",
            "[15]\ttrain-aucpr:0.99918\teval-aucpr:0.97096\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97178\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97243\n",
            "[18]\ttrain-aucpr:0.99945\teval-aucpr:0.97295\n",
            "[19]\ttrain-aucpr:0.99952\teval-aucpr:0.97329\n",
            "[20]\ttrain-aucpr:0.99959\teval-aucpr:0.97385\n",
            "[21]\ttrain-aucpr:0.99964\teval-aucpr:0.97411\n",
            "[22]\ttrain-aucpr:0.99969\teval-aucpr:0.97427\n",
            "[23]\ttrain-aucpr:0.99974\teval-aucpr:0.97428\n",
            "[24]\ttrain-aucpr:0.99977\teval-aucpr:0.97461\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97471\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97508\n",
            "[27]\ttrain-aucpr:0.99985\teval-aucpr:0.97521\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97526\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97525\n",
            "[30]\ttrain-aucpr:0.99989\teval-aucpr:0.97545\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97545\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97568\n",
            "[33]\ttrain-aucpr:0.99993\teval-aucpr:0.97562\n",
            "[34]\ttrain-aucpr:0.99994\teval-aucpr:0.97561\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97574\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97598\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97599\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97598\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97600\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97609\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97599\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97598\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97608\n",
            "[0]\ttrain-aucpr:0.95801\teval-aucpr:0.89513\n",
            "[1]\ttrain-aucpr:0.98134\teval-aucpr:0.92580\n",
            "[2]\ttrain-aucpr:0.98951\teval-aucpr:0.94370\n",
            "[3]\ttrain-aucpr:0.99249\teval-aucpr:0.94937\n",
            "[4]\ttrain-aucpr:0.99421\teval-aucpr:0.95291\n",
            "[5]\ttrain-aucpr:0.99555\teval-aucpr:0.95742\n",
            "[6]\ttrain-aucpr:0.99642\teval-aucpr:0.96023\n",
            "[7]\ttrain-aucpr:0.99712\teval-aucpr:0.96190\n",
            "[8]\ttrain-aucpr:0.99760\teval-aucpr:0.96321\n",
            "[9]\ttrain-aucpr:0.99799\teval-aucpr:0.96421\n",
            "[10]\ttrain-aucpr:0.99831\teval-aucpr:0.96589\n",
            "[11]\ttrain-aucpr:0.99856\teval-aucpr:0.96749\n",
            "[12]\ttrain-aucpr:0.99882\teval-aucpr:0.96892\n",
            "[13]\ttrain-aucpr:0.99901\teval-aucpr:0.96981\n",
            "[14]\ttrain-aucpr:0.99917\teval-aucpr:0.97063\n",
            "[15]\ttrain-aucpr:0.99929\teval-aucpr:0.97132\n",
            "[16]\ttrain-aucpr:0.99940\teval-aucpr:0.97161\n",
            "[17]\ttrain-aucpr:0.99948\teval-aucpr:0.97185\n",
            "[18]\ttrain-aucpr:0.99956\teval-aucpr:0.97228\n",
            "[19]\ttrain-aucpr:0.99962\teval-aucpr:0.97303\n",
            "[20]\ttrain-aucpr:0.99966\teval-aucpr:0.97324\n",
            "[21]\ttrain-aucpr:0.99972\teval-aucpr:0.97357\n",
            "[22]\ttrain-aucpr:0.99975\teval-aucpr:0.97385\n",
            "[23]\ttrain-aucpr:0.99979\teval-aucpr:0.97436\n",
            "[24]\ttrain-aucpr:0.99982\teval-aucpr:0.97428\n",
            "[25]\ttrain-aucpr:0.99984\teval-aucpr:0.97455\n",
            "[26]\ttrain-aucpr:0.99986\teval-aucpr:0.97467\n",
            "[27]\ttrain-aucpr:0.99988\teval-aucpr:0.97459\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97472\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97484\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97489\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97500\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97496\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97491\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97501\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97525\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97522\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97530\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97550\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97539\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97540\n",
            "[0]\ttrain-aucpr:0.95727\teval-aucpr:0.89617\n",
            "[1]\ttrain-aucpr:0.97878\teval-aucpr:0.92792\n",
            "[2]\ttrain-aucpr:0.98863\teval-aucpr:0.94272\n",
            "[3]\ttrain-aucpr:0.99154\teval-aucpr:0.95010\n",
            "[4]\ttrain-aucpr:0.99391\teval-aucpr:0.95603\n",
            "[5]\ttrain-aucpr:0.99528\teval-aucpr:0.96038\n",
            "[6]\ttrain-aucpr:0.99612\teval-aucpr:0.96273\n",
            "[7]\ttrain-aucpr:0.99677\teval-aucpr:0.96486\n",
            "[8]\ttrain-aucpr:0.99733\teval-aucpr:0.96650\n",
            "[9]\ttrain-aucpr:0.99777\teval-aucpr:0.96775\n",
            "[10]\ttrain-aucpr:0.99811\teval-aucpr:0.96883\n",
            "[11]\ttrain-aucpr:0.99844\teval-aucpr:0.96989\n",
            "[12]\ttrain-aucpr:0.99873\teval-aucpr:0.97055\n",
            "[13]\ttrain-aucpr:0.99889\teval-aucpr:0.97115\n",
            "[14]\ttrain-aucpr:0.99905\teval-aucpr:0.97226\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97291\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97348\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97400\n",
            "[18]\ttrain-aucpr:0.99949\teval-aucpr:0.97457\n",
            "[19]\ttrain-aucpr:0.99956\teval-aucpr:0.97465\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97462\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97492\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97526\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97598\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97608\n",
            "[25]\ttrain-aucpr:0.99983\teval-aucpr:0.97645\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97660\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97679\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97684\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97689\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97710\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97738\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97741\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97758\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97762\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97750\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97780\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97797\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97799\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97807\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97824\n",
            "[41]\ttrain-aucpr:0.99999\teval-aucpr:0.97819\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97826\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97850\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97854\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97855\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97844\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97851\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97860\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97860\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97861\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97865\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97865\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97872\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97881\n",
            "[57]\ttrain-aucpr:1.00000\teval-aucpr:0.97879\n",
            "[58]\ttrain-aucpr:1.00000\teval-aucpr:0.97883\n",
            "[59]\ttrain-aucpr:1.00000\teval-aucpr:0.97886\n",
            "[60]\ttrain-aucpr:1.00000\teval-aucpr:0.97903\n",
            "[61]\ttrain-aucpr:1.00000\teval-aucpr:0.97907\n",
            "[62]\ttrain-aucpr:1.00000\teval-aucpr:0.97909\n",
            "[63]\ttrain-aucpr:1.00000\teval-aucpr:0.97921\n",
            "[64]\ttrain-aucpr:1.00000\teval-aucpr:0.97924\n",
            "[65]\ttrain-aucpr:1.00000\teval-aucpr:0.97923\n",
            "[66]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[67]\ttrain-aucpr:1.00000\teval-aucpr:0.97931\n",
            "[68]\ttrain-aucpr:1.00000\teval-aucpr:0.97932\n",
            "[69]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[70]\ttrain-aucpr:1.00000\teval-aucpr:0.97929\n",
            "[71]\ttrain-aucpr:1.00000\teval-aucpr:0.97928\n",
            "[0]\ttrain-aucpr:0.95861\teval-aucpr:0.89379\n",
            "[1]\ttrain-aucpr:0.98252\teval-aucpr:0.92981\n",
            "[2]\ttrain-aucpr:0.98929\teval-aucpr:0.94090\n",
            "[3]\ttrain-aucpr:0.99224\teval-aucpr:0.94901\n",
            "[4]\ttrain-aucpr:0.99390\teval-aucpr:0.95400\n",
            "[5]\ttrain-aucpr:0.99530\teval-aucpr:0.95655\n",
            "[6]\ttrain-aucpr:0.99613\teval-aucpr:0.95870\n",
            "[7]\ttrain-aucpr:0.99685\teval-aucpr:0.96131\n",
            "[8]\ttrain-aucpr:0.99743\teval-aucpr:0.96315\n",
            "[9]\ttrain-aucpr:0.99790\teval-aucpr:0.96530\n",
            "[10]\ttrain-aucpr:0.99823\teval-aucpr:0.96668\n",
            "[11]\ttrain-aucpr:0.99850\teval-aucpr:0.96795\n",
            "[12]\ttrain-aucpr:0.99868\teval-aucpr:0.96927\n",
            "[13]\ttrain-aucpr:0.99887\teval-aucpr:0.97029\n",
            "[14]\ttrain-aucpr:0.99902\teval-aucpr:0.97088\n",
            "[15]\ttrain-aucpr:0.99916\teval-aucpr:0.97150\n",
            "[16]\ttrain-aucpr:0.99927\teval-aucpr:0.97200\n",
            "[17]\ttrain-aucpr:0.99937\teval-aucpr:0.97254\n",
            "[18]\ttrain-aucpr:0.99946\teval-aucpr:0.97321\n",
            "[19]\ttrain-aucpr:0.99954\teval-aucpr:0.97371\n",
            "[20]\ttrain-aucpr:0.99958\teval-aucpr:0.97389\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97434\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97440\n",
            "[23]\ttrain-aucpr:0.99971\teval-aucpr:0.97456\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97489\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97499\n",
            "[26]\ttrain-aucpr:0.99981\teval-aucpr:0.97529\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97528\n",
            "[28]\ttrain-aucpr:0.99987\teval-aucpr:0.97537\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97522\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97543\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97569\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97588\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97593\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97596\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97602\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97613\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97616\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97605\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97617\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97613\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97617\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97619\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97635\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97644\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97647\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97650\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97645\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97647\n",
            "[0]\ttrain-aucpr:0.95768\teval-aucpr:0.89666\n",
            "[1]\ttrain-aucpr:0.97882\teval-aucpr:0.92033\n",
            "[2]\ttrain-aucpr:0.98827\teval-aucpr:0.93851\n",
            "[3]\ttrain-aucpr:0.99182\teval-aucpr:0.94801\n",
            "[4]\ttrain-aucpr:0.99370\teval-aucpr:0.95212\n",
            "[5]\ttrain-aucpr:0.99489\teval-aucpr:0.95683\n",
            "[6]\ttrain-aucpr:0.99599\teval-aucpr:0.96004\n",
            "[7]\ttrain-aucpr:0.99672\teval-aucpr:0.96261\n",
            "[8]\ttrain-aucpr:0.99732\teval-aucpr:0.96427\n",
            "[9]\ttrain-aucpr:0.99776\teval-aucpr:0.96598\n",
            "[10]\ttrain-aucpr:0.99807\teval-aucpr:0.96720\n",
            "[11]\ttrain-aucpr:0.99836\teval-aucpr:0.96863\n",
            "[12]\ttrain-aucpr:0.99867\teval-aucpr:0.96956\n",
            "[13]\ttrain-aucpr:0.99889\teval-aucpr:0.97061\n",
            "[14]\ttrain-aucpr:0.99906\teval-aucpr:0.97132\n",
            "[15]\ttrain-aucpr:0.99917\teval-aucpr:0.97157\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97233\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97296\n",
            "[18]\ttrain-aucpr:0.99946\teval-aucpr:0.97334\n",
            "[19]\ttrain-aucpr:0.99951\teval-aucpr:0.97367\n",
            "[20]\ttrain-aucpr:0.99957\teval-aucpr:0.97424\n",
            "[21]\ttrain-aucpr:0.99962\teval-aucpr:0.97451\n",
            "[22]\ttrain-aucpr:0.99966\teval-aucpr:0.97441\n",
            "[23]\ttrain-aucpr:0.99971\teval-aucpr:0.97478\n",
            "[24]\ttrain-aucpr:0.99973\teval-aucpr:0.97488\n",
            "[25]\ttrain-aucpr:0.99974\teval-aucpr:0.97499\n",
            "[26]\ttrain-aucpr:0.99978\teval-aucpr:0.97517\n",
            "[27]\ttrain-aucpr:0.99981\teval-aucpr:0.97513\n",
            "[28]\ttrain-aucpr:0.99984\teval-aucpr:0.97524\n",
            "[29]\ttrain-aucpr:0.99986\teval-aucpr:0.97537\n",
            "[30]\ttrain-aucpr:0.99988\teval-aucpr:0.97570\n",
            "[31]\ttrain-aucpr:0.99990\teval-aucpr:0.97583\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97598\n",
            "[33]\ttrain-aucpr:0.99993\teval-aucpr:0.97621\n",
            "[34]\ttrain-aucpr:0.99994\teval-aucpr:0.97646\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97643\n",
            "[36]\ttrain-aucpr:0.99995\teval-aucpr:0.97645\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97657\n",
            "[38]\ttrain-aucpr:0.99996\teval-aucpr:0.97668\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97660\n",
            "[40]\ttrain-aucpr:0.99997\teval-aucpr:0.97660\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97654\n",
            "[0]\ttrain-aucpr:0.96092\teval-aucpr:0.90690\n",
            "[1]\ttrain-aucpr:0.98014\teval-aucpr:0.93451\n",
            "[2]\ttrain-aucpr:0.98790\teval-aucpr:0.94811\n",
            "[3]\ttrain-aucpr:0.99204\teval-aucpr:0.95522\n",
            "[4]\ttrain-aucpr:0.99411\teval-aucpr:0.95921\n",
            "[5]\ttrain-aucpr:0.99527\teval-aucpr:0.96241\n",
            "[6]\ttrain-aucpr:0.99612\teval-aucpr:0.96398\n",
            "[7]\ttrain-aucpr:0.99688\teval-aucpr:0.96658\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96751\n",
            "[9]\ttrain-aucpr:0.99782\teval-aucpr:0.96868\n",
            "[10]\ttrain-aucpr:0.99822\teval-aucpr:0.97003\n",
            "[11]\ttrain-aucpr:0.99849\teval-aucpr:0.97103\n",
            "[12]\ttrain-aucpr:0.99875\teval-aucpr:0.97174\n",
            "[13]\ttrain-aucpr:0.99895\teval-aucpr:0.97237\n",
            "[14]\ttrain-aucpr:0.99912\teval-aucpr:0.97300\n",
            "[15]\ttrain-aucpr:0.99925\teval-aucpr:0.97388\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97442\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97491\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97539\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97574\n",
            "[20]\ttrain-aucpr:0.99963\teval-aucpr:0.97616\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97623\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97668\n",
            "[23]\ttrain-aucpr:0.99973\teval-aucpr:0.97694\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97705\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97728\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97744\n",
            "[27]\ttrain-aucpr:0.99985\teval-aucpr:0.97761\n",
            "[28]\ttrain-aucpr:0.99987\teval-aucpr:0.97765\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97763\n",
            "[30]\ttrain-aucpr:0.99989\teval-aucpr:0.97767\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97779\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97774\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97782\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97781\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97787\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97802\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97817\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97826\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97831\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97841\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97842\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97843\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97848\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97849\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97856\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97865\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97867\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97873\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97872\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97873\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97878\n",
            "[52]\ttrain-aucpr:0.99999\teval-aucpr:0.97880\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97892\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97903\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97902\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97899\n",
            "[57]\ttrain-aucpr:1.00000\teval-aucpr:0.97895\n",
            "[0]\ttrain-aucpr:0.95693\teval-aucpr:0.90258\n",
            "[1]\ttrain-aucpr:0.98237\teval-aucpr:0.93263\n",
            "[2]\ttrain-aucpr:0.98938\teval-aucpr:0.94299\n",
            "[3]\ttrain-aucpr:0.99211\teval-aucpr:0.95102\n",
            "[4]\ttrain-aucpr:0.99421\teval-aucpr:0.95600\n",
            "[5]\ttrain-aucpr:0.99539\teval-aucpr:0.95897\n",
            "[6]\ttrain-aucpr:0.99626\teval-aucpr:0.96128\n",
            "[7]\ttrain-aucpr:0.99685\teval-aucpr:0.96353\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96566\n",
            "[9]\ttrain-aucpr:0.99784\teval-aucpr:0.96718\n",
            "[10]\ttrain-aucpr:0.99825\teval-aucpr:0.96856\n",
            "[11]\ttrain-aucpr:0.99850\teval-aucpr:0.96955\n",
            "[12]\ttrain-aucpr:0.99876\teval-aucpr:0.97064\n",
            "[13]\ttrain-aucpr:0.99894\teval-aucpr:0.97149\n",
            "[14]\ttrain-aucpr:0.99911\teval-aucpr:0.97238\n",
            "[15]\ttrain-aucpr:0.99924\teval-aucpr:0.97277\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97366\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97404\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97458\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97481\n",
            "[20]\ttrain-aucpr:0.99965\teval-aucpr:0.97521\n",
            "[21]\ttrain-aucpr:0.99969\teval-aucpr:0.97536\n",
            "[22]\ttrain-aucpr:0.99973\teval-aucpr:0.97535\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97556\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97608\n",
            "[25]\ttrain-aucpr:0.99982\teval-aucpr:0.97646\n",
            "[26]\ttrain-aucpr:0.99986\teval-aucpr:0.97656\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97680\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97672\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97706\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97737\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97748\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97771\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97784\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97783\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97795\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97818\n",
            "[37]\ttrain-aucpr:0.99996\teval-aucpr:0.97803\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97806\n",
            "[0]\ttrain-aucpr:0.95826\teval-aucpr:0.90189\n",
            "[1]\ttrain-aucpr:0.98201\teval-aucpr:0.93658\n",
            "[2]\ttrain-aucpr:0.98893\teval-aucpr:0.94766\n",
            "[3]\ttrain-aucpr:0.99220\teval-aucpr:0.95450\n",
            "[4]\ttrain-aucpr:0.99392\teval-aucpr:0.95832\n",
            "[5]\ttrain-aucpr:0.99522\teval-aucpr:0.96179\n",
            "[6]\ttrain-aucpr:0.99607\teval-aucpr:0.96335\n",
            "[7]\ttrain-aucpr:0.99681\teval-aucpr:0.96478\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96697\n",
            "[9]\ttrain-aucpr:0.99778\teval-aucpr:0.96869\n",
            "[10]\ttrain-aucpr:0.99824\teval-aucpr:0.96972\n",
            "[11]\ttrain-aucpr:0.99854\teval-aucpr:0.97073\n",
            "[12]\ttrain-aucpr:0.99872\teval-aucpr:0.97191\n",
            "[13]\ttrain-aucpr:0.99890\teval-aucpr:0.97258\n",
            "[14]\ttrain-aucpr:0.99907\teval-aucpr:0.97304\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97404\n",
            "[16]\ttrain-aucpr:0.99929\teval-aucpr:0.97449\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97492\n",
            "[18]\ttrain-aucpr:0.99948\teval-aucpr:0.97533\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97566\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97573\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97613\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97612\n",
            "[23]\ttrain-aucpr:0.99972\teval-aucpr:0.97635\n",
            "[24]\ttrain-aucpr:0.99976\teval-aucpr:0.97647\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97647\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97673\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97700\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97717\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97742\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97739\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97763\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97761\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97767\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97800\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97812\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97820\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97824\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97821\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97835\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97842\n",
            "[41]\ttrain-aucpr:0.99999\teval-aucpr:0.97842\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97842\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97848\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97858\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97867\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97869\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97874\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97875\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97868\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97866\n",
            "[51]\ttrain-aucpr:1.00000\teval-aucpr:0.97868\n",
            "[0]\ttrain-aucpr:0.95892\teval-aucpr:0.89196\n",
            "[1]\ttrain-aucpr:0.97821\teval-aucpr:0.91875\n",
            "[2]\ttrain-aucpr:0.98816\teval-aucpr:0.94167\n",
            "[3]\ttrain-aucpr:0.99183\teval-aucpr:0.94968\n",
            "[4]\ttrain-aucpr:0.99388\teval-aucpr:0.95508\n",
            "[5]\ttrain-aucpr:0.99537\teval-aucpr:0.95780\n",
            "[6]\ttrain-aucpr:0.99623\teval-aucpr:0.95934\n",
            "[7]\ttrain-aucpr:0.99689\teval-aucpr:0.96085\n",
            "[8]\ttrain-aucpr:0.99742\teval-aucpr:0.96265\n",
            "[9]\ttrain-aucpr:0.99781\teval-aucpr:0.96463\n",
            "[10]\ttrain-aucpr:0.99822\teval-aucpr:0.96611\n",
            "[11]\ttrain-aucpr:0.99843\teval-aucpr:0.96749\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96853\n",
            "[13]\ttrain-aucpr:0.99893\teval-aucpr:0.96954\n",
            "[14]\ttrain-aucpr:0.99908\teval-aucpr:0.97040\n",
            "[15]\ttrain-aucpr:0.99920\teval-aucpr:0.97097\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97173\n",
            "[17]\ttrain-aucpr:0.99942\teval-aucpr:0.97206\n",
            "[18]\ttrain-aucpr:0.99952\teval-aucpr:0.97261\n",
            "[19]\ttrain-aucpr:0.99958\teval-aucpr:0.97299\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97368\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97376\n",
            "[22]\ttrain-aucpr:0.99968\teval-aucpr:0.97401\n",
            "[23]\ttrain-aucpr:0.99974\teval-aucpr:0.97399\n",
            "[24]\ttrain-aucpr:0.99978\teval-aucpr:0.97426\n",
            "[25]\ttrain-aucpr:0.99980\teval-aucpr:0.97428\n",
            "[26]\ttrain-aucpr:0.99983\teval-aucpr:0.97452\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97452\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97455\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97457\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97476\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97473\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97474\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97489\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97506\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97503\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97495\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97529\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97539\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97535\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97523\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97540\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97569\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97585\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97593\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97601\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97600\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97603\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97606\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97610\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97618\n",
            "[51]\ttrain-aucpr:0.99999\teval-aucpr:0.97615\n",
            "[52]\ttrain-aucpr:0.99999\teval-aucpr:0.97624\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97640\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97643\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97642\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97641\n",
            "[0]\ttrain-aucpr:0.95662\teval-aucpr:0.89489\n",
            "[1]\ttrain-aucpr:0.97949\teval-aucpr:0.92672\n",
            "[2]\ttrain-aucpr:0.98794\teval-aucpr:0.94024\n",
            "[3]\ttrain-aucpr:0.99173\teval-aucpr:0.94889\n",
            "[4]\ttrain-aucpr:0.99363\teval-aucpr:0.95289\n",
            "[5]\ttrain-aucpr:0.99503\teval-aucpr:0.95696\n",
            "[6]\ttrain-aucpr:0.99601\teval-aucpr:0.95995\n",
            "[7]\ttrain-aucpr:0.99673\teval-aucpr:0.96160\n",
            "[8]\ttrain-aucpr:0.99727\teval-aucpr:0.96314\n",
            "[9]\ttrain-aucpr:0.99771\teval-aucpr:0.96451\n",
            "[10]\ttrain-aucpr:0.99814\teval-aucpr:0.96621\n",
            "[11]\ttrain-aucpr:0.99839\teval-aucpr:0.96715\n",
            "[12]\ttrain-aucpr:0.99866\teval-aucpr:0.96872\n",
            "[13]\ttrain-aucpr:0.99888\teval-aucpr:0.96948\n",
            "[14]\ttrain-aucpr:0.99907\teval-aucpr:0.97029\n",
            "[15]\ttrain-aucpr:0.99919\teval-aucpr:0.97080\n",
            "[16]\ttrain-aucpr:0.99930\teval-aucpr:0.97137\n",
            "[17]\ttrain-aucpr:0.99940\teval-aucpr:0.97151\n",
            "[18]\ttrain-aucpr:0.99947\teval-aucpr:0.97224\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97300\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97326\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97340\n",
            "[22]\ttrain-aucpr:0.99969\teval-aucpr:0.97371\n",
            "[23]\ttrain-aucpr:0.99973\teval-aucpr:0.97402\n",
            "[24]\ttrain-aucpr:0.99975\teval-aucpr:0.97426\n",
            "[25]\ttrain-aucpr:0.99979\teval-aucpr:0.97414\n",
            "[26]\ttrain-aucpr:0.99982\teval-aucpr:0.97428\n",
            "[27]\ttrain-aucpr:0.99984\teval-aucpr:0.97465\n",
            "[28]\ttrain-aucpr:0.99986\teval-aucpr:0.97454\n",
            "[29]\ttrain-aucpr:0.99988\teval-aucpr:0.97463\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97505\n",
            "[31]\ttrain-aucpr:0.99991\teval-aucpr:0.97521\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97529\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97540\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97535\n",
            "[35]\ttrain-aucpr:0.99995\teval-aucpr:0.97532\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97548\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97568\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97552\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97558\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97571\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97566\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97574\n",
            "[43]\ttrain-aucpr:0.99998\teval-aucpr:0.97565\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97566\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97577\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97580\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97581\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97594\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97590\n",
            "[50]\ttrain-aucpr:0.99999\teval-aucpr:0.97583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m3[idx] = np.round(fold_results.get(i).get('predictions')[j], 0)"
      ],
      "metadata": {
        "id": "7hSFBjJSXmnc"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_cost = cost_func(preds_m3,y)\n",
        "m3_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSw-zr1_YDa6",
        "outputId": "173bbbf2-8577-4aa1-ddba-5794746d75c2"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1164650"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new3 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.65:\n",
        "      preds_new3[idx] = 1\n",
        "    else:\n",
        "      preds_new3[idx] = 0\n",
        "m3_cost_t = cost_func(y,preds_new3)\n",
        "m3_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2L2e6fDvB0M",
        "outputId": "3f7014b1-2a71-47a0-c72c-af2ff31db9c5"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100600"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sets binary values for predictions\n",
        "def cost(y_true,y_pred):\n",
        "\n",
        "  bin_p = K.switch(K.greater_equal(y_pred,0.5),K.constant(1,shape=y_pred.shape),\n",
        "                   K.constant(0,shape=y_pred.shape))\n",
        "  diff = bin_p-y_true\n",
        "\n",
        "  error = K.switch(\n",
        "      K.equal(diff,1),K.constant(100,shape=y_pred.shape),\n",
        "      K.switch(\n",
        "          K.equal(diff,-1),K.constant(150,shape=y_pred.shape),\n",
        "          K.constant(0,shape=y_pred.shape)\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error))"
      ],
      "metadata": {
        "id": "z2vUglkTkzxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### define a cost function used in validation with keras and backend\n",
        "### returns the average cost (total cost divided by array tensor size)\n",
        "def cost(y_true,y_pred):\n",
        "  bin_p = tf.where(tf.greater_equal(y_pred,0.5),tf.constant(1,dtype='float32'),tf.constant(0,dtype='float32'))\n",
        "\n",
        "  diff = bin_p - y_true\n",
        "\n",
        "  error = tf.where(\n",
        "      tf.equal(diff,1),100,\n",
        "      tf.where(\n",
        "          tf.equal(diff,-1),150,\n",
        "          0\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error)/tf.size(bin_p))"
      ],
      "metadata": {
        "id": "EV-gIgK12n02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#updated to cost instead of val_cost, and saw cost lowered\n",
        "es = EarlyStopping(monitor='cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False, curve='PR'), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model4.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "  print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "a6ca9131-05d9-4789-ab09-b95049659ab0"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1215 - auc: 0.9847 - accuracy: 0.9606 - cost: 5.0143 - val_loss: 0.1295 - val_auc: 0.9822 - val_accuracy: 0.9579 - val_cost: 5.6999\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1185 - auc: 0.9852 - accuracy: 0.9616 - cost: 4.8743 - val_loss: 0.1278 - val_auc: 0.9819 - val_accuracy: 0.9597 - val_cost: 5.2897\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9854 - accuracy: 0.9623 - cost: 4.8102 - val_loss: 0.1247 - val_auc: 0.9825 - val_accuracy: 0.9606 - val_cost: 5.3353\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1159 - auc: 0.9858 - accuracy: 0.9627 - cost: 4.7421 - val_loss: 0.1265 - val_auc: 0.9825 - val_accuracy: 0.9599 - val_cost: 5.5957\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1150 - auc: 0.9859 - accuracy: 0.9634 - cost: 4.6569 - val_loss: 0.1240 - val_auc: 0.9826 - val_accuracy: 0.9610 - val_cost: 5.3353\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1136 - auc: 0.9860 - accuracy: 0.9635 - cost: 4.6493 - val_loss: 0.1224 - val_auc: 0.9830 - val_accuracy: 0.9622 - val_cost: 4.9121\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1118 - auc: 0.9868 - accuracy: 0.9646 - cost: 4.5157 - val_loss: 0.1220 - val_auc: 0.9830 - val_accuracy: 0.9629 - val_cost: 4.9056\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9866 - accuracy: 0.9646 - cost: 4.5120 - val_loss: 0.1209 - val_auc: 0.9832 - val_accuracy: 0.9640 - val_cost: 4.7819\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1109 - auc: 0.9866 - accuracy: 0.9647 - cost: 4.4964 - val_loss: 0.1193 - val_auc: 0.9836 - val_accuracy: 0.9635 - val_cost: 5.0391\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1095 - auc: 0.9868 - accuracy: 0.9655 - cost: 4.4132 - val_loss: 0.1180 - val_auc: 0.9836 - val_accuracy: 0.9632 - val_cost: 4.7331\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1087 - auc: 0.9872 - accuracy: 0.9663 - cost: 4.2966 - val_loss: 0.1186 - val_auc: 0.9839 - val_accuracy: 0.9643 - val_cost: 4.5671\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1075 - auc: 0.9872 - accuracy: 0.9662 - cost: 4.3074 - val_loss: 0.1165 - val_auc: 0.9840 - val_accuracy: 0.9643 - val_cost: 4.6810\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1068 - auc: 0.9874 - accuracy: 0.9666 - cost: 4.2620 - val_loss: 0.1168 - val_auc: 0.9841 - val_accuracy: 0.9635 - val_cost: 4.8242\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1050 - auc: 0.9875 - accuracy: 0.9670 - cost: 4.2280 - val_loss: 0.1151 - val_auc: 0.9841 - val_accuracy: 0.9651 - val_cost: 4.5410\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1050 - auc: 0.9875 - accuracy: 0.9677 - cost: 4.1231 - val_loss: 0.1148 - val_auc: 0.9843 - val_accuracy: 0.9653 - val_cost: 4.5215\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9877 - accuracy: 0.9676 - cost: 4.1414 - val_loss: 0.1151 - val_auc: 0.9845 - val_accuracy: 0.9652 - val_cost: 4.4010\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1030 - auc: 0.9879 - accuracy: 0.9680 - cost: 4.0884 - val_loss: 0.1146 - val_auc: 0.9838 - val_accuracy: 0.9649 - val_cost: 4.5052\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9884 - accuracy: 0.9681 - cost: 4.0636 - val_loss: 0.1143 - val_auc: 0.9841 - val_accuracy: 0.9656 - val_cost: 4.5801\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1005 - auc: 0.9883 - accuracy: 0.9689 - cost: 3.9831 - val_loss: 0.1134 - val_auc: 0.9845 - val_accuracy: 0.9656 - val_cost: 4.3913\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9886 - accuracy: 0.9692 - cost: 3.9412 - val_loss: 0.1133 - val_auc: 0.9847 - val_accuracy: 0.9660 - val_cost: 4.2871\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0993 - auc: 0.9886 - accuracy: 0.9696 - cost: 3.8842 - val_loss: 0.1123 - val_auc: 0.9845 - val_accuracy: 0.9656 - val_cost: 4.3327\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0989 - auc: 0.9887 - accuracy: 0.9700 - cost: 3.8265 - val_loss: 0.1132 - val_auc: 0.9845 - val_accuracy: 0.9663 - val_cost: 4.5378\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9886 - accuracy: 0.9699 - cost: 3.8479 - val_loss: 0.1127 - val_auc: 0.9840 - val_accuracy: 0.9665 - val_cost: 4.1113\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9887 - accuracy: 0.9701 - cost: 3.8197 - val_loss: 0.1101 - val_auc: 0.9847 - val_accuracy: 0.9689 - val_cost: 3.9909\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0971 - auc: 0.9888 - accuracy: 0.9707 - cost: 3.7467 - val_loss: 0.1122 - val_auc: 0.9840 - val_accuracy: 0.9666 - val_cost: 4.1927\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0976 - auc: 0.9889 - accuracy: 0.9707 - cost: 3.7412 - val_loss: 0.1115 - val_auc: 0.9849 - val_accuracy: 0.9665 - val_cost: 4.2969\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0968 - auc: 0.9886 - accuracy: 0.9707 - cost: 3.7376 - val_loss: 0.1101 - val_auc: 0.9846 - val_accuracy: 0.9678 - val_cost: 4.3001\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9889 - accuracy: 0.9713 - cost: 3.6740 - val_loss: 0.1114 - val_auc: 0.9837 - val_accuracy: 0.9681 - val_cost: 3.9844\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0962 - auc: 0.9890 - accuracy: 0.9710 - cost: 3.7066 - val_loss: 0.1105 - val_auc: 0.9842 - val_accuracy: 0.9678 - val_cost: 3.9160\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0958 - auc: 0.9890 - accuracy: 0.9708 - cost: 3.7299 - val_loss: 0.1098 - val_auc: 0.9845 - val_accuracy: 0.9681 - val_cost: 4.0430\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0944 - auc: 0.9892 - accuracy: 0.9712 - cost: 3.6772 - val_loss: 0.1086 - val_auc: 0.9851 - val_accuracy: 0.9685 - val_cost: 4.1862\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0929 - auc: 0.9896 - accuracy: 0.9722 - cost: 3.5583 - val_loss: 0.1097 - val_auc: 0.9848 - val_accuracy: 0.9680 - val_cost: 4.0755\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0939 - auc: 0.9893 - accuracy: 0.9718 - cost: 3.6202 - val_loss: 0.1110 - val_auc: 0.9840 - val_accuracy: 0.9682 - val_cost: 3.8249\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0918 - auc: 0.9898 - accuracy: 0.9728 - cost: 3.4822 - val_loss: 0.1105 - val_auc: 0.9846 - val_accuracy: 0.9686 - val_cost: 4.1243\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0914 - auc: 0.9899 - accuracy: 0.9725 - cost: 3.5091 - val_loss: 0.1106 - val_auc: 0.9844 - val_accuracy: 0.9678 - val_cost: 4.0918\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0908 - auc: 0.9901 - accuracy: 0.9728 - cost: 3.4806 - val_loss: 0.1104 - val_auc: 0.9848 - val_accuracy: 0.9677 - val_cost: 4.1276\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9897 - accuracy: 0.9727 - cost: 3.4999 - val_loss: 0.1092 - val_auc: 0.9845 - val_accuracy: 0.9682 - val_cost: 3.9811\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9896 - accuracy: 0.9726 - cost: 3.4973 - val_loss: 0.1097 - val_auc: 0.9842 - val_accuracy: 0.9683 - val_cost: 4.0072\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9899 - accuracy: 0.9728 - cost: 3.4707 - val_loss: 0.1097 - val_auc: 0.9844 - val_accuracy: 0.9679 - val_cost: 4.0788\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9901 - accuracy: 0.9734 - cost: 3.4046 - val_loss: 0.1114 - val_auc: 0.9842 - val_accuracy: 0.9685 - val_cost: 3.8672\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - auc: 0.9897 - accuracy: 0.9739 - cost: 3.3432 - val_loss: 0.1093 - val_auc: 0.9851 - val_accuracy: 0.9692 - val_cost: 3.9909\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9902 - accuracy: 0.9734 - cost: 3.3942 - val_loss: 0.1100 - val_auc: 0.9847 - val_accuracy: 0.9688 - val_cost: 4.0267\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9899 - accuracy: 0.9735 - cost: 3.4026 - val_loss: 0.1084 - val_auc: 0.9850 - val_accuracy: 0.9694 - val_cost: 3.9714\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9899 - accuracy: 0.9739 - cost: 3.3553 - val_loss: 0.1109 - val_auc: 0.9838 - val_accuracy: 0.9692 - val_cost: 4.0234\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9899 - accuracy: 0.9742 - cost: 3.3168 - val_loss: 0.1112 - val_auc: 0.9836 - val_accuracy: 0.9684 - val_cost: 3.9844\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0887 - auc: 0.9899 - accuracy: 0.9741 - cost: 3.3075 - val_loss: 0.1089 - val_auc: 0.9847 - val_accuracy: 0.9700 - val_cost: 4.0365\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9904 - accuracy: 0.9740 - cost: 3.3355 - val_loss: 0.1088 - val_auc: 0.9848 - val_accuracy: 0.9693 - val_cost: 4.0202\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9903 - accuracy: 0.9742 - cost: 3.2990 - val_loss: 0.1097 - val_auc: 0.9845 - val_accuracy: 0.9695 - val_cost: 4.0723\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9906 - accuracy: 0.9740 - cost: 3.3338 - val_loss: 0.1097 - val_auc: 0.9846 - val_accuracy: 0.9699 - val_cost: 3.8639\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9903 - accuracy: 0.9743 - cost: 3.3007 - val_loss: 0.1098 - val_auc: 0.9845 - val_accuracy: 0.9685 - val_cost: 3.8477\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9905 - accuracy: 0.9746 - cost: 3.2577 - val_loss: 0.1087 - val_auc: 0.9843 - val_accuracy: 0.9700 - val_cost: 3.8379\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9902 - accuracy: 0.9740 - cost: 3.3337 - val_loss: 0.1067 - val_auc: 0.9852 - val_accuracy: 0.9691 - val_cost: 3.9779\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9904 - accuracy: 0.9750 - cost: 3.2070 - val_loss: 0.1096 - val_auc: 0.9842 - val_accuracy: 0.9703 - val_cost: 3.9160\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9905 - accuracy: 0.9749 - cost: 3.2127 - val_loss: 0.1092 - val_auc: 0.9848 - val_accuracy: 0.9698 - val_cost: 3.8542\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0867 - auc: 0.9904 - accuracy: 0.9746 - cost: 3.2501 - val_loss: 0.1110 - val_auc: 0.9842 - val_accuracy: 0.9692 - val_cost: 3.9388\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0856 - auc: 0.9905 - accuracy: 0.9750 - cost: 3.2168 - val_loss: 0.1118 - val_auc: 0.9839 - val_accuracy: 0.9702 - val_cost: 3.7240\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9905 - accuracy: 0.9750 - cost: 3.2163 - val_loss: 0.1095 - val_auc: 0.9844 - val_accuracy: 0.9699 - val_cost: 3.8965\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0842 - auc: 0.9908 - accuracy: 0.9757 - cost: 3.1192 - val_loss: 0.1095 - val_auc: 0.9839 - val_accuracy: 0.9701 - val_cost: 3.8053\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9903 - accuracy: 0.9755 - cost: 3.1414 - val_loss: 0.1088 - val_auc: 0.9838 - val_accuracy: 0.9706 - val_cost: 3.7370\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9906 - accuracy: 0.9754 - cost: 3.1491 - val_loss: 0.1101 - val_auc: 0.9836 - val_accuracy: 0.9698 - val_cost: 3.8216\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9905 - accuracy: 0.9748 - cost: 3.2310 - val_loss: 0.1073 - val_auc: 0.9848 - val_accuracy: 0.9711 - val_cost: 3.7044\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9904 - accuracy: 0.9752 - cost: 3.1919 - val_loss: 0.1095 - val_auc: 0.9850 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9910 - accuracy: 0.9749 - cost: 3.2263 - val_loss: 0.1090 - val_auc: 0.9842 - val_accuracy: 0.9698 - val_cost: 3.8216\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9910 - accuracy: 0.9758 - cost: 3.1059 - val_loss: 0.1091 - val_auc: 0.9843 - val_accuracy: 0.9703 - val_cost: 3.9388\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9907 - accuracy: 0.9761 - cost: 3.0713 - val_loss: 0.1126 - val_auc: 0.9842 - val_accuracy: 0.9701 - val_cost: 3.4733\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9910 - accuracy: 0.9755 - cost: 3.1372 - val_loss: 0.1089 - val_auc: 0.9845 - val_accuracy: 0.9702 - val_cost: 3.9030\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9908 - accuracy: 0.9756 - cost: 3.1588 - val_loss: 0.1114 - val_auc: 0.9833 - val_accuracy: 0.9705 - val_cost: 3.5449\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9908 - accuracy: 0.9757 - cost: 3.1185 - val_loss: 0.1092 - val_auc: 0.9843 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9910 - accuracy: 0.9761 - cost: 3.0631 - val_loss: 0.1102 - val_auc: 0.9838 - val_accuracy: 0.9699 - val_cost: 3.8086\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9908 - accuracy: 0.9762 - cost: 3.0662 - val_loss: 0.1090 - val_auc: 0.9842 - val_accuracy: 0.9708 - val_cost: 3.5286\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9910 - accuracy: 0.9764 - cost: 3.0443 - val_loss: 0.1091 - val_auc: 0.9841 - val_accuracy: 0.9697 - val_cost: 3.8379\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9911 - accuracy: 0.9758 - cost: 3.1096 - val_loss: 0.1082 - val_auc: 0.9843 - val_accuracy: 0.9709 - val_cost: 3.5645\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9911 - accuracy: 0.9760 - cost: 3.0832 - val_loss: 0.1106 - val_auc: 0.9832 - val_accuracy: 0.9706 - val_cost: 3.4017\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9909 - accuracy: 0.9766 - cost: 3.0229 - val_loss: 0.1087 - val_auc: 0.9843 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9910 - accuracy: 0.9762 - cost: 3.0652 - val_loss: 0.1091 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9909 - accuracy: 0.9764 - cost: 3.0194 - val_loss: 0.1107 - val_auc: 0.9846 - val_accuracy: 0.9702 - val_cost: 3.8997\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0823 - auc: 0.9913 - accuracy: 0.9762 - cost: 3.0816 - val_loss: 0.1077 - val_auc: 0.9844 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0820 - auc: 0.9910 - accuracy: 0.9766 - cost: 3.0035 - val_loss: 0.1097 - val_auc: 0.9848 - val_accuracy: 0.9703 - val_cost: 3.9095\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0804 - val_loss: 0.1098 - val_auc: 0.9844 - val_accuracy: 0.9708 - val_cost: 3.8574\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9911 - accuracy: 0.9764 - cost: 3.0451 - val_loss: 0.1097 - val_auc: 0.9854 - val_accuracy: 0.9701 - val_cost: 3.9421\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0808 - auc: 0.9916 - accuracy: 0.9768 - cost: 2.9785 - val_loss: 0.1127 - val_auc: 0.9834 - val_accuracy: 0.9705 - val_cost: 3.5254\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9913 - accuracy: 0.9763 - cost: 3.0485 - val_loss: 0.1093 - val_auc: 0.9844 - val_accuracy: 0.9724 - val_cost: 3.4082\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9913 - accuracy: 0.9766 - cost: 3.0090 - val_loss: 0.1084 - val_auc: 0.9846 - val_accuracy: 0.9711 - val_cost: 3.5742\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9910 - accuracy: 0.9768 - cost: 2.9954 - val_loss: 0.1110 - val_auc: 0.9831 - val_accuracy: 0.9701 - val_cost: 3.6230\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9611 - val_loss: 0.1126 - val_auc: 0.9840 - val_accuracy: 0.9700 - val_cost: 3.8086\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9911 - accuracy: 0.9767 - cost: 3.0038 - val_loss: 0.1115 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9914 - accuracy: 0.9764 - cost: 3.0175 - val_loss: 0.1114 - val_auc: 0.9845 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9912 - accuracy: 0.9769 - cost: 2.9755 - val_loss: 0.1107 - val_auc: 0.9841 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9915 - accuracy: 0.9767 - cost: 3.0028 - val_loss: 0.1142 - val_auc: 0.9833 - val_accuracy: 0.9691 - val_cost: 3.5254\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9497 - val_loss: 0.1124 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.3887\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9914 - accuracy: 0.9769 - cost: 2.9681 - val_loss: 0.1102 - val_auc: 0.9843 - val_accuracy: 0.9704 - val_cost: 3.7370\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9917 - accuracy: 0.9769 - cost: 2.9710 - val_loss: 0.1114 - val_auc: 0.9839 - val_accuracy: 0.9698 - val_cost: 3.8574\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9913 - accuracy: 0.9772 - cost: 2.9419 - val_loss: 0.1106 - val_auc: 0.9845 - val_accuracy: 0.9703 - val_cost: 3.7923\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9914 - accuracy: 0.9771 - cost: 2.9428 - val_loss: 0.1113 - val_auc: 0.9843 - val_accuracy: 0.9700 - val_cost: 4.0202\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9913 - accuracy: 0.9773 - cost: 2.9384 - val_loss: 0.1113 - val_auc: 0.9839 - val_accuracy: 0.9714 - val_cost: 3.6296\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9678 - val_loss: 0.1103 - val_auc: 0.9842 - val_accuracy: 0.9703 - val_cost: 3.8021\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9914 - accuracy: 0.9768 - cost: 2.9946 - val_loss: 0.1108 - val_auc: 0.9844 - val_accuracy: 0.9704 - val_cost: 3.5872\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9918 - accuracy: 0.9778 - cost: 2.8532 - val_loss: 0.1113 - val_auc: 0.9842 - val_accuracy: 0.9705 - val_cost: 3.4408\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9916 - accuracy: 0.9777 - cost: 2.8626 - val_loss: 0.1120 - val_auc: 0.9835 - val_accuracy: 0.9712 - val_cost: 3.5124\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0803 - auc: 0.9911 - accuracy: 0.9771 - cost: 2.9408 - val_loss: 0.1119 - val_auc: 0.9844 - val_accuracy: 0.9708 - val_cost: 3.6849\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9916 - accuracy: 0.9774 - cost: 2.9058 - val_loss: 0.1126 - val_auc: 0.9831 - val_accuracy: 0.9706 - val_cost: 3.7240\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0787 - auc: 0.9915 - accuracy: 0.9777 - cost: 2.8645 - val_loss: 0.1109 - val_auc: 0.9838 - val_accuracy: 0.9711 - val_cost: 3.8411\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9916 - accuracy: 0.9775 - cost: 2.8981 - val_loss: 0.1115 - val_auc: 0.9836 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0785 - auc: 0.9917 - accuracy: 0.9778 - cost: 2.8659 - val_loss: 0.1106 - val_auc: 0.9846 - val_accuracy: 0.9711 - val_cost: 3.5775\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9915 - accuracy: 0.9782 - cost: 2.8030 - val_loss: 0.1111 - val_auc: 0.9840 - val_accuracy: 0.9719 - val_cost: 3.6393\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9915 - accuracy: 0.9772 - cost: 2.9444 - val_loss: 0.1135 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.6133\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9916 - accuracy: 0.9776 - cost: 2.8786 - val_loss: 0.1127 - val_auc: 0.9835 - val_accuracy: 0.9719 - val_cost: 3.6523\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.8966 - val_loss: 0.1118 - val_auc: 0.9834 - val_accuracy: 0.9721 - val_cost: 3.4831\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9779 - cost: 2.8431 - val_loss: 0.1144 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9775 - cost: 2.8884 - val_loss: 0.1113 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.6686\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9916 - accuracy: 0.9775 - cost: 2.9087 - val_loss: 0.1130 - val_auc: 0.9835 - val_accuracy: 0.9702 - val_cost: 3.4766\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9920 - accuracy: 0.9778 - cost: 2.8569 - val_loss: 0.1123 - val_auc: 0.9841 - val_accuracy: 0.9709 - val_cost: 3.7337\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9914 - accuracy: 0.9777 - cost: 2.8694 - val_loss: 0.1106 - val_auc: 0.9844 - val_accuracy: 0.9720 - val_cost: 3.4277\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9918 - accuracy: 0.9773 - cost: 2.9296 - val_loss: 0.1121 - val_auc: 0.9844 - val_accuracy: 0.9700 - val_cost: 3.5677\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9919 - accuracy: 0.9779 - cost: 2.8415 - val_loss: 0.1107 - val_auc: 0.9845 - val_accuracy: 0.9701 - val_cost: 3.5449\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7963 - val_loss: 0.1125 - val_auc: 0.9840 - val_accuracy: 0.9708 - val_cost: 3.4212\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8647 - val_loss: 0.1116 - val_auc: 0.9838 - val_accuracy: 0.9706 - val_cost: 3.5156\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9919 - accuracy: 0.9779 - cost: 2.8519 - val_loss: 0.1112 - val_auc: 0.9843 - val_accuracy: 0.9710 - val_cost: 3.6296\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8335 - val_loss: 0.1121 - val_auc: 0.9842 - val_accuracy: 0.9709 - val_cost: 3.4212\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9916 - accuracy: 0.9778 - cost: 2.8514 - val_loss: 0.1122 - val_auc: 0.9833 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9919 - accuracy: 0.9779 - cost: 2.8427 - val_loss: 0.1123 - val_auc: 0.9839 - val_accuracy: 0.9703 - val_cost: 3.8900\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9918 - accuracy: 0.9784 - cost: 2.8045 - val_loss: 0.1124 - val_auc: 0.9832 - val_accuracy: 0.9709 - val_cost: 3.5352\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9918 - accuracy: 0.9777 - cost: 2.8609 - val_loss: 0.1141 - val_auc: 0.9834 - val_accuracy: 0.9718 - val_cost: 3.2715\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8176 - val_loss: 0.1151 - val_auc: 0.9838 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9917 - accuracy: 0.9783 - cost: 2.7873 - val_loss: 0.1127 - val_auc: 0.9838 - val_accuracy: 0.9712 - val_cost: 3.7370\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9923 - accuracy: 0.9782 - cost: 2.8117 - val_loss: 0.1141 - val_auc: 0.9833 - val_accuracy: 0.9705 - val_cost: 3.7565\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9918 - accuracy: 0.9780 - cost: 2.8334 - val_loss: 0.1143 - val_auc: 0.9835 - val_accuracy: 0.9707 - val_cost: 3.9290\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7999 - val_loss: 0.1146 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9916 - accuracy: 0.9784 - cost: 2.7835 - val_loss: 0.1123 - val_auc: 0.9841 - val_accuracy: 0.9706 - val_cost: 3.5189\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9920 - accuracy: 0.9782 - cost: 2.8053 - val_loss: 0.1124 - val_auc: 0.9839 - val_accuracy: 0.9706 - val_cost: 3.6361\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9918 - accuracy: 0.9777 - cost: 2.8796 - val_loss: 0.1130 - val_auc: 0.9839 - val_accuracy: 0.9694 - val_cost: 3.7305\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9919 - accuracy: 0.9783 - cost: 2.7908 - val_loss: 0.1141 - val_auc: 0.9832 - val_accuracy: 0.9702 - val_cost: 3.6035\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9917 - accuracy: 0.9778 - cost: 2.8712 - val_loss: 0.1147 - val_auc: 0.9842 - val_accuracy: 0.9706 - val_cost: 3.5872\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9920 - accuracy: 0.9784 - cost: 2.7751 - val_loss: 0.1124 - val_auc: 0.9843 - val_accuracy: 0.9713 - val_cost: 3.6686\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9920 - accuracy: 0.9780 - cost: 2.8299 - val_loss: 0.1125 - val_auc: 0.9839 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9921 - accuracy: 0.9783 - cost: 2.8014 - val_loss: 0.1148 - val_auc: 0.9834 - val_accuracy: 0.9713 - val_cost: 3.7012\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9919 - accuracy: 0.9781 - cost: 2.8235 - val_loss: 0.1127 - val_auc: 0.9838 - val_accuracy: 0.9711 - val_cost: 3.5872\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9922 - accuracy: 0.9784 - cost: 2.7923 - val_loss: 0.1123 - val_auc: 0.9837 - val_accuracy: 0.9710 - val_cost: 3.5612\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9919 - accuracy: 0.9786 - cost: 2.7611 - val_loss: 0.1129 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7402 - val_loss: 0.1158 - val_auc: 0.9839 - val_accuracy: 0.9700 - val_cost: 3.6556\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0754 - auc: 0.9923 - accuracy: 0.9785 - cost: 2.7680 - val_loss: 0.1161 - val_auc: 0.9829 - val_accuracy: 0.9711 - val_cost: 3.4701\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9919 - accuracy: 0.9782 - cost: 2.8074 - val_loss: 0.1128 - val_auc: 0.9844 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9923 - accuracy: 0.9789 - cost: 2.7304 - val_loss: 0.1113 - val_auc: 0.9844 - val_accuracy: 0.9719 - val_cost: 3.8021\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9921 - accuracy: 0.9789 - cost: 2.7306 - val_loss: 0.1141 - val_auc: 0.9838 - val_accuracy: 0.9711 - val_cost: 3.5579\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9921 - accuracy: 0.9787 - cost: 2.7427 - val_loss: 0.1124 - val_auc: 0.9850 - val_accuracy: 0.9700 - val_cost: 3.7728\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8023 - val_loss: 0.1132 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.7935 - val_loss: 0.1135 - val_auc: 0.9840 - val_accuracy: 0.9717 - val_cost: 3.4603\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9922 - accuracy: 0.9783 - cost: 2.8015 - val_loss: 0.1127 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9919 - accuracy: 0.9780 - cost: 2.8500 - val_loss: 0.1132 - val_auc: 0.9836 - val_accuracy: 0.9710 - val_cost: 3.3626\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9922 - accuracy: 0.9786 - cost: 2.7623 - val_loss: 0.1131 - val_auc: 0.9838 - val_accuracy: 0.9705 - val_cost: 3.6784\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7657 - val_loss: 0.1117 - val_auc: 0.9844 - val_accuracy: 0.9707 - val_cost: 3.6296\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9923 - accuracy: 0.9785 - cost: 2.7676 - val_loss: 0.1134 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9921 - accuracy: 0.9791 - cost: 2.6913 - val_loss: 0.1153 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.7370\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8248 - val_loss: 0.1146 - val_auc: 0.9833 - val_accuracy: 0.9708 - val_cost: 3.5742\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9924 - accuracy: 0.9791 - cost: 2.6897 - val_loss: 0.1135 - val_auc: 0.9839 - val_accuracy: 0.9714 - val_cost: 3.3757\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7606 - val_loss: 0.1125 - val_auc: 0.9841 - val_accuracy: 0.9712 - val_cost: 3.8672\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9927 - accuracy: 0.9789 - cost: 2.7389 - val_loss: 0.1154 - val_auc: 0.9834 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9926 - accuracy: 0.9790 - cost: 2.7089 - val_loss: 0.1156 - val_auc: 0.9842 - val_accuracy: 0.9706 - val_cost: 3.7044\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9923 - accuracy: 0.9787 - cost: 2.7433 - val_loss: 0.1141 - val_auc: 0.9830 - val_accuracy: 0.9716 - val_cost: 3.3236\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7607 - val_loss: 0.1138 - val_auc: 0.9832 - val_accuracy: 0.9703 - val_cost: 3.5059\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7149 - val_loss: 0.1165 - val_auc: 0.9833 - val_accuracy: 0.9713 - val_cost: 3.3561\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9923 - accuracy: 0.9785 - cost: 2.7780 - val_loss: 0.1127 - val_auc: 0.9842 - val_accuracy: 0.9714 - val_cost: 3.4993\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6729 - val_loss: 0.1138 - val_auc: 0.9842 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7246 - val_loss: 0.1105 - val_auc: 0.9846 - val_accuracy: 0.9717 - val_cost: 3.4766\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7129 - val_loss: 0.1152 - val_auc: 0.9834 - val_accuracy: 0.9712 - val_cost: 3.3854\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9923 - accuracy: 0.9790 - cost: 2.7153 - val_loss: 0.1143 - val_auc: 0.9847 - val_accuracy: 0.9720 - val_cost: 3.4701\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9923 - accuracy: 0.9790 - cost: 2.7137 - val_loss: 0.1128 - val_auc: 0.9840 - val_accuracy: 0.9722 - val_cost: 3.4635\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9923 - accuracy: 0.9790 - cost: 2.7119 - val_loss: 0.1148 - val_auc: 0.9834 - val_accuracy: 0.9703 - val_cost: 3.6784\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7210 - val_loss: 0.1135 - val_auc: 0.9844 - val_accuracy: 0.9703 - val_cost: 3.9225\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6997 - val_loss: 0.1147 - val_auc: 0.9844 - val_accuracy: 0.9710 - val_cost: 3.7467\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9921 - accuracy: 0.9789 - cost: 2.7179 - val_loss: 0.1128 - val_auc: 0.9840 - val_accuracy: 0.9715 - val_cost: 3.5612\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7148 - val_loss: 0.1146 - val_auc: 0.9836 - val_accuracy: 0.9707 - val_cost: 3.5579\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9924 - accuracy: 0.9797 - cost: 2.6287 - val_loss: 0.1143 - val_auc: 0.9845 - val_accuracy: 0.9709 - val_cost: 3.9583\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9923 - accuracy: 0.9791 - cost: 2.6979 - val_loss: 0.1127 - val_auc: 0.9839 - val_accuracy: 0.9706 - val_cost: 3.6393\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9925 - accuracy: 0.9785 - cost: 2.7715 - val_loss: 0.1155 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.4342\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7275 - val_loss: 0.1145 - val_auc: 0.9835 - val_accuracy: 0.9708 - val_cost: 3.6100\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7195 - val_loss: 0.1154 - val_auc: 0.9834 - val_accuracy: 0.9705 - val_cost: 3.7891\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6391 - val_loss: 0.1145 - val_auc: 0.9832 - val_accuracy: 0.9710 - val_cost: 3.4049\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9926 - accuracy: 0.9790 - cost: 2.7116 - val_loss: 0.1151 - val_auc: 0.9832 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9922 - accuracy: 0.9789 - cost: 2.7213 - val_loss: 0.1146 - val_auc: 0.9839 - val_accuracy: 0.9712 - val_cost: 3.3626\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7430 - val_loss: 0.1148 - val_auc: 0.9835 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6728 - val_loss: 0.1150 - val_auc: 0.9831 - val_accuracy: 0.9708 - val_cost: 3.7044\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6842 - val_loss: 0.1130 - val_auc: 0.9841 - val_accuracy: 0.9715 - val_cost: 3.5059\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6789 - val_loss: 0.1155 - val_auc: 0.9841 - val_accuracy: 0.9701 - val_cost: 3.6100\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9924 - accuracy: 0.9790 - cost: 2.7166 - val_loss: 0.1137 - val_auc: 0.9838 - val_accuracy: 0.9719 - val_cost: 3.2943\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.6819 - val_loss: 0.1153 - val_auc: 0.9838 - val_accuracy: 0.9706 - val_cost: 3.4766\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6456 - val_loss: 0.1158 - val_auc: 0.9841 - val_accuracy: 0.9707 - val_cost: 3.7988\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9923 - accuracy: 0.9789 - cost: 2.7228 - val_loss: 0.1143 - val_auc: 0.9846 - val_accuracy: 0.9700 - val_cost: 4.0299\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6956 - val_loss: 0.1140 - val_auc: 0.9838 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7450 - val_loss: 0.1151 - val_auc: 0.9838 - val_accuracy: 0.9710 - val_cost: 3.5514\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6203 - val_loss: 0.1154 - val_auc: 0.9842 - val_accuracy: 0.9709 - val_cost: 3.4440\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6620 - val_loss: 0.1168 - val_auc: 0.9830 - val_accuracy: 0.9706 - val_cost: 3.4766\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0728 - auc: 0.9925 - accuracy: 0.9795 - cost: 2.6436 - val_loss: 0.1154 - val_auc: 0.9833 - val_accuracy: 0.9709 - val_cost: 3.6947\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6560 - val_loss: 0.1154 - val_auc: 0.9837 - val_accuracy: 0.9704 - val_cost: 3.5840\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9925 - accuracy: 0.9797 - cost: 2.6252 - val_loss: 0.1145 - val_auc: 0.9837 - val_accuracy: 0.9706 - val_cost: 3.6654\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9926 - accuracy: 0.9786 - cost: 2.7625 - val_loss: 0.1168 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.6523\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6648 - val_loss: 0.1171 - val_auc: 0.9835 - val_accuracy: 0.9705 - val_cost: 3.4766\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6210 - val_loss: 0.1162 - val_auc: 0.9835 - val_accuracy: 0.9699 - val_cost: 3.8737\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6823 - val_loss: 0.1170 - val_auc: 0.9835 - val_accuracy: 0.9704 - val_cost: 3.4798\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7257 - val_loss: 0.1169 - val_auc: 0.9832 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6339 - val_loss: 0.1157 - val_auc: 0.9844 - val_accuracy: 0.9714 - val_cost: 3.7207\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6698 - val_loss: 0.1167 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.6100\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6972 - val_loss: 0.1195 - val_auc: 0.9827 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9797 - cost: 2.6379 - val_loss: 0.1167 - val_auc: 0.9831 - val_accuracy: 0.9722 - val_cost: 3.3659\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9798 - cost: 2.6032 - val_loss: 0.1144 - val_auc: 0.9840 - val_accuracy: 0.9706 - val_cost: 3.6296\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6173 - val_loss: 0.1154 - val_auc: 0.9834 - val_accuracy: 0.9698 - val_cost: 3.6003\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6159 - val_loss: 0.1191 - val_auc: 0.9834 - val_accuracy: 0.9697 - val_cost: 3.7663\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6767 - val_loss: 0.1160 - val_auc: 0.9829 - val_accuracy: 0.9702 - val_cost: 3.8086\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9929 - accuracy: 0.9795 - cost: 2.6498 - val_loss: 0.1179 - val_auc: 0.9837 - val_accuracy: 0.9705 - val_cost: 3.6361\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6627 - val_loss: 0.1184 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.5059\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6556 - val_loss: 0.1155 - val_auc: 0.9844 - val_accuracy: 0.9714 - val_cost: 3.6914\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6546 - val_loss: 0.1178 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.6003\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6334 - val_loss: 0.1174 - val_auc: 0.9837 - val_accuracy: 0.9698 - val_cost: 3.7305\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6238 - val_loss: 0.1185 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.3789\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1165 - val_auc: 0.9839 - val_accuracy: 0.9706 - val_cost: 3.8053\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9924 - accuracy: 0.9794 - cost: 2.6650 - val_loss: 0.1163 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.5124\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6863 - val_loss: 0.1174 - val_auc: 0.9833 - val_accuracy: 0.9705 - val_cost: 3.4310\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9929 - accuracy: 0.9793 - cost: 2.6741 - val_loss: 0.1182 - val_auc: 0.9829 - val_accuracy: 0.9714 - val_cost: 3.6556\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6034 - val_loss: 0.1179 - val_auc: 0.9830 - val_accuracy: 0.9702 - val_cost: 3.6719\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6679 - val_loss: 0.1174 - val_auc: 0.9827 - val_accuracy: 0.9706 - val_cost: 3.4538\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5689 - val_loss: 0.1175 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5952 - val_loss: 0.1177 - val_auc: 0.9834 - val_accuracy: 0.9707 - val_cost: 3.7695\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6527 - val_loss: 0.1196 - val_auc: 0.9824 - val_accuracy: 0.9706 - val_cost: 3.4277\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9930 - accuracy: 0.9793 - cost: 2.6784 - val_loss: 0.1186 - val_auc: 0.9840 - val_accuracy: 0.9711 - val_cost: 3.5938\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6145 - val_loss: 0.1178 - val_auc: 0.9840 - val_accuracy: 0.9704 - val_cost: 3.5384\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6204 - val_loss: 0.1182 - val_auc: 0.9836 - val_accuracy: 0.9705 - val_cost: 3.7728\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6309 - val_loss: 0.1171 - val_auc: 0.9839 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6171 - val_loss: 0.1177 - val_auc: 0.9841 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6283 - val_loss: 0.1170 - val_auc: 0.9834 - val_accuracy: 0.9717 - val_cost: 3.2747\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9927 - accuracy: 0.9799 - cost: 2.5961 - val_loss: 0.1171 - val_auc: 0.9834 - val_accuracy: 0.9720 - val_cost: 3.5872\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9925 - accuracy: 0.9796 - cost: 2.6543 - val_loss: 0.1183 - val_auc: 0.9825 - val_accuracy: 0.9705 - val_cost: 3.4831\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6442 - val_loss: 0.1177 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.5990 - val_loss: 0.1181 - val_auc: 0.9841 - val_accuracy: 0.9706 - val_cost: 3.6914\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6275 - val_loss: 0.1183 - val_auc: 0.9831 - val_accuracy: 0.9701 - val_cost: 3.6393\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6649 - val_loss: 0.1164 - val_auc: 0.9830 - val_accuracy: 0.9707 - val_cost: 3.9095\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6404 - val_loss: 0.1168 - val_auc: 0.9836 - val_accuracy: 0.9715 - val_cost: 3.5872\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5995 - val_loss: 0.1183 - val_auc: 0.9836 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9932 - accuracy: 0.9799 - cost: 2.6016 - val_loss: 0.1194 - val_auc: 0.9829 - val_accuracy: 0.9700 - val_cost: 3.6979\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9927 - accuracy: 0.9801 - cost: 2.5837 - val_loss: 0.1195 - val_auc: 0.9827 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9929 - accuracy: 0.9802 - cost: 2.5442 - val_loss: 0.1196 - val_auc: 0.9830 - val_accuracy: 0.9692 - val_cost: 3.9421\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.6043 - val_loss: 0.1151 - val_auc: 0.9842 - val_accuracy: 0.9710 - val_cost: 3.7728\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6190 - val_loss: 0.1165 - val_auc: 0.9842 - val_accuracy: 0.9707 - val_cost: 3.7923\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6171 - val_loss: 0.1200 - val_auc: 0.9829 - val_accuracy: 0.9699 - val_cost: 3.8346\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6472 - val_loss: 0.1167 - val_auc: 0.9834 - val_accuracy: 0.9717 - val_cost: 3.5221\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5741 - val_loss: 0.1172 - val_auc: 0.9832 - val_accuracy: 0.9710 - val_cost: 3.7142\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6536 - val_loss: 0.1185 - val_auc: 0.9823 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9928 - accuracy: 0.9802 - cost: 2.5650 - val_loss: 0.1195 - val_auc: 0.9834 - val_accuracy: 0.9700 - val_cost: 3.4831\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5966 - val_loss: 0.1205 - val_auc: 0.9830 - val_accuracy: 0.9705 - val_cost: 3.6523\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5738 - val_loss: 0.1198 - val_auc: 0.9825 - val_accuracy: 0.9708 - val_cost: 3.5352\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5837 - val_loss: 0.1170 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5981 - val_loss: 0.1185 - val_auc: 0.9840 - val_accuracy: 0.9701 - val_cost: 3.8900\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5466 - val_loss: 0.1173 - val_auc: 0.9832 - val_accuracy: 0.9702 - val_cost: 3.7923\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6210 - val_loss: 0.1157 - val_auc: 0.9842 - val_accuracy: 0.9715 - val_cost: 3.2975\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5303 - val_loss: 0.1177 - val_auc: 0.9834 - val_accuracy: 0.9696 - val_cost: 3.8802\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6046 - val_loss: 0.1186 - val_auc: 0.9838 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5917 - val_loss: 0.1188 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.4082\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9928 - accuracy: 0.9803 - cost: 2.5409 - val_loss: 0.1195 - val_auc: 0.9837 - val_accuracy: 0.9705 - val_cost: 3.5156\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5998 - val_loss: 0.1193 - val_auc: 0.9838 - val_accuracy: 0.9703 - val_cost: 3.6491\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9803 - cost: 2.5359 - val_loss: 0.1184 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.7012\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9804 - cost: 2.5401 - val_loss: 0.1190 - val_auc: 0.9834 - val_accuracy: 0.9698 - val_cost: 3.9323\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5638 - val_loss: 0.1199 - val_auc: 0.9832 - val_accuracy: 0.9710 - val_cost: 3.4212\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9933 - accuracy: 0.9799 - cost: 2.5975 - val_loss: 0.1180 - val_auc: 0.9833 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6174 - val_loss: 0.1177 - val_auc: 0.9835 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5433 - val_loss: 0.1221 - val_auc: 0.9830 - val_accuracy: 0.9709 - val_cost: 3.6165\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9928 - accuracy: 0.9804 - cost: 2.5285 - val_loss: 0.1197 - val_auc: 0.9833 - val_accuracy: 0.9704 - val_cost: 3.4733\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5747 - val_loss: 0.1197 - val_auc: 0.9829 - val_accuracy: 0.9709 - val_cost: 3.5742\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5570 - val_loss: 0.1209 - val_auc: 0.9827 - val_accuracy: 0.9709 - val_cost: 3.5482\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5207 - val_loss: 0.1202 - val_auc: 0.9824 - val_accuracy: 0.9708 - val_cost: 3.4733\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9928 - accuracy: 0.9804 - cost: 2.5300 - val_loss: 0.1177 - val_auc: 0.9834 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5812 - val_loss: 0.1192 - val_auc: 0.9833 - val_accuracy: 0.9713 - val_cost: 3.3529\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6170 - val_loss: 0.1209 - val_auc: 0.9830 - val_accuracy: 0.9705 - val_cost: 3.5254\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5764 - val_loss: 0.1166 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.5091\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9931 - accuracy: 0.9807 - cost: 2.4866 - val_loss: 0.1200 - val_auc: 0.9840 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6506 - val_loss: 0.1185 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.7240\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5718 - val_loss: 0.1215 - val_auc: 0.9820 - val_accuracy: 0.9698 - val_cost: 3.6133\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5630 - val_loss: 0.1218 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.4049\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9929 - accuracy: 0.9803 - cost: 2.5472 - val_loss: 0.1193 - val_auc: 0.9841 - val_accuracy: 0.9705 - val_cost: 3.6719\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5716 - val_loss: 0.1226 - val_auc: 0.9828 - val_accuracy: 0.9700 - val_cost: 3.5319\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5233 - val_loss: 0.1183 - val_auc: 0.9831 - val_accuracy: 0.9696 - val_cost: 3.8965\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5471 - val_loss: 0.1194 - val_auc: 0.9829 - val_accuracy: 0.9701 - val_cost: 3.6621\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5452 - val_loss: 0.1195 - val_auc: 0.9829 - val_accuracy: 0.9707 - val_cost: 3.5775\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9929 - accuracy: 0.9804 - cost: 2.5428 - val_loss: 0.1214 - val_auc: 0.9830 - val_accuracy: 0.9693 - val_cost: 3.9290\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5861 - val_loss: 0.1190 - val_auc: 0.9838 - val_accuracy: 0.9706 - val_cost: 3.6361\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6261 - val_loss: 0.1193 - val_auc: 0.9835 - val_accuracy: 0.9702 - val_cost: 3.4375\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9929 - accuracy: 0.9805 - cost: 2.5158 - val_loss: 0.1197 - val_auc: 0.9835 - val_accuracy: 0.9702 - val_cost: 3.4993\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9930 - accuracy: 0.9805 - cost: 2.5163 - val_loss: 0.1186 - val_auc: 0.9834 - val_accuracy: 0.9708 - val_cost: 3.6165\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5611 - val_loss: 0.1205 - val_auc: 0.9832 - val_accuracy: 0.9702 - val_cost: 3.8216\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5477 - val_loss: 0.1223 - val_auc: 0.9814 - val_accuracy: 0.9694 - val_cost: 3.8770\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5522 - val_loss: 0.1199 - val_auc: 0.9831 - val_accuracy: 0.9701 - val_cost: 3.8444\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9930 - accuracy: 0.9805 - cost: 2.5226 - val_loss: 0.1205 - val_auc: 0.9830 - val_accuracy: 0.9704 - val_cost: 3.7272\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9931 - accuracy: 0.9807 - cost: 2.4889 - val_loss: 0.1204 - val_auc: 0.9831 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5347 - val_loss: 0.1215 - val_auc: 0.9827 - val_accuracy: 0.9715 - val_cost: 3.3431\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9931 - accuracy: 0.9809 - cost: 2.4708 - val_loss: 0.1219 - val_auc: 0.9823 - val_accuracy: 0.9703 - val_cost: 3.6165\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5567 - val_loss: 0.1230 - val_auc: 0.9827 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5417 - val_loss: 0.1203 - val_auc: 0.9820 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5340 - val_loss: 0.1213 - val_auc: 0.9832 - val_accuracy: 0.9699 - val_cost: 3.7370\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5676 - val_loss: 0.1189 - val_auc: 0.9834 - val_accuracy: 0.9698 - val_cost: 3.9128\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5276 - val_loss: 0.1189 - val_auc: 0.9843 - val_accuracy: 0.9710 - val_cost: 3.4049\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5501 - val_loss: 0.1194 - val_auc: 0.9827 - val_accuracy: 0.9717 - val_cost: 3.6621\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5170 - val_loss: 0.1220 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.5417\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9932 - accuracy: 0.9805 - cost: 2.5217 - val_loss: 0.1202 - val_auc: 0.9836 - val_accuracy: 0.9697 - val_cost: 3.5417\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5529 - val_loss: 0.1213 - val_auc: 0.9826 - val_accuracy: 0.9707 - val_cost: 3.7142\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9927 - accuracy: 0.9805 - cost: 2.5204 - val_loss: 0.1201 - val_auc: 0.9842 - val_accuracy: 0.9700 - val_cost: 3.8574\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5572 - val_loss: 0.1204 - val_auc: 0.9832 - val_accuracy: 0.9714 - val_cost: 3.4766\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9929 - accuracy: 0.9806 - cost: 2.5143 - val_loss: 0.1190 - val_auc: 0.9841 - val_accuracy: 0.9704 - val_cost: 3.6589\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5462 - val_loss: 0.1200 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.5124\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9931 - accuracy: 0.9814 - cost: 2.4109 - val_loss: 0.1183 - val_auc: 0.9845 - val_accuracy: 0.9710 - val_cost: 3.4245\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5113 - val_loss: 0.1192 - val_auc: 0.9835 - val_accuracy: 0.9691 - val_cost: 3.6849\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4496 - val_loss: 0.1199 - val_auc: 0.9837 - val_accuracy: 0.9703 - val_cost: 3.8477\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9809 - cost: 2.4842 - val_loss: 0.1228 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.5221\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5193 - val_loss: 0.1202 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5070 - val_loss: 0.1203 - val_auc: 0.9833 - val_accuracy: 0.9694 - val_cost: 3.9648\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9932 - accuracy: 0.9806 - cost: 2.5063 - val_loss: 0.1198 - val_auc: 0.9837 - val_accuracy: 0.9706 - val_cost: 3.4505\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9934 - accuracy: 0.9801 - cost: 2.5811 - val_loss: 0.1202 - val_auc: 0.9829 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9929 - accuracy: 0.9807 - cost: 2.5007 - val_loss: 0.1191 - val_auc: 0.9833 - val_accuracy: 0.9714 - val_cost: 3.8542\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5254 - val_loss: 0.1217 - val_auc: 0.9825 - val_accuracy: 0.9699 - val_cost: 3.6686\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5454 - val_loss: 0.1216 - val_auc: 0.9829 - val_accuracy: 0.9701 - val_cost: 3.4831\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5835 - val_loss: 0.1201 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.6816\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5330 - val_loss: 0.1219 - val_auc: 0.9829 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9931 - accuracy: 0.9810 - cost: 2.4682 - val_loss: 0.1218 - val_auc: 0.9825 - val_accuracy: 0.9697 - val_cost: 3.9876\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5635 - val_loss: 0.1204 - val_auc: 0.9831 - val_accuracy: 0.9709 - val_cost: 3.6882\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9805 - cost: 2.5216 - val_loss: 0.1203 - val_auc: 0.9836 - val_accuracy: 0.9699 - val_cost: 3.6947\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4843 - val_loss: 0.1213 - val_auc: 0.9829 - val_accuracy: 0.9696 - val_cost: 3.7435\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9931 - accuracy: 0.9807 - cost: 2.5022 - val_loss: 0.1201 - val_auc: 0.9830 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5121 - val_loss: 0.1198 - val_auc: 0.9826 - val_accuracy: 0.9694 - val_cost: 3.9095\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4748 - val_loss: 0.1235 - val_auc: 0.9825 - val_accuracy: 0.9693 - val_cost: 3.5156\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0685 - auc: 0.9933 - accuracy: 0.9807 - cost: 2.5004 - val_loss: 0.1212 - val_auc: 0.9833 - val_accuracy: 0.9699 - val_cost: 3.6816\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9932 - accuracy: 0.9808 - cost: 2.4765 - val_loss: 0.1222 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.6491\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4927 - val_loss: 0.1244 - val_auc: 0.9823 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9930 - accuracy: 0.9810 - cost: 2.4668 - val_loss: 0.1217 - val_auc: 0.9833 - val_accuracy: 0.9694 - val_cost: 3.9095\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4667 - val_loss: 0.1248 - val_auc: 0.9817 - val_accuracy: 0.9701 - val_cost: 3.5026\n",
            "Epoch 361/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5244 - val_loss: 0.1215 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.4049\n",
            "Epoch 362/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9932 - accuracy: 0.9808 - cost: 2.4840 - val_loss: 0.1205 - val_auc: 0.9836 - val_accuracy: 0.9699 - val_cost: 3.7272\n",
            "Epoch 363/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4852 - val_loss: 0.1221 - val_auc: 0.9826 - val_accuracy: 0.9698 - val_cost: 3.6589\n",
            "Epoch 364/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4905 - val_loss: 0.1219 - val_auc: 0.9833 - val_accuracy: 0.9697 - val_cost: 4.0690\n",
            "Epoch 365/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5262 - val_loss: 0.1205 - val_auc: 0.9839 - val_accuracy: 0.9694 - val_cost: 3.6100\n",
            "Epoch 366/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4792 - val_loss: 0.1172 - val_auc: 0.9835 - val_accuracy: 0.9715 - val_cost: 3.5352\n",
            "Epoch 367/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5123 - val_loss: 0.1233 - val_auc: 0.9817 - val_accuracy: 0.9700 - val_cost: 3.7012\n",
            "Epoch 368/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5733 - val_loss: 0.1223 - val_auc: 0.9820 - val_accuracy: 0.9705 - val_cost: 3.7598\n",
            "Epoch 369/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4574 - val_loss: 0.1232 - val_auc: 0.9826 - val_accuracy: 0.9704 - val_cost: 3.6230\n",
            "Epoch 370/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9811 - cost: 2.4513 - val_loss: 0.1201 - val_auc: 0.9826 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 371/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9934 - accuracy: 0.9810 - cost: 2.4434 - val_loss: 0.1237 - val_auc: 0.9820 - val_accuracy: 0.9692 - val_cost: 4.1699\n",
            "Epoch 372/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5840 - val_loss: 0.1236 - val_auc: 0.9833 - val_accuracy: 0.9699 - val_cost: 3.6914\n",
            "Epoch 373/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5483 - val_loss: 0.1224 - val_auc: 0.9819 - val_accuracy: 0.9699 - val_cost: 3.6816\n",
            "Epoch 374/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5325 - val_loss: 0.1222 - val_auc: 0.9828 - val_accuracy: 0.9698 - val_cost: 3.9355\n",
            "Epoch 375/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4775 - val_loss: 0.1222 - val_auc: 0.9834 - val_accuracy: 0.9702 - val_cost: 3.8151\n",
            "Epoch 376/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5206 - val_loss: 0.1223 - val_auc: 0.9830 - val_accuracy: 0.9685 - val_cost: 4.0592\n",
            "Epoch 377/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4345 - val_loss: 0.1235 - val_auc: 0.9824 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 378/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9935 - accuracy: 0.9812 - cost: 2.4297 - val_loss: 0.1213 - val_auc: 0.9824 - val_accuracy: 0.9699 - val_cost: 3.9290\n",
            "Epoch 379/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4326 - val_loss: 0.1239 - val_auc: 0.9820 - val_accuracy: 0.9703 - val_cost: 3.6426\n",
            "Epoch 380/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4738 - val_loss: 0.1224 - val_auc: 0.9829 - val_accuracy: 0.9697 - val_cost: 3.9062\n",
            "Epoch 381/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4925 - val_loss: 0.1233 - val_auc: 0.9819 - val_accuracy: 0.9695 - val_cost: 3.7109\n",
            "Epoch 382/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4828 - val_loss: 0.1232 - val_auc: 0.9831 - val_accuracy: 0.9698 - val_cost: 3.7663\n",
            "Epoch 383/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4634 - val_loss: 0.1215 - val_auc: 0.9828 - val_accuracy: 0.9698 - val_cost: 3.5645\n",
            "Epoch 384/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9935 - accuracy: 0.9811 - cost: 2.4482 - val_loss: 0.1239 - val_auc: 0.9830 - val_accuracy: 0.9690 - val_cost: 3.8477\n",
            "Epoch 385/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9930 - accuracy: 0.9808 - cost: 2.4893 - val_loss: 0.1217 - val_auc: 0.9824 - val_accuracy: 0.9691 - val_cost: 4.1406\n",
            "Epoch 386/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9806 - cost: 2.5276 - val_loss: 0.1265 - val_auc: 0.9816 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1068 - auc: 0.9848 - accuracy: 0.9721 - cost: 3.5563\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:42.346146\n",
            "fold accuracy: 0.9721249938011169 - fold cost: 3.5562500953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5445 - auc: 0.7122 - accuracy: 0.7161 - cost: 37.5719 - val_loss: 0.4099 - val_auc: 0.8496 - val_accuracy: 0.8222 - val_cost: 22.5749\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3664 - auc: 0.8765 - accuracy: 0.8422 - cost: 20.0714 - val_loss: 0.3243 - val_auc: 0.9055 - val_accuracy: 0.8618 - val_cost: 16.5951\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3140 - auc: 0.9105 - accuracy: 0.8704 - cost: 16.3583 - val_loss: 0.2948 - val_auc: 0.9251 - val_accuracy: 0.8778 - val_cost: 14.6452\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2861 - auc: 0.9266 - accuracy: 0.8830 - cost: 14.7612 - val_loss: 0.2721 - val_auc: 0.9369 - val_accuracy: 0.8902 - val_cost: 13.2878\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2641 - auc: 0.9380 - accuracy: 0.8941 - cost: 13.3667 - val_loss: 0.2522 - val_auc: 0.9461 - val_accuracy: 0.9013 - val_cost: 12.0443\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2468 - auc: 0.9459 - accuracy: 0.9033 - cost: 12.2068 - val_loss: 0.2356 - val_auc: 0.9525 - val_accuracy: 0.9082 - val_cost: 11.2402\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2305 - auc: 0.9525 - accuracy: 0.9104 - cost: 11.3335 - val_loss: 0.2250 - val_auc: 0.9563 - val_accuracy: 0.9153 - val_cost: 10.2279\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2182 - auc: 0.9575 - accuracy: 0.9164 - cost: 10.5886 - val_loss: 0.2122 - val_auc: 0.9609 - val_accuracy: 0.9199 - val_cost: 9.9479\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2062 - auc: 0.9619 - accuracy: 0.9225 - cost: 9.7875 - val_loss: 0.2018 - val_auc: 0.9636 - val_accuracy: 0.9262 - val_cost: 8.8574\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1960 - auc: 0.9652 - accuracy: 0.9266 - cost: 9.3049 - val_loss: 0.1924 - val_auc: 0.9665 - val_accuracy: 0.9302 - val_cost: 8.6393\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1884 - auc: 0.9677 - accuracy: 0.9302 - cost: 8.8385 - val_loss: 0.1843 - val_auc: 0.9690 - val_accuracy: 0.9335 - val_cost: 8.3008\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1816 - auc: 0.9698 - accuracy: 0.9337 - cost: 8.4173 - val_loss: 0.1789 - val_auc: 0.9703 - val_accuracy: 0.9365 - val_cost: 7.8483\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1745 - auc: 0.9719 - accuracy: 0.9368 - cost: 8.0025 - val_loss: 0.1731 - val_auc: 0.9722 - val_accuracy: 0.9403 - val_cost: 7.5586\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1693 - auc: 0.9734 - accuracy: 0.9395 - cost: 7.6907 - val_loss: 0.1690 - val_auc: 0.9734 - val_accuracy: 0.9395 - val_cost: 7.4121\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1629 - auc: 0.9751 - accuracy: 0.9419 - cost: 7.3748 - val_loss: 0.1628 - val_auc: 0.9748 - val_accuracy: 0.9433 - val_cost: 7.1419\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1590 - auc: 0.9762 - accuracy: 0.9442 - cost: 7.0966 - val_loss: 0.1604 - val_auc: 0.9757 - val_accuracy: 0.9444 - val_cost: 7.0768\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1551 - auc: 0.9772 - accuracy: 0.9450 - cost: 6.9670 - val_loss: 0.1566 - val_auc: 0.9770 - val_accuracy: 0.9451 - val_cost: 7.0085\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1523 - auc: 0.9779 - accuracy: 0.9469 - cost: 6.7461 - val_loss: 0.1534 - val_auc: 0.9778 - val_accuracy: 0.9467 - val_cost: 6.9857\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1486 - auc: 0.9789 - accuracy: 0.9486 - cost: 6.5407 - val_loss: 0.1509 - val_auc: 0.9784 - val_accuracy: 0.9467 - val_cost: 6.8164\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1463 - auc: 0.9793 - accuracy: 0.9500 - cost: 6.3580 - val_loss: 0.1511 - val_auc: 0.9780 - val_accuracy: 0.9480 - val_cost: 6.6992\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1434 - auc: 0.9802 - accuracy: 0.9517 - cost: 6.1388 - val_loss: 0.1465 - val_auc: 0.9795 - val_accuracy: 0.9500 - val_cost: 6.4811\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1402 - auc: 0.9807 - accuracy: 0.9519 - cost: 6.1068 - val_loss: 0.1457 - val_auc: 0.9801 - val_accuracy: 0.9509 - val_cost: 6.5007\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1383 - auc: 0.9812 - accuracy: 0.9533 - cost: 5.9305 - val_loss: 0.1413 - val_auc: 0.9810 - val_accuracy: 0.9531 - val_cost: 5.9993\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9819 - accuracy: 0.9544 - cost: 5.7970 - val_loss: 0.1406 - val_auc: 0.9812 - val_accuracy: 0.9538 - val_cost: 6.0319\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1334 - auc: 0.9823 - accuracy: 0.9554 - cost: 5.6513 - val_loss: 0.1396 - val_auc: 0.9810 - val_accuracy: 0.9530 - val_cost: 6.0579\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1322 - auc: 0.9821 - accuracy: 0.9556 - cost: 5.6433 - val_loss: 0.1373 - val_auc: 0.9814 - val_accuracy: 0.9551 - val_cost: 5.8529\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9832 - accuracy: 0.9564 - cost: 5.5355 - val_loss: 0.1361 - val_auc: 0.9818 - val_accuracy: 0.9565 - val_cost: 5.4102\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1278 - auc: 0.9835 - accuracy: 0.9578 - cost: 5.3629 - val_loss: 0.1355 - val_auc: 0.9820 - val_accuracy: 0.9557 - val_cost: 5.8105\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1274 - auc: 0.9835 - accuracy: 0.9582 - cost: 5.3025 - val_loss: 0.1342 - val_auc: 0.9815 - val_accuracy: 0.9573 - val_cost: 5.6120\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1248 - auc: 0.9843 - accuracy: 0.9594 - cost: 5.1685 - val_loss: 0.1340 - val_auc: 0.9820 - val_accuracy: 0.9571 - val_cost: 5.7194\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1223 - auc: 0.9843 - accuracy: 0.9599 - cost: 5.0879 - val_loss: 0.1301 - val_auc: 0.9823 - val_accuracy: 0.9584 - val_cost: 5.2376\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1217 - auc: 0.9847 - accuracy: 0.9599 - cost: 5.0918 - val_loss: 0.1310 - val_auc: 0.9819 - val_accuracy: 0.9591 - val_cost: 5.0391\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1194 - auc: 0.9850 - accuracy: 0.9613 - cost: 4.9198 - val_loss: 0.1284 - val_auc: 0.9822 - val_accuracy: 0.9590 - val_cost: 5.2539\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1173 - auc: 0.9854 - accuracy: 0.9623 - cost: 4.7913 - val_loss: 0.1267 - val_auc: 0.9830 - val_accuracy: 0.9602 - val_cost: 5.1628\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1178 - auc: 0.9852 - accuracy: 0.9624 - cost: 4.7844 - val_loss: 0.1257 - val_auc: 0.9832 - val_accuracy: 0.9602 - val_cost: 5.2441\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9856 - accuracy: 0.9630 - cost: 4.7095 - val_loss: 0.1249 - val_auc: 0.9834 - val_accuracy: 0.9607 - val_cost: 4.9382\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1141 - auc: 0.9860 - accuracy: 0.9635 - cost: 4.6335 - val_loss: 0.1244 - val_auc: 0.9834 - val_accuracy: 0.9623 - val_cost: 4.7461\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1130 - auc: 0.9861 - accuracy: 0.9639 - cost: 4.5923 - val_loss: 0.1230 - val_auc: 0.9834 - val_accuracy: 0.9623 - val_cost: 4.8405\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1121 - auc: 0.9864 - accuracy: 0.9645 - cost: 4.5169 - val_loss: 0.1227 - val_auc: 0.9838 - val_accuracy: 0.9625 - val_cost: 4.5605\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9863 - accuracy: 0.9648 - cost: 4.4872 - val_loss: 0.1242 - val_auc: 0.9829 - val_accuracy: 0.9625 - val_cost: 4.7168\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1102 - auc: 0.9866 - accuracy: 0.9655 - cost: 4.3991 - val_loss: 0.1212 - val_auc: 0.9838 - val_accuracy: 0.9637 - val_cost: 4.6452\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9861 - accuracy: 0.9654 - cost: 4.4047 - val_loss: 0.1222 - val_auc: 0.9838 - val_accuracy: 0.9635 - val_cost: 4.2904\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9871 - accuracy: 0.9668 - cost: 4.2233 - val_loss: 0.1212 - val_auc: 0.9836 - val_accuracy: 0.9635 - val_cost: 4.4043\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9871 - accuracy: 0.9662 - cost: 4.2990 - val_loss: 0.1190 - val_auc: 0.9839 - val_accuracy: 0.9647 - val_cost: 4.3587\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9871 - accuracy: 0.9667 - cost: 4.2363 - val_loss: 0.1200 - val_auc: 0.9837 - val_accuracy: 0.9640 - val_cost: 4.3522\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1060 - auc: 0.9873 - accuracy: 0.9673 - cost: 4.1626 - val_loss: 0.1192 - val_auc: 0.9839 - val_accuracy: 0.9640 - val_cost: 4.3815\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1039 - auc: 0.9879 - accuracy: 0.9673 - cost: 4.1742 - val_loss: 0.1175 - val_auc: 0.9846 - val_accuracy: 0.9647 - val_cost: 4.2188\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9875 - accuracy: 0.9678 - cost: 4.1028 - val_loss: 0.1182 - val_auc: 0.9839 - val_accuracy: 0.9651 - val_cost: 4.1764\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1039 - auc: 0.9878 - accuracy: 0.9681 - cost: 4.0566 - val_loss: 0.1185 - val_auc: 0.9838 - val_accuracy: 0.9657 - val_cost: 4.2871\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1040 - auc: 0.9876 - accuracy: 0.9681 - cost: 4.0835 - val_loss: 0.1163 - val_auc: 0.9844 - val_accuracy: 0.9658 - val_cost: 4.0885\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9880 - accuracy: 0.9688 - cost: 3.9755 - val_loss: 0.1163 - val_auc: 0.9841 - val_accuracy: 0.9657 - val_cost: 4.1699\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9881 - accuracy: 0.9689 - cost: 3.9456 - val_loss: 0.1164 - val_auc: 0.9838 - val_accuracy: 0.9658 - val_cost: 4.2546\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1024 - auc: 0.9881 - accuracy: 0.9688 - cost: 3.9876 - val_loss: 0.1158 - val_auc: 0.9835 - val_accuracy: 0.9663 - val_cost: 4.2090\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1005 - auc: 0.9883 - accuracy: 0.9694 - cost: 3.9092 - val_loss: 0.1162 - val_auc: 0.9835 - val_accuracy: 0.9665 - val_cost: 4.3424\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9882 - accuracy: 0.9697 - cost: 3.8710 - val_loss: 0.1142 - val_auc: 0.9838 - val_accuracy: 0.9662 - val_cost: 4.1081\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0994 - auc: 0.9884 - accuracy: 0.9700 - cost: 3.8329 - val_loss: 0.1148 - val_auc: 0.9839 - val_accuracy: 0.9665 - val_cost: 4.0560\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1003 - auc: 0.9881 - accuracy: 0.9698 - cost: 3.8702 - val_loss: 0.1152 - val_auc: 0.9843 - val_accuracy: 0.9669 - val_cost: 4.1243\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9886 - accuracy: 0.9697 - cost: 3.8575 - val_loss: 0.1152 - val_auc: 0.9836 - val_accuracy: 0.9672 - val_cost: 4.0625\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9887 - accuracy: 0.9704 - cost: 3.7950 - val_loss: 0.1140 - val_auc: 0.9839 - val_accuracy: 0.9662 - val_cost: 4.1081\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0971 - auc: 0.9890 - accuracy: 0.9712 - cost: 3.6853 - val_loss: 0.1148 - val_auc: 0.9837 - val_accuracy: 0.9662 - val_cost: 4.1895\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0971 - auc: 0.9887 - accuracy: 0.9709 - cost: 3.7412 - val_loss: 0.1136 - val_auc: 0.9844 - val_accuracy: 0.9662 - val_cost: 4.1243\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9890 - accuracy: 0.9712 - cost: 3.6761 - val_loss: 0.1136 - val_auc: 0.9839 - val_accuracy: 0.9670 - val_cost: 4.0430\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9889 - accuracy: 0.9713 - cost: 3.6794 - val_loss: 0.1153 - val_auc: 0.9840 - val_accuracy: 0.9656 - val_cost: 4.1602\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9890 - accuracy: 0.9717 - cost: 3.6264 - val_loss: 0.1124 - val_auc: 0.9842 - val_accuracy: 0.9685 - val_cost: 3.8932\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9893 - accuracy: 0.9715 - cost: 3.6513 - val_loss: 0.1145 - val_auc: 0.9843 - val_accuracy: 0.9666 - val_cost: 4.0104\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9892 - accuracy: 0.9715 - cost: 3.6421 - val_loss: 0.1144 - val_auc: 0.9839 - val_accuracy: 0.9685 - val_cost: 3.8411\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9892 - accuracy: 0.9719 - cost: 3.5866 - val_loss: 0.1137 - val_auc: 0.9840 - val_accuracy: 0.9674 - val_cost: 4.0495\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9892 - accuracy: 0.9720 - cost: 3.5829 - val_loss: 0.1132 - val_auc: 0.9841 - val_accuracy: 0.9666 - val_cost: 4.0755\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9897 - accuracy: 0.9721 - cost: 3.5792 - val_loss: 0.1140 - val_auc: 0.9840 - val_accuracy: 0.9658 - val_cost: 4.0918\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9895 - accuracy: 0.9725 - cost: 3.5281 - val_loss: 0.1140 - val_auc: 0.9841 - val_accuracy: 0.9676 - val_cost: 4.0397\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9899 - accuracy: 0.9726 - cost: 3.4977 - val_loss: 0.1111 - val_auc: 0.9844 - val_accuracy: 0.9681 - val_cost: 3.8997\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0930 - auc: 0.9896 - accuracy: 0.9726 - cost: 3.5163 - val_loss: 0.1109 - val_auc: 0.9849 - val_accuracy: 0.9678 - val_cost: 4.1667\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9897 - accuracy: 0.9730 - cost: 3.4540 - val_loss: 0.1120 - val_auc: 0.9843 - val_accuracy: 0.9682 - val_cost: 3.9844\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9898 - accuracy: 0.9725 - cost: 3.5249 - val_loss: 0.1129 - val_auc: 0.9839 - val_accuracy: 0.9680 - val_cost: 3.8997\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9897 - accuracy: 0.9730 - cost: 3.4740 - val_loss: 0.1126 - val_auc: 0.9845 - val_accuracy: 0.9674 - val_cost: 4.2383\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0907 - auc: 0.9897 - accuracy: 0.9730 - cost: 3.4627 - val_loss: 0.1117 - val_auc: 0.9849 - val_accuracy: 0.9682 - val_cost: 3.8965\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9900 - accuracy: 0.9733 - cost: 3.4279 - val_loss: 0.1126 - val_auc: 0.9839 - val_accuracy: 0.9681 - val_cost: 3.9128\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0896 - auc: 0.9900 - accuracy: 0.9732 - cost: 3.4454 - val_loss: 0.1114 - val_auc: 0.9849 - val_accuracy: 0.9681 - val_cost: 3.8802\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0908 - auc: 0.9900 - accuracy: 0.9731 - cost: 3.4528 - val_loss: 0.1114 - val_auc: 0.9847 - val_accuracy: 0.9689 - val_cost: 3.7923\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9896 - accuracy: 0.9734 - cost: 3.4120 - val_loss: 0.1119 - val_auc: 0.9846 - val_accuracy: 0.9685 - val_cost: 3.7109\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0904 - auc: 0.9900 - accuracy: 0.9735 - cost: 3.4093 - val_loss: 0.1127 - val_auc: 0.9845 - val_accuracy: 0.9695 - val_cost: 3.8379\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9900 - accuracy: 0.9734 - cost: 3.3991 - val_loss: 0.1110 - val_auc: 0.9849 - val_accuracy: 0.9685 - val_cost: 3.7695\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9903 - accuracy: 0.9737 - cost: 3.3849 - val_loss: 0.1129 - val_auc: 0.9844 - val_accuracy: 0.9683 - val_cost: 3.7565\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9900 - accuracy: 0.9741 - cost: 3.3167 - val_loss: 0.1118 - val_auc: 0.9849 - val_accuracy: 0.9694 - val_cost: 3.5254\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9901 - accuracy: 0.9737 - cost: 3.3887 - val_loss: 0.1121 - val_auc: 0.9844 - val_accuracy: 0.9679 - val_cost: 4.0234\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9904 - accuracy: 0.9739 - cost: 3.3477 - val_loss: 0.1122 - val_auc: 0.9844 - val_accuracy: 0.9685 - val_cost: 3.8379\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9904 - accuracy: 0.9744 - cost: 3.2962 - val_loss: 0.1123 - val_auc: 0.9848 - val_accuracy: 0.9683 - val_cost: 3.8802\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9905 - accuracy: 0.9747 - cost: 3.2520 - val_loss: 0.1095 - val_auc: 0.9850 - val_accuracy: 0.9694 - val_cost: 3.9128\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0881 - auc: 0.9902 - accuracy: 0.9744 - cost: 3.2978 - val_loss: 0.1100 - val_auc: 0.9845 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9902 - accuracy: 0.9739 - cost: 3.3565 - val_loss: 0.1096 - val_auc: 0.9849 - val_accuracy: 0.9699 - val_cost: 3.7663\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9903 - accuracy: 0.9743 - cost: 3.3109 - val_loss: 0.1112 - val_auc: 0.9843 - val_accuracy: 0.9696 - val_cost: 3.5384\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9905 - accuracy: 0.9748 - cost: 3.2358 - val_loss: 0.1091 - val_auc: 0.9851 - val_accuracy: 0.9703 - val_cost: 3.5124\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9905 - accuracy: 0.9749 - cost: 3.2335 - val_loss: 0.1091 - val_auc: 0.9853 - val_accuracy: 0.9698 - val_cost: 3.7402\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9903 - accuracy: 0.9746 - cost: 3.2610 - val_loss: 0.1111 - val_auc: 0.9847 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9902 - accuracy: 0.9747 - cost: 3.2532 - val_loss: 0.1108 - val_auc: 0.9853 - val_accuracy: 0.9695 - val_cost: 3.5905\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0868 - auc: 0.9903 - accuracy: 0.9750 - cost: 3.2254 - val_loss: 0.1109 - val_auc: 0.9846 - val_accuracy: 0.9700 - val_cost: 3.5384\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9908 - accuracy: 0.9747 - cost: 3.2490 - val_loss: 0.1103 - val_auc: 0.9852 - val_accuracy: 0.9701 - val_cost: 3.9323\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9908 - accuracy: 0.9752 - cost: 3.1908 - val_loss: 0.1100 - val_auc: 0.9848 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9907 - accuracy: 0.9754 - cost: 3.1745 - val_loss: 0.1108 - val_auc: 0.9847 - val_accuracy: 0.9695 - val_cost: 3.9225\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9904 - accuracy: 0.9748 - cost: 3.2277 - val_loss: 0.1138 - val_auc: 0.9842 - val_accuracy: 0.9692 - val_cost: 3.6296\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0844 - auc: 0.9908 - accuracy: 0.9753 - cost: 3.1783 - val_loss: 0.1116 - val_auc: 0.9842 - val_accuracy: 0.9698 - val_cost: 3.5938\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0851 - auc: 0.9906 - accuracy: 0.9752 - cost: 3.1904 - val_loss: 0.1150 - val_auc: 0.9839 - val_accuracy: 0.9698 - val_cost: 3.4766\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9904 - accuracy: 0.9755 - cost: 3.1493 - val_loss: 0.1108 - val_auc: 0.9843 - val_accuracy: 0.9703 - val_cost: 3.7207\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9908 - accuracy: 0.9751 - cost: 3.2031 - val_loss: 0.1116 - val_auc: 0.9847 - val_accuracy: 0.9707 - val_cost: 3.4928\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9909 - accuracy: 0.9754 - cost: 3.1465 - val_loss: 0.1105 - val_auc: 0.9843 - val_accuracy: 0.9715 - val_cost: 3.3171\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9909 - accuracy: 0.9759 - cost: 3.1033 - val_loss: 0.1097 - val_auc: 0.9851 - val_accuracy: 0.9707 - val_cost: 3.7012\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9907 - accuracy: 0.9753 - cost: 3.1673 - val_loss: 0.1088 - val_auc: 0.9848 - val_accuracy: 0.9715 - val_cost: 3.5384\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0838 - auc: 0.9907 - accuracy: 0.9757 - cost: 3.1328 - val_loss: 0.1097 - val_auc: 0.9853 - val_accuracy: 0.9702 - val_cost: 3.5091\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9907 - accuracy: 0.9753 - cost: 3.1758 - val_loss: 0.1095 - val_auc: 0.9849 - val_accuracy: 0.9710 - val_cost: 3.4212\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9908 - accuracy: 0.9751 - cost: 3.2052 - val_loss: 0.1091 - val_auc: 0.9847 - val_accuracy: 0.9715 - val_cost: 3.3887\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9911 - accuracy: 0.9757 - cost: 3.1273 - val_loss: 0.1117 - val_auc: 0.9840 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9912 - accuracy: 0.9756 - cost: 3.1454 - val_loss: 0.1092 - val_auc: 0.9848 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9911 - accuracy: 0.9758 - cost: 3.1175 - val_loss: 0.1098 - val_auc: 0.9853 - val_accuracy: 0.9706 - val_cost: 3.6849\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9911 - accuracy: 0.9762 - cost: 3.0561 - val_loss: 0.1096 - val_auc: 0.9843 - val_accuracy: 0.9697 - val_cost: 3.7402\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9913 - accuracy: 0.9758 - cost: 3.1196 - val_loss: 0.1154 - val_auc: 0.9844 - val_accuracy: 0.9699 - val_cost: 3.4115\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9914 - accuracy: 0.9763 - cost: 3.0542 - val_loss: 0.1124 - val_auc: 0.9844 - val_accuracy: 0.9691 - val_cost: 3.7760\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9912 - accuracy: 0.9763 - cost: 3.0590 - val_loss: 0.1102 - val_auc: 0.9843 - val_accuracy: 0.9705 - val_cost: 3.6458\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9911 - accuracy: 0.9761 - cost: 3.0820 - val_loss: 0.1122 - val_auc: 0.9848 - val_accuracy: 0.9701 - val_cost: 3.8118\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9913 - accuracy: 0.9761 - cost: 3.0927 - val_loss: 0.1097 - val_auc: 0.9844 - val_accuracy: 0.9712 - val_cost: 3.5775\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9913 - accuracy: 0.9760 - cost: 3.0950 - val_loss: 0.1121 - val_auc: 0.9842 - val_accuracy: 0.9707 - val_cost: 3.4375\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0817 - val_loss: 0.1091 - val_auc: 0.9851 - val_accuracy: 0.9710 - val_cost: 3.4082\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9520 - val_loss: 0.1094 - val_auc: 0.9852 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0816 - auc: 0.9914 - accuracy: 0.9766 - cost: 3.0063 - val_loss: 0.1098 - val_auc: 0.9849 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9913 - accuracy: 0.9764 - cost: 3.0342 - val_loss: 0.1096 - val_auc: 0.9854 - val_accuracy: 0.9702 - val_cost: 3.5221\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9912 - accuracy: 0.9758 - cost: 3.1262 - val_loss: 0.1095 - val_auc: 0.9845 - val_accuracy: 0.9709 - val_cost: 3.6165\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9910 - accuracy: 0.9768 - cost: 2.9910 - val_loss: 0.1113 - val_auc: 0.9845 - val_accuracy: 0.9705 - val_cost: 3.4408\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9916 - accuracy: 0.9763 - cost: 3.0444 - val_loss: 0.1103 - val_auc: 0.9845 - val_accuracy: 0.9702 - val_cost: 3.6523\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9915 - accuracy: 0.9765 - cost: 3.0423 - val_loss: 0.1112 - val_auc: 0.9842 - val_accuracy: 0.9709 - val_cost: 3.6003\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9914 - accuracy: 0.9768 - cost: 2.9943 - val_loss: 0.1104 - val_auc: 0.9848 - val_accuracy: 0.9717 - val_cost: 3.4928\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0674 - val_loss: 0.1102 - val_auc: 0.9846 - val_accuracy: 0.9704 - val_cost: 3.6556\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9915 - accuracy: 0.9766 - cost: 3.0032 - val_loss: 0.1093 - val_auc: 0.9849 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9912 - accuracy: 0.9765 - cost: 3.0338 - val_loss: 0.1103 - val_auc: 0.9843 - val_accuracy: 0.9703 - val_cost: 4.0625\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9915 - accuracy: 0.9765 - cost: 3.0269 - val_loss: 0.1101 - val_auc: 0.9848 - val_accuracy: 0.9705 - val_cost: 3.6556\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9916 - accuracy: 0.9765 - cost: 3.0345 - val_loss: 0.1108 - val_auc: 0.9844 - val_accuracy: 0.9711 - val_cost: 3.3919\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9916 - accuracy: 0.9769 - cost: 2.9719 - val_loss: 0.1094 - val_auc: 0.9847 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9916 - accuracy: 0.9771 - cost: 2.9476 - val_loss: 0.1109 - val_auc: 0.9840 - val_accuracy: 0.9708 - val_cost: 3.7858\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9914 - accuracy: 0.9765 - cost: 3.0241 - val_loss: 0.1109 - val_auc: 0.9841 - val_accuracy: 0.9719 - val_cost: 3.3073\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9773 - val_loss: 0.1109 - val_auc: 0.9841 - val_accuracy: 0.9708 - val_cost: 3.4017\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9913 - accuracy: 0.9768 - cost: 2.9898 - val_loss: 0.1121 - val_auc: 0.9840 - val_accuracy: 0.9717 - val_cost: 3.6523\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9917 - accuracy: 0.9771 - cost: 2.9634 - val_loss: 0.1124 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9917 - accuracy: 0.9769 - cost: 2.9707 - val_loss: 0.1117 - val_auc: 0.9841 - val_accuracy: 0.9711 - val_cost: 3.6263\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9917 - accuracy: 0.9774 - cost: 2.9167 - val_loss: 0.1135 - val_auc: 0.9836 - val_accuracy: 0.9708 - val_cost: 3.5286\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9726 - val_loss: 0.1088 - val_auc: 0.9837 - val_accuracy: 0.9711 - val_cost: 3.4342\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9918 - accuracy: 0.9777 - cost: 2.8747 - val_loss: 0.1114 - val_auc: 0.9845 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9918 - accuracy: 0.9770 - cost: 2.9786 - val_loss: 0.1091 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.4408\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9915 - accuracy: 0.9773 - cost: 2.9408 - val_loss: 0.1111 - val_auc: 0.9843 - val_accuracy: 0.9713 - val_cost: 3.5417\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9920 - accuracy: 0.9771 - cost: 2.9492 - val_loss: 0.1107 - val_auc: 0.9834 - val_accuracy: 0.9718 - val_cost: 3.4538\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9916 - accuracy: 0.9768 - cost: 2.9983 - val_loss: 0.1125 - val_auc: 0.9837 - val_accuracy: 0.9713 - val_cost: 3.4635\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9919 - accuracy: 0.9772 - cost: 2.9470 - val_loss: 0.1105 - val_auc: 0.9837 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8859 - val_loss: 0.1103 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.4147\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9920 - accuracy: 0.9776 - cost: 2.8894 - val_loss: 0.1098 - val_auc: 0.9841 - val_accuracy: 0.9712 - val_cost: 3.5677\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9169 - val_loss: 0.1115 - val_auc: 0.9838 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8782 - val_loss: 0.1087 - val_auc: 0.9846 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9917 - accuracy: 0.9772 - cost: 2.9510 - val_loss: 0.1105 - val_auc: 0.9844 - val_accuracy: 0.9710 - val_cost: 3.7207\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8764 - val_loss: 0.1098 - val_auc: 0.9841 - val_accuracy: 0.9713 - val_cost: 3.6947\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9133 - val_loss: 0.1100 - val_auc: 0.9843 - val_accuracy: 0.9713 - val_cost: 3.4993\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9920 - accuracy: 0.9778 - cost: 2.8655 - val_loss: 0.1109 - val_auc: 0.9839 - val_accuracy: 0.9711 - val_cost: 3.5612\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9917 - accuracy: 0.9779 - cost: 2.8412 - val_loss: 0.1092 - val_auc: 0.9852 - val_accuracy: 0.9706 - val_cost: 3.8184\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9916 - accuracy: 0.9777 - cost: 2.8640 - val_loss: 0.1100 - val_auc: 0.9849 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9918 - accuracy: 0.9774 - cost: 2.9179 - val_loss: 0.1102 - val_auc: 0.9836 - val_accuracy: 0.9717 - val_cost: 3.3561\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9920 - accuracy: 0.9772 - cost: 2.9478 - val_loss: 0.1103 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9776 - cost: 2.8823 - val_loss: 0.1102 - val_auc: 0.9838 - val_accuracy: 0.9705 - val_cost: 3.5482\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8923 - val_loss: 0.1093 - val_auc: 0.9840 - val_accuracy: 0.9718 - val_cost: 3.6589\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9919 - accuracy: 0.9780 - cost: 2.8358 - val_loss: 0.1099 - val_auc: 0.9843 - val_accuracy: 0.9706 - val_cost: 3.6491\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9922 - accuracy: 0.9777 - cost: 2.8758 - val_loss: 0.1108 - val_auc: 0.9841 - val_accuracy: 0.9711 - val_cost: 3.7240\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9921 - accuracy: 0.9782 - cost: 2.8140 - val_loss: 0.1122 - val_auc: 0.9841 - val_accuracy: 0.9708 - val_cost: 3.6589\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9230 - val_loss: 0.1107 - val_auc: 0.9836 - val_accuracy: 0.9710 - val_cost: 3.3854\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9922 - accuracy: 0.9779 - cost: 2.8494 - val_loss: 0.1131 - val_auc: 0.9830 - val_accuracy: 0.9699 - val_cost: 3.5775\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9921 - accuracy: 0.9776 - cost: 2.8941 - val_loss: 0.1114 - val_auc: 0.9843 - val_accuracy: 0.9715 - val_cost: 3.4635\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9921 - accuracy: 0.9777 - cost: 2.8760 - val_loss: 0.1108 - val_auc: 0.9836 - val_accuracy: 0.9715 - val_cost: 3.4993\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0771 - auc: 0.9920 - accuracy: 0.9776 - cost: 2.8944 - val_loss: 0.1110 - val_auc: 0.9832 - val_accuracy: 0.9708 - val_cost: 3.6035\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9919 - accuracy: 0.9782 - cost: 2.8218 - val_loss: 0.1113 - val_auc: 0.9839 - val_accuracy: 0.9704 - val_cost: 3.5091\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9921 - accuracy: 0.9779 - cost: 2.8527 - val_loss: 0.1126 - val_auc: 0.9839 - val_accuracy: 0.9715 - val_cost: 3.3919\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9921 - accuracy: 0.9782 - cost: 2.8176 - val_loss: 0.1105 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.7760\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7395 - val_loss: 0.1121 - val_auc: 0.9843 - val_accuracy: 0.9720 - val_cost: 3.4310\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9922 - accuracy: 0.9781 - cost: 2.8181 - val_loss: 0.1111 - val_auc: 0.9840 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8849 - val_loss: 0.1115 - val_auc: 0.9842 - val_accuracy: 0.9708 - val_cost: 3.4701\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9921 - accuracy: 0.9775 - cost: 2.9094 - val_loss: 0.1122 - val_auc: 0.9843 - val_accuracy: 0.9704 - val_cost: 3.6816\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9921 - accuracy: 0.9783 - cost: 2.7991 - val_loss: 0.1117 - val_auc: 0.9842 - val_accuracy: 0.9718 - val_cost: 3.6361\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9919 - accuracy: 0.9785 - cost: 2.7850 - val_loss: 0.1117 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.4342\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7553 - val_loss: 0.1109 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8178 - val_loss: 0.1099 - val_auc: 0.9844 - val_accuracy: 0.9706 - val_cost: 3.8216\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9921 - accuracy: 0.9782 - cost: 2.8125 - val_loss: 0.1132 - val_auc: 0.9834 - val_accuracy: 0.9709 - val_cost: 3.7109\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9921 - accuracy: 0.9789 - cost: 2.7309 - val_loss: 0.1113 - val_auc: 0.9845 - val_accuracy: 0.9694 - val_cost: 3.9941\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7753 - val_loss: 0.1117 - val_auc: 0.9845 - val_accuracy: 0.9708 - val_cost: 3.5547\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9920 - accuracy: 0.9779 - cost: 2.8568 - val_loss: 0.1116 - val_auc: 0.9839 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9927 - accuracy: 0.9787 - cost: 2.7622 - val_loss: 0.1108 - val_auc: 0.9843 - val_accuracy: 0.9709 - val_cost: 3.7207\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9921 - accuracy: 0.9784 - cost: 2.7904 - val_loss: 0.1127 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.6947\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9923 - accuracy: 0.9787 - cost: 2.7545 - val_loss: 0.1136 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.3496\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9923 - accuracy: 0.9780 - cost: 2.8358 - val_loss: 0.1103 - val_auc: 0.9842 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8199 - val_loss: 0.1135 - val_auc: 0.9833 - val_accuracy: 0.9709 - val_cost: 3.3789\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9922 - accuracy: 0.9784 - cost: 2.7903 - val_loss: 0.1119 - val_auc: 0.9843 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0749 - auc: 0.9923 - accuracy: 0.9784 - cost: 2.7925 - val_loss: 0.1120 - val_auc: 0.9841 - val_accuracy: 0.9709 - val_cost: 3.6458\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0767 - auc: 0.9920 - accuracy: 0.9782 - cost: 2.8126 - val_loss: 0.1103 - val_auc: 0.9840 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0749 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.8092 - val_loss: 0.1112 - val_auc: 0.9839 - val_accuracy: 0.9705 - val_cost: 3.6719\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7756 - val_loss: 0.1146 - val_auc: 0.9832 - val_accuracy: 0.9700 - val_cost: 3.4505\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9920 - accuracy: 0.9786 - cost: 2.7589 - val_loss: 0.1125 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7646 - val_loss: 0.1134 - val_auc: 0.9841 - val_accuracy: 0.9710 - val_cost: 3.4310\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7401 - val_loss: 0.1125 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.7240\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9921 - accuracy: 0.9787 - cost: 2.7522 - val_loss: 0.1133 - val_auc: 0.9834 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8251 - val_loss: 0.1111 - val_auc: 0.9846 - val_accuracy: 0.9711 - val_cost: 3.7370\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9924 - accuracy: 0.9787 - cost: 2.7489 - val_loss: 0.1112 - val_auc: 0.9835 - val_accuracy: 0.9717 - val_cost: 3.3301\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9923 - accuracy: 0.9792 - cost: 2.6957 - val_loss: 0.1136 - val_auc: 0.9836 - val_accuracy: 0.9709 - val_cost: 3.4993\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9922 - accuracy: 0.9784 - cost: 2.7753 - val_loss: 0.1116 - val_auc: 0.9847 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9791 - cost: 2.7172 - val_loss: 0.1132 - val_auc: 0.9842 - val_accuracy: 0.9707 - val_cost: 3.6003\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0749 - auc: 0.9922 - accuracy: 0.9784 - cost: 2.7864 - val_loss: 0.1117 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.4603\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7418 - val_loss: 0.1110 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.5221\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9922 - accuracy: 0.9787 - cost: 2.7515 - val_loss: 0.1129 - val_auc: 0.9837 - val_accuracy: 0.9707 - val_cost: 3.7826\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.7919 - val_loss: 0.1131 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.5417\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9926 - accuracy: 0.9787 - cost: 2.7526 - val_loss: 0.1145 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.6882\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7274 - val_loss: 0.1132 - val_auc: 0.9832 - val_accuracy: 0.9699 - val_cost: 3.4733\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6905 - val_loss: 0.1088 - val_auc: 0.9845 - val_accuracy: 0.9718 - val_cost: 3.5221\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7382 - val_loss: 0.1136 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.4798\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0754 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7408 - val_loss: 0.1144 - val_auc: 0.9839 - val_accuracy: 0.9716 - val_cost: 3.3594\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7297 - val_loss: 0.1121 - val_auc: 0.9836 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9785 - cost: 2.7853 - val_loss: 0.1119 - val_auc: 0.9842 - val_accuracy: 0.9712 - val_cost: 3.6165\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9927 - accuracy: 0.9787 - cost: 2.7506 - val_loss: 0.1138 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.4798\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6973 - val_loss: 0.1101 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.3887\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.7767 - val_loss: 0.1114 - val_auc: 0.9842 - val_accuracy: 0.9715 - val_cost: 3.3431\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7112 - val_loss: 0.1093 - val_auc: 0.9840 - val_accuracy: 0.9717 - val_cost: 3.4082\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9925 - accuracy: 0.9786 - cost: 2.7699 - val_loss: 0.1137 - val_auc: 0.9841 - val_accuracy: 0.9718 - val_cost: 3.3008\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9924 - accuracy: 0.9794 - cost: 2.6596 - val_loss: 0.1145 - val_auc: 0.9836 - val_accuracy: 0.9714 - val_cost: 3.5482\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7310 - val_loss: 0.1125 - val_auc: 0.9839 - val_accuracy: 0.9715 - val_cost: 3.3919\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.7027 - val_loss: 0.1132 - val_auc: 0.9838 - val_accuracy: 0.9711 - val_cost: 3.5742\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6784 - val_loss: 0.1155 - val_auc: 0.9833 - val_accuracy: 0.9709 - val_cost: 3.3822\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.7011 - val_loss: 0.1150 - val_auc: 0.9838 - val_accuracy: 0.9716 - val_cost: 3.4928\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6199 - val_loss: 0.1134 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6780 - val_loss: 0.1122 - val_auc: 0.9837 - val_accuracy: 0.9728 - val_cost: 3.3040\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6864 - val_loss: 0.1120 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.6100\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9926 - accuracy: 0.9797 - cost: 2.6316 - val_loss: 0.1130 - val_auc: 0.9830 - val_accuracy: 0.9717 - val_cost: 3.3333\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7224 - val_loss: 0.1135 - val_auc: 0.9834 - val_accuracy: 0.9712 - val_cost: 3.5514\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9794 - cost: 2.6512 - val_loss: 0.1124 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.4310\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6805 - val_loss: 0.1134 - val_auc: 0.9837 - val_accuracy: 0.9718 - val_cost: 3.5026\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6489 - val_loss: 0.1134 - val_auc: 0.9838 - val_accuracy: 0.9720 - val_cost: 3.5905\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9790 - cost: 2.7118 - val_loss: 0.1161 - val_auc: 0.9832 - val_accuracy: 0.9719 - val_cost: 3.4408\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9925 - accuracy: 0.9796 - cost: 2.6294 - val_loss: 0.1142 - val_auc: 0.9833 - val_accuracy: 0.9709 - val_cost: 3.5579\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6876 - val_loss: 0.1143 - val_auc: 0.9830 - val_accuracy: 0.9714 - val_cost: 3.4863\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6674 - val_loss: 0.1144 - val_auc: 0.9841 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.7013 - val_loss: 0.1156 - val_auc: 0.9836 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7206 - val_loss: 0.1151 - val_auc: 0.9839 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6570 - val_loss: 0.1155 - val_auc: 0.9835 - val_accuracy: 0.9722 - val_cost: 3.3040\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9930 - accuracy: 0.9790 - cost: 2.7127 - val_loss: 0.1167 - val_auc: 0.9841 - val_accuracy: 0.9709 - val_cost: 3.8379\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6684 - val_loss: 0.1150 - val_auc: 0.9840 - val_accuracy: 0.9716 - val_cost: 3.3073\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6509 - val_loss: 0.1159 - val_auc: 0.9840 - val_accuracy: 0.9712 - val_cost: 3.6654\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6600 - val_loss: 0.1136 - val_auc: 0.9836 - val_accuracy: 0.9724 - val_cost: 3.2617\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6648 - val_loss: 0.1125 - val_auc: 0.9847 - val_accuracy: 0.9719 - val_cost: 3.6621\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6561 - val_loss: 0.1115 - val_auc: 0.9848 - val_accuracy: 0.9719 - val_cost: 3.5026\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6342 - val_loss: 0.1170 - val_auc: 0.9824 - val_accuracy: 0.9720 - val_cost: 3.2292\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6447 - val_loss: 0.1160 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6443 - val_loss: 0.1166 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.4049\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6385 - val_loss: 0.1157 - val_auc: 0.9837 - val_accuracy: 0.9710 - val_cost: 3.5482\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6732 - val_loss: 0.1134 - val_auc: 0.9841 - val_accuracy: 0.9713 - val_cost: 3.5840\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6796 - val_loss: 0.1138 - val_auc: 0.9843 - val_accuracy: 0.9724 - val_cost: 3.6458\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5869 - val_loss: 0.1143 - val_auc: 0.9831 - val_accuracy: 0.9723 - val_cost: 3.5514\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6257 - val_loss: 0.1144 - val_auc: 0.9832 - val_accuracy: 0.9704 - val_cost: 3.7695\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9800 - cost: 2.5961 - val_loss: 0.1137 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.3301\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6204 - val_loss: 0.1173 - val_auc: 0.9828 - val_accuracy: 0.9709 - val_cost: 3.5352\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9927 - accuracy: 0.9800 - cost: 2.5890 - val_loss: 0.1137 - val_auc: 0.9844 - val_accuracy: 0.9718 - val_cost: 3.3724\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6655 - val_loss: 0.1156 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.3626\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5916 - val_loss: 0.1138 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6111 - val_loss: 0.1165 - val_auc: 0.9829 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6521 - val_loss: 0.1155 - val_auc: 0.9838 - val_accuracy: 0.9713 - val_cost: 3.5579\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6388 - val_loss: 0.1164 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.7305\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6193 - val_loss: 0.1137 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.3496\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6648 - val_loss: 0.1167 - val_auc: 0.9836 - val_accuracy: 0.9711 - val_cost: 3.5677\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6305 - val_loss: 0.1137 - val_auc: 0.9835 - val_accuracy: 0.9708 - val_cost: 3.6100\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5901 - val_loss: 0.1150 - val_auc: 0.9843 - val_accuracy: 0.9719 - val_cost: 3.5124\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5500 - val_loss: 0.1131 - val_auc: 0.9850 - val_accuracy: 0.9708 - val_cost: 3.4701\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6058 - val_loss: 0.1149 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5891 - val_loss: 0.1172 - val_auc: 0.9840 - val_accuracy: 0.9712 - val_cost: 3.3594\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5804 - val_loss: 0.1152 - val_auc: 0.9843 - val_accuracy: 0.9702 - val_cost: 3.5872\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.7036 - val_loss: 0.1142 - val_auc: 0.9842 - val_accuracy: 0.9710 - val_cost: 3.6882\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6475 - val_loss: 0.1128 - val_auc: 0.9848 - val_accuracy: 0.9714 - val_cost: 3.5514\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9797 - cost: 2.6233 - val_loss: 0.1134 - val_auc: 0.9841 - val_accuracy: 0.9721 - val_cost: 3.4473\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6267 - val_loss: 0.1133 - val_auc: 0.9845 - val_accuracy: 0.9710 - val_cost: 3.7630\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9930 - accuracy: 0.9795 - cost: 2.6577 - val_loss: 0.1186 - val_auc: 0.9826 - val_accuracy: 0.9716 - val_cost: 3.4473\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6302 - val_loss: 0.1162 - val_auc: 0.9846 - val_accuracy: 0.9710 - val_cost: 3.7858\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6382 - val_loss: 0.1146 - val_auc: 0.9841 - val_accuracy: 0.9722 - val_cost: 3.4733\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6002 - val_loss: 0.1179 - val_auc: 0.9825 - val_accuracy: 0.9717 - val_cost: 3.3073\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6255 - val_loss: 0.1149 - val_auc: 0.9844 - val_accuracy: 0.9709 - val_cost: 3.7663\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5801 - val_loss: 0.1188 - val_auc: 0.9829 - val_accuracy: 0.9713 - val_cost: 3.3594\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6343 - val_loss: 0.1148 - val_auc: 0.9839 - val_accuracy: 0.9712 - val_cost: 3.5547\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6418 - val_loss: 0.1147 - val_auc: 0.9837 - val_accuracy: 0.9725 - val_cost: 3.2454\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9930 - accuracy: 0.9795 - cost: 2.6585 - val_loss: 0.1145 - val_auc: 0.9839 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5737 - val_loss: 0.1145 - val_auc: 0.9835 - val_accuracy: 0.9705 - val_cost: 3.6816\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6101 - val_loss: 0.1179 - val_auc: 0.9829 - val_accuracy: 0.9717 - val_cost: 3.7077\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9932 - accuracy: 0.9806 - cost: 2.5147 - val_loss: 0.1158 - val_auc: 0.9836 - val_accuracy: 0.9709 - val_cost: 3.5840\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.6063 - val_loss: 0.1137 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.6165\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5872 - val_loss: 0.1140 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5883 - val_loss: 0.1152 - val_auc: 0.9842 - val_accuracy: 0.9724 - val_cost: 3.4701\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6060 - val_loss: 0.1158 - val_auc: 0.9837 - val_accuracy: 0.9717 - val_cost: 3.3105\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5952 - val_loss: 0.1143 - val_auc: 0.9844 - val_accuracy: 0.9724 - val_cost: 3.4440\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5774 - val_loss: 0.1155 - val_auc: 0.9843 - val_accuracy: 0.9709 - val_cost: 3.7695\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9933 - accuracy: 0.9801 - cost: 2.5892 - val_loss: 0.1157 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.7467\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5628 - val_loss: 0.1172 - val_auc: 0.9839 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.6100 - val_loss: 0.1158 - val_auc: 0.9835 - val_accuracy: 0.9723 - val_cost: 3.2780\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5879 - val_loss: 0.1155 - val_auc: 0.9832 - val_accuracy: 0.9720 - val_cost: 3.4668\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5707 - val_loss: 0.1167 - val_auc: 0.9833 - val_accuracy: 0.9713 - val_cost: 3.3757\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5928 - val_loss: 0.1158 - val_auc: 0.9835 - val_accuracy: 0.9717 - val_cost: 3.6523\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9809 - cost: 2.4766 - val_loss: 0.1168 - val_auc: 0.9834 - val_accuracy: 0.9709 - val_cost: 3.8281\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5127 - val_loss: 0.1168 - val_auc: 0.9831 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5609 - val_loss: 0.1182 - val_auc: 0.9840 - val_accuracy: 0.9715 - val_cost: 3.5645\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5776 - val_loss: 0.1153 - val_auc: 0.9832 - val_accuracy: 0.9714 - val_cost: 3.7077\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5923 - val_loss: 0.1159 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.5872\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9806 - cost: 2.5156 - val_loss: 0.1178 - val_auc: 0.9844 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9929 - accuracy: 0.9803 - cost: 2.5438 - val_loss: 0.1170 - val_auc: 0.9837 - val_accuracy: 0.9704 - val_cost: 3.8281\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5715 - val_loss: 0.1192 - val_auc: 0.9832 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9804 - cost: 2.5388 - val_loss: 0.1170 - val_auc: 0.9835 - val_accuracy: 0.9715 - val_cost: 3.5612\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9803 - cost: 2.5413 - val_loss: 0.1160 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.4310\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5181 - val_loss: 0.1182 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.4440\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9931 - accuracy: 0.9795 - cost: 2.6473 - val_loss: 0.1173 - val_auc: 0.9837 - val_accuracy: 0.9713 - val_cost: 3.6621\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5712 - val_loss: 0.1143 - val_auc: 0.9843 - val_accuracy: 0.9726 - val_cost: 3.5156\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9929 - accuracy: 0.9806 - cost: 2.5266 - val_loss: 0.1204 - val_auc: 0.9825 - val_accuracy: 0.9710 - val_cost: 3.7565\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9801 - cost: 2.5807 - val_loss: 0.1160 - val_auc: 0.9847 - val_accuracy: 0.9719 - val_cost: 3.5417\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9934 - accuracy: 0.9800 - cost: 2.5960 - val_loss: 0.1145 - val_auc: 0.9839 - val_accuracy: 0.9719 - val_cost: 3.6165\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9930 - accuracy: 0.9804 - cost: 2.5476 - val_loss: 0.1170 - val_auc: 0.9835 - val_accuracy: 0.9706 - val_cost: 3.5807\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5673 - val_loss: 0.1180 - val_auc: 0.9835 - val_accuracy: 0.9712 - val_cost: 3.6458\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9930 - accuracy: 0.9801 - cost: 2.5773 - val_loss: 0.1155 - val_auc: 0.9832 - val_accuracy: 0.9712 - val_cost: 3.5026\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9929 - accuracy: 0.9804 - cost: 2.5278 - val_loss: 0.1182 - val_auc: 0.9835 - val_accuracy: 0.9709 - val_cost: 3.8444\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5533 - val_loss: 0.1169 - val_auc: 0.9837 - val_accuracy: 0.9714 - val_cost: 3.5449\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5226 - val_loss: 0.1165 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.7305\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5083 - val_loss: 0.1187 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.7467\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.5002 - val_loss: 0.1167 - val_auc: 0.9836 - val_accuracy: 0.9714 - val_cost: 3.5677\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4960 - val_loss: 0.1181 - val_auc: 0.9834 - val_accuracy: 0.9714 - val_cost: 3.6198\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5983 - val_loss: 0.1195 - val_auc: 0.9835 - val_accuracy: 0.9722 - val_cost: 3.4375\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5430 - val_loss: 0.1159 - val_auc: 0.9837 - val_accuracy: 0.9717 - val_cost: 3.6751\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9805 - cost: 2.5244 - val_loss: 0.1174 - val_auc: 0.9834 - val_accuracy: 0.9711 - val_cost: 3.6686\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5392 - val_loss: 0.1171 - val_auc: 0.9840 - val_accuracy: 0.9721 - val_cost: 3.6263\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6178 - val_loss: 0.1163 - val_auc: 0.9840 - val_accuracy: 0.9711 - val_cost: 3.6816\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5439 - val_loss: 0.1147 - val_auc: 0.9840 - val_accuracy: 0.9722 - val_cost: 3.5840\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4750 - val_loss: 0.1149 - val_auc: 0.9847 - val_accuracy: 0.9722 - val_cost: 3.6719\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5662 - val_loss: 0.1171 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.6328\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5766 - val_loss: 0.1144 - val_auc: 0.9838 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5213 - val_loss: 0.1148 - val_auc: 0.9838 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5409 - val_loss: 0.1168 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.7858\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9929 - accuracy: 0.9805 - cost: 2.5291 - val_loss: 0.1186 - val_auc: 0.9834 - val_accuracy: 0.9702 - val_cost: 3.9225\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9934 - accuracy: 0.9802 - cost: 2.5759 - val_loss: 0.1162 - val_auc: 0.9841 - val_accuracy: 0.9715 - val_cost: 3.6523\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5119 - val_loss: 0.1168 - val_auc: 0.9841 - val_accuracy: 0.9705 - val_cost: 3.8216\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5326 - val_loss: 0.1190 - val_auc: 0.9827 - val_accuracy: 0.9718 - val_cost: 3.6589\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5572 - val_loss: 0.1176 - val_auc: 0.9835 - val_accuracy: 0.9723 - val_cost: 3.3952\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5154 - val_loss: 0.1169 - val_auc: 0.9836 - val_accuracy: 0.9710 - val_cost: 3.4245\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4993 - val_loss: 0.1140 - val_auc: 0.9842 - val_accuracy: 0.9719 - val_cost: 3.4668\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4822 - val_loss: 0.1182 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5696 - val_loss: 0.1178 - val_auc: 0.9830 - val_accuracy: 0.9722 - val_cost: 3.4049\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5667 - val_loss: 0.1174 - val_auc: 0.9835 - val_accuracy: 0.9707 - val_cost: 3.7565\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9937 - accuracy: 0.9802 - cost: 2.5666 - val_loss: 0.1163 - val_auc: 0.9836 - val_accuracy: 0.9713 - val_cost: 3.7728\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9807 - cost: 2.5117 - val_loss: 0.1182 - val_auc: 0.9831 - val_accuracy: 0.9704 - val_cost: 3.6230\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9806 - cost: 2.5159 - val_loss: 0.1170 - val_auc: 0.9841 - val_accuracy: 0.9706 - val_cost: 3.6979\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9809 - cost: 2.4809 - val_loss: 0.1205 - val_auc: 0.9826 - val_accuracy: 0.9713 - val_cost: 3.5189\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9933 - accuracy: 0.9807 - cost: 2.4981 - val_loss: 0.1182 - val_auc: 0.9838 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4779 - val_loss: 0.1150 - val_auc: 0.9841 - val_accuracy: 0.9715 - val_cost: 3.6784\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9809 - cost: 2.4822 - val_loss: 0.1172 - val_auc: 0.9838 - val_accuracy: 0.9719 - val_cost: 3.6426\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.6031 - val_loss: 0.1180 - val_auc: 0.9837 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4612 - val_loss: 0.1176 - val_auc: 0.9841 - val_accuracy: 0.9711 - val_cost: 3.5482\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4973 - val_loss: 0.1187 - val_auc: 0.9836 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9934 - accuracy: 0.9802 - cost: 2.5665 - val_loss: 0.1225 - val_auc: 0.9824 - val_accuracy: 0.9705 - val_cost: 3.8411\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5296 - val_loss: 0.1189 - val_auc: 0.9836 - val_accuracy: 0.9708 - val_cost: 3.6133\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.5130 - val_loss: 0.1187 - val_auc: 0.9826 - val_accuracy: 0.9712 - val_cost: 3.5221\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.5036 - val_loss: 0.1165 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.5156\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5330 - val_loss: 0.1163 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 361/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4887 - val_loss: 0.1196 - val_auc: 0.9826 - val_accuracy: 0.9704 - val_cost: 3.7012\n",
            "Epoch 362/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9936 - accuracy: 0.9811 - cost: 2.4407 - val_loss: 0.1165 - val_auc: 0.9837 - val_accuracy: 0.9719 - val_cost: 3.4701\n",
            "Epoch 363/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9801 - cost: 2.5727 - val_loss: 0.1176 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 364/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5495 - val_loss: 0.1196 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.4212\n",
            "Epoch 365/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5239 - val_loss: 0.1185 - val_auc: 0.9838 - val_accuracy: 0.9716 - val_cost: 3.6654\n",
            "Epoch 366/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.5033 - val_loss: 0.1178 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.6003\n",
            "Epoch 367/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5160 - val_loss: 0.1189 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.5742\n",
            "Epoch 368/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9938 - accuracy: 0.9809 - cost: 2.4790 - val_loss: 0.1182 - val_auc: 0.9831 - val_accuracy: 0.9710 - val_cost: 3.4017\n",
            "Epoch 369/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9937 - accuracy: 0.9811 - cost: 2.4603 - val_loss: 0.1172 - val_auc: 0.9833 - val_accuracy: 0.9713 - val_cost: 3.5449\n",
            "Epoch 370/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9934 - accuracy: 0.9809 - cost: 2.4893 - val_loss: 0.1202 - val_auc: 0.9826 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 371/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9807 - cost: 2.5098 - val_loss: 0.1184 - val_auc: 0.9833 - val_accuracy: 0.9718 - val_cost: 3.3073\n",
            "Epoch 372/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.4969 - val_loss: 0.1175 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.6849\n",
            "Epoch 373/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4937 - val_loss: 0.1200 - val_auc: 0.9832 - val_accuracy: 0.9717 - val_cost: 3.5124\n",
            "Epoch 374/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9809 - cost: 2.4897 - val_loss: 0.1191 - val_auc: 0.9842 - val_accuracy: 0.9721 - val_cost: 3.6393\n",
            "Epoch 375/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4555 - val_loss: 0.1201 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.6165\n",
            "Epoch 376/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9937 - accuracy: 0.9812 - cost: 2.4366 - val_loss: 0.1198 - val_auc: 0.9842 - val_accuracy: 0.9708 - val_cost: 3.8184\n",
            "Epoch 377/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4949 - val_loss: 0.1184 - val_auc: 0.9839 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 378/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5389 - val_loss: 0.1222 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.7077\n",
            "Epoch 379/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9932 - accuracy: 0.9811 - cost: 2.4637 - val_loss: 0.1191 - val_auc: 0.9829 - val_accuracy: 0.9712 - val_cost: 3.9062\n",
            "Epoch 380/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4948 - val_loss: 0.1193 - val_auc: 0.9837 - val_accuracy: 0.9718 - val_cost: 3.4896\n",
            "Epoch 381/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4900 - val_loss: 0.1183 - val_auc: 0.9835 - val_accuracy: 0.9714 - val_cost: 3.7077\n",
            "Epoch 382/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4987 - val_loss: 0.1216 - val_auc: 0.9824 - val_accuracy: 0.9717 - val_cost: 3.3691\n",
            "Epoch 383/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9933 - accuracy: 0.9809 - cost: 2.4789 - val_loss: 0.1203 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.5710\n",
            "Epoch 384/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5663 - val_loss: 0.1237 - val_auc: 0.9821 - val_accuracy: 0.9703 - val_cost: 3.4505\n",
            "Epoch 385/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5251 - val_loss: 0.1199 - val_auc: 0.9835 - val_accuracy: 0.9713 - val_cost: 3.5124\n",
            "Epoch 386/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9933 - accuracy: 0.9812 - cost: 2.4492 - val_loss: 0.1165 - val_auc: 0.9832 - val_accuracy: 0.9707 - val_cost: 3.7760\n",
            "Epoch 387/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4623 - val_loss: 0.1160 - val_auc: 0.9837 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 388/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4598 - val_loss: 0.1179 - val_auc: 0.9837 - val_accuracy: 0.9713 - val_cost: 3.7467\n",
            "Epoch 389/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4870 - val_loss: 0.1177 - val_auc: 0.9837 - val_accuracy: 0.9722 - val_cost: 3.4635\n",
            "Epoch 390/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4947 - val_loss: 0.1183 - val_auc: 0.9832 - val_accuracy: 0.9714 - val_cost: 3.6458\n",
            "Epoch 391/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9807 - cost: 2.4999 - val_loss: 0.1197 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 392/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4394 - val_loss: 0.1200 - val_auc: 0.9834 - val_accuracy: 0.9712 - val_cost: 3.5775\n",
            "Epoch 393/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9810 - cost: 2.4642 - val_loss: 0.1190 - val_auc: 0.9826 - val_accuracy: 0.9714 - val_cost: 3.6458\n",
            "Epoch 394/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9933 - accuracy: 0.9807 - cost: 2.4994 - val_loss: 0.1201 - val_auc: 0.9832 - val_accuracy: 0.9715 - val_cost: 3.5221\n",
            "Epoch 395/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4888 - val_loss: 0.1195 - val_auc: 0.9832 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 396/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4780 - val_loss: 0.1184 - val_auc: 0.9834 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 397/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4951 - val_loss: 0.1178 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.7663\n",
            "Epoch 398/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4761 - val_loss: 0.1207 - val_auc: 0.9833 - val_accuracy: 0.9715 - val_cost: 3.4310\n",
            "Epoch 399/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0674 - auc: 0.9937 - accuracy: 0.9807 - cost: 2.4944 - val_loss: 0.1169 - val_auc: 0.9831 - val_accuracy: 0.9715 - val_cost: 3.3952\n",
            "Epoch 400/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9937 - accuracy: 0.9811 - cost: 2.4522 - val_loss: 0.1193 - val_auc: 0.9831 - val_accuracy: 0.9706 - val_cost: 3.5091\n",
            "Epoch 401/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.5210 - val_loss: 0.1227 - val_auc: 0.9823 - val_accuracy: 0.9714 - val_cost: 3.6784\n",
            "Epoch 402/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5144 - val_loss: 0.1180 - val_auc: 0.9829 - val_accuracy: 0.9720 - val_cost: 3.4766\n",
            "Epoch 403/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4821 - val_loss: 0.1180 - val_auc: 0.9829 - val_accuracy: 0.9723 - val_cost: 3.2812\n",
            "Epoch 404/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4489 - val_loss: 0.1180 - val_auc: 0.9826 - val_accuracy: 0.9722 - val_cost: 3.2812\n",
            "Epoch 405/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9936 - accuracy: 0.9811 - cost: 2.4623 - val_loss: 0.1170 - val_auc: 0.9833 - val_accuracy: 0.9723 - val_cost: 3.2520\n",
            "Epoch 406/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9940 - accuracy: 0.9813 - cost: 2.4293 - val_loss: 0.1200 - val_auc: 0.9828 - val_accuracy: 0.9711 - val_cost: 3.5612\n",
            "Epoch 407/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4865 - val_loss: 0.1205 - val_auc: 0.9829 - val_accuracy: 0.9717 - val_cost: 3.3105\n",
            "Epoch 408/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4637 - val_loss: 0.1208 - val_auc: 0.9827 - val_accuracy: 0.9713 - val_cost: 3.4082\n",
            "Epoch 409/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9934 - accuracy: 0.9803 - cost: 2.5663 - val_loss: 0.1187 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 410/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9937 - accuracy: 0.9813 - cost: 2.4208 - val_loss: 0.1180 - val_auc: 0.9840 - val_accuracy: 0.9716 - val_cost: 3.5514\n",
            "Epoch 411/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4354 - val_loss: 0.1188 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.6296\n",
            "Epoch 412/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9936 - accuracy: 0.9814 - cost: 2.4090 - val_loss: 0.1160 - val_auc: 0.9839 - val_accuracy: 0.9719 - val_cost: 3.6751\n",
            "Epoch 413/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9933 - accuracy: 0.9809 - cost: 2.4870 - val_loss: 0.1181 - val_auc: 0.9840 - val_accuracy: 0.9726 - val_cost: 3.3529\n",
            "Epoch 414/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5250 - val_loss: 0.1176 - val_auc: 0.9840 - val_accuracy: 0.9717 - val_cost: 3.7142\n",
            "Epoch 415/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9937 - accuracy: 0.9804 - cost: 2.5419 - val_loss: 0.1185 - val_auc: 0.9832 - val_accuracy: 0.9714 - val_cost: 3.6751\n",
            "Epoch 416/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.5020 - val_loss: 0.1214 - val_auc: 0.9828 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 417/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9811 - cost: 2.4436 - val_loss: 0.1199 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.3594\n",
            "Epoch 418/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9937 - accuracy: 0.9813 - cost: 2.4320 - val_loss: 0.1219 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 419/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4737 - val_loss: 0.1234 - val_auc: 0.9821 - val_accuracy: 0.9710 - val_cost: 3.7435\n",
            "Epoch 420/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4312 - val_loss: 0.1189 - val_auc: 0.9841 - val_accuracy: 0.9717 - val_cost: 3.6491\n",
            "Epoch 421/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4709 - val_loss: 0.1192 - val_auc: 0.9833 - val_accuracy: 0.9722 - val_cost: 3.4049\n",
            "Epoch 422/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9935 - accuracy: 0.9809 - cost: 2.4882 - val_loss: 0.1187 - val_auc: 0.9837 - val_accuracy: 0.9719 - val_cost: 3.6654\n",
            "Epoch 423/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4403 - val_loss: 0.1231 - val_auc: 0.9830 - val_accuracy: 0.9720 - val_cost: 3.2487\n",
            "Epoch 424/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4352 - val_loss: 0.1220 - val_auc: 0.9833 - val_accuracy: 0.9711 - val_cost: 3.4017\n",
            "Epoch 425/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4675 - val_loss: 0.1192 - val_auc: 0.9830 - val_accuracy: 0.9719 - val_cost: 3.6719\n",
            "Epoch 426/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4333 - val_loss: 0.1208 - val_auc: 0.9831 - val_accuracy: 0.9715 - val_cost: 3.6621\n",
            "Epoch 427/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4691 - val_loss: 0.1197 - val_auc: 0.9838 - val_accuracy: 0.9710 - val_cost: 3.6230\n",
            "Epoch 428/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4984 - val_loss: 0.1195 - val_auc: 0.9832 - val_accuracy: 0.9726 - val_cost: 3.3529\n",
            "Epoch 429/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9935 - accuracy: 0.9814 - cost: 2.4180 - val_loss: 0.1207 - val_auc: 0.9831 - val_accuracy: 0.9711 - val_cost: 3.3822\n",
            "Epoch 430/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9936 - accuracy: 0.9815 - cost: 2.4085 - val_loss: 0.1177 - val_auc: 0.9832 - val_accuracy: 0.9725 - val_cost: 3.4115\n",
            "Epoch 431/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4655 - val_loss: 0.1191 - val_auc: 0.9829 - val_accuracy: 0.9716 - val_cost: 3.5026\n",
            "Epoch 432/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9937 - accuracy: 0.9814 - cost: 2.4137 - val_loss: 0.1232 - val_auc: 0.9828 - val_accuracy: 0.9705 - val_cost: 3.6589\n",
            "Epoch 433/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9934 - accuracy: 0.9811 - cost: 2.4596 - val_loss: 0.1182 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.6947\n",
            "Epoch 434/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9935 - accuracy: 0.9812 - cost: 2.4318 - val_loss: 0.1229 - val_auc: 0.9816 - val_accuracy: 0.9720 - val_cost: 3.6458\n",
            "Epoch 435/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4478 - val_loss: 0.1195 - val_auc: 0.9834 - val_accuracy: 0.9717 - val_cost: 3.5319\n",
            "Epoch 436/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9936 - accuracy: 0.9816 - cost: 2.3813 - val_loss: 0.1194 - val_auc: 0.9834 - val_accuracy: 0.9720 - val_cost: 3.5091\n",
            "Epoch 437/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3886 - val_loss: 0.1216 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.5775\n",
            "Epoch 438/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9940 - accuracy: 0.9813 - cost: 2.4313 - val_loss: 0.1208 - val_auc: 0.9834 - val_accuracy: 0.9722 - val_cost: 3.6035\n",
            "Epoch 439/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9935 - accuracy: 0.9813 - cost: 2.4328 - val_loss: 0.1201 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.5482\n",
            "Epoch 440/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.5056 - val_loss: 0.1229 - val_auc: 0.9832 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 441/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9937 - accuracy: 0.9813 - cost: 2.4203 - val_loss: 0.1200 - val_auc: 0.9842 - val_accuracy: 0.9717 - val_cost: 3.5775\n",
            "Epoch 442/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.4106 - val_loss: 0.1231 - val_auc: 0.9827 - val_accuracy: 0.9715 - val_cost: 3.5840\n",
            "Epoch 443/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4812 - val_loss: 0.1223 - val_auc: 0.9834 - val_accuracy: 0.9719 - val_cost: 3.4961\n",
            "Epoch 444/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4378 - val_loss: 0.1194 - val_auc: 0.9829 - val_accuracy: 0.9723 - val_cost: 3.4277\n",
            "Epoch 445/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9937 - accuracy: 0.9815 - cost: 2.4111 - val_loss: 0.1244 - val_auc: 0.9825 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 446/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4800 - val_loss: 0.1221 - val_auc: 0.9830 - val_accuracy: 0.9715 - val_cost: 3.5352\n",
            "Epoch 447/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4688 - val_loss: 0.1194 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.6426\n",
            "Epoch 448/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4207 - val_loss: 0.1197 - val_auc: 0.9829 - val_accuracy: 0.9715 - val_cost: 3.3626\n",
            "Epoch 449/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9938 - accuracy: 0.9819 - cost: 2.3522 - val_loss: 0.1188 - val_auc: 0.9834 - val_accuracy: 0.9722 - val_cost: 3.4635\n",
            "Epoch 450/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4285 - val_loss: 0.1184 - val_auc: 0.9826 - val_accuracy: 0.9719 - val_cost: 3.4701\n",
            "Epoch 451/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9937 - accuracy: 0.9811 - cost: 2.4566 - val_loss: 0.1197 - val_auc: 0.9831 - val_accuracy: 0.9729 - val_cost: 3.5254\n",
            "Epoch 452/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9937 - accuracy: 0.9815 - cost: 2.4200 - val_loss: 0.1228 - val_auc: 0.9820 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 453/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4611 - val_loss: 0.1188 - val_auc: 0.9834 - val_accuracy: 0.9723 - val_cost: 3.4635\n",
            "Epoch 454/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4672 - val_loss: 0.1214 - val_auc: 0.9829 - val_accuracy: 0.9713 - val_cost: 3.7305\n",
            "Epoch 455/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9939 - accuracy: 0.9815 - cost: 2.4055 - val_loss: 0.1211 - val_auc: 0.9825 - val_accuracy: 0.9720 - val_cost: 3.4798\n",
            "Epoch 456/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9937 - accuracy: 0.9812 - cost: 2.4542 - val_loss: 0.1199 - val_auc: 0.9834 - val_accuracy: 0.9719 - val_cost: 3.4570\n",
            "Epoch 457/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9939 - accuracy: 0.9813 - cost: 2.4251 - val_loss: 0.1217 - val_auc: 0.9828 - val_accuracy: 0.9719 - val_cost: 3.4473\n",
            "Epoch 458/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4830 - val_loss: 0.1228 - val_auc: 0.9825 - val_accuracy: 0.9726 - val_cost: 3.2585\n",
            "Epoch 459/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9937 - accuracy: 0.9806 - cost: 2.5021 - val_loss: 0.1227 - val_auc: 0.9826 - val_accuracy: 0.9720 - val_cost: 3.3040\n",
            "Epoch 460/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4166 - val_loss: 0.1242 - val_auc: 0.9826 - val_accuracy: 0.9719 - val_cost: 3.5970\n",
            "Epoch 461/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4629 - val_loss: 0.1193 - val_auc: 0.9828 - val_accuracy: 0.9728 - val_cost: 3.3496\n",
            "Epoch 462/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9815 - cost: 2.4124 - val_loss: 0.1193 - val_auc: 0.9838 - val_accuracy: 0.9726 - val_cost: 3.5742\n",
            "Epoch 463/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4651 - val_loss: 0.1241 - val_auc: 0.9820 - val_accuracy: 0.9719 - val_cost: 3.2520\n",
            "Epoch 464/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9936 - accuracy: 0.9813 - cost: 2.4268 - val_loss: 0.1208 - val_auc: 0.9830 - val_accuracy: 0.9718 - val_cost: 3.3529\n",
            "Epoch 465/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4295 - val_loss: 0.1209 - val_auc: 0.9832 - val_accuracy: 0.9716 - val_cost: 3.3626\n",
            "Epoch 466/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9936 - accuracy: 0.9812 - cost: 2.4413 - val_loss: 0.1194 - val_auc: 0.9832 - val_accuracy: 0.9724 - val_cost: 3.3952\n",
            "Epoch 467/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9938 - accuracy: 0.9809 - cost: 2.4895 - val_loss: 0.1176 - val_auc: 0.9832 - val_accuracy: 0.9717 - val_cost: 3.6784\n",
            "Epoch 468/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4360 - val_loss: 0.1243 - val_auc: 0.9823 - val_accuracy: 0.9708 - val_cost: 3.3984\n",
            "Epoch 469/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4259 - val_loss: 0.1232 - val_auc: 0.9824 - val_accuracy: 0.9724 - val_cost: 3.4408\n",
            "Epoch 470/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4359 - val_loss: 0.1210 - val_auc: 0.9835 - val_accuracy: 0.9714 - val_cost: 3.7728\n",
            "Epoch 471/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9941 - accuracy: 0.9809 - cost: 2.4854 - val_loss: 0.1231 - val_auc: 0.9830 - val_accuracy: 0.9714 - val_cost: 3.3398\n",
            "Epoch 472/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9940 - accuracy: 0.9813 - cost: 2.4255 - val_loss: 0.1260 - val_auc: 0.9821 - val_accuracy: 0.9706 - val_cost: 3.5091\n",
            "Epoch 473/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3842 - val_loss: 0.1229 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 474/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9933 - accuracy: 0.9812 - cost: 2.4420 - val_loss: 0.1228 - val_auc: 0.9825 - val_accuracy: 0.9716 - val_cost: 3.3984\n",
            "Epoch 475/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4906 - val_loss: 0.1202 - val_auc: 0.9836 - val_accuracy: 0.9713 - val_cost: 3.5872\n",
            "Epoch 476/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9936 - accuracy: 0.9815 - cost: 2.4010 - val_loss: 0.1210 - val_auc: 0.9836 - val_accuracy: 0.9719 - val_cost: 3.4831\n",
            "Epoch 477/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9939 - accuracy: 0.9815 - cost: 2.3812 - val_loss: 0.1203 - val_auc: 0.9831 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 478/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9939 - accuracy: 0.9810 - cost: 2.4734 - val_loss: 0.1225 - val_auc: 0.9832 - val_accuracy: 0.9719 - val_cost: 3.3333\n",
            "Epoch 479/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4669 - val_loss: 0.1222 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.6426\n",
            "Epoch 480/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4021 - val_loss: 0.1217 - val_auc: 0.9834 - val_accuracy: 0.9725 - val_cost: 3.4082\n",
            "Epoch 481/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4928 - val_loss: 0.1187 - val_auc: 0.9830 - val_accuracy: 0.9722 - val_cost: 3.6426\n",
            "Epoch 482/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4634 - val_loss: 0.1230 - val_auc: 0.9831 - val_accuracy: 0.9724 - val_cost: 3.4212\n",
            "Epoch 483/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4347 - val_loss: 0.1214 - val_auc: 0.9832 - val_accuracy: 0.9717 - val_cost: 3.6686\n",
            "Epoch 484/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4203 - val_loss: 0.1226 - val_auc: 0.9830 - val_accuracy: 0.9723 - val_cost: 3.4896\n",
            "Epoch 485/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4341 - val_loss: 0.1237 - val_auc: 0.9824 - val_accuracy: 0.9723 - val_cost: 3.5612\n",
            "Epoch 486/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9937 - accuracy: 0.9811 - cost: 2.4447 - val_loss: 0.1235 - val_auc: 0.9822 - val_accuracy: 0.9714 - val_cost: 3.5872\n",
            "Epoch 487/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9939 - accuracy: 0.9812 - cost: 2.4495 - val_loss: 0.1221 - val_auc: 0.9832 - val_accuracy: 0.9717 - val_cost: 3.5124\n",
            "Epoch 488/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9938 - accuracy: 0.9815 - cost: 2.4071 - val_loss: 0.1254 - val_auc: 0.9821 - val_accuracy: 0.9717 - val_cost: 3.2747\n",
            "Epoch 489/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4140 - val_loss: 0.1244 - val_auc: 0.9823 - val_accuracy: 0.9716 - val_cost: 3.5189\n",
            "Epoch 490/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9938 - accuracy: 0.9815 - cost: 2.4001 - val_loss: 0.1257 - val_auc: 0.9829 - val_accuracy: 0.9723 - val_cost: 3.2617\n",
            "Epoch 491/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9939 - accuracy: 0.9809 - cost: 2.4757 - val_loss: 0.1255 - val_auc: 0.9822 - val_accuracy: 0.9721 - val_cost: 3.4473\n",
            "Epoch 492/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9938 - accuracy: 0.9809 - cost: 2.4727 - val_loss: 0.1205 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.5189\n",
            "Epoch 493/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.4254 - val_loss: 0.1226 - val_auc: 0.9827 - val_accuracy: 0.9694 - val_cost: 3.9648\n",
            "Epoch 494/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4629 - val_loss: 0.1208 - val_auc: 0.9828 - val_accuracy: 0.9699 - val_cost: 3.6133\n",
            "Epoch 495/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3936 - val_loss: 0.1230 - val_auc: 0.9822 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 496/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.4221 - val_loss: 0.1229 - val_auc: 0.9828 - val_accuracy: 0.9722 - val_cost: 3.3984\n",
            "Epoch 497/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4390 - val_loss: 0.1214 - val_auc: 0.9837 - val_accuracy: 0.9719 - val_cost: 3.3073\n",
            "Epoch 498/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9939 - accuracy: 0.9812 - cost: 2.4482 - val_loss: 0.1214 - val_auc: 0.9834 - val_accuracy: 0.9724 - val_cost: 3.2129\n",
            "Epoch 499/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9935 - accuracy: 0.9814 - cost: 2.4094 - val_loss: 0.1250 - val_auc: 0.9825 - val_accuracy: 0.9722 - val_cost: 3.3887\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1152 - auc: 0.9840 - accuracy: 0.9716 - cost: 3.6281\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:04:44.504277\n",
            "fold accuracy: 0.9715625047683716 - fold cost: 3.628124952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5458 - auc: 0.7110 - accuracy: 0.7158 - cost: 37.6375 - val_loss: 0.4082 - val_auc: 0.8511 - val_accuracy: 0.8201 - val_cost: 23.7012\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3657 - auc: 0.8773 - accuracy: 0.8415 - cost: 20.1920 - val_loss: 0.3210 - val_auc: 0.9071 - val_accuracy: 0.8619 - val_cost: 16.8880\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3142 - auc: 0.9097 - accuracy: 0.8707 - cost: 16.3326 - val_loss: 0.2927 - val_auc: 0.9248 - val_accuracy: 0.8781 - val_cost: 14.9316\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2871 - auc: 0.9261 - accuracy: 0.8832 - cost: 14.7601 - val_loss: 0.2708 - val_auc: 0.9368 - val_accuracy: 0.8901 - val_cost: 13.4049\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9373 - accuracy: 0.8934 - cost: 13.4851 - val_loss: 0.2530 - val_auc: 0.9448 - val_accuracy: 0.9015 - val_cost: 12.0182\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2464 - auc: 0.9461 - accuracy: 0.9027 - cost: 12.2865 - val_loss: 0.2373 - val_auc: 0.9511 - val_accuracy: 0.9087 - val_cost: 11.1816\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2311 - auc: 0.9524 - accuracy: 0.9106 - cost: 11.2717 - val_loss: 0.2234 - val_auc: 0.9562 - val_accuracy: 0.9151 - val_cost: 10.4232\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2170 - auc: 0.9583 - accuracy: 0.9167 - cost: 10.5298 - val_loss: 0.2113 - val_auc: 0.9598 - val_accuracy: 0.9212 - val_cost: 9.7884\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2051 - auc: 0.9621 - accuracy: 0.9224 - cost: 9.8079 - val_loss: 0.2007 - val_auc: 0.9634 - val_accuracy: 0.9276 - val_cost: 8.7565\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1949 - auc: 0.9656 - accuracy: 0.9269 - cost: 9.2921 - val_loss: 0.1925 - val_auc: 0.9657 - val_accuracy: 0.9301 - val_cost: 8.3984\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1874 - auc: 0.9681 - accuracy: 0.9304 - cost: 8.8304 - val_loss: 0.1859 - val_auc: 0.9677 - val_accuracy: 0.9336 - val_cost: 8.0534\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1798 - auc: 0.9704 - accuracy: 0.9334 - cost: 8.4453 - val_loss: 0.1797 - val_auc: 0.9696 - val_accuracy: 0.9356 - val_cost: 8.2064\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1732 - auc: 0.9725 - accuracy: 0.9370 - cost: 7.9982 - val_loss: 0.1757 - val_auc: 0.9708 - val_accuracy: 0.9381 - val_cost: 7.7311\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1673 - auc: 0.9740 - accuracy: 0.9399 - cost: 7.6205 - val_loss: 0.1700 - val_auc: 0.9715 - val_accuracy: 0.9420 - val_cost: 6.9531\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1625 - auc: 0.9754 - accuracy: 0.9415 - cost: 7.4463 - val_loss: 0.1674 - val_auc: 0.9726 - val_accuracy: 0.9428 - val_cost: 6.8815\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1576 - auc: 0.9768 - accuracy: 0.9442 - cost: 7.0970 - val_loss: 0.1635 - val_auc: 0.9738 - val_accuracy: 0.9438 - val_cost: 6.8587\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1544 - auc: 0.9775 - accuracy: 0.9462 - cost: 6.8460 - val_loss: 0.1598 - val_auc: 0.9751 - val_accuracy: 0.9450 - val_cost: 6.6146\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1502 - auc: 0.9784 - accuracy: 0.9480 - cost: 6.6172 - val_loss: 0.1565 - val_auc: 0.9757 - val_accuracy: 0.9472 - val_cost: 6.5495\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1469 - auc: 0.9792 - accuracy: 0.9486 - cost: 6.5284 - val_loss: 0.1539 - val_auc: 0.9763 - val_accuracy: 0.9476 - val_cost: 6.3997\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9800 - accuracy: 0.9505 - cost: 6.2640 - val_loss: 0.1515 - val_auc: 0.9771 - val_accuracy: 0.9492 - val_cost: 6.3900\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1408 - auc: 0.9806 - accuracy: 0.9521 - cost: 6.0978 - val_loss: 0.1506 - val_auc: 0.9770 - val_accuracy: 0.9497 - val_cost: 6.3184\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1392 - auc: 0.9810 - accuracy: 0.9527 - cost: 6.0123 - val_loss: 0.1471 - val_auc: 0.9784 - val_accuracy: 0.9510 - val_cost: 6.0189\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9820 - accuracy: 0.9537 - cost: 5.8958 - val_loss: 0.1450 - val_auc: 0.9783 - val_accuracy: 0.9519 - val_cost: 5.8398\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1332 - auc: 0.9824 - accuracy: 0.9553 - cost: 5.6855 - val_loss: 0.1429 - val_auc: 0.9791 - val_accuracy: 0.9522 - val_cost: 5.8659\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1320 - auc: 0.9823 - accuracy: 0.9555 - cost: 5.6506 - val_loss: 0.1410 - val_auc: 0.9793 - val_accuracy: 0.9536 - val_cost: 5.5827\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9836 - accuracy: 0.9569 - cost: 5.4851 - val_loss: 0.1401 - val_auc: 0.9794 - val_accuracy: 0.9551 - val_cost: 5.4818\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1273 - auc: 0.9835 - accuracy: 0.9584 - cost: 5.2907 - val_loss: 0.1394 - val_auc: 0.9793 - val_accuracy: 0.9554 - val_cost: 5.6055\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1259 - auc: 0.9834 - accuracy: 0.9582 - cost: 5.3037 - val_loss: 0.1361 - val_auc: 0.9801 - val_accuracy: 0.9558 - val_cost: 5.3255\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1237 - auc: 0.9842 - accuracy: 0.9590 - cost: 5.2203 - val_loss: 0.1356 - val_auc: 0.9809 - val_accuracy: 0.9556 - val_cost: 5.3483\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9847 - accuracy: 0.9606 - cost: 5.0087 - val_loss: 0.1333 - val_auc: 0.9808 - val_accuracy: 0.9574 - val_cost: 5.3255\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1211 - auc: 0.9847 - accuracy: 0.9608 - cost: 4.9835 - val_loss: 0.1323 - val_auc: 0.9810 - val_accuracy: 0.9581 - val_cost: 5.0098\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9851 - accuracy: 0.9617 - cost: 4.8679 - val_loss: 0.1313 - val_auc: 0.9810 - val_accuracy: 0.9597 - val_cost: 4.9479\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1180 - auc: 0.9853 - accuracy: 0.9622 - cost: 4.8060 - val_loss: 0.1293 - val_auc: 0.9812 - val_accuracy: 0.9599 - val_cost: 4.8763\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1158 - auc: 0.9859 - accuracy: 0.9624 - cost: 4.7762 - val_loss: 0.1290 - val_auc: 0.9811 - val_accuracy: 0.9599 - val_cost: 4.8503\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1145 - auc: 0.9859 - accuracy: 0.9628 - cost: 4.7385 - val_loss: 0.1284 - val_auc: 0.9818 - val_accuracy: 0.9598 - val_cost: 4.7754\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9862 - accuracy: 0.9639 - cost: 4.5940 - val_loss: 0.1269 - val_auc: 0.9813 - val_accuracy: 0.9598 - val_cost: 4.7786\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9864 - accuracy: 0.9641 - cost: 4.5773 - val_loss: 0.1260 - val_auc: 0.9815 - val_accuracy: 0.9613 - val_cost: 4.6452\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1103 - auc: 0.9868 - accuracy: 0.9654 - cost: 4.4047 - val_loss: 0.1245 - val_auc: 0.9819 - val_accuracy: 0.9613 - val_cost: 4.6680\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1096 - auc: 0.9867 - accuracy: 0.9653 - cost: 4.4182 - val_loss: 0.1237 - val_auc: 0.9821 - val_accuracy: 0.9611 - val_cost: 4.7168\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1086 - auc: 0.9869 - accuracy: 0.9658 - cost: 4.3551 - val_loss: 0.1229 - val_auc: 0.9825 - val_accuracy: 0.9626 - val_cost: 4.5833\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9871 - accuracy: 0.9669 - cost: 4.2205 - val_loss: 0.1239 - val_auc: 0.9818 - val_accuracy: 0.9621 - val_cost: 4.5215\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1074 - auc: 0.9874 - accuracy: 0.9664 - cost: 4.2758 - val_loss: 0.1212 - val_auc: 0.9829 - val_accuracy: 0.9634 - val_cost: 4.4173\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1058 - auc: 0.9873 - accuracy: 0.9670 - cost: 4.2034 - val_loss: 0.1220 - val_auc: 0.9827 - val_accuracy: 0.9635 - val_cost: 4.5410\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1050 - auc: 0.9876 - accuracy: 0.9677 - cost: 4.1274 - val_loss: 0.1198 - val_auc: 0.9831 - val_accuracy: 0.9633 - val_cost: 4.5833\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9876 - accuracy: 0.9671 - cost: 4.1982 - val_loss: 0.1194 - val_auc: 0.9827 - val_accuracy: 0.9640 - val_cost: 4.4010\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9879 - accuracy: 0.9687 - cost: 3.9863 - val_loss: 0.1201 - val_auc: 0.9828 - val_accuracy: 0.9638 - val_cost: 4.5540\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1021 - auc: 0.9880 - accuracy: 0.9689 - cost: 3.9693 - val_loss: 0.1215 - val_auc: 0.9831 - val_accuracy: 0.9639 - val_cost: 4.2350\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9880 - accuracy: 0.9682 - cost: 4.0667 - val_loss: 0.1201 - val_auc: 0.9827 - val_accuracy: 0.9640 - val_cost: 4.4629\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1003 - auc: 0.9882 - accuracy: 0.9691 - cost: 3.9367 - val_loss: 0.1185 - val_auc: 0.9832 - val_accuracy: 0.9656 - val_cost: 4.3750\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0999 - auc: 0.9885 - accuracy: 0.9693 - cost: 3.9146 - val_loss: 0.1185 - val_auc: 0.9828 - val_accuracy: 0.9644 - val_cost: 4.4271\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1004 - auc: 0.9883 - accuracy: 0.9693 - cost: 3.9076 - val_loss: 0.1177 - val_auc: 0.9831 - val_accuracy: 0.9649 - val_cost: 4.5215\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0987 - auc: 0.9886 - accuracy: 0.9701 - cost: 3.8191 - val_loss: 0.1179 - val_auc: 0.9829 - val_accuracy: 0.9654 - val_cost: 4.4076\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9886 - accuracy: 0.9697 - cost: 3.8501 - val_loss: 0.1171 - val_auc: 0.9831 - val_accuracy: 0.9659 - val_cost: 4.3392\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0982 - auc: 0.9886 - accuracy: 0.9702 - cost: 3.8000 - val_loss: 0.1172 - val_auc: 0.9827 - val_accuracy: 0.9656 - val_cost: 4.3034\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9887 - accuracy: 0.9706 - cost: 3.7588 - val_loss: 0.1172 - val_auc: 0.9830 - val_accuracy: 0.9662 - val_cost: 4.4076\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9889 - accuracy: 0.9710 - cost: 3.6991 - val_loss: 0.1167 - val_auc: 0.9828 - val_accuracy: 0.9660 - val_cost: 4.4108\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0961 - auc: 0.9890 - accuracy: 0.9704 - cost: 3.7709 - val_loss: 0.1174 - val_auc: 0.9823 - val_accuracy: 0.9658 - val_cost: 4.1992\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9889 - accuracy: 0.9706 - cost: 3.7678 - val_loss: 0.1171 - val_auc: 0.9824 - val_accuracy: 0.9664 - val_cost: 4.1634\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9889 - accuracy: 0.9711 - cost: 3.7049 - val_loss: 0.1149 - val_auc: 0.9831 - val_accuracy: 0.9671 - val_cost: 4.3262\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0955 - auc: 0.9889 - accuracy: 0.9715 - cost: 3.6515 - val_loss: 0.1155 - val_auc: 0.9833 - val_accuracy: 0.9663 - val_cost: 4.3229\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9892 - accuracy: 0.9717 - cost: 3.6157 - val_loss: 0.1164 - val_auc: 0.9829 - val_accuracy: 0.9662 - val_cost: 4.4922\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0955 - auc: 0.9890 - accuracy: 0.9711 - cost: 3.6811 - val_loss: 0.1150 - val_auc: 0.9834 - val_accuracy: 0.9665 - val_cost: 4.2285\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9892 - accuracy: 0.9716 - cost: 3.6483 - val_loss: 0.1163 - val_auc: 0.9822 - val_accuracy: 0.9669 - val_cost: 4.0332\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9892 - accuracy: 0.9721 - cost: 3.5501 - val_loss: 0.1148 - val_auc: 0.9833 - val_accuracy: 0.9677 - val_cost: 4.3685\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0933 - auc: 0.9895 - accuracy: 0.9721 - cost: 3.5723 - val_loss: 0.1152 - val_auc: 0.9829 - val_accuracy: 0.9668 - val_cost: 4.3262\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9897 - accuracy: 0.9718 - cost: 3.6025 - val_loss: 0.1143 - val_auc: 0.9831 - val_accuracy: 0.9669 - val_cost: 4.1536\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9896 - accuracy: 0.9720 - cost: 3.5859 - val_loss: 0.1141 - val_auc: 0.9831 - val_accuracy: 0.9672 - val_cost: 4.2969\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9895 - accuracy: 0.9727 - cost: 3.5022 - val_loss: 0.1151 - val_auc: 0.9833 - val_accuracy: 0.9666 - val_cost: 4.2578\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9894 - accuracy: 0.9726 - cost: 3.5102 - val_loss: 0.1159 - val_auc: 0.9833 - val_accuracy: 0.9674 - val_cost: 4.1374\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0915 - auc: 0.9897 - accuracy: 0.9728 - cost: 3.4959 - val_loss: 0.1149 - val_auc: 0.9834 - val_accuracy: 0.9675 - val_cost: 4.0430\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9895 - accuracy: 0.9730 - cost: 3.4499 - val_loss: 0.1140 - val_auc: 0.9832 - val_accuracy: 0.9672 - val_cost: 4.1016\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9893 - accuracy: 0.9724 - cost: 3.5387 - val_loss: 0.1129 - val_auc: 0.9835 - val_accuracy: 0.9676 - val_cost: 4.1211\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0901 - auc: 0.9897 - accuracy: 0.9734 - cost: 3.3977 - val_loss: 0.1138 - val_auc: 0.9832 - val_accuracy: 0.9670 - val_cost: 4.3099\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9901 - accuracy: 0.9737 - cost: 3.3811 - val_loss: 0.1150 - val_auc: 0.9826 - val_accuracy: 0.9665 - val_cost: 4.3685\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9898 - accuracy: 0.9730 - cost: 3.4631 - val_loss: 0.1148 - val_auc: 0.9832 - val_accuracy: 0.9678 - val_cost: 4.2057\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9901 - accuracy: 0.9742 - cost: 3.3022 - val_loss: 0.1189 - val_auc: 0.9822 - val_accuracy: 0.9663 - val_cost: 4.0137\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0898 - auc: 0.9899 - accuracy: 0.9733 - cost: 3.4126 - val_loss: 0.1132 - val_auc: 0.9839 - val_accuracy: 0.9672 - val_cost: 4.1927\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9899 - accuracy: 0.9735 - cost: 3.3918 - val_loss: 0.1130 - val_auc: 0.9832 - val_accuracy: 0.9681 - val_cost: 3.8639\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9903 - accuracy: 0.9739 - cost: 3.3452 - val_loss: 0.1121 - val_auc: 0.9837 - val_accuracy: 0.9670 - val_cost: 4.1862\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9904 - accuracy: 0.9742 - cost: 3.2993 - val_loss: 0.1148 - val_auc: 0.9827 - val_accuracy: 0.9681 - val_cost: 3.9779\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9901 - accuracy: 0.9746 - cost: 3.2533 - val_loss: 0.1134 - val_auc: 0.9832 - val_accuracy: 0.9673 - val_cost: 4.0951\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9903 - accuracy: 0.9741 - cost: 3.3237 - val_loss: 0.1128 - val_auc: 0.9841 - val_accuracy: 0.9685 - val_cost: 4.0820\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9905 - accuracy: 0.9746 - cost: 3.2649 - val_loss: 0.1132 - val_auc: 0.9831 - val_accuracy: 0.9680 - val_cost: 4.0299\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0873 - auc: 0.9902 - accuracy: 0.9743 - cost: 3.3047 - val_loss: 0.1121 - val_auc: 0.9834 - val_accuracy: 0.9690 - val_cost: 3.9648\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9907 - accuracy: 0.9747 - cost: 3.2427 - val_loss: 0.1153 - val_auc: 0.9830 - val_accuracy: 0.9673 - val_cost: 4.2220\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9904 - accuracy: 0.9744 - cost: 3.2720 - val_loss: 0.1127 - val_auc: 0.9834 - val_accuracy: 0.9680 - val_cost: 4.1439\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9905 - accuracy: 0.9747 - cost: 3.2324 - val_loss: 0.1143 - val_auc: 0.9830 - val_accuracy: 0.9682 - val_cost: 4.0332\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9905 - accuracy: 0.9744 - cost: 3.2916 - val_loss: 0.1157 - val_auc: 0.9831 - val_accuracy: 0.9672 - val_cost: 4.1471\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9904 - accuracy: 0.9754 - cost: 3.1532 - val_loss: 0.1152 - val_auc: 0.9830 - val_accuracy: 0.9681 - val_cost: 3.9779\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9907 - accuracy: 0.9746 - cost: 3.2516 - val_loss: 0.1142 - val_auc: 0.9830 - val_accuracy: 0.9684 - val_cost: 3.8542\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9907 - accuracy: 0.9747 - cost: 3.2419 - val_loss: 0.1139 - val_auc: 0.9839 - val_accuracy: 0.9684 - val_cost: 4.0723\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9907 - accuracy: 0.9750 - cost: 3.2115 - val_loss: 0.1141 - val_auc: 0.9833 - val_accuracy: 0.9677 - val_cost: 4.0723\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9907 - accuracy: 0.9749 - cost: 3.2186 - val_loss: 0.1124 - val_auc: 0.9840 - val_accuracy: 0.9686 - val_cost: 4.0397\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9906 - accuracy: 0.9750 - cost: 3.2108 - val_loss: 0.1127 - val_auc: 0.9833 - val_accuracy: 0.9683 - val_cost: 4.0690\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9908 - accuracy: 0.9751 - cost: 3.2023 - val_loss: 0.1148 - val_auc: 0.9831 - val_accuracy: 0.9681 - val_cost: 4.0104\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9911 - accuracy: 0.9754 - cost: 3.1438 - val_loss: 0.1142 - val_auc: 0.9826 - val_accuracy: 0.9687 - val_cost: 3.9258\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9906 - accuracy: 0.9755 - cost: 3.1351 - val_loss: 0.1153 - val_auc: 0.9828 - val_accuracy: 0.9688 - val_cost: 3.8346\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0849 - auc: 0.9906 - accuracy: 0.9753 - cost: 3.1747 - val_loss: 0.1151 - val_auc: 0.9831 - val_accuracy: 0.9674 - val_cost: 4.1048\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9910 - accuracy: 0.9755 - cost: 3.1405 - val_loss: 0.1116 - val_auc: 0.9830 - val_accuracy: 0.9681 - val_cost: 3.9258\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9910 - accuracy: 0.9757 - cost: 3.1099 - val_loss: 0.1129 - val_auc: 0.9834 - val_accuracy: 0.9682 - val_cost: 3.8574\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0672 - val_loss: 0.1145 - val_auc: 0.9835 - val_accuracy: 0.9673 - val_cost: 4.1536\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9911 - accuracy: 0.9756 - cost: 3.1355 - val_loss: 0.1155 - val_auc: 0.9827 - val_accuracy: 0.9681 - val_cost: 4.0983\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0830 - auc: 0.9910 - accuracy: 0.9758 - cost: 3.1085 - val_loss: 0.1153 - val_auc: 0.9832 - val_accuracy: 0.9692 - val_cost: 3.7142\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9909 - accuracy: 0.9757 - cost: 3.1312 - val_loss: 0.1148 - val_auc: 0.9833 - val_accuracy: 0.9688 - val_cost: 3.8314\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9912 - accuracy: 0.9762 - cost: 3.0622 - val_loss: 0.1125 - val_auc: 0.9833 - val_accuracy: 0.9683 - val_cost: 3.8867\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9913 - accuracy: 0.9762 - cost: 3.0651 - val_loss: 0.1144 - val_auc: 0.9829 - val_accuracy: 0.9683 - val_cost: 3.9551\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9911 - accuracy: 0.9760 - cost: 3.0734 - val_loss: 0.1129 - val_auc: 0.9836 - val_accuracy: 0.9692 - val_cost: 3.7956\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9913 - accuracy: 0.9759 - cost: 3.0996 - val_loss: 0.1140 - val_auc: 0.9832 - val_accuracy: 0.9691 - val_cost: 3.7240\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9911 - accuracy: 0.9754 - cost: 3.1609 - val_loss: 0.1141 - val_auc: 0.9837 - val_accuracy: 0.9694 - val_cost: 3.6361\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9912 - accuracy: 0.9765 - cost: 3.0094 - val_loss: 0.1128 - val_auc: 0.9831 - val_accuracy: 0.9697 - val_cost: 3.8346\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9911 - accuracy: 0.9764 - cost: 3.0237 - val_loss: 0.1106 - val_auc: 0.9843 - val_accuracy: 0.9698 - val_cost: 3.7370\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9913 - accuracy: 0.9765 - cost: 3.0142 - val_loss: 0.1117 - val_auc: 0.9837 - val_accuracy: 0.9688 - val_cost: 3.8118\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9911 - accuracy: 0.9761 - cost: 3.0695 - val_loss: 0.1127 - val_auc: 0.9834 - val_accuracy: 0.9692 - val_cost: 3.7565\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9912 - accuracy: 0.9765 - cost: 3.0231 - val_loss: 0.1146 - val_auc: 0.9828 - val_accuracy: 0.9690 - val_cost: 3.7760\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9911 - accuracy: 0.9761 - cost: 3.0697 - val_loss: 0.1132 - val_auc: 0.9839 - val_accuracy: 0.9696 - val_cost: 3.7044\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9914 - accuracy: 0.9766 - cost: 3.0064 - val_loss: 0.1123 - val_auc: 0.9839 - val_accuracy: 0.9693 - val_cost: 3.9030\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9912 - accuracy: 0.9768 - cost: 2.9839 - val_loss: 0.1137 - val_auc: 0.9834 - val_accuracy: 0.9691 - val_cost: 4.0365\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9916 - accuracy: 0.9769 - cost: 2.9710 - val_loss: 0.1148 - val_auc: 0.9834 - val_accuracy: 0.9684 - val_cost: 3.8379\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9910 - accuracy: 0.9763 - cost: 3.0409 - val_loss: 0.1112 - val_auc: 0.9837 - val_accuracy: 0.9695 - val_cost: 3.7435\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0807 - auc: 0.9914 - accuracy: 0.9766 - cost: 3.0153 - val_loss: 0.1108 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.5775\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9915 - accuracy: 0.9767 - cost: 2.9946 - val_loss: 0.1124 - val_auc: 0.9841 - val_accuracy: 0.9697 - val_cost: 3.7044\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9916 - accuracy: 0.9769 - cost: 2.9531 - val_loss: 0.1117 - val_auc: 0.9846 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9916 - accuracy: 0.9773 - cost: 2.9209 - val_loss: 0.1139 - val_auc: 0.9832 - val_accuracy: 0.9694 - val_cost: 3.7956\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9913 - accuracy: 0.9769 - cost: 2.9739 - val_loss: 0.1129 - val_auc: 0.9840 - val_accuracy: 0.9694 - val_cost: 3.9583\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9915 - accuracy: 0.9768 - cost: 2.9790 - val_loss: 0.1134 - val_auc: 0.9834 - val_accuracy: 0.9693 - val_cost: 3.7565\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9912 - accuracy: 0.9770 - cost: 2.9540 - val_loss: 0.1139 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.4798\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9916 - accuracy: 0.9765 - cost: 3.0299 - val_loss: 0.1121 - val_auc: 0.9835 - val_accuracy: 0.9700 - val_cost: 3.6621\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9917 - accuracy: 0.9771 - cost: 2.9374 - val_loss: 0.1114 - val_auc: 0.9841 - val_accuracy: 0.9691 - val_cost: 3.8021\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9915 - accuracy: 0.9775 - cost: 2.8960 - val_loss: 0.1122 - val_auc: 0.9836 - val_accuracy: 0.9691 - val_cost: 3.9388\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9913 - accuracy: 0.9766 - cost: 3.0112 - val_loss: 0.1167 - val_auc: 0.9830 - val_accuracy: 0.9692 - val_cost: 3.6914\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9556 - val_loss: 0.1126 - val_auc: 0.9839 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9916 - accuracy: 0.9773 - cost: 2.9134 - val_loss: 0.1144 - val_auc: 0.9829 - val_accuracy: 0.9697 - val_cost: 3.6947\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9915 - accuracy: 0.9772 - cost: 2.9274 - val_loss: 0.1126 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.6979\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.8985 - val_loss: 0.1123 - val_auc: 0.9841 - val_accuracy: 0.9696 - val_cost: 3.6426\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9916 - accuracy: 0.9773 - cost: 2.9257 - val_loss: 0.1145 - val_auc: 0.9835 - val_accuracy: 0.9694 - val_cost: 3.6849\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9917 - accuracy: 0.9774 - cost: 2.9014 - val_loss: 0.1143 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.8053\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8752 - val_loss: 0.1144 - val_auc: 0.9830 - val_accuracy: 0.9700 - val_cost: 3.6849\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9918 - accuracy: 0.9773 - cost: 2.9340 - val_loss: 0.1137 - val_auc: 0.9838 - val_accuracy: 0.9696 - val_cost: 3.9714\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9918 - accuracy: 0.9778 - cost: 2.8663 - val_loss: 0.1159 - val_auc: 0.9833 - val_accuracy: 0.9690 - val_cost: 3.7402\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9776 - cost: 2.8819 - val_loss: 0.1144 - val_auc: 0.9833 - val_accuracy: 0.9695 - val_cost: 3.7240\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9915 - accuracy: 0.9775 - cost: 2.8950 - val_loss: 0.1146 - val_auc: 0.9837 - val_accuracy: 0.9688 - val_cost: 3.7923\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9919 - accuracy: 0.9778 - cost: 2.8511 - val_loss: 0.1154 - val_auc: 0.9834 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8716 - val_loss: 0.1151 - val_auc: 0.9820 - val_accuracy: 0.9697 - val_cost: 3.6914\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9918 - accuracy: 0.9776 - cost: 2.8705 - val_loss: 0.1150 - val_auc: 0.9833 - val_accuracy: 0.9690 - val_cost: 3.8444\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0774 - auc: 0.9918 - accuracy: 0.9778 - cost: 2.8571 - val_loss: 0.1147 - val_auc: 0.9833 - val_accuracy: 0.9699 - val_cost: 3.7142\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9917 - accuracy: 0.9772 - cost: 2.9373 - val_loss: 0.1147 - val_auc: 0.9829 - val_accuracy: 0.9705 - val_cost: 3.5840\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9917 - accuracy: 0.9781 - cost: 2.8054 - val_loss: 0.1156 - val_auc: 0.9830 - val_accuracy: 0.9694 - val_cost: 3.6621\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8573 - val_loss: 0.1121 - val_auc: 0.9834 - val_accuracy: 0.9696 - val_cost: 3.8249\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9918 - accuracy: 0.9778 - cost: 2.8566 - val_loss: 0.1136 - val_auc: 0.9830 - val_accuracy: 0.9706 - val_cost: 3.5840\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9921 - accuracy: 0.9781 - cost: 2.8095 - val_loss: 0.1155 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.6035\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9920 - accuracy: 0.9780 - cost: 2.8218 - val_loss: 0.1152 - val_auc: 0.9828 - val_accuracy: 0.9698 - val_cost: 3.7337\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9921 - accuracy: 0.9778 - cost: 2.8660 - val_loss: 0.1143 - val_auc: 0.9826 - val_accuracy: 0.9701 - val_cost: 3.6979\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8196 - val_loss: 0.1152 - val_auc: 0.9826 - val_accuracy: 0.9691 - val_cost: 3.8835\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9008 - val_loss: 0.1162 - val_auc: 0.9825 - val_accuracy: 0.9692 - val_cost: 3.7598\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9920 - accuracy: 0.9782 - cost: 2.8084 - val_loss: 0.1150 - val_auc: 0.9837 - val_accuracy: 0.9710 - val_cost: 3.5742\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7802 - val_loss: 0.1155 - val_auc: 0.9834 - val_accuracy: 0.9703 - val_cost: 3.5905\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9922 - accuracy: 0.9780 - cost: 2.8309 - val_loss: 0.1146 - val_auc: 0.9833 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9920 - accuracy: 0.9780 - cost: 2.8485 - val_loss: 0.1157 - val_auc: 0.9832 - val_accuracy: 0.9692 - val_cost: 3.7630\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9922 - accuracy: 0.9780 - cost: 2.8372 - val_loss: 0.1146 - val_auc: 0.9832 - val_accuracy: 0.9690 - val_cost: 3.8314\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9919 - accuracy: 0.9778 - cost: 2.8574 - val_loss: 0.1157 - val_auc: 0.9827 - val_accuracy: 0.9699 - val_cost: 3.6751\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9923 - accuracy: 0.9782 - cost: 2.8076 - val_loss: 0.1151 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.7077\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9919 - accuracy: 0.9774 - cost: 2.9235 - val_loss: 0.1150 - val_auc: 0.9823 - val_accuracy: 0.9699 - val_cost: 3.6784\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9918 - accuracy: 0.9780 - cost: 2.8292 - val_loss: 0.1161 - val_auc: 0.9828 - val_accuracy: 0.9694 - val_cost: 3.7109\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9923 - accuracy: 0.9781 - cost: 2.8095 - val_loss: 0.1167 - val_auc: 0.9827 - val_accuracy: 0.9694 - val_cost: 3.7598\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9923 - accuracy: 0.9782 - cost: 2.8088 - val_loss: 0.1166 - val_auc: 0.9827 - val_accuracy: 0.9699 - val_cost: 3.6003\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9918 - accuracy: 0.9776 - cost: 2.8796 - val_loss: 0.1152 - val_auc: 0.9828 - val_accuracy: 0.9694 - val_cost: 3.6816\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9919 - accuracy: 0.9783 - cost: 2.7805 - val_loss: 0.1165 - val_auc: 0.9826 - val_accuracy: 0.9697 - val_cost: 3.6654\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9923 - accuracy: 0.9779 - cost: 2.8472 - val_loss: 0.1139 - val_auc: 0.9842 - val_accuracy: 0.9702 - val_cost: 3.8672\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8252 - val_loss: 0.1156 - val_auc: 0.9832 - val_accuracy: 0.9698 - val_cost: 3.6947\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9921 - accuracy: 0.9784 - cost: 2.7857 - val_loss: 0.1144 - val_auc: 0.9830 - val_accuracy: 0.9691 - val_cost: 3.8314\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9924 - accuracy: 0.9780 - cost: 2.8305 - val_loss: 0.1155 - val_auc: 0.9828 - val_accuracy: 0.9693 - val_cost: 3.7793\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9925 - accuracy: 0.9781 - cost: 2.8137 - val_loss: 0.1154 - val_auc: 0.9828 - val_accuracy: 0.9699 - val_cost: 3.6426\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8022 - val_loss: 0.1171 - val_auc: 0.9826 - val_accuracy: 0.9694 - val_cost: 3.6816\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7880 - val_loss: 0.1171 - val_auc: 0.9830 - val_accuracy: 0.9703 - val_cost: 3.6458\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.7937 - val_loss: 0.1166 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.5319\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8212 - val_loss: 0.1155 - val_auc: 0.9827 - val_accuracy: 0.9698 - val_cost: 3.6751\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9923 - accuracy: 0.9784 - cost: 2.7755 - val_loss: 0.1153 - val_auc: 0.9839 - val_accuracy: 0.9702 - val_cost: 3.6198\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9926 - accuracy: 0.9787 - cost: 2.7341 - val_loss: 0.1174 - val_auc: 0.9827 - val_accuracy: 0.9694 - val_cost: 3.7337\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9921 - accuracy: 0.9784 - cost: 2.7949 - val_loss: 0.1170 - val_auc: 0.9829 - val_accuracy: 0.9704 - val_cost: 3.6230\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9925 - accuracy: 0.9785 - cost: 2.7580 - val_loss: 0.1163 - val_auc: 0.9825 - val_accuracy: 0.9700 - val_cost: 3.6784\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9920 - accuracy: 0.9779 - cost: 2.8454 - val_loss: 0.1158 - val_auc: 0.9827 - val_accuracy: 0.9694 - val_cost: 3.8411\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6787 - val_loss: 0.1164 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.5384\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9924 - accuracy: 0.9786 - cost: 2.7633 - val_loss: 0.1141 - val_auc: 0.9830 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9787 - cost: 2.7407 - val_loss: 0.1176 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.5645\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9923 - accuracy: 0.9791 - cost: 2.6863 - val_loss: 0.1158 - val_auc: 0.9824 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9923 - accuracy: 0.9782 - cost: 2.8108 - val_loss: 0.1194 - val_auc: 0.9820 - val_accuracy: 0.9703 - val_cost: 3.5612\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.7849 - val_loss: 0.1185 - val_auc: 0.9824 - val_accuracy: 0.9707 - val_cost: 3.5384\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7602 - val_loss: 0.1163 - val_auc: 0.9825 - val_accuracy: 0.9700 - val_cost: 3.6426\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9921 - accuracy: 0.9781 - cost: 2.8203 - val_loss: 0.1179 - val_auc: 0.9827 - val_accuracy: 0.9702 - val_cost: 3.6165\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7154 - val_loss: 0.1176 - val_auc: 0.9829 - val_accuracy: 0.9703 - val_cost: 3.6491\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9921 - accuracy: 0.9784 - cost: 2.7838 - val_loss: 0.1158 - val_auc: 0.9829 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7590 - val_loss: 0.1171 - val_auc: 0.9835 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9924 - accuracy: 0.9781 - cost: 2.8181 - val_loss: 0.1146 - val_auc: 0.9834 - val_accuracy: 0.9715 - val_cost: 3.5352\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9922 - accuracy: 0.9787 - cost: 2.7392 - val_loss: 0.1161 - val_auc: 0.9830 - val_accuracy: 0.9701 - val_cost: 3.6882\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7171 - val_loss: 0.1178 - val_auc: 0.9830 - val_accuracy: 0.9696 - val_cost: 3.7630\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7705 - val_loss: 0.1163 - val_auc: 0.9836 - val_accuracy: 0.9714 - val_cost: 3.5384\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9922 - accuracy: 0.9789 - cost: 2.7139 - val_loss: 0.1181 - val_auc: 0.9822 - val_accuracy: 0.9702 - val_cost: 3.5710\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9922 - accuracy: 0.9792 - cost: 2.6869 - val_loss: 0.1163 - val_auc: 0.9834 - val_accuracy: 0.9706 - val_cost: 3.6068\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9925 - accuracy: 0.9786 - cost: 2.7441 - val_loss: 0.1162 - val_auc: 0.9834 - val_accuracy: 0.9713 - val_cost: 3.6426\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9923 - accuracy: 0.9794 - cost: 2.6533 - val_loss: 0.1140 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.4798\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9925 - accuracy: 0.9783 - cost: 2.8108 - val_loss: 0.1192 - val_auc: 0.9825 - val_accuracy: 0.9696 - val_cost: 3.5417\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7224 - val_loss: 0.1170 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.6393\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7260 - val_loss: 0.1163 - val_auc: 0.9827 - val_accuracy: 0.9706 - val_cost: 3.7858\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9924 - accuracy: 0.9785 - cost: 2.7588 - val_loss: 0.1170 - val_auc: 0.9825 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.6940 - val_loss: 0.1173 - val_auc: 0.9820 - val_accuracy: 0.9711 - val_cost: 3.5742\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6896 - val_loss: 0.1187 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9924 - accuracy: 0.9785 - cost: 2.7648 - val_loss: 0.1199 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.5872\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7730 - val_loss: 0.1194 - val_auc: 0.9830 - val_accuracy: 0.9700 - val_cost: 3.7012\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9926 - accuracy: 0.9784 - cost: 2.7870 - val_loss: 0.1172 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.7077\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7329 - val_loss: 0.1195 - val_auc: 0.9824 - val_accuracy: 0.9703 - val_cost: 3.8216\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7383 - val_loss: 0.1202 - val_auc: 0.9828 - val_accuracy: 0.9708 - val_cost: 3.8021\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9927 - accuracy: 0.9790 - cost: 2.7055 - val_loss: 0.1191 - val_auc: 0.9819 - val_accuracy: 0.9708 - val_cost: 3.5026\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6725 - val_loss: 0.1169 - val_auc: 0.9825 - val_accuracy: 0.9710 - val_cost: 3.5319\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9924 - accuracy: 0.9786 - cost: 2.7548 - val_loss: 0.1181 - val_auc: 0.9827 - val_accuracy: 0.9705 - val_cost: 3.5319\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6569 - val_loss: 0.1196 - val_auc: 0.9830 - val_accuracy: 0.9700 - val_cost: 3.7858\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7419 - val_loss: 0.1200 - val_auc: 0.9818 - val_accuracy: 0.9692 - val_cost: 3.6784\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7020 - val_loss: 0.1180 - val_auc: 0.9829 - val_accuracy: 0.9704 - val_cost: 3.8509\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9927 - accuracy: 0.9787 - cost: 2.7377 - val_loss: 0.1201 - val_auc: 0.9819 - val_accuracy: 0.9697 - val_cost: 3.6393\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9926 - accuracy: 0.9790 - cost: 2.7151 - val_loss: 0.1194 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.6784\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.6985 - val_loss: 0.1207 - val_auc: 0.9823 - val_accuracy: 0.9705 - val_cost: 3.5286\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9928 - accuracy: 0.9790 - cost: 2.7045 - val_loss: 0.1179 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.5905\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9927 - accuracy: 0.9789 - cost: 2.7213 - val_loss: 0.1227 - val_auc: 0.9821 - val_accuracy: 0.9700 - val_cost: 3.5091\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6873 - val_loss: 0.1161 - val_auc: 0.9831 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9927 - accuracy: 0.9791 - cost: 2.7085 - val_loss: 0.1200 - val_auc: 0.9822 - val_accuracy: 0.9700 - val_cost: 3.6328\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9923 - accuracy: 0.9793 - cost: 2.6624 - val_loss: 0.1207 - val_auc: 0.9821 - val_accuracy: 0.9710 - val_cost: 3.3496\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9791 - cost: 2.6996 - val_loss: 0.1178 - val_auc: 0.9828 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6504 - val_loss: 0.1196 - val_auc: 0.9823 - val_accuracy: 0.9701 - val_cost: 3.7858\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7287 - val_loss: 0.1190 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.6035\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6568 - val_loss: 0.1192 - val_auc: 0.9821 - val_accuracy: 0.9703 - val_cost: 3.6230\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6283 - val_loss: 0.1225 - val_auc: 0.9824 - val_accuracy: 0.9697 - val_cost: 3.6263\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.6935 - val_loss: 0.1193 - val_auc: 0.9822 - val_accuracy: 0.9702 - val_cost: 3.8184\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9933 - accuracy: 0.9796 - cost: 2.6400 - val_loss: 0.1187 - val_auc: 0.9826 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6724 - val_loss: 0.1206 - val_auc: 0.9820 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6445 - val_loss: 0.1204 - val_auc: 0.9825 - val_accuracy: 0.9697 - val_cost: 3.8379\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6793 - val_loss: 0.1206 - val_auc: 0.9820 - val_accuracy: 0.9709 - val_cost: 3.5124\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9793 - cost: 2.6778 - val_loss: 0.1203 - val_auc: 0.9830 - val_accuracy: 0.9701 - val_cost: 3.7565\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6985 - val_loss: 0.1218 - val_auc: 0.9824 - val_accuracy: 0.9705 - val_cost: 3.3724\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9801 - cost: 2.5737 - val_loss: 0.1206 - val_auc: 0.9823 - val_accuracy: 0.9707 - val_cost: 3.4277\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9927 - accuracy: 0.9790 - cost: 2.7097 - val_loss: 0.1191 - val_auc: 0.9826 - val_accuracy: 0.9715 - val_cost: 3.5449\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9928 - accuracy: 0.9791 - cost: 2.7071 - val_loss: 0.1158 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.7565\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6396 - val_loss: 0.1200 - val_auc: 0.9827 - val_accuracy: 0.9718 - val_cost: 3.4245\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6635 - val_loss: 0.1196 - val_auc: 0.9832 - val_accuracy: 0.9715 - val_cost: 3.5026\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6871 - val_loss: 0.1221 - val_auc: 0.9826 - val_accuracy: 0.9704 - val_cost: 3.6458\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6261 - val_loss: 0.1177 - val_auc: 0.9835 - val_accuracy: 0.9720 - val_cost: 3.2845\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9924 - accuracy: 0.9796 - cost: 2.6223 - val_loss: 0.1207 - val_auc: 0.9827 - val_accuracy: 0.9710 - val_cost: 3.7337\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9928 - accuracy: 0.9790 - cost: 2.7184 - val_loss: 0.1187 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6363 - val_loss: 0.1202 - val_auc: 0.9826 - val_accuracy: 0.9712 - val_cost: 3.5872\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6783 - val_loss: 0.1185 - val_auc: 0.9829 - val_accuracy: 0.9706 - val_cost: 3.7598\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6468 - val_loss: 0.1190 - val_auc: 0.9825 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6581 - val_loss: 0.1217 - val_auc: 0.9828 - val_accuracy: 0.9708 - val_cost: 3.6361\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5926 - val_loss: 0.1208 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.7174\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.6015 - val_loss: 0.1184 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.5970\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6182 - val_loss: 0.1195 - val_auc: 0.9826 - val_accuracy: 0.9719 - val_cost: 3.5482\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6217 - val_loss: 0.1189 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.5872\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6855 - val_loss: 0.1206 - val_auc: 0.9830 - val_accuracy: 0.9714 - val_cost: 3.5189\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5937 - val_loss: 0.1244 - val_auc: 0.9824 - val_accuracy: 0.9706 - val_cost: 3.6784\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6346 - val_loss: 0.1219 - val_auc: 0.9829 - val_accuracy: 0.9706 - val_cost: 3.5514\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6292 - val_loss: 0.1197 - val_auc: 0.9830 - val_accuracy: 0.9706 - val_cost: 3.6458\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9926 - accuracy: 0.9794 - cost: 2.6590 - val_loss: 0.1194 - val_auc: 0.9830 - val_accuracy: 0.9722 - val_cost: 3.4863\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6592 - val_loss: 0.1203 - val_auc: 0.9832 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9924 - accuracy: 0.9795 - cost: 2.6475 - val_loss: 0.1170 - val_auc: 0.9828 - val_accuracy: 0.9713 - val_cost: 3.5612\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6213 - val_loss: 0.1190 - val_auc: 0.9830 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9931 - accuracy: 0.9797 - cost: 2.6240 - val_loss: 0.1216 - val_auc: 0.9824 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9930 - accuracy: 0.9796 - cost: 2.6406 - val_loss: 0.1218 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.5352\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6064 - val_loss: 0.1206 - val_auc: 0.9827 - val_accuracy: 0.9718 - val_cost: 3.5547\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5932 - val_loss: 0.1196 - val_auc: 0.9826 - val_accuracy: 0.9717 - val_cost: 3.4896\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9930 - accuracy: 0.9796 - cost: 2.6367 - val_loss: 0.1227 - val_auc: 0.9825 - val_accuracy: 0.9701 - val_cost: 3.8444\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5585 - val_loss: 0.1215 - val_auc: 0.9826 - val_accuracy: 0.9716 - val_cost: 3.3626\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9930 - accuracy: 0.9795 - cost: 2.6305 - val_loss: 0.1187 - val_auc: 0.9828 - val_accuracy: 0.9719 - val_cost: 3.5026\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6358 - val_loss: 0.1198 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.5221\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9928 - accuracy: 0.9805 - cost: 2.5250 - val_loss: 0.1207 - val_auc: 0.9835 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9929 - accuracy: 0.9794 - cost: 2.6608 - val_loss: 0.1204 - val_auc: 0.9825 - val_accuracy: 0.9706 - val_cost: 3.6198\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6213 - val_loss: 0.1197 - val_auc: 0.9825 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6187 - val_loss: 0.1203 - val_auc: 0.9826 - val_accuracy: 0.9711 - val_cost: 3.4831\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5966 - val_loss: 0.1204 - val_auc: 0.9827 - val_accuracy: 0.9708 - val_cost: 3.6426\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6386 - val_loss: 0.1204 - val_auc: 0.9826 - val_accuracy: 0.9705 - val_cost: 3.7760\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9797 - cost: 2.6199 - val_loss: 0.1211 - val_auc: 0.9825 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.6040 - val_loss: 0.1185 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.4277\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.6078 - val_loss: 0.1229 - val_auc: 0.9819 - val_accuracy: 0.9699 - val_cost: 3.6523\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6130 - val_loss: 0.1212 - val_auc: 0.9825 - val_accuracy: 0.9720 - val_cost: 3.3789\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5959 - val_loss: 0.1191 - val_auc: 0.9832 - val_accuracy: 0.9712 - val_cost: 3.6784\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6226 - val_loss: 0.1209 - val_auc: 0.9820 - val_accuracy: 0.9716 - val_cost: 3.5221\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9931 - accuracy: 0.9796 - cost: 2.6451 - val_loss: 0.1204 - val_auc: 0.9826 - val_accuracy: 0.9712 - val_cost: 3.7337\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9933 - accuracy: 0.9798 - cost: 2.6037 - val_loss: 0.1223 - val_auc: 0.9819 - val_accuracy: 0.9722 - val_cost: 3.3626\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6223 - val_loss: 0.1238 - val_auc: 0.9812 - val_accuracy: 0.9711 - val_cost: 3.5872\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9932 - accuracy: 0.9798 - cost: 2.6051 - val_loss: 0.1215 - val_auc: 0.9824 - val_accuracy: 0.9716 - val_cost: 3.5319\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9932 - accuracy: 0.9799 - cost: 2.5911 - val_loss: 0.1211 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9930 - accuracy: 0.9804 - cost: 2.5264 - val_loss: 0.1216 - val_auc: 0.9824 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6056 - val_loss: 0.1212 - val_auc: 0.9828 - val_accuracy: 0.9710 - val_cost: 3.5840\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5938 - val_loss: 0.1183 - val_auc: 0.9835 - val_accuracy: 0.9718 - val_cost: 3.5417\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5807 - val_loss: 0.1248 - val_auc: 0.9817 - val_accuracy: 0.9710 - val_cost: 3.5645\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5694 - val_loss: 0.1217 - val_auc: 0.9818 - val_accuracy: 0.9708 - val_cost: 3.6393\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9797 - cost: 2.6392 - val_loss: 0.1216 - val_auc: 0.9822 - val_accuracy: 0.9708 - val_cost: 3.3984\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5900 - val_loss: 0.1210 - val_auc: 0.9828 - val_accuracy: 0.9713 - val_cost: 3.4277\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5708 - val_loss: 0.1215 - val_auc: 0.9827 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6020 - val_loss: 0.1221 - val_auc: 0.9826 - val_accuracy: 0.9724 - val_cost: 3.2454\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5934 - val_loss: 0.1212 - val_auc: 0.9825 - val_accuracy: 0.9708 - val_cost: 3.4180\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.5958 - val_loss: 0.1228 - val_auc: 0.9826 - val_accuracy: 0.9713 - val_cost: 3.5254\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9932 - accuracy: 0.9799 - cost: 2.6006 - val_loss: 0.1213 - val_auc: 0.9822 - val_accuracy: 0.9712 - val_cost: 3.5091\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9936 - accuracy: 0.9804 - cost: 2.5302 - val_loss: 0.1207 - val_auc: 0.9829 - val_accuracy: 0.9722 - val_cost: 3.4245\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5797 - val_loss: 0.1206 - val_auc: 0.9821 - val_accuracy: 0.9708 - val_cost: 3.3496\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5519 - val_loss: 0.1231 - val_auc: 0.9825 - val_accuracy: 0.9705 - val_cost: 3.4701\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0708 - auc: 0.9931 - accuracy: 0.9796 - cost: 2.6266 - val_loss: 0.1228 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.6914\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9932 - accuracy: 0.9799 - cost: 2.6125 - val_loss: 0.1227 - val_auc: 0.9825 - val_accuracy: 0.9706 - val_cost: 3.6556\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9930 - accuracy: 0.9801 - cost: 2.5714 - val_loss: 0.1234 - val_auc: 0.9832 - val_accuracy: 0.9713 - val_cost: 3.5124\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6104 - val_loss: 0.1214 - val_auc: 0.9825 - val_accuracy: 0.9720 - val_cost: 3.2943\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5271 - val_loss: 0.1226 - val_auc: 0.9828 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5957 - val_loss: 0.1244 - val_auc: 0.9825 - val_accuracy: 0.9703 - val_cost: 3.5905\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5334 - val_loss: 0.1220 - val_auc: 0.9820 - val_accuracy: 0.9711 - val_cost: 3.3789\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9934 - accuracy: 0.9798 - cost: 2.5970 - val_loss: 0.1258 - val_auc: 0.9819 - val_accuracy: 0.9715 - val_cost: 3.3073\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9932 - accuracy: 0.9795 - cost: 2.6580 - val_loss: 0.1240 - val_auc: 0.9819 - val_accuracy: 0.9715 - val_cost: 3.3040\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9930 - accuracy: 0.9805 - cost: 2.5090 - val_loss: 0.1209 - val_auc: 0.9823 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9936 - accuracy: 0.9801 - cost: 2.5575 - val_loss: 0.1242 - val_auc: 0.9817 - val_accuracy: 0.9712 - val_cost: 3.5677\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5693 - val_loss: 0.1230 - val_auc: 0.9818 - val_accuracy: 0.9708 - val_cost: 3.7565\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9931 - accuracy: 0.9796 - cost: 2.6350 - val_loss: 0.1238 - val_auc: 0.9815 - val_accuracy: 0.9712 - val_cost: 3.5742\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5975 - val_loss: 0.1251 - val_auc: 0.9822 - val_accuracy: 0.9710 - val_cost: 3.6426\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9934 - accuracy: 0.9801 - cost: 2.5753 - val_loss: 0.1239 - val_auc: 0.9825 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5490 - val_loss: 0.1238 - val_auc: 0.9821 - val_accuracy: 0.9703 - val_cost: 3.5612\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9934 - accuracy: 0.9802 - cost: 2.5657 - val_loss: 0.1215 - val_auc: 0.9825 - val_accuracy: 0.9715 - val_cost: 3.3691\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5839 - val_loss: 0.1238 - val_auc: 0.9813 - val_accuracy: 0.9714 - val_cost: 3.3724\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5592 - val_loss: 0.1189 - val_auc: 0.9826 - val_accuracy: 0.9728 - val_cost: 3.4993\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5372 - val_loss: 0.1223 - val_auc: 0.9818 - val_accuracy: 0.9717 - val_cost: 3.6230\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5786 - val_loss: 0.1249 - val_auc: 0.9815 - val_accuracy: 0.9711 - val_cost: 3.5677\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9930 - accuracy: 0.9801 - cost: 2.5714 - val_loss: 0.1220 - val_auc: 0.9824 - val_accuracy: 0.9718 - val_cost: 3.6719\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5624 - val_loss: 0.1222 - val_auc: 0.9817 - val_accuracy: 0.9722 - val_cost: 3.6296\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5482 - val_loss: 0.1211 - val_auc: 0.9829 - val_accuracy: 0.9712 - val_cost: 3.4017\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5346 - val_loss: 0.1232 - val_auc: 0.9819 - val_accuracy: 0.9714 - val_cost: 3.3366\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9936 - accuracy: 0.9803 - cost: 2.5519 - val_loss: 0.1241 - val_auc: 0.9819 - val_accuracy: 0.9711 - val_cost: 3.5091\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5372 - val_loss: 0.1231 - val_auc: 0.9817 - val_accuracy: 0.9710 - val_cost: 3.4408\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5831 - val_loss: 0.1231 - val_auc: 0.9820 - val_accuracy: 0.9718 - val_cost: 3.2780\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5344 - val_loss: 0.1224 - val_auc: 0.9829 - val_accuracy: 0.9705 - val_cost: 3.5026\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5493 - val_loss: 0.1256 - val_auc: 0.9822 - val_accuracy: 0.9714 - val_cost: 3.3659\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5355 - val_loss: 0.1228 - val_auc: 0.9826 - val_accuracy: 0.9726 - val_cost: 3.5221\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9794 - cost: 2.6522 - val_loss: 0.1226 - val_auc: 0.9823 - val_accuracy: 0.9714 - val_cost: 3.4310\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5577 - val_loss: 0.1277 - val_auc: 0.9819 - val_accuracy: 0.9697 - val_cost: 3.6426\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5962 - val_loss: 0.1241 - val_auc: 0.9823 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5174 - val_loss: 0.1254 - val_auc: 0.9824 - val_accuracy: 0.9714 - val_cost: 3.4082\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9935 - accuracy: 0.9802 - cost: 2.5609 - val_loss: 0.1239 - val_auc: 0.9822 - val_accuracy: 0.9713 - val_cost: 3.4082\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9932 - accuracy: 0.9806 - cost: 2.5079 - val_loss: 0.1258 - val_auc: 0.9817 - val_accuracy: 0.9706 - val_cost: 3.6068\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9938 - accuracy: 0.9803 - cost: 2.5521 - val_loss: 0.1243 - val_auc: 0.9821 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5643 - val_loss: 0.1242 - val_auc: 0.9823 - val_accuracy: 0.9706 - val_cost: 3.6654\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5898 - val_loss: 0.1248 - val_auc: 0.9815 - val_accuracy: 0.9698 - val_cost: 3.7305\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5512 - val_loss: 0.1229 - val_auc: 0.9818 - val_accuracy: 0.9711 - val_cost: 3.7402\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4722 - val_loss: 0.1242 - val_auc: 0.9816 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5580 - val_loss: 0.1250 - val_auc: 0.9818 - val_accuracy: 0.9711 - val_cost: 3.3952\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5246 - val_loss: 0.1258 - val_auc: 0.9817 - val_accuracy: 0.9717 - val_cost: 3.4440\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9935 - accuracy: 0.9811 - cost: 2.4425 - val_loss: 0.1249 - val_auc: 0.9817 - val_accuracy: 0.9717 - val_cost: 3.2845\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9932 - accuracy: 0.9805 - cost: 2.5136 - val_loss: 0.1271 - val_auc: 0.9821 - val_accuracy: 0.9703 - val_cost: 3.6784\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4890 - val_loss: 0.1241 - val_auc: 0.9821 - val_accuracy: 0.9714 - val_cost: 3.6849\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5634 - val_loss: 0.1230 - val_auc: 0.9824 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5206 - val_loss: 0.1222 - val_auc: 0.9827 - val_accuracy: 0.9716 - val_cost: 3.3919\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9800 - cost: 2.5834 - val_loss: 0.1254 - val_auc: 0.9821 - val_accuracy: 0.9712 - val_cost: 3.5742\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9935 - accuracy: 0.9800 - cost: 2.5927 - val_loss: 0.1245 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.6686\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9936 - accuracy: 0.9801 - cost: 2.5720 - val_loss: 0.1230 - val_auc: 0.9825 - val_accuracy: 0.9718 - val_cost: 3.2943\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5389 - val_loss: 0.1228 - val_auc: 0.9821 - val_accuracy: 0.9721 - val_cost: 3.3268\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5175 - val_loss: 0.1256 - val_auc: 0.9824 - val_accuracy: 0.9707 - val_cost: 3.4831\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5114 - val_loss: 0.1255 - val_auc: 0.9814 - val_accuracy: 0.9718 - val_cost: 3.2878\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9806 - cost: 2.5072 - val_loss: 0.1248 - val_auc: 0.9817 - val_accuracy: 0.9718 - val_cost: 3.3203\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5214 - val_loss: 0.1280 - val_auc: 0.9818 - val_accuracy: 0.9710 - val_cost: 3.5124\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9934 - accuracy: 0.9809 - cost: 2.4778 - val_loss: 0.1238 - val_auc: 0.9820 - val_accuracy: 0.9722 - val_cost: 3.2845\n",
            "Epoch 361/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4603 - val_loss: 0.1266 - val_auc: 0.9816 - val_accuracy: 0.9722 - val_cost: 3.3398\n",
            "Epoch 362/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9935 - accuracy: 0.9807 - cost: 2.4971 - val_loss: 0.1276 - val_auc: 0.9820 - val_accuracy: 0.9710 - val_cost: 3.4538\n",
            "Epoch 363/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5316 - val_loss: 0.1275 - val_auc: 0.9808 - val_accuracy: 0.9707 - val_cost: 3.4082\n",
            "Epoch 364/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5026 - val_loss: 0.1241 - val_auc: 0.9819 - val_accuracy: 0.9720 - val_cost: 3.6458\n",
            "Epoch 365/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9939 - accuracy: 0.9809 - cost: 2.4649 - val_loss: 0.1248 - val_auc: 0.9814 - val_accuracy: 0.9709 - val_cost: 3.7109\n",
            "Epoch 366/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4848 - val_loss: 0.1243 - val_auc: 0.9820 - val_accuracy: 0.9714 - val_cost: 3.3887\n",
            "Epoch 367/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5406 - val_loss: 0.1251 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.6263\n",
            "Epoch 368/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9938 - accuracy: 0.9808 - cost: 2.4915 - val_loss: 0.1276 - val_auc: 0.9815 - val_accuracy: 0.9712 - val_cost: 3.4180\n",
            "Epoch 369/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4703 - val_loss: 0.1276 - val_auc: 0.9813 - val_accuracy: 0.9721 - val_cost: 3.3691\n",
            "Epoch 370/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9933 - accuracy: 0.9808 - cost: 2.4661 - val_loss: 0.1238 - val_auc: 0.9822 - val_accuracy: 0.9710 - val_cost: 3.5319\n",
            "Epoch 371/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9937 - accuracy: 0.9812 - cost: 2.4388 - val_loss: 0.1272 - val_auc: 0.9816 - val_accuracy: 0.9712 - val_cost: 3.3757\n",
            "Epoch 372/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5354 - val_loss: 0.1254 - val_auc: 0.9822 - val_accuracy: 0.9717 - val_cost: 3.5417\n",
            "Epoch 373/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5550 - val_loss: 0.1246 - val_auc: 0.9819 - val_accuracy: 0.9715 - val_cost: 3.3594\n",
            "Epoch 374/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4161 - val_loss: 0.1264 - val_auc: 0.9822 - val_accuracy: 0.9712 - val_cost: 3.3431\n",
            "Epoch 375/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9937 - accuracy: 0.9807 - cost: 2.5104 - val_loss: 0.1274 - val_auc: 0.9818 - val_accuracy: 0.9707 - val_cost: 3.3919\n",
            "Epoch 376/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5353 - val_loss: 0.1270 - val_auc: 0.9812 - val_accuracy: 0.9714 - val_cost: 3.3073\n",
            "Epoch 377/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5261 - val_loss: 0.1240 - val_auc: 0.9812 - val_accuracy: 0.9714 - val_cost: 3.7207\n",
            "Epoch 378/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4821 - val_loss: 0.1291 - val_auc: 0.9816 - val_accuracy: 0.9709 - val_cost: 3.3464\n",
            "Epoch 379/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5099 - val_loss: 0.1286 - val_auc: 0.9813 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 380/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5146 - val_loss: 0.1273 - val_auc: 0.9813 - val_accuracy: 0.9710 - val_cost: 3.3659\n",
            "Epoch 381/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4624 - val_loss: 0.1292 - val_auc: 0.9802 - val_accuracy: 0.9703 - val_cost: 3.4310\n",
            "Epoch 382/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5148 - val_loss: 0.1260 - val_auc: 0.9814 - val_accuracy: 0.9701 - val_cost: 3.5840\n",
            "Epoch 383/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5494 - val_loss: 0.1283 - val_auc: 0.9810 - val_accuracy: 0.9710 - val_cost: 3.3691\n",
            "Epoch 384/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9939 - accuracy: 0.9807 - cost: 2.4978 - val_loss: 0.1258 - val_auc: 0.9818 - val_accuracy: 0.9712 - val_cost: 3.4635\n",
            "Epoch 385/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5028 - val_loss: 0.1258 - val_auc: 0.9826 - val_accuracy: 0.9720 - val_cost: 3.3268\n",
            "Epoch 386/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9937 - accuracy: 0.9809 - cost: 2.4742 - val_loss: 0.1253 - val_auc: 0.9813 - val_accuracy: 0.9699 - val_cost: 3.7760\n",
            "Epoch 387/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5216 - val_loss: 0.1279 - val_auc: 0.9814 - val_accuracy: 0.9711 - val_cost: 3.4766\n",
            "Epoch 388/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4616 - val_loss: 0.1248 - val_auc: 0.9820 - val_accuracy: 0.9717 - val_cost: 3.5807\n",
            "Epoch 389/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5493 - val_loss: 0.1271 - val_auc: 0.9820 - val_accuracy: 0.9716 - val_cost: 3.7077\n",
            "Epoch 390/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.5034 - val_loss: 0.1272 - val_auc: 0.9818 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 391/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9937 - accuracy: 0.9809 - cost: 2.4706 - val_loss: 0.1256 - val_auc: 0.9824 - val_accuracy: 0.9715 - val_cost: 3.5807\n",
            "Epoch 392/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4703 - val_loss: 0.1286 - val_auc: 0.9816 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 393/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5204 - val_loss: 0.1262 - val_auc: 0.9820 - val_accuracy: 0.9715 - val_cost: 3.5254\n",
            "Epoch 394/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9937 - accuracy: 0.9807 - cost: 2.5018 - val_loss: 0.1284 - val_auc: 0.9811 - val_accuracy: 0.9706 - val_cost: 3.4896\n",
            "Epoch 395/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9937 - accuracy: 0.9809 - cost: 2.4598 - val_loss: 0.1275 - val_auc: 0.9822 - val_accuracy: 0.9714 - val_cost: 3.3952\n",
            "Epoch 396/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9937 - accuracy: 0.9806 - cost: 2.5086 - val_loss: 0.1260 - val_auc: 0.9815 - val_accuracy: 0.9726 - val_cost: 3.2161\n",
            "Epoch 397/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5104 - val_loss: 0.1262 - val_auc: 0.9817 - val_accuracy: 0.9716 - val_cost: 3.3431\n",
            "Epoch 398/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5149 - val_loss: 0.1254 - val_auc: 0.9816 - val_accuracy: 0.9716 - val_cost: 3.3008\n",
            "Epoch 399/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9935 - accuracy: 0.9807 - cost: 2.4938 - val_loss: 0.1275 - val_auc: 0.9816 - val_accuracy: 0.9720 - val_cost: 3.2585\n",
            "Epoch 400/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9933 - accuracy: 0.9809 - cost: 2.4693 - val_loss: 0.1277 - val_auc: 0.9816 - val_accuracy: 0.9709 - val_cost: 3.5612\n",
            "Epoch 401/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9936 - accuracy: 0.9803 - cost: 2.5414 - val_loss: 0.1285 - val_auc: 0.9815 - val_accuracy: 0.9717 - val_cost: 3.3366\n",
            "Epoch 402/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9935 - accuracy: 0.9809 - cost: 2.4677 - val_loss: 0.1254 - val_auc: 0.9812 - val_accuracy: 0.9712 - val_cost: 3.5905\n",
            "Epoch 403/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9939 - accuracy: 0.9807 - cost: 2.4949 - val_loss: 0.1286 - val_auc: 0.9813 - val_accuracy: 0.9713 - val_cost: 3.5710\n",
            "Epoch 404/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4721 - val_loss: 0.1291 - val_auc: 0.9807 - val_accuracy: 0.9707 - val_cost: 3.4147\n",
            "Epoch 405/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9936 - accuracy: 0.9804 - cost: 2.5417 - val_loss: 0.1287 - val_auc: 0.9816 - val_accuracy: 0.9710 - val_cost: 3.3724\n",
            "Epoch 406/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5179 - val_loss: 0.1294 - val_auc: 0.9813 - val_accuracy: 0.9701 - val_cost: 3.7663\n",
            "Epoch 407/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9939 - accuracy: 0.9810 - cost: 2.4729 - val_loss: 0.1304 - val_auc: 0.9808 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "Epoch 408/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4532 - val_loss: 0.1266 - val_auc: 0.9812 - val_accuracy: 0.9717 - val_cost: 3.3529\n",
            "Epoch 409/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9807 - cost: 2.5012 - val_loss: 0.1286 - val_auc: 0.9814 - val_accuracy: 0.9713 - val_cost: 3.3626\n",
            "Epoch 410/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.5006 - val_loss: 0.1258 - val_auc: 0.9813 - val_accuracy: 0.9723 - val_cost: 3.4245\n",
            "Epoch 411/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5205 - val_loss: 0.1279 - val_auc: 0.9817 - val_accuracy: 0.9708 - val_cost: 3.5677\n",
            "Epoch 412/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4720 - val_loss: 0.1290 - val_auc: 0.9813 - val_accuracy: 0.9717 - val_cost: 3.4603\n",
            "Epoch 413/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9938 - accuracy: 0.9805 - cost: 2.5225 - val_loss: 0.1270 - val_auc: 0.9822 - val_accuracy: 0.9703 - val_cost: 3.5872\n",
            "Epoch 414/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.5079 - val_loss: 0.1299 - val_auc: 0.9817 - val_accuracy: 0.9705 - val_cost: 3.6198\n",
            "Epoch 415/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4712 - val_loss: 0.1253 - val_auc: 0.9820 - val_accuracy: 0.9710 - val_cost: 3.6361\n",
            "Epoch 416/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9936 - accuracy: 0.9811 - cost: 2.4514 - val_loss: 0.1274 - val_auc: 0.9817 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 417/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5318 - val_loss: 0.1273 - val_auc: 0.9819 - val_accuracy: 0.9715 - val_cost: 3.4863\n",
            "Epoch 418/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9937 - accuracy: 0.9812 - cost: 2.4385 - val_loss: 0.1279 - val_auc: 0.9813 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 419/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9934 - accuracy: 0.9810 - cost: 2.4552 - val_loss: 0.1296 - val_auc: 0.9813 - val_accuracy: 0.9706 - val_cost: 3.6263\n",
            "Epoch 420/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9939 - accuracy: 0.9813 - cost: 2.4132 - val_loss: 0.1283 - val_auc: 0.9809 - val_accuracy: 0.9694 - val_cost: 3.9095\n",
            "Epoch 421/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9938 - accuracy: 0.9809 - cost: 2.4634 - val_loss: 0.1275 - val_auc: 0.9810 - val_accuracy: 0.9709 - val_cost: 3.5905\n",
            "Epoch 422/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4945 - val_loss: 0.1282 - val_auc: 0.9817 - val_accuracy: 0.9714 - val_cost: 3.4017\n",
            "Epoch 423/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9937 - accuracy: 0.9811 - cost: 2.4374 - val_loss: 0.1298 - val_auc: 0.9811 - val_accuracy: 0.9704 - val_cost: 3.6198\n",
            "Epoch 424/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4995 - val_loss: 0.1299 - val_auc: 0.9808 - val_accuracy: 0.9708 - val_cost: 3.4570\n",
            "Epoch 425/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9934 - accuracy: 0.9814 - cost: 2.4044 - val_loss: 0.1275 - val_auc: 0.9812 - val_accuracy: 0.9708 - val_cost: 3.4635\n",
            "Epoch 426/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9940 - accuracy: 0.9809 - cost: 2.4734 - val_loss: 0.1284 - val_auc: 0.9810 - val_accuracy: 0.9704 - val_cost: 3.6849\n",
            "Epoch 427/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.5156 - val_loss: 0.1282 - val_auc: 0.9808 - val_accuracy: 0.9710 - val_cost: 3.5059\n",
            "Epoch 428/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9940 - accuracy: 0.9814 - cost: 2.4081 - val_loss: 0.1290 - val_auc: 0.9813 - val_accuracy: 0.9708 - val_cost: 3.4961\n",
            "Epoch 429/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4787 - val_loss: 0.1304 - val_auc: 0.9805 - val_accuracy: 0.9708 - val_cost: 3.6361\n",
            "Epoch 430/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9935 - accuracy: 0.9808 - cost: 2.4972 - val_loss: 0.1305 - val_auc: 0.9805 - val_accuracy: 0.9705 - val_cost: 3.5026\n",
            "Epoch 431/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4681 - val_loss: 0.1294 - val_auc: 0.9815 - val_accuracy: 0.9710 - val_cost: 3.5221\n",
            "Epoch 432/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4456 - val_loss: 0.1319 - val_auc: 0.9810 - val_accuracy: 0.9695 - val_cost: 3.5254\n",
            "Epoch 433/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9941 - accuracy: 0.9808 - cost: 2.4827 - val_loss: 0.1313 - val_auc: 0.9806 - val_accuracy: 0.9715 - val_cost: 3.5124\n",
            "Epoch 434/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9936 - accuracy: 0.9805 - cost: 2.5213 - val_loss: 0.1292 - val_auc: 0.9816 - val_accuracy: 0.9701 - val_cost: 3.6035\n",
            "Epoch 435/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9941 - accuracy: 0.9810 - cost: 2.4559 - val_loss: 0.1292 - val_auc: 0.9814 - val_accuracy: 0.9719 - val_cost: 3.4635\n",
            "Epoch 436/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9938 - accuracy: 0.9807 - cost: 2.5033 - val_loss: 0.1297 - val_auc: 0.9814 - val_accuracy: 0.9711 - val_cost: 3.3854\n",
            "Epoch 437/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0667 - auc: 0.9939 - accuracy: 0.9807 - cost: 2.5139 - val_loss: 0.1284 - val_auc: 0.9820 - val_accuracy: 0.9710 - val_cost: 3.4408\n",
            "Epoch 438/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9937 - accuracy: 0.9806 - cost: 2.5028 - val_loss: 0.1310 - val_auc: 0.9811 - val_accuracy: 0.9713 - val_cost: 3.3952\n",
            "Epoch 439/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4995 - val_loss: 0.1301 - val_auc: 0.9811 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 440/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9808 - cost: 2.4879 - val_loss: 0.1292 - val_auc: 0.9814 - val_accuracy: 0.9713 - val_cost: 3.6068\n",
            "Epoch 441/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9806 - cost: 2.5130 - val_loss: 0.1313 - val_auc: 0.9811 - val_accuracy: 0.9703 - val_cost: 3.6100\n",
            "Epoch 442/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9938 - accuracy: 0.9811 - cost: 2.4496 - val_loss: 0.1304 - val_auc: 0.9814 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 443/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4604 - val_loss: 0.1279 - val_auc: 0.9816 - val_accuracy: 0.9713 - val_cost: 3.5579\n",
            "Epoch 444/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9938 - accuracy: 0.9808 - cost: 2.4900 - val_loss: 0.1267 - val_auc: 0.9816 - val_accuracy: 0.9713 - val_cost: 3.7337\n",
            "Epoch 445/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9936 - accuracy: 0.9810 - cost: 2.4665 - val_loss: 0.1296 - val_auc: 0.9811 - val_accuracy: 0.9717 - val_cost: 3.4505\n",
            "Epoch 446/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4674 - val_loss: 0.1292 - val_auc: 0.9812 - val_accuracy: 0.9706 - val_cost: 3.6003\n",
            "Epoch 447/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4354 - val_loss: 0.1280 - val_auc: 0.9816 - val_accuracy: 0.9703 - val_cost: 3.7630\n",
            "Epoch 448/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9939 - accuracy: 0.9808 - cost: 2.4804 - val_loss: 0.1276 - val_auc: 0.9827 - val_accuracy: 0.9710 - val_cost: 3.6165\n",
            "Epoch 449/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.3958 - val_loss: 0.1326 - val_auc: 0.9810 - val_accuracy: 0.9707 - val_cost: 3.7923\n",
            "Epoch 450/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9937 - accuracy: 0.9806 - cost: 2.5201 - val_loss: 0.1284 - val_auc: 0.9813 - val_accuracy: 0.9700 - val_cost: 3.5612\n",
            "Epoch 451/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9937 - accuracy: 0.9807 - cost: 2.4888 - val_loss: 0.1302 - val_auc: 0.9817 - val_accuracy: 0.9715 - val_cost: 3.3952\n",
            "Epoch 452/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4403 - val_loss: 0.1291 - val_auc: 0.9817 - val_accuracy: 0.9708 - val_cost: 3.4635\n",
            "Epoch 453/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4092 - val_loss: 0.1330 - val_auc: 0.9803 - val_accuracy: 0.9699 - val_cost: 3.5059\n",
            "Epoch 454/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9937 - accuracy: 0.9809 - cost: 2.4793 - val_loss: 0.1287 - val_auc: 0.9815 - val_accuracy: 0.9709 - val_cost: 3.4212\n",
            "Epoch 455/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9940 - accuracy: 0.9816 - cost: 2.3836 - val_loss: 0.1317 - val_auc: 0.9818 - val_accuracy: 0.9705 - val_cost: 3.4798\n",
            "Epoch 456/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9938 - accuracy: 0.9805 - cost: 2.5207 - val_loss: 0.1310 - val_auc: 0.9802 - val_accuracy: 0.9717 - val_cost: 3.2943\n",
            "Epoch 457/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9937 - accuracy: 0.9813 - cost: 2.4304 - val_loss: 0.1312 - val_auc: 0.9811 - val_accuracy: 0.9703 - val_cost: 3.4668\n",
            "Epoch 458/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9936 - accuracy: 0.9812 - cost: 2.4357 - val_loss: 0.1282 - val_auc: 0.9812 - val_accuracy: 0.9706 - val_cost: 3.6523\n",
            "Epoch 459/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9936 - accuracy: 0.9806 - cost: 2.5022 - val_loss: 0.1294 - val_auc: 0.9802 - val_accuracy: 0.9700 - val_cost: 3.5579\n",
            "Epoch 460/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0668 - auc: 0.9939 - accuracy: 0.9806 - cost: 2.5237 - val_loss: 0.1306 - val_auc: 0.9813 - val_accuracy: 0.9711 - val_cost: 3.6296\n",
            "Epoch 461/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0657 - auc: 0.9940 - accuracy: 0.9811 - cost: 2.4570 - val_loss: 0.1314 - val_auc: 0.9805 - val_accuracy: 0.9712 - val_cost: 3.6165\n",
            "Epoch 462/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9940 - accuracy: 0.9814 - cost: 2.3941 - val_loss: 0.1303 - val_auc: 0.9806 - val_accuracy: 0.9713 - val_cost: 3.3659\n",
            "Epoch 463/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9939 - accuracy: 0.9809 - cost: 2.4650 - val_loss: 0.1299 - val_auc: 0.9812 - val_accuracy: 0.9709 - val_cost: 3.5970\n",
            "Epoch 464/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9939 - accuracy: 0.9809 - cost: 2.4844 - val_loss: 0.1306 - val_auc: 0.9807 - val_accuracy: 0.9710 - val_cost: 3.5807\n",
            "Epoch 465/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9938 - accuracy: 0.9805 - cost: 2.5246 - val_loss: 0.1311 - val_auc: 0.9810 - val_accuracy: 0.9701 - val_cost: 3.4538\n",
            "Epoch 466/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9940 - accuracy: 0.9806 - cost: 2.4948 - val_loss: 0.1289 - val_auc: 0.9815 - val_accuracy: 0.9712 - val_cost: 3.5189\n",
            "Epoch 467/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9936 - accuracy: 0.9805 - cost: 2.5221 - val_loss: 0.1321 - val_auc: 0.9807 - val_accuracy: 0.9699 - val_cost: 3.6393\n",
            "Epoch 468/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9940 - accuracy: 0.9807 - cost: 2.5010 - val_loss: 0.1331 - val_auc: 0.9810 - val_accuracy: 0.9713 - val_cost: 3.3887\n",
            "Epoch 469/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9937 - accuracy: 0.9808 - cost: 2.4890 - val_loss: 0.1326 - val_auc: 0.9807 - val_accuracy: 0.9700 - val_cost: 3.7272\n",
            "Epoch 470/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9940 - accuracy: 0.9813 - cost: 2.4271 - val_loss: 0.1308 - val_auc: 0.9811 - val_accuracy: 0.9706 - val_cost: 3.6068\n",
            "Epoch 471/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4710 - val_loss: 0.1280 - val_auc: 0.9816 - val_accuracy: 0.9715 - val_cost: 3.5254\n",
            "Epoch 472/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4422 - val_loss: 0.1326 - val_auc: 0.9805 - val_accuracy: 0.9709 - val_cost: 3.5938\n",
            "Epoch 473/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9938 - accuracy: 0.9811 - cost: 2.4578 - val_loss: 0.1318 - val_auc: 0.9812 - val_accuracy: 0.9712 - val_cost: 3.6100\n",
            "Epoch 474/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9937 - accuracy: 0.9810 - cost: 2.4667 - val_loss: 0.1310 - val_auc: 0.9805 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 475/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9939 - accuracy: 0.9807 - cost: 2.5086 - val_loss: 0.1297 - val_auc: 0.9803 - val_accuracy: 0.9712 - val_cost: 3.5612\n",
            "Epoch 476/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9940 - accuracy: 0.9814 - cost: 2.4108 - val_loss: 0.1315 - val_auc: 0.9813 - val_accuracy: 0.9717 - val_cost: 3.3008\n",
            "Epoch 477/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9939 - accuracy: 0.9810 - cost: 2.4626 - val_loss: 0.1316 - val_auc: 0.9809 - val_accuracy: 0.9718 - val_cost: 3.5059\n",
            "Epoch 478/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9940 - accuracy: 0.9812 - cost: 2.4381 - val_loss: 0.1292 - val_auc: 0.9816 - val_accuracy: 0.9718 - val_cost: 3.3626\n",
            "Epoch 479/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9942 - accuracy: 0.9815 - cost: 2.3920 - val_loss: 0.1288 - val_auc: 0.9812 - val_accuracy: 0.9715 - val_cost: 3.3984\n",
            "Epoch 480/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9938 - accuracy: 0.9809 - cost: 2.4774 - val_loss: 0.1316 - val_auc: 0.9817 - val_accuracy: 0.9715 - val_cost: 3.5384\n",
            "Epoch 481/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9938 - accuracy: 0.9811 - cost: 2.4639 - val_loss: 0.1318 - val_auc: 0.9808 - val_accuracy: 0.9708 - val_cost: 3.5938\n",
            "Epoch 482/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9938 - accuracy: 0.9810 - cost: 2.4691 - val_loss: 0.1305 - val_auc: 0.9813 - val_accuracy: 0.9716 - val_cost: 3.5124\n",
            "Epoch 483/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9940 - accuracy: 0.9814 - cost: 2.4086 - val_loss: 0.1310 - val_auc: 0.9814 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 484/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9940 - accuracy: 0.9812 - cost: 2.4327 - val_loss: 0.1311 - val_auc: 0.9812 - val_accuracy: 0.9719 - val_cost: 3.3203\n",
            "Epoch 485/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4608 - val_loss: 0.1316 - val_auc: 0.9806 - val_accuracy: 0.9712 - val_cost: 3.4049\n",
            "Epoch 486/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9939 - accuracy: 0.9815 - cost: 2.4085 - val_loss: 0.1324 - val_auc: 0.9803 - val_accuracy: 0.9710 - val_cost: 3.3952\n",
            "Epoch 487/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4176 - val_loss: 0.1298 - val_auc: 0.9811 - val_accuracy: 0.9719 - val_cost: 3.3333\n",
            "Epoch 488/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4311 - val_loss: 0.1338 - val_auc: 0.9813 - val_accuracy: 0.9710 - val_cost: 3.4017\n",
            "Epoch 489/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9941 - accuracy: 0.9808 - cost: 2.4919 - val_loss: 0.1322 - val_auc: 0.9807 - val_accuracy: 0.9716 - val_cost: 3.3138\n",
            "Epoch 490/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9940 - accuracy: 0.9811 - cost: 2.4406 - val_loss: 0.1315 - val_auc: 0.9807 - val_accuracy: 0.9706 - val_cost: 3.4180\n",
            "Epoch 491/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3941 - val_loss: 0.1314 - val_auc: 0.9817 - val_accuracy: 0.9707 - val_cost: 3.5026\n",
            "Epoch 492/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4236 - val_loss: 0.1313 - val_auc: 0.9816 - val_accuracy: 0.9711 - val_cost: 3.4310\n",
            "Epoch 493/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9937 - accuracy: 0.9813 - cost: 2.4213 - val_loss: 0.1312 - val_auc: 0.9807 - val_accuracy: 0.9708 - val_cost: 3.4277\n",
            "Epoch 494/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4352 - val_loss: 0.1352 - val_auc: 0.9811 - val_accuracy: 0.9709 - val_cost: 3.3854\n",
            "Epoch 495/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9942 - accuracy: 0.9814 - cost: 2.4038 - val_loss: 0.1300 - val_auc: 0.9809 - val_accuracy: 0.9711 - val_cost: 3.4603\n",
            "Epoch 496/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9941 - accuracy: 0.9814 - cost: 2.4118 - val_loss: 0.1337 - val_auc: 0.9806 - val_accuracy: 0.9706 - val_cost: 3.4635\n",
            "Epoch 497/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9940 - accuracy: 0.9819 - cost: 2.3547 - val_loss: 0.1342 - val_auc: 0.9808 - val_accuracy: 0.9687 - val_cost: 3.6491\n",
            "Epoch 498/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9938 - accuracy: 0.9811 - cost: 2.4578 - val_loss: 0.1293 - val_auc: 0.9814 - val_accuracy: 0.9705 - val_cost: 3.6556\n",
            "Epoch 499/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4552 - val_loss: 0.1309 - val_auc: 0.9800 - val_accuracy: 0.9699 - val_cost: 3.6426\n",
            "Epoch 500/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9936 - accuracy: 0.9812 - cost: 2.4458 - val_loss: 0.1316 - val_auc: 0.9808 - val_accuracy: 0.9710 - val_cost: 3.4538\n",
            "Epoch 501/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9940 - accuracy: 0.9812 - cost: 2.4355 - val_loss: 0.1313 - val_auc: 0.9811 - val_accuracy: 0.9706 - val_cost: 3.7174\n",
            "Epoch 502/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4049 - val_loss: 0.1310 - val_auc: 0.9806 - val_accuracy: 0.9712 - val_cost: 3.3398\n",
            "Epoch 503/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9940 - accuracy: 0.9816 - cost: 2.3820 - val_loss: 0.1311 - val_auc: 0.9814 - val_accuracy: 0.9711 - val_cost: 3.4147\n",
            "Epoch 504/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9941 - accuracy: 0.9816 - cost: 2.3869 - val_loss: 0.1328 - val_auc: 0.9814 - val_accuracy: 0.9707 - val_cost: 3.5286\n",
            "Epoch 505/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4009 - val_loss: 0.1300 - val_auc: 0.9810 - val_accuracy: 0.9712 - val_cost: 3.4798\n",
            "Epoch 506/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9939 - accuracy: 0.9813 - cost: 2.4343 - val_loss: 0.1318 - val_auc: 0.9812 - val_accuracy: 0.9715 - val_cost: 3.3919\n",
            "Epoch 507/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0648 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3827 - val_loss: 0.1305 - val_auc: 0.9805 - val_accuracy: 0.9714 - val_cost: 3.4863\n",
            "Epoch 508/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9940 - accuracy: 0.9810 - cost: 2.4676 - val_loss: 0.1321 - val_auc: 0.9813 - val_accuracy: 0.9710 - val_cost: 3.6003\n",
            "Epoch 509/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9940 - accuracy: 0.9814 - cost: 2.4095 - val_loss: 0.1298 - val_auc: 0.9812 - val_accuracy: 0.9709 - val_cost: 3.7598\n",
            "Epoch 510/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9941 - accuracy: 0.9811 - cost: 2.4494 - val_loss: 0.1356 - val_auc: 0.9810 - val_accuracy: 0.9707 - val_cost: 3.4017\n",
            "Epoch 511/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9941 - accuracy: 0.9818 - cost: 2.3655 - val_loss: 0.1306 - val_auc: 0.9814 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 512/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4396 - val_loss: 0.1345 - val_auc: 0.9805 - val_accuracy: 0.9719 - val_cost: 3.3431\n",
            "Epoch 513/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4569 - val_loss: 0.1330 - val_auc: 0.9810 - val_accuracy: 0.9719 - val_cost: 3.3398\n",
            "Epoch 514/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9943 - accuracy: 0.9814 - cost: 2.4092 - val_loss: 0.1341 - val_auc: 0.9808 - val_accuracy: 0.9704 - val_cost: 3.5189\n",
            "Epoch 515/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9940 - accuracy: 0.9811 - cost: 2.4532 - val_loss: 0.1312 - val_auc: 0.9806 - val_accuracy: 0.9711 - val_cost: 3.4375\n",
            "Epoch 516/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9939 - accuracy: 0.9815 - cost: 2.3939 - val_loss: 0.1328 - val_auc: 0.9808 - val_accuracy: 0.9715 - val_cost: 3.3496\n",
            "Epoch 517/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9939 - accuracy: 0.9810 - cost: 2.4642 - val_loss: 0.1342 - val_auc: 0.9805 - val_accuracy: 0.9718 - val_cost: 3.4310\n",
            "Epoch 518/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.4028 - val_loss: 0.1299 - val_auc: 0.9813 - val_accuracy: 0.9717 - val_cost: 3.3691\n",
            "Epoch 519/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4282 - val_loss: 0.1336 - val_auc: 0.9804 - val_accuracy: 0.9701 - val_cost: 3.5905\n",
            "Epoch 520/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9937 - accuracy: 0.9814 - cost: 2.4138 - val_loss: 0.1317 - val_auc: 0.9807 - val_accuracy: 0.9711 - val_cost: 3.3724\n",
            "Epoch 521/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9938 - accuracy: 0.9813 - cost: 2.4197 - val_loss: 0.1318 - val_auc: 0.9815 - val_accuracy: 0.9708 - val_cost: 3.4766\n",
            "Epoch 522/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9940 - accuracy: 0.9811 - cost: 2.4605 - val_loss: 0.1304 - val_auc: 0.9813 - val_accuracy: 0.9719 - val_cost: 3.2943\n",
            "Epoch 523/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9813 - cost: 2.4285 - val_loss: 0.1347 - val_auc: 0.9813 - val_accuracy: 0.9705 - val_cost: 3.4245\n",
            "Epoch 524/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9941 - accuracy: 0.9817 - cost: 2.3666 - val_loss: 0.1322 - val_auc: 0.9805 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 525/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4491 - val_loss: 0.1316 - val_auc: 0.9812 - val_accuracy: 0.9709 - val_cost: 3.3789\n",
            "Epoch 526/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4356 - val_loss: 0.1352 - val_auc: 0.9811 - val_accuracy: 0.9712 - val_cost: 3.4147\n",
            "Epoch 527/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9939 - accuracy: 0.9817 - cost: 2.3710 - val_loss: 0.1359 - val_auc: 0.9800 - val_accuracy: 0.9714 - val_cost: 3.3268\n",
            "Epoch 528/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0648 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4006 - val_loss: 0.1312 - val_auc: 0.9808 - val_accuracy: 0.9706 - val_cost: 3.5091\n",
            "Epoch 529/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9815 - cost: 2.3891 - val_loss: 0.1331 - val_auc: 0.9812 - val_accuracy: 0.9710 - val_cost: 3.4733\n",
            "Epoch 530/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9941 - accuracy: 0.9814 - cost: 2.4197 - val_loss: 0.1328 - val_auc: 0.9811 - val_accuracy: 0.9712 - val_cost: 3.3854\n",
            "Epoch 531/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9817 - cost: 2.3814 - val_loss: 0.1324 - val_auc: 0.9809 - val_accuracy: 0.9706 - val_cost: 3.4342\n",
            "Epoch 532/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9942 - accuracy: 0.9812 - cost: 2.4378 - val_loss: 0.1319 - val_auc: 0.9812 - val_accuracy: 0.9716 - val_cost: 3.3887\n",
            "Epoch 533/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4056 - val_loss: 0.1334 - val_auc: 0.9818 - val_accuracy: 0.9707 - val_cost: 3.6426\n",
            "Epoch 534/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9938 - accuracy: 0.9814 - cost: 2.4135 - val_loss: 0.1333 - val_auc: 0.9812 - val_accuracy: 0.9699 - val_cost: 3.6621\n",
            "Epoch 535/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9942 - accuracy: 0.9816 - cost: 2.3799 - val_loss: 0.1328 - val_auc: 0.9807 - val_accuracy: 0.9701 - val_cost: 3.6751\n",
            "Epoch 536/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9945 - accuracy: 0.9821 - cost: 2.3150 - val_loss: 0.1305 - val_auc: 0.9812 - val_accuracy: 0.9712 - val_cost: 3.6165\n",
            "Epoch 537/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9940 - accuracy: 0.9817 - cost: 2.3787 - val_loss: 0.1338 - val_auc: 0.9809 - val_accuracy: 0.9702 - val_cost: 3.6621\n",
            "Epoch 538/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9940 - accuracy: 0.9813 - cost: 2.4262 - val_loss: 0.1345 - val_auc: 0.9803 - val_accuracy: 0.9706 - val_cost: 3.5807\n",
            "Epoch 539/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9942 - accuracy: 0.9815 - cost: 2.4018 - val_loss: 0.1337 - val_auc: 0.9807 - val_accuracy: 0.9703 - val_cost: 3.7337\n",
            "Epoch 540/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9943 - accuracy: 0.9817 - cost: 2.3773 - val_loss: 0.1352 - val_auc: 0.9805 - val_accuracy: 0.9699 - val_cost: 3.8704\n",
            "Epoch 541/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9942 - accuracy: 0.9817 - cost: 2.3858 - val_loss: 0.1323 - val_auc: 0.9811 - val_accuracy: 0.9707 - val_cost: 3.6165\n",
            "Epoch 542/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9944 - accuracy: 0.9814 - cost: 2.3973 - val_loss: 0.1322 - val_auc: 0.9808 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 543/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9943 - accuracy: 0.9816 - cost: 2.3833 - val_loss: 0.1341 - val_auc: 0.9802 - val_accuracy: 0.9706 - val_cost: 3.4505\n",
            "Epoch 544/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9941 - accuracy: 0.9813 - cost: 2.4330 - val_loss: 0.1356 - val_auc: 0.9810 - val_accuracy: 0.9694 - val_cost: 3.5677\n",
            "Epoch 545/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9942 - accuracy: 0.9816 - cost: 2.3901 - val_loss: 0.1335 - val_auc: 0.9814 - val_accuracy: 0.9701 - val_cost: 3.5775\n",
            "Epoch 546/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9944 - accuracy: 0.9816 - cost: 2.3916 - val_loss: 0.1334 - val_auc: 0.9807 - val_accuracy: 0.9722 - val_cost: 3.3203\n",
            "Epoch 547/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9941 - accuracy: 0.9817 - cost: 2.3766 - val_loss: 0.1358 - val_auc: 0.9807 - val_accuracy: 0.9699 - val_cost: 3.4831\n",
            "Epoch 548/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9941 - accuracy: 0.9812 - cost: 2.4468 - val_loss: 0.1332 - val_auc: 0.9811 - val_accuracy: 0.9704 - val_cost: 3.8118\n",
            "Epoch 549/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3953 - val_loss: 0.1343 - val_auc: 0.9810 - val_accuracy: 0.9704 - val_cost: 3.5026\n",
            "Epoch 550/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9940 - accuracy: 0.9817 - cost: 2.3823 - val_loss: 0.1361 - val_auc: 0.9810 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 551/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9943 - accuracy: 0.9814 - cost: 2.4230 - val_loss: 0.1337 - val_auc: 0.9808 - val_accuracy: 0.9699 - val_cost: 3.5645\n",
            "Epoch 552/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9943 - accuracy: 0.9813 - cost: 2.4309 - val_loss: 0.1351 - val_auc: 0.9799 - val_accuracy: 0.9699 - val_cost: 3.4896\n",
            "Epoch 553/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9939 - accuracy: 0.9814 - cost: 2.4093 - val_loss: 0.1357 - val_auc: 0.9807 - val_accuracy: 0.9705 - val_cost: 3.6296\n",
            "Epoch 554/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0633 - auc: 0.9943 - accuracy: 0.9818 - cost: 2.3678 - val_loss: 0.1346 - val_auc: 0.9803 - val_accuracy: 0.9710 - val_cost: 3.5286\n",
            "Epoch 555/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9939 - accuracy: 0.9811 - cost: 2.4654 - val_loss: 0.1334 - val_auc: 0.9802 - val_accuracy: 0.9715 - val_cost: 3.3496\n",
            "Epoch 556/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9940 - accuracy: 0.9815 - cost: 2.4042 - val_loss: 0.1317 - val_auc: 0.9806 - val_accuracy: 0.9710 - val_cost: 3.5124\n",
            "Epoch 557/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9941 - accuracy: 0.9809 - cost: 2.4834 - val_loss: 0.1343 - val_auc: 0.9808 - val_accuracy: 0.9712 - val_cost: 3.3887\n",
            "Epoch 558/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9942 - accuracy: 0.9817 - cost: 2.3736 - val_loss: 0.1334 - val_auc: 0.9805 - val_accuracy: 0.9708 - val_cost: 3.4538\n",
            "Epoch 559/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9942 - accuracy: 0.9812 - cost: 2.4474 - val_loss: 0.1319 - val_auc: 0.9810 - val_accuracy: 0.9715 - val_cost: 3.5514\n",
            "Epoch 560/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9942 - accuracy: 0.9813 - cost: 2.4384 - val_loss: 0.1329 - val_auc: 0.9805 - val_accuracy: 0.9706 - val_cost: 3.6263\n",
            "Epoch 561/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9942 - accuracy: 0.9815 - cost: 2.4122 - val_loss: 0.1368 - val_auc: 0.9799 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 562/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9941 - accuracy: 0.9813 - cost: 2.4274 - val_loss: 0.1330 - val_auc: 0.9814 - val_accuracy: 0.9706 - val_cost: 3.5124\n",
            "Epoch 563/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9938 - accuracy: 0.9816 - cost: 2.3847 - val_loss: 0.1349 - val_auc: 0.9800 - val_accuracy: 0.9690 - val_cost: 3.7891\n",
            "Epoch 564/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3944 - val_loss: 0.1343 - val_auc: 0.9802 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 565/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9942 - accuracy: 0.9812 - cost: 2.4315 - val_loss: 0.1363 - val_auc: 0.9803 - val_accuracy: 0.9705 - val_cost: 3.4570\n",
            "Epoch 566/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9939 - accuracy: 0.9817 - cost: 2.3848 - val_loss: 0.1352 - val_auc: 0.9805 - val_accuracy: 0.9711 - val_cost: 3.7923\n",
            "Epoch 567/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9940 - accuracy: 0.9819 - cost: 2.3640 - val_loss: 0.1337 - val_auc: 0.9807 - val_accuracy: 0.9709 - val_cost: 3.5091\n",
            "Epoch 568/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9943 - accuracy: 0.9815 - cost: 2.3939 - val_loss: 0.1364 - val_auc: 0.9804 - val_accuracy: 0.9702 - val_cost: 3.4538\n",
            "Epoch 569/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9812 - cost: 2.4411 - val_loss: 0.1354 - val_auc: 0.9807 - val_accuracy: 0.9696 - val_cost: 3.5384\n",
            "Epoch 570/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9939 - accuracy: 0.9813 - cost: 2.4200 - val_loss: 0.1320 - val_auc: 0.9810 - val_accuracy: 0.9708 - val_cost: 3.6491\n",
            "Epoch 571/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9942 - accuracy: 0.9816 - cost: 2.3821 - val_loss: 0.1353 - val_auc: 0.9808 - val_accuracy: 0.9708 - val_cost: 3.5026\n",
            "Epoch 572/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9942 - accuracy: 0.9817 - cost: 2.3868 - val_loss: 0.1349 - val_auc: 0.9806 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 573/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9944 - accuracy: 0.9815 - cost: 2.4098 - val_loss: 0.1368 - val_auc: 0.9802 - val_accuracy: 0.9705 - val_cost: 3.4701\n",
            "Epoch 574/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9940 - accuracy: 0.9812 - cost: 2.4519 - val_loss: 0.1324 - val_auc: 0.9806 - val_accuracy: 0.9706 - val_cost: 3.4505\n",
            "Epoch 575/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9943 - accuracy: 0.9816 - cost: 2.3836 - val_loss: 0.1357 - val_auc: 0.9806 - val_accuracy: 0.9705 - val_cost: 3.4961\n",
            "Epoch 576/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9940 - accuracy: 0.9818 - cost: 2.3673 - val_loss: 0.1366 - val_auc: 0.9810 - val_accuracy: 0.9702 - val_cost: 3.4993\n",
            "Epoch 577/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0644 - auc: 0.9942 - accuracy: 0.9812 - cost: 2.4511 - val_loss: 0.1356 - val_auc: 0.9806 - val_accuracy: 0.9700 - val_cost: 3.5286\n",
            "Epoch 578/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9939 - accuracy: 0.9816 - cost: 2.3845 - val_loss: 0.1359 - val_auc: 0.9800 - val_accuracy: 0.9698 - val_cost: 3.4993\n",
            "Epoch 579/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9942 - accuracy: 0.9814 - cost: 2.4144 - val_loss: 0.1343 - val_auc: 0.9817 - val_accuracy: 0.9706 - val_cost: 3.5482\n",
            "Epoch 580/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9944 - accuracy: 0.9819 - cost: 2.3430 - val_loss: 0.1364 - val_auc: 0.9803 - val_accuracy: 0.9701 - val_cost: 3.4928\n",
            "Epoch 581/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9814 - cost: 2.4274 - val_loss: 0.1350 - val_auc: 0.9806 - val_accuracy: 0.9703 - val_cost: 3.5352\n",
            "Epoch 582/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9940 - accuracy: 0.9817 - cost: 2.3750 - val_loss: 0.1336 - val_auc: 0.9811 - val_accuracy: 0.9701 - val_cost: 3.9258\n",
            "Epoch 583/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9941 - accuracy: 0.9814 - cost: 2.4095 - val_loss: 0.1362 - val_auc: 0.9801 - val_accuracy: 0.9714 - val_cost: 3.3887\n",
            "Epoch 584/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9941 - accuracy: 0.9815 - cost: 2.4070 - val_loss: 0.1363 - val_auc: 0.9805 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 585/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9940 - accuracy: 0.9816 - cost: 2.3868 - val_loss: 0.1342 - val_auc: 0.9804 - val_accuracy: 0.9706 - val_cost: 3.7337\n",
            "Epoch 586/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9943 - accuracy: 0.9815 - cost: 2.3937 - val_loss: 0.1356 - val_auc: 0.9804 - val_accuracy: 0.9705 - val_cost: 3.6003\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1114 - auc: 0.9867 - accuracy: 0.9721 - cost: 3.5844\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:05:35.383817\n",
            "fold accuracy: 0.9720625281333923 - fold cost: 3.5843749046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5455 - auc: 0.7110 - accuracy: 0.7158 - cost: 37.6467 - val_loss: 0.4066 - val_auc: 0.8536 - val_accuracy: 0.8217 - val_cost: 23.4733\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.3654 - auc: 0.8776 - accuracy: 0.8430 - cost: 20.0138 - val_loss: 0.3224 - val_auc: 0.9065 - val_accuracy: 0.8619 - val_cost: 17.0833\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.3132 - auc: 0.9114 - accuracy: 0.8700 - cost: 16.4319 - val_loss: 0.2958 - val_auc: 0.9233 - val_accuracy: 0.8767 - val_cost: 15.3060\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2860 - auc: 0.9270 - accuracy: 0.8835 - cost: 14.6980 - val_loss: 0.2707 - val_auc: 0.9366 - val_accuracy: 0.8902 - val_cost: 13.4245\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2646 - auc: 0.9378 - accuracy: 0.8940 - cost: 13.3706 - val_loss: 0.2521 - val_auc: 0.9453 - val_accuracy: 0.8995 - val_cost: 12.2233\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2464 - auc: 0.9461 - accuracy: 0.9034 - cost: 12.2263 - val_loss: 0.2371 - val_auc: 0.9513 - val_accuracy: 0.9092 - val_cost: 11.1849\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2313 - auc: 0.9524 - accuracy: 0.9103 - cost: 11.3391 - val_loss: 0.2229 - val_auc: 0.9564 - val_accuracy: 0.9153 - val_cost: 10.3451\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2180 - auc: 0.9576 - accuracy: 0.9162 - cost: 10.5960 - val_loss: 0.2114 - val_auc: 0.9605 - val_accuracy: 0.9212 - val_cost: 9.6908\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2059 - auc: 0.9617 - accuracy: 0.9219 - cost: 9.8766 - val_loss: 0.2004 - val_auc: 0.9642 - val_accuracy: 0.9251 - val_cost: 9.3327\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1962 - auc: 0.9652 - accuracy: 0.9266 - cost: 9.3002 - val_loss: 0.1912 - val_auc: 0.9668 - val_accuracy: 0.9296 - val_cost: 8.9421\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1866 - auc: 0.9683 - accuracy: 0.9308 - cost: 8.7658 - val_loss: 0.1844 - val_auc: 0.9685 - val_accuracy: 0.9353 - val_cost: 7.9134\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1798 - auc: 0.9707 - accuracy: 0.9342 - cost: 8.3285 - val_loss: 0.1773 - val_auc: 0.9703 - val_accuracy: 0.9385 - val_cost: 7.8581\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1734 - auc: 0.9722 - accuracy: 0.9374 - cost: 7.9449 - val_loss: 0.1718 - val_auc: 0.9726 - val_accuracy: 0.9416 - val_cost: 7.3698\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1672 - auc: 0.9740 - accuracy: 0.9403 - cost: 7.5523 - val_loss: 0.1665 - val_auc: 0.9735 - val_accuracy: 0.9433 - val_cost: 7.1777\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1633 - auc: 0.9748 - accuracy: 0.9417 - cost: 7.4030 - val_loss: 0.1623 - val_auc: 0.9749 - val_accuracy: 0.9438 - val_cost: 7.1908\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1600 - auc: 0.9755 - accuracy: 0.9436 - cost: 7.1782 - val_loss: 0.1591 - val_auc: 0.9758 - val_accuracy: 0.9449 - val_cost: 6.7871\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1538 - auc: 0.9774 - accuracy: 0.9457 - cost: 6.9054 - val_loss: 0.1559 - val_auc: 0.9767 - val_accuracy: 0.9464 - val_cost: 6.7090\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1521 - auc: 0.9779 - accuracy: 0.9466 - cost: 6.7896 - val_loss: 0.1552 - val_auc: 0.9769 - val_accuracy: 0.9473 - val_cost: 6.5397\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1480 - auc: 0.9787 - accuracy: 0.9490 - cost: 6.4856 - val_loss: 0.1513 - val_auc: 0.9779 - val_accuracy: 0.9486 - val_cost: 6.4486\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1449 - auc: 0.9795 - accuracy: 0.9505 - cost: 6.2798 - val_loss: 0.1486 - val_auc: 0.9782 - val_accuracy: 0.9503 - val_cost: 6.4225\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1421 - auc: 0.9800 - accuracy: 0.9513 - cost: 6.1912 - val_loss: 0.1468 - val_auc: 0.9789 - val_accuracy: 0.9513 - val_cost: 6.3444\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1400 - auc: 0.9807 - accuracy: 0.9520 - cost: 6.1103 - val_loss: 0.1452 - val_auc: 0.9792 - val_accuracy: 0.9511 - val_cost: 6.2500\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1371 - auc: 0.9815 - accuracy: 0.9539 - cost: 5.8475 - val_loss: 0.1428 - val_auc: 0.9796 - val_accuracy: 0.9527 - val_cost: 6.0840\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1359 - auc: 0.9814 - accuracy: 0.9541 - cost: 5.8371 - val_loss: 0.1426 - val_auc: 0.9797 - val_accuracy: 0.9538 - val_cost: 5.6706\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1326 - auc: 0.9823 - accuracy: 0.9555 - cost: 5.6610 - val_loss: 0.1398 - val_auc: 0.9798 - val_accuracy: 0.9547 - val_cost: 5.7878\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9828 - accuracy: 0.9555 - cost: 5.6592 - val_loss: 0.1391 - val_auc: 0.9804 - val_accuracy: 0.9541 - val_cost: 5.7031\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1282 - auc: 0.9833 - accuracy: 0.9576 - cost: 5.3754 - val_loss: 0.1375 - val_auc: 0.9806 - val_accuracy: 0.9555 - val_cost: 5.6999\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1275 - auc: 0.9831 - accuracy: 0.9577 - cost: 5.3794 - val_loss: 0.1367 - val_auc: 0.9807 - val_accuracy: 0.9567 - val_cost: 5.6152\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9835 - accuracy: 0.9585 - cost: 5.2850 - val_loss: 0.1360 - val_auc: 0.9804 - val_accuracy: 0.9575 - val_cost: 5.3971\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1236 - auc: 0.9840 - accuracy: 0.9591 - cost: 5.1966 - val_loss: 0.1341 - val_auc: 0.9811 - val_accuracy: 0.9575 - val_cost: 5.3939\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1226 - auc: 0.9842 - accuracy: 0.9599 - cost: 5.1083 - val_loss: 0.1317 - val_auc: 0.9816 - val_accuracy: 0.9591 - val_cost: 5.1432\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9847 - accuracy: 0.9607 - cost: 4.9936 - val_loss: 0.1286 - val_auc: 0.9820 - val_accuracy: 0.9595 - val_cost: 5.1888\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9849 - accuracy: 0.9615 - cost: 4.8999 - val_loss: 0.1290 - val_auc: 0.9818 - val_accuracy: 0.9605 - val_cost: 5.0749\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9855 - accuracy: 0.9616 - cost: 4.9070 - val_loss: 0.1280 - val_auc: 0.9818 - val_accuracy: 0.9599 - val_cost: 5.1725\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9857 - accuracy: 0.9627 - cost: 4.7313 - val_loss: 0.1277 - val_auc: 0.9822 - val_accuracy: 0.9608 - val_cost: 4.9154\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1152 - auc: 0.9856 - accuracy: 0.9628 - cost: 4.7284 - val_loss: 0.1280 - val_auc: 0.9824 - val_accuracy: 0.9601 - val_cost: 4.8210\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1141 - auc: 0.9858 - accuracy: 0.9634 - cost: 4.6448 - val_loss: 0.1266 - val_auc: 0.9819 - val_accuracy: 0.9604 - val_cost: 4.9121\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1125 - auc: 0.9864 - accuracy: 0.9639 - cost: 4.5852 - val_loss: 0.1257 - val_auc: 0.9825 - val_accuracy: 0.9608 - val_cost: 4.9414\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9862 - accuracy: 0.9640 - cost: 4.5919 - val_loss: 0.1246 - val_auc: 0.9825 - val_accuracy: 0.9616 - val_cost: 4.9089\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9863 - accuracy: 0.9648 - cost: 4.4898 - val_loss: 0.1234 - val_auc: 0.9830 - val_accuracy: 0.9619 - val_cost: 4.9544\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1098 - auc: 0.9868 - accuracy: 0.9655 - cost: 4.4011 - val_loss: 0.1240 - val_auc: 0.9823 - val_accuracy: 0.9621 - val_cost: 4.7070\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1079 - auc: 0.9870 - accuracy: 0.9657 - cost: 4.3596 - val_loss: 0.1214 - val_auc: 0.9829 - val_accuracy: 0.9629 - val_cost: 4.5801\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1084 - auc: 0.9872 - accuracy: 0.9659 - cost: 4.3531 - val_loss: 0.1218 - val_auc: 0.9825 - val_accuracy: 0.9626 - val_cost: 4.6842\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9873 - accuracy: 0.9664 - cost: 4.2853 - val_loss: 0.1213 - val_auc: 0.9825 - val_accuracy: 0.9633 - val_cost: 4.6615\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9874 - accuracy: 0.9666 - cost: 4.2604 - val_loss: 0.1197 - val_auc: 0.9833 - val_accuracy: 0.9640 - val_cost: 4.5964\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1053 - auc: 0.9873 - accuracy: 0.9669 - cost: 4.2222 - val_loss: 0.1219 - val_auc: 0.9820 - val_accuracy: 0.9632 - val_cost: 4.4987\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9875 - accuracy: 0.9678 - cost: 4.0952 - val_loss: 0.1212 - val_auc: 0.9826 - val_accuracy: 0.9639 - val_cost: 4.6615\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1045 - auc: 0.9877 - accuracy: 0.9672 - cost: 4.1806 - val_loss: 0.1184 - val_auc: 0.9829 - val_accuracy: 0.9639 - val_cost: 4.4531\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1024 - auc: 0.9879 - accuracy: 0.9682 - cost: 4.0573 - val_loss: 0.1174 - val_auc: 0.9831 - val_accuracy: 0.9650 - val_cost: 4.4499\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1032 - auc: 0.9878 - accuracy: 0.9680 - cost: 4.0650 - val_loss: 0.1198 - val_auc: 0.9830 - val_accuracy: 0.9632 - val_cost: 4.4694\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1021 - auc: 0.9881 - accuracy: 0.9684 - cost: 4.0464 - val_loss: 0.1163 - val_auc: 0.9833 - val_accuracy: 0.9657 - val_cost: 4.2773\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9881 - accuracy: 0.9683 - cost: 4.0511 - val_loss: 0.1171 - val_auc: 0.9829 - val_accuracy: 0.9644 - val_cost: 4.4987\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9883 - accuracy: 0.9695 - cost: 3.9047 - val_loss: 0.1176 - val_auc: 0.9836 - val_accuracy: 0.9647 - val_cost: 4.4043\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9881 - accuracy: 0.9694 - cost: 3.9052 - val_loss: 0.1186 - val_auc: 0.9827 - val_accuracy: 0.9638 - val_cost: 4.5280\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1001 - auc: 0.9883 - accuracy: 0.9693 - cost: 3.9179 - val_loss: 0.1160 - val_auc: 0.9836 - val_accuracy: 0.9647 - val_cost: 4.4922\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0991 - auc: 0.9883 - accuracy: 0.9699 - cost: 3.8432 - val_loss: 0.1156 - val_auc: 0.9830 - val_accuracy: 0.9667 - val_cost: 4.0560\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9887 - accuracy: 0.9694 - cost: 3.9102 - val_loss: 0.1173 - val_auc: 0.9829 - val_accuracy: 0.9648 - val_cost: 4.3359\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9888 - accuracy: 0.9707 - cost: 3.7377 - val_loss: 0.1156 - val_auc: 0.9834 - val_accuracy: 0.9654 - val_cost: 4.3880\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9886 - accuracy: 0.9706 - cost: 3.7715 - val_loss: 0.1182 - val_auc: 0.9829 - val_accuracy: 0.9664 - val_cost: 4.2285\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9888 - accuracy: 0.9707 - cost: 3.7659 - val_loss: 0.1171 - val_auc: 0.9830 - val_accuracy: 0.9649 - val_cost: 4.5605\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9890 - accuracy: 0.9713 - cost: 3.6660 - val_loss: 0.1147 - val_auc: 0.9830 - val_accuracy: 0.9651 - val_cost: 4.3164\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9889 - accuracy: 0.9706 - cost: 3.7671 - val_loss: 0.1135 - val_auc: 0.9834 - val_accuracy: 0.9671 - val_cost: 3.9941\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0960 - auc: 0.9887 - accuracy: 0.9711 - cost: 3.6990 - val_loss: 0.1156 - val_auc: 0.9832 - val_accuracy: 0.9658 - val_cost: 4.2936\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9892 - accuracy: 0.9711 - cost: 3.7183 - val_loss: 0.1140 - val_auc: 0.9841 - val_accuracy: 0.9658 - val_cost: 4.2090\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0946 - auc: 0.9892 - accuracy: 0.9716 - cost: 3.6387 - val_loss: 0.1140 - val_auc: 0.9834 - val_accuracy: 0.9669 - val_cost: 4.1927\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9894 - accuracy: 0.9718 - cost: 3.6201 - val_loss: 0.1163 - val_auc: 0.9835 - val_accuracy: 0.9666 - val_cost: 4.1276\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9891 - accuracy: 0.9719 - cost: 3.5908 - val_loss: 0.1144 - val_auc: 0.9833 - val_accuracy: 0.9678 - val_cost: 4.0462\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9894 - accuracy: 0.9718 - cost: 3.6096 - val_loss: 0.1138 - val_auc: 0.9841 - val_accuracy: 0.9669 - val_cost: 4.0853\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9893 - accuracy: 0.9720 - cost: 3.5782 - val_loss: 0.1151 - val_auc: 0.9834 - val_accuracy: 0.9680 - val_cost: 3.8542\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9896 - accuracy: 0.9727 - cost: 3.4835 - val_loss: 0.1129 - val_auc: 0.9845 - val_accuracy: 0.9667 - val_cost: 4.1992\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0922 - auc: 0.9895 - accuracy: 0.9726 - cost: 3.5002 - val_loss: 0.1123 - val_auc: 0.9838 - val_accuracy: 0.9676 - val_cost: 4.0560\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0912 - auc: 0.9899 - accuracy: 0.9724 - cost: 3.5244 - val_loss: 0.1137 - val_auc: 0.9840 - val_accuracy: 0.9671 - val_cost: 4.0527\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0915 - auc: 0.9898 - accuracy: 0.9728 - cost: 3.4856 - val_loss: 0.1147 - val_auc: 0.9836 - val_accuracy: 0.9669 - val_cost: 4.0755\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0915 - auc: 0.9898 - accuracy: 0.9729 - cost: 3.4629 - val_loss: 0.1115 - val_auc: 0.9839 - val_accuracy: 0.9682 - val_cost: 3.9095\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0899 - auc: 0.9898 - accuracy: 0.9736 - cost: 3.3929 - val_loss: 0.1141 - val_auc: 0.9832 - val_accuracy: 0.9682 - val_cost: 3.8932\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9901 - accuracy: 0.9735 - cost: 3.4197 - val_loss: 0.1122 - val_auc: 0.9844 - val_accuracy: 0.9685 - val_cost: 3.8281\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9898 - accuracy: 0.9734 - cost: 3.4136 - val_loss: 0.1134 - val_auc: 0.9838 - val_accuracy: 0.9679 - val_cost: 3.9876\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0903 - auc: 0.9899 - accuracy: 0.9733 - cost: 3.4248 - val_loss: 0.1136 - val_auc: 0.9839 - val_accuracy: 0.9679 - val_cost: 3.9746\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9897 - accuracy: 0.9736 - cost: 3.3754 - val_loss: 0.1131 - val_auc: 0.9842 - val_accuracy: 0.9681 - val_cost: 3.9290\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9902 - accuracy: 0.9736 - cost: 3.3845 - val_loss: 0.1117 - val_auc: 0.9844 - val_accuracy: 0.9688 - val_cost: 3.9388\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9901 - accuracy: 0.9740 - cost: 3.3355 - val_loss: 0.1119 - val_auc: 0.9837 - val_accuracy: 0.9690 - val_cost: 3.7240\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9899 - accuracy: 0.9736 - cost: 3.3851 - val_loss: 0.1107 - val_auc: 0.9832 - val_accuracy: 0.9688 - val_cost: 4.0267\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9901 - accuracy: 0.9735 - cost: 3.3988 - val_loss: 0.1114 - val_auc: 0.9840 - val_accuracy: 0.9686 - val_cost: 3.8607\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9901 - accuracy: 0.9741 - cost: 3.3133 - val_loss: 0.1108 - val_auc: 0.9841 - val_accuracy: 0.9695 - val_cost: 3.6947\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9900 - accuracy: 0.9737 - cost: 3.3839 - val_loss: 0.1123 - val_auc: 0.9839 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9901 - accuracy: 0.9744 - cost: 3.2826 - val_loss: 0.1122 - val_auc: 0.9836 - val_accuracy: 0.9692 - val_cost: 3.8021\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0872 - auc: 0.9901 - accuracy: 0.9744 - cost: 3.2929 - val_loss: 0.1132 - val_auc: 0.9835 - val_accuracy: 0.9683 - val_cost: 3.8574\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9902 - accuracy: 0.9746 - cost: 3.2520 - val_loss: 0.1112 - val_auc: 0.9839 - val_accuracy: 0.9686 - val_cost: 3.9974\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0875 - auc: 0.9902 - accuracy: 0.9743 - cost: 3.2864 - val_loss: 0.1113 - val_auc: 0.9839 - val_accuracy: 0.9688 - val_cost: 3.8997\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9906 - accuracy: 0.9748 - cost: 3.2339 - val_loss: 0.1124 - val_auc: 0.9829 - val_accuracy: 0.9692 - val_cost: 3.6784\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9906 - accuracy: 0.9743 - cost: 3.2831 - val_loss: 0.1125 - val_auc: 0.9835 - val_accuracy: 0.9686 - val_cost: 3.8477\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9905 - accuracy: 0.9747 - cost: 3.2428 - val_loss: 0.1119 - val_auc: 0.9832 - val_accuracy: 0.9687 - val_cost: 3.7370\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9905 - accuracy: 0.9742 - cost: 3.3118 - val_loss: 0.1126 - val_auc: 0.9833 - val_accuracy: 0.9688 - val_cost: 3.7565\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0860 - auc: 0.9906 - accuracy: 0.9749 - cost: 3.2199 - val_loss: 0.1118 - val_auc: 0.9829 - val_accuracy: 0.9695 - val_cost: 3.6686\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9903 - accuracy: 0.9749 - cost: 3.2167 - val_loss: 0.1111 - val_auc: 0.9826 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0866 - auc: 0.9905 - accuracy: 0.9747 - cost: 3.2427 - val_loss: 0.1118 - val_auc: 0.9837 - val_accuracy: 0.9676 - val_cost: 4.0820\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0858 - auc: 0.9905 - accuracy: 0.9748 - cost: 3.2385 - val_loss: 0.1123 - val_auc: 0.9832 - val_accuracy: 0.9685 - val_cost: 3.8346\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0848 - auc: 0.9909 - accuracy: 0.9751 - cost: 3.1889 - val_loss: 0.1130 - val_auc: 0.9831 - val_accuracy: 0.9691 - val_cost: 3.6719\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9906 - accuracy: 0.9758 - cost: 3.1131 - val_loss: 0.1129 - val_auc: 0.9833 - val_accuracy: 0.9697 - val_cost: 3.6621\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9907 - accuracy: 0.9755 - cost: 3.1411 - val_loss: 0.1111 - val_auc: 0.9841 - val_accuracy: 0.9682 - val_cost: 3.9486\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9905 - accuracy: 0.9755 - cost: 3.1460 - val_loss: 0.1107 - val_auc: 0.9836 - val_accuracy: 0.9690 - val_cost: 3.8835\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9908 - accuracy: 0.9760 - cost: 3.0936 - val_loss: 0.1107 - val_auc: 0.9837 - val_accuracy: 0.9698 - val_cost: 3.7240\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9910 - accuracy: 0.9753 - cost: 3.1811 - val_loss: 0.1120 - val_auc: 0.9840 - val_accuracy: 0.9701 - val_cost: 3.7077\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9906 - accuracy: 0.9755 - cost: 3.1427 - val_loss: 0.1103 - val_auc: 0.9840 - val_accuracy: 0.9692 - val_cost: 3.8216\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9910 - accuracy: 0.9758 - cost: 3.1107 - val_loss: 0.1129 - val_auc: 0.9829 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9906 - accuracy: 0.9756 - cost: 3.1292 - val_loss: 0.1111 - val_auc: 0.9838 - val_accuracy: 0.9688 - val_cost: 3.7826\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9910 - accuracy: 0.9760 - cost: 3.0869 - val_loss: 0.1099 - val_auc: 0.9838 - val_accuracy: 0.9692 - val_cost: 3.8314\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9911 - accuracy: 0.9759 - cost: 3.0933 - val_loss: 0.1124 - val_auc: 0.9843 - val_accuracy: 0.9690 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9909 - accuracy: 0.9765 - cost: 3.0237 - val_loss: 0.1114 - val_auc: 0.9836 - val_accuracy: 0.9705 - val_cost: 3.5742\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9908 - accuracy: 0.9766 - cost: 3.0074 - val_loss: 0.1105 - val_auc: 0.9841 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9913 - accuracy: 0.9762 - cost: 3.0550 - val_loss: 0.1127 - val_auc: 0.9829 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9906 - accuracy: 0.9760 - cost: 3.0759 - val_loss: 0.1106 - val_auc: 0.9839 - val_accuracy: 0.9697 - val_cost: 3.7305\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9912 - accuracy: 0.9763 - cost: 3.0262 - val_loss: 0.1112 - val_auc: 0.9837 - val_accuracy: 0.9692 - val_cost: 3.7337\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9910 - accuracy: 0.9761 - cost: 3.0669 - val_loss: 0.1100 - val_auc: 0.9839 - val_accuracy: 0.9707 - val_cost: 3.6296\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9911 - accuracy: 0.9762 - cost: 3.0563 - val_loss: 0.1107 - val_auc: 0.9839 - val_accuracy: 0.9689 - val_cost: 3.8509\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9910 - accuracy: 0.9763 - cost: 3.0502 - val_loss: 0.1105 - val_auc: 0.9836 - val_accuracy: 0.9695 - val_cost: 3.8900\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9909 - accuracy: 0.9764 - cost: 3.0377 - val_loss: 0.1099 - val_auc: 0.9840 - val_accuracy: 0.9699 - val_cost: 3.6686\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9914 - accuracy: 0.9763 - cost: 3.0515 - val_loss: 0.1122 - val_auc: 0.9831 - val_accuracy: 0.9694 - val_cost: 3.8314\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9913 - accuracy: 0.9764 - cost: 3.0279 - val_loss: 0.1115 - val_auc: 0.9838 - val_accuracy: 0.9700 - val_cost: 3.7077\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9912 - accuracy: 0.9760 - cost: 3.0812 - val_loss: 0.1128 - val_auc: 0.9836 - val_accuracy: 0.9683 - val_cost: 3.9095\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0809 - auc: 0.9914 - accuracy: 0.9767 - cost: 3.0026 - val_loss: 0.1119 - val_auc: 0.9839 - val_accuracy: 0.9694 - val_cost: 3.7565\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9913 - accuracy: 0.9771 - cost: 2.9463 - val_loss: 0.1130 - val_auc: 0.9842 - val_accuracy: 0.9685 - val_cost: 3.7891\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9911 - accuracy: 0.9768 - cost: 2.9836 - val_loss: 0.1122 - val_auc: 0.9834 - val_accuracy: 0.9695 - val_cost: 3.7174\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9433 - val_loss: 0.1120 - val_auc: 0.9835 - val_accuracy: 0.9699 - val_cost: 3.7142\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9915 - accuracy: 0.9766 - cost: 3.0077 - val_loss: 0.1113 - val_auc: 0.9845 - val_accuracy: 0.9701 - val_cost: 3.6458\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9911 - accuracy: 0.9771 - cost: 2.9446 - val_loss: 0.1143 - val_auc: 0.9833 - val_accuracy: 0.9693 - val_cost: 3.7305\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9913 - accuracy: 0.9768 - cost: 2.9742 - val_loss: 0.1117 - val_auc: 0.9842 - val_accuracy: 0.9686 - val_cost: 3.9453\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9914 - accuracy: 0.9768 - cost: 2.9996 - val_loss: 0.1119 - val_auc: 0.9840 - val_accuracy: 0.9692 - val_cost: 3.7956\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9913 - accuracy: 0.9766 - cost: 3.0194 - val_loss: 0.1106 - val_auc: 0.9835 - val_accuracy: 0.9692 - val_cost: 3.8477\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9914 - accuracy: 0.9772 - cost: 2.9348 - val_loss: 0.1127 - val_auc: 0.9837 - val_accuracy: 0.9701 - val_cost: 3.6654\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9915 - accuracy: 0.9775 - cost: 2.8924 - val_loss: 0.1111 - val_auc: 0.9841 - val_accuracy: 0.9701 - val_cost: 3.6230\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9915 - accuracy: 0.9766 - cost: 3.0129 - val_loss: 0.1152 - val_auc: 0.9833 - val_accuracy: 0.9693 - val_cost: 3.7272\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9915 - accuracy: 0.9767 - cost: 3.0032 - val_loss: 0.1133 - val_auc: 0.9838 - val_accuracy: 0.9682 - val_cost: 3.9225\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9914 - accuracy: 0.9768 - cost: 2.9759 - val_loss: 0.1124 - val_auc: 0.9839 - val_accuracy: 0.9699 - val_cost: 3.7012\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9916 - accuracy: 0.9769 - cost: 2.9654 - val_loss: 0.1110 - val_auc: 0.9838 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9502 - val_loss: 0.1133 - val_auc: 0.9839 - val_accuracy: 0.9686 - val_cost: 4.0137\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9912 - accuracy: 0.9777 - cost: 2.8784 - val_loss: 0.1130 - val_auc: 0.9838 - val_accuracy: 0.9701 - val_cost: 3.8900\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9915 - accuracy: 0.9772 - cost: 2.9328 - val_loss: 0.1124 - val_auc: 0.9837 - val_accuracy: 0.9689 - val_cost: 3.8802\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9913 - accuracy: 0.9772 - cost: 2.9341 - val_loss: 0.1095 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.6816\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9917 - accuracy: 0.9773 - cost: 2.9134 - val_loss: 0.1104 - val_auc: 0.9840 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9622 - val_loss: 0.1142 - val_auc: 0.9828 - val_accuracy: 0.9701 - val_cost: 3.6100\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0786 - auc: 0.9917 - accuracy: 0.9774 - cost: 2.9285 - val_loss: 0.1128 - val_auc: 0.9839 - val_accuracy: 0.9695 - val_cost: 3.7500\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9632 - val_loss: 0.1124 - val_auc: 0.9831 - val_accuracy: 0.9697 - val_cost: 3.8997\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9915 - accuracy: 0.9775 - cost: 2.8923 - val_loss: 0.1101 - val_auc: 0.9837 - val_accuracy: 0.9708 - val_cost: 3.5645\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9915 - accuracy: 0.9775 - cost: 2.8923 - val_loss: 0.1126 - val_auc: 0.9832 - val_accuracy: 0.9699 - val_cost: 3.7663\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9917 - accuracy: 0.9774 - cost: 2.8990 - val_loss: 0.1137 - val_auc: 0.9831 - val_accuracy: 0.9691 - val_cost: 3.8607\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9918 - accuracy: 0.9772 - cost: 2.9285 - val_loss: 0.1143 - val_auc: 0.9832 - val_accuracy: 0.9694 - val_cost: 3.7663\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9917 - accuracy: 0.9772 - cost: 2.9275 - val_loss: 0.1123 - val_auc: 0.9829 - val_accuracy: 0.9691 - val_cost: 3.7956\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9919 - accuracy: 0.9777 - cost: 2.8841 - val_loss: 0.1137 - val_auc: 0.9837 - val_accuracy: 0.9693 - val_cost: 3.8184\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9920 - accuracy: 0.9781 - cost: 2.8313 - val_loss: 0.1147 - val_auc: 0.9834 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9917 - accuracy: 0.9776 - cost: 2.8749 - val_loss: 0.1116 - val_auc: 0.9843 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9920 - accuracy: 0.9776 - cost: 2.8883 - val_loss: 0.1122 - val_auc: 0.9837 - val_accuracy: 0.9698 - val_cost: 3.6328\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8918 - val_loss: 0.1138 - val_auc: 0.9838 - val_accuracy: 0.9698 - val_cost: 3.8281\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9919 - accuracy: 0.9770 - cost: 2.9706 - val_loss: 0.1129 - val_auc: 0.9835 - val_accuracy: 0.9701 - val_cost: 3.7337\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9916 - accuracy: 0.9779 - cost: 2.8451 - val_loss: 0.1106 - val_auc: 0.9842 - val_accuracy: 0.9708 - val_cost: 3.6068\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9918 - accuracy: 0.9781 - cost: 2.8283 - val_loss: 0.1120 - val_auc: 0.9841 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9914 - accuracy: 0.9780 - cost: 2.8391 - val_loss: 0.1125 - val_auc: 0.9840 - val_accuracy: 0.9701 - val_cost: 3.8444\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9917 - accuracy: 0.9777 - cost: 2.8701 - val_loss: 0.1148 - val_auc: 0.9829 - val_accuracy: 0.9676 - val_cost: 4.0202\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7844 - val_loss: 0.1130 - val_auc: 0.9830 - val_accuracy: 0.9690 - val_cost: 4.0885\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9916 - accuracy: 0.9779 - cost: 2.8500 - val_loss: 0.1114 - val_auc: 0.9843 - val_accuracy: 0.9684 - val_cost: 3.9551\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9917 - accuracy: 0.9779 - cost: 2.8514 - val_loss: 0.1131 - val_auc: 0.9836 - val_accuracy: 0.9693 - val_cost: 3.8835\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8790 - val_loss: 0.1115 - val_auc: 0.9832 - val_accuracy: 0.9711 - val_cost: 3.5645\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9918 - accuracy: 0.9782 - cost: 2.8041 - val_loss: 0.1118 - val_auc: 0.9836 - val_accuracy: 0.9697 - val_cost: 3.7305\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9917 - accuracy: 0.9777 - cost: 2.8823 - val_loss: 0.1123 - val_auc: 0.9844 - val_accuracy: 0.9699 - val_cost: 3.7435\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9917 - accuracy: 0.9778 - cost: 2.8566 - val_loss: 0.1130 - val_auc: 0.9839 - val_accuracy: 0.9692 - val_cost: 3.8216\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9918 - accuracy: 0.9783 - cost: 2.8091 - val_loss: 0.1127 - val_auc: 0.9841 - val_accuracy: 0.9703 - val_cost: 3.6523\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7749 - val_loss: 0.1137 - val_auc: 0.9835 - val_accuracy: 0.9701 - val_cost: 3.8737\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9921 - accuracy: 0.9782 - cost: 2.8103 - val_loss: 0.1165 - val_auc: 0.9827 - val_accuracy: 0.9692 - val_cost: 3.7174\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9920 - accuracy: 0.9782 - cost: 2.8183 - val_loss: 0.1138 - val_auc: 0.9833 - val_accuracy: 0.9693 - val_cost: 3.7891\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9920 - accuracy: 0.9779 - cost: 2.8393 - val_loss: 0.1136 - val_auc: 0.9836 - val_accuracy: 0.9703 - val_cost: 3.8411\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9916 - accuracy: 0.9784 - cost: 2.7850 - val_loss: 0.1169 - val_auc: 0.9827 - val_accuracy: 0.9688 - val_cost: 3.7630\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8298 - val_loss: 0.1122 - val_auc: 0.9834 - val_accuracy: 0.9699 - val_cost: 3.9323\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8896 - val_loss: 0.1148 - val_auc: 0.9831 - val_accuracy: 0.9709 - val_cost: 3.6816\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7642 - val_loss: 0.1151 - val_auc: 0.9831 - val_accuracy: 0.9697 - val_cost: 3.8477\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9918 - accuracy: 0.9783 - cost: 2.8009 - val_loss: 0.1149 - val_auc: 0.9832 - val_accuracy: 0.9692 - val_cost: 3.9551\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9918 - accuracy: 0.9790 - cost: 2.7118 - val_loss: 0.1133 - val_auc: 0.9835 - val_accuracy: 0.9702 - val_cost: 3.8770\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9920 - accuracy: 0.9785 - cost: 2.7759 - val_loss: 0.1138 - val_auc: 0.9836 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9922 - accuracy: 0.9784 - cost: 2.7980 - val_loss: 0.1132 - val_auc: 0.9833 - val_accuracy: 0.9691 - val_cost: 3.9355\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9919 - accuracy: 0.9778 - cost: 2.8687 - val_loss: 0.1121 - val_auc: 0.9838 - val_accuracy: 0.9695 - val_cost: 4.0527\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.7853 - val_loss: 0.1126 - val_auc: 0.9835 - val_accuracy: 0.9705 - val_cost: 3.6751\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9920 - accuracy: 0.9784 - cost: 2.7758 - val_loss: 0.1127 - val_auc: 0.9837 - val_accuracy: 0.9700 - val_cost: 3.8346\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9921 - accuracy: 0.9783 - cost: 2.7972 - val_loss: 0.1139 - val_auc: 0.9831 - val_accuracy: 0.9705 - val_cost: 3.6556\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9922 - accuracy: 0.9787 - cost: 2.7508 - val_loss: 0.1146 - val_auc: 0.9836 - val_accuracy: 0.9697 - val_cost: 4.0625\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9922 - accuracy: 0.9792 - cost: 2.6745 - val_loss: 0.1156 - val_auc: 0.9832 - val_accuracy: 0.9705 - val_cost: 3.8086\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9922 - accuracy: 0.9787 - cost: 2.7482 - val_loss: 0.1166 - val_auc: 0.9832 - val_accuracy: 0.9706 - val_cost: 3.5775\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9921 - accuracy: 0.9786 - cost: 2.7667 - val_loss: 0.1164 - val_auc: 0.9827 - val_accuracy: 0.9702 - val_cost: 3.5645\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9919 - accuracy: 0.9782 - cost: 2.8056 - val_loss: 0.1135 - val_auc: 0.9840 - val_accuracy: 0.9699 - val_cost: 3.7142\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9924 - accuracy: 0.9790 - cost: 2.6981 - val_loss: 0.1139 - val_auc: 0.9837 - val_accuracy: 0.9698 - val_cost: 3.7760\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7129 - val_loss: 0.1122 - val_auc: 0.9834 - val_accuracy: 0.9706 - val_cost: 3.7923\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.7967 - val_loss: 0.1133 - val_auc: 0.9835 - val_accuracy: 0.9708 - val_cost: 3.8086\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9923 - accuracy: 0.9784 - cost: 2.7917 - val_loss: 0.1132 - val_auc: 0.9841 - val_accuracy: 0.9710 - val_cost: 3.6165\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9924 - accuracy: 0.9783 - cost: 2.8007 - val_loss: 0.1147 - val_auc: 0.9827 - val_accuracy: 0.9699 - val_cost: 3.8509\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7811 - val_loss: 0.1144 - val_auc: 0.9836 - val_accuracy: 0.9701 - val_cost: 3.6784\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9923 - accuracy: 0.9785 - cost: 2.7608 - val_loss: 0.1163 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.5352\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9923 - accuracy: 0.9789 - cost: 2.7224 - val_loss: 0.1145 - val_auc: 0.9828 - val_accuracy: 0.9695 - val_cost: 3.7272\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9925 - accuracy: 0.9786 - cost: 2.7678 - val_loss: 0.1150 - val_auc: 0.9835 - val_accuracy: 0.9692 - val_cost: 3.9258\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7309 - val_loss: 0.1142 - val_auc: 0.9834 - val_accuracy: 0.9701 - val_cost: 3.8379\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7414 - val_loss: 0.1144 - val_auc: 0.9832 - val_accuracy: 0.9703 - val_cost: 3.6979\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6600 - val_loss: 0.1143 - val_auc: 0.9828 - val_accuracy: 0.9705 - val_cost: 3.8997\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9921 - accuracy: 0.9786 - cost: 2.7642 - val_loss: 0.1157 - val_auc: 0.9826 - val_accuracy: 0.9690 - val_cost: 4.0495\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.6900 - val_loss: 0.1141 - val_auc: 0.9832 - val_accuracy: 0.9697 - val_cost: 3.7337\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7584 - val_loss: 0.1160 - val_auc: 0.9831 - val_accuracy: 0.9699 - val_cost: 3.6751\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9921 - accuracy: 0.9791 - cost: 2.7007 - val_loss: 0.1144 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.6491\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9788 - cost: 2.7283 - val_loss: 0.1164 - val_auc: 0.9831 - val_accuracy: 0.9693 - val_cost: 3.8835\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9921 - accuracy: 0.9792 - cost: 2.6722 - val_loss: 0.1146 - val_auc: 0.9838 - val_accuracy: 0.9700 - val_cost: 3.8379\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7424 - val_loss: 0.1150 - val_auc: 0.9834 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9923 - accuracy: 0.9790 - cost: 2.6935 - val_loss: 0.1146 - val_auc: 0.9836 - val_accuracy: 0.9696 - val_cost: 3.7402\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0737 - auc: 0.9924 - accuracy: 0.9793 - cost: 2.6647 - val_loss: 0.1140 - val_auc: 0.9830 - val_accuracy: 0.9699 - val_cost: 3.7760\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9924 - accuracy: 0.9791 - cost: 2.6991 - val_loss: 0.1149 - val_auc: 0.9832 - val_accuracy: 0.9696 - val_cost: 3.6979\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9789 - cost: 2.7238 - val_loss: 0.1161 - val_auc: 0.9827 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9927 - accuracy: 0.9789 - cost: 2.7191 - val_loss: 0.1134 - val_auc: 0.9826 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7095 - val_loss: 0.1143 - val_auc: 0.9832 - val_accuracy: 0.9698 - val_cost: 3.7923\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9791 - cost: 2.7043 - val_loss: 0.1142 - val_auc: 0.9841 - val_accuracy: 0.9697 - val_cost: 3.7598\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6894 - val_loss: 0.1178 - val_auc: 0.9821 - val_accuracy: 0.9694 - val_cost: 3.6979\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7276 - val_loss: 0.1152 - val_auc: 0.9835 - val_accuracy: 0.9689 - val_cost: 3.8216\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6541 - val_loss: 0.1170 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.6784\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.7081 - val_loss: 0.1150 - val_auc: 0.9833 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9927 - accuracy: 0.9790 - cost: 2.7245 - val_loss: 0.1151 - val_auc: 0.9833 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.6914 - val_loss: 0.1166 - val_auc: 0.9832 - val_accuracy: 0.9702 - val_cost: 3.6686\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9920 - accuracy: 0.9791 - cost: 2.7028 - val_loss: 0.1160 - val_auc: 0.9829 - val_accuracy: 0.9693 - val_cost: 3.7923\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9794 - cost: 2.6522 - val_loss: 0.1144 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.6816\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7094 - val_loss: 0.1140 - val_auc: 0.9834 - val_accuracy: 0.9694 - val_cost: 3.9225\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6976 - val_loss: 0.1177 - val_auc: 0.9818 - val_accuracy: 0.9689 - val_cost: 3.7956\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9930 - accuracy: 0.9789 - cost: 2.7140 - val_loss: 0.1159 - val_auc: 0.9830 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6863 - val_loss: 0.1161 - val_auc: 0.9831 - val_accuracy: 0.9709 - val_cost: 3.5254\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6702 - val_loss: 0.1171 - val_auc: 0.9833 - val_accuracy: 0.9700 - val_cost: 3.6100\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6189 - val_loss: 0.1166 - val_auc: 0.9824 - val_accuracy: 0.9686 - val_cost: 3.8509\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6779 - val_loss: 0.1157 - val_auc: 0.9833 - val_accuracy: 0.9704 - val_cost: 3.8509\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6717 - val_loss: 0.1159 - val_auc: 0.9827 - val_accuracy: 0.9693 - val_cost: 3.9355\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9922 - accuracy: 0.9792 - cost: 2.6788 - val_loss: 0.1168 - val_auc: 0.9829 - val_accuracy: 0.9698 - val_cost: 3.7402\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0728 - auc: 0.9923 - accuracy: 0.9793 - cost: 2.6717 - val_loss: 0.1152 - val_auc: 0.9837 - val_accuracy: 0.9699 - val_cost: 3.8249\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9929 - accuracy: 0.9792 - cost: 2.6988 - val_loss: 0.1162 - val_auc: 0.9829 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9924 - accuracy: 0.9793 - cost: 2.6728 - val_loss: 0.1170 - val_auc: 0.9827 - val_accuracy: 0.9704 - val_cost: 3.6979\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6398 - val_loss: 0.1160 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.8086\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6855 - val_loss: 0.1172 - val_auc: 0.9824 - val_accuracy: 0.9693 - val_cost: 3.9811\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9931 - accuracy: 0.9791 - cost: 2.6948 - val_loss: 0.1158 - val_auc: 0.9834 - val_accuracy: 0.9697 - val_cost: 3.7435\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6704 - val_loss: 0.1188 - val_auc: 0.9828 - val_accuracy: 0.9685 - val_cost: 3.8965\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6612 - val_loss: 0.1154 - val_auc: 0.9835 - val_accuracy: 0.9704 - val_cost: 3.6882\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9930 - accuracy: 0.9795 - cost: 2.6408 - val_loss: 0.1179 - val_auc: 0.9828 - val_accuracy: 0.9699 - val_cost: 3.8607\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6570 - val_loss: 0.1180 - val_auc: 0.9834 - val_accuracy: 0.9696 - val_cost: 3.9746\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9926 - accuracy: 0.9794 - cost: 2.6479 - val_loss: 0.1174 - val_auc: 0.9821 - val_accuracy: 0.9701 - val_cost: 3.6589\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6418 - val_loss: 0.1191 - val_auc: 0.9830 - val_accuracy: 0.9699 - val_cost: 3.6816\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6712 - val_loss: 0.1166 - val_auc: 0.9831 - val_accuracy: 0.9699 - val_cost: 3.8118\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9799 - cost: 2.5947 - val_loss: 0.1176 - val_auc: 0.9829 - val_accuracy: 0.9697 - val_cost: 3.8021\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6884 - val_loss: 0.1150 - val_auc: 0.9832 - val_accuracy: 0.9706 - val_cost: 3.6719\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6075 - val_loss: 0.1185 - val_auc: 0.9825 - val_accuracy: 0.9710 - val_cost: 3.5124\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5938 - val_loss: 0.1177 - val_auc: 0.9828 - val_accuracy: 0.9697 - val_cost: 3.8997\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6586 - val_loss: 0.1181 - val_auc: 0.9827 - val_accuracy: 0.9691 - val_cost: 3.8249\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6829 - val_loss: 0.1213 - val_auc: 0.9821 - val_accuracy: 0.9690 - val_cost: 3.7467\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6064 - val_loss: 0.1161 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.6979\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6336 - val_loss: 0.1155 - val_auc: 0.9837 - val_accuracy: 0.9713 - val_cost: 3.5189\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6338 - val_loss: 0.1183 - val_auc: 0.9832 - val_accuracy: 0.9699 - val_cost: 3.7402\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6735 - val_loss: 0.1186 - val_auc: 0.9826 - val_accuracy: 0.9698 - val_cost: 3.7988\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9927 - accuracy: 0.9799 - cost: 2.5891 - val_loss: 0.1186 - val_auc: 0.9830 - val_accuracy: 0.9693 - val_cost: 3.8281\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5870 - val_loss: 0.1170 - val_auc: 0.9830 - val_accuracy: 0.9705 - val_cost: 3.6198\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6660 - val_loss: 0.1197 - val_auc: 0.9822 - val_accuracy: 0.9701 - val_cost: 3.7565\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6380 - val_loss: 0.1156 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9927 - accuracy: 0.9800 - cost: 2.5841 - val_loss: 0.1180 - val_auc: 0.9824 - val_accuracy: 0.9703 - val_cost: 3.6784\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6173 - val_loss: 0.1178 - val_auc: 0.9825 - val_accuracy: 0.9703 - val_cost: 3.6393\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6715 - val_loss: 0.1188 - val_auc: 0.9821 - val_accuracy: 0.9685 - val_cost: 3.9095\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5862 - val_loss: 0.1164 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.6328\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6623 - val_loss: 0.1172 - val_auc: 0.9826 - val_accuracy: 0.9711 - val_cost: 3.5872\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9926 - accuracy: 0.9802 - cost: 2.5521 - val_loss: 0.1170 - val_auc: 0.9839 - val_accuracy: 0.9700 - val_cost: 3.7826\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6445 - val_loss: 0.1208 - val_auc: 0.9810 - val_accuracy: 0.9696 - val_cost: 3.7044\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5854 - val_loss: 0.1165 - val_auc: 0.9829 - val_accuracy: 0.9711 - val_cost: 3.5417\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9927 - accuracy: 0.9798 - cost: 2.6079 - val_loss: 0.1158 - val_auc: 0.9832 - val_accuracy: 0.9704 - val_cost: 3.6491\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6363 - val_loss: 0.1166 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.8249\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6087 - val_loss: 0.1176 - val_auc: 0.9835 - val_accuracy: 0.9701 - val_cost: 3.9355\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6051 - val_loss: 0.1156 - val_auc: 0.9832 - val_accuracy: 0.9699 - val_cost: 3.7337\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9927 - accuracy: 0.9798 - cost: 2.6057 - val_loss: 0.1162 - val_auc: 0.9833 - val_accuracy: 0.9703 - val_cost: 3.6621\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6275 - val_loss: 0.1156 - val_auc: 0.9832 - val_accuracy: 0.9702 - val_cost: 3.7142\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6511 - val_loss: 0.1163 - val_auc: 0.9830 - val_accuracy: 0.9703 - val_cost: 3.8770\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9796 - cost: 2.6232 - val_loss: 0.1171 - val_auc: 0.9830 - val_accuracy: 0.9710 - val_cost: 3.7174\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9925 - accuracy: 0.9800 - cost: 2.5794 - val_loss: 0.1189 - val_auc: 0.9826 - val_accuracy: 0.9707 - val_cost: 3.5254\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5437 - val_loss: 0.1158 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.9941\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9928 - accuracy: 0.9800 - cost: 2.5769 - val_loss: 0.1151 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.7435\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5839 - val_loss: 0.1154 - val_auc: 0.9830 - val_accuracy: 0.9705 - val_cost: 3.6719\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5374 - val_loss: 0.1181 - val_auc: 0.9832 - val_accuracy: 0.9708 - val_cost: 3.5872\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5990 - val_loss: 0.1168 - val_auc: 0.9832 - val_accuracy: 0.9706 - val_cost: 3.8574\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5169 - val_loss: 0.1173 - val_auc: 0.9831 - val_accuracy: 0.9710 - val_cost: 3.8965\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5840 - val_loss: 0.1171 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.7533\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6124 - val_loss: 0.1175 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.8672\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5485 - val_loss: 0.1193 - val_auc: 0.9828 - val_accuracy: 0.9704 - val_cost: 3.6458\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6095 - val_loss: 0.1183 - val_auc: 0.9824 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5836 - val_loss: 0.1188 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9802 - cost: 2.5637 - val_loss: 0.1178 - val_auc: 0.9827 - val_accuracy: 0.9702 - val_cost: 3.7012\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9795 - cost: 2.6457 - val_loss: 0.1168 - val_auc: 0.9834 - val_accuracy: 0.9707 - val_cost: 3.8346\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5653 - val_loss: 0.1171 - val_auc: 0.9830 - val_accuracy: 0.9696 - val_cost: 3.8021\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5563 - val_loss: 0.1179 - val_auc: 0.9830 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5451 - val_loss: 0.1190 - val_auc: 0.9824 - val_accuracy: 0.9706 - val_cost: 3.6751\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9925 - accuracy: 0.9799 - cost: 2.5852 - val_loss: 0.1186 - val_auc: 0.9826 - val_accuracy: 0.9705 - val_cost: 3.6849\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5696 - val_loss: 0.1183 - val_auc: 0.9821 - val_accuracy: 0.9698 - val_cost: 3.7402\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6125 - val_loss: 0.1164 - val_auc: 0.9825 - val_accuracy: 0.9701 - val_cost: 3.8932\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.6071 - val_loss: 0.1197 - val_auc: 0.9819 - val_accuracy: 0.9695 - val_cost: 4.0267\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5370 - val_loss: 0.1181 - val_auc: 0.9829 - val_accuracy: 0.9704 - val_cost: 3.6426\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9804 - cost: 2.5381 - val_loss: 0.1184 - val_auc: 0.9825 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9926 - accuracy: 0.9798 - cost: 2.6146 - val_loss: 0.1184 - val_auc: 0.9827 - val_accuracy: 0.9704 - val_cost: 3.6784\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9804 - cost: 2.5165 - val_loss: 0.1165 - val_auc: 0.9829 - val_accuracy: 0.9722 - val_cost: 3.4798\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5312 - val_loss: 0.1189 - val_auc: 0.9830 - val_accuracy: 0.9709 - val_cost: 3.5514\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5702 - val_loss: 0.1160 - val_auc: 0.9831 - val_accuracy: 0.9708 - val_cost: 3.6361\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5549 - val_loss: 0.1189 - val_auc: 0.9825 - val_accuracy: 0.9712 - val_cost: 3.6198\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6156 - val_loss: 0.1175 - val_auc: 0.9829 - val_accuracy: 0.9717 - val_cost: 3.6654\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9927 - accuracy: 0.9802 - cost: 2.5518 - val_loss: 0.1170 - val_auc: 0.9834 - val_accuracy: 0.9712 - val_cost: 3.7663\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9805 - cost: 2.5205 - val_loss: 0.1192 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.8346\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9929 - accuracy: 0.9805 - cost: 2.5138 - val_loss: 0.1167 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.6686\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9930 - accuracy: 0.9809 - cost: 2.4790 - val_loss: 0.1207 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.7565\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5517 - val_loss: 0.1196 - val_auc: 0.9832 - val_accuracy: 0.9697 - val_cost: 3.9128\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5781 - val_loss: 0.1165 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.7207\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9930 - accuracy: 0.9801 - cost: 2.5570 - val_loss: 0.1204 - val_auc: 0.9817 - val_accuracy: 0.9709 - val_cost: 3.9258\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5395 - val_loss: 0.1194 - val_auc: 0.9832 - val_accuracy: 0.9728 - val_cost: 3.3236\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5607 - val_loss: 0.1181 - val_auc: 0.9825 - val_accuracy: 0.9717 - val_cost: 3.6165\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4826 - val_loss: 0.1207 - val_auc: 0.9829 - val_accuracy: 0.9704 - val_cost: 3.8770\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9928 - accuracy: 0.9803 - cost: 2.5433 - val_loss: 0.1176 - val_auc: 0.9829 - val_accuracy: 0.9716 - val_cost: 3.5417\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9931 - accuracy: 0.9797 - cost: 2.6228 - val_loss: 0.1178 - val_auc: 0.9823 - val_accuracy: 0.9703 - val_cost: 3.8965\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5787 - val_loss: 0.1186 - val_auc: 0.9835 - val_accuracy: 0.9710 - val_cost: 3.6393\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.5905 - val_loss: 0.1181 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.8639\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0695 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5014 - val_loss: 0.1217 - val_auc: 0.9831 - val_accuracy: 0.9699 - val_cost: 3.9974\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9934 - accuracy: 0.9806 - cost: 2.5168 - val_loss: 0.1189 - val_auc: 0.9830 - val_accuracy: 0.9709 - val_cost: 3.7630\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5430 - val_loss: 0.1198 - val_auc: 0.9826 - val_accuracy: 0.9701 - val_cost: 3.7305\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9802 - cost: 2.5459 - val_loss: 0.1186 - val_auc: 0.9839 - val_accuracy: 0.9710 - val_cost: 3.9616\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5780 - val_loss: 0.1204 - val_auc: 0.9821 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6044 - val_loss: 0.1186 - val_auc: 0.9833 - val_accuracy: 0.9707 - val_cost: 3.6849\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9929 - accuracy: 0.9805 - cost: 2.5134 - val_loss: 0.1204 - val_auc: 0.9819 - val_accuracy: 0.9711 - val_cost: 3.7272\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5190 - val_loss: 0.1177 - val_auc: 0.9831 - val_accuracy: 0.9703 - val_cost: 3.8704\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4905 - val_loss: 0.1181 - val_auc: 0.9825 - val_accuracy: 0.9709 - val_cost: 3.6296\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9809 - cost: 2.4784 - val_loss: 0.1213 - val_auc: 0.9828 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9805 - cost: 2.5188 - val_loss: 0.1186 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.7207\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5247 - val_loss: 0.1186 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.5645\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5743 - val_loss: 0.1198 - val_auc: 0.9828 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5283 - val_loss: 0.1177 - val_auc: 0.9832 - val_accuracy: 0.9713 - val_cost: 3.5840\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9932 - accuracy: 0.9808 - cost: 2.4847 - val_loss: 0.1177 - val_auc: 0.9833 - val_accuracy: 0.9706 - val_cost: 3.8444\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9929 - accuracy: 0.9806 - cost: 2.5084 - val_loss: 0.1180 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.7533\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9810 - cost: 2.4542 - val_loss: 0.1183 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.5677\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4699 - val_loss: 0.1184 - val_auc: 0.9831 - val_accuracy: 0.9713 - val_cost: 3.5547\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5371 - val_loss: 0.1206 - val_auc: 0.9831 - val_accuracy: 0.9710 - val_cost: 3.5710\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4861 - val_loss: 0.1197 - val_auc: 0.9831 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5295 - val_loss: 0.1177 - val_auc: 0.9831 - val_accuracy: 0.9721 - val_cost: 3.6296\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9804 - cost: 2.5323 - val_loss: 0.1218 - val_auc: 0.9826 - val_accuracy: 0.9694 - val_cost: 3.6882\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9929 - accuracy: 0.9811 - cost: 2.4313 - val_loss: 0.1180 - val_auc: 0.9825 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9930 - accuracy: 0.9806 - cost: 2.5139 - val_loss: 0.1217 - val_auc: 0.9815 - val_accuracy: 0.9712 - val_cost: 3.5124\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5505 - val_loss: 0.1180 - val_auc: 0.9828 - val_accuracy: 0.9716 - val_cost: 3.7012\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5651 - val_loss: 0.1187 - val_auc: 0.9833 - val_accuracy: 0.9719 - val_cost: 3.5156\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9932 - accuracy: 0.9811 - cost: 2.4430 - val_loss: 0.1179 - val_auc: 0.9839 - val_accuracy: 0.9710 - val_cost: 3.7630\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.4979 - val_loss: 0.1202 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.6589\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5079 - val_loss: 0.1188 - val_auc: 0.9829 - val_accuracy: 0.9707 - val_cost: 3.6328\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5230 - val_loss: 0.1189 - val_auc: 0.9829 - val_accuracy: 0.9714 - val_cost: 3.5710\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5071 - val_loss: 0.1189 - val_auc: 0.9833 - val_accuracy: 0.9711 - val_cost: 3.5547\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5380 - val_loss: 0.1203 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.6068\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9931 - accuracy: 0.9806 - cost: 2.5094 - val_loss: 0.1195 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.5970\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9936 - accuracy: 0.9805 - cost: 2.5226 - val_loss: 0.1175 - val_auc: 0.9832 - val_accuracy: 0.9717 - val_cost: 3.5091\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9936 - accuracy: 0.9807 - cost: 2.4937 - val_loss: 0.1187 - val_auc: 0.9834 - val_accuracy: 0.9721 - val_cost: 3.5026\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9932 - accuracy: 0.9810 - cost: 2.4667 - val_loss: 0.1189 - val_auc: 0.9834 - val_accuracy: 0.9714 - val_cost: 3.5514\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9929 - accuracy: 0.9804 - cost: 2.5409 - val_loss: 0.1187 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9930 - accuracy: 0.9807 - cost: 2.4910 - val_loss: 0.1202 - val_auc: 0.9829 - val_accuracy: 0.9715 - val_cost: 3.5384\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5396 - val_loss: 0.1185 - val_auc: 0.9841 - val_accuracy: 0.9714 - val_cost: 3.8086\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5374 - val_loss: 0.1200 - val_auc: 0.9826 - val_accuracy: 0.9703 - val_cost: 3.6296\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5116 - val_loss: 0.1175 - val_auc: 0.9837 - val_accuracy: 0.9707 - val_cost: 3.7142\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5550 - val_loss: 0.1197 - val_auc: 0.9822 - val_accuracy: 0.9709 - val_cost: 3.5872\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9938 - accuracy: 0.9812 - cost: 2.4462 - val_loss: 0.1201 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.5579\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9932 - accuracy: 0.9808 - cost: 2.4869 - val_loss: 0.1202 - val_auc: 0.9831 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 361/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5491 - val_loss: 0.1174 - val_auc: 0.9833 - val_accuracy: 0.9711 - val_cost: 3.6035\n",
            "Epoch 362/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4863 - val_loss: 0.1188 - val_auc: 0.9824 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 363/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5653 - val_loss: 0.1199 - val_auc: 0.9825 - val_accuracy: 0.9710 - val_cost: 3.6068\n",
            "Epoch 364/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5065 - val_loss: 0.1185 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.6230\n",
            "Epoch 365/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9930 - accuracy: 0.9806 - cost: 2.5045 - val_loss: 0.1192 - val_auc: 0.9831 - val_accuracy: 0.9713 - val_cost: 3.7500\n",
            "Epoch 366/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9935 - accuracy: 0.9802 - cost: 2.5583 - val_loss: 0.1216 - val_auc: 0.9819 - val_accuracy: 0.9713 - val_cost: 3.5514\n",
            "Epoch 367/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9930 - accuracy: 0.9810 - cost: 2.4552 - val_loss: 0.1199 - val_auc: 0.9834 - val_accuracy: 0.9715 - val_cost: 3.5547\n",
            "Epoch 368/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9934 - accuracy: 0.9812 - cost: 2.4350 - val_loss: 0.1222 - val_auc: 0.9824 - val_accuracy: 0.9710 - val_cost: 3.5221\n",
            "Epoch 369/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9932 - accuracy: 0.9809 - cost: 2.4684 - val_loss: 0.1231 - val_auc: 0.9819 - val_accuracy: 0.9704 - val_cost: 3.6458\n",
            "Epoch 370/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.5025 - val_loss: 0.1194 - val_auc: 0.9819 - val_accuracy: 0.9706 - val_cost: 3.8444\n",
            "Epoch 371/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9935 - accuracy: 0.9809 - cost: 2.4728 - val_loss: 0.1208 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 372/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4959 - val_loss: 0.1190 - val_auc: 0.9830 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 373/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4967 - val_loss: 0.1199 - val_auc: 0.9813 - val_accuracy: 0.9714 - val_cost: 3.5221\n",
            "Epoch 374/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9931 - accuracy: 0.9809 - cost: 2.4727 - val_loss: 0.1188 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.6458\n",
            "Epoch 375/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9809 - cost: 2.4702 - val_loss: 0.1189 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 376/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9932 - accuracy: 0.9810 - cost: 2.4492 - val_loss: 0.1202 - val_auc: 0.9823 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 377/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9933 - accuracy: 0.9801 - cost: 2.5756 - val_loss: 0.1229 - val_auc: 0.9817 - val_accuracy: 0.9712 - val_cost: 3.4798\n",
            "Epoch 378/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4838 - val_loss: 0.1218 - val_auc: 0.9829 - val_accuracy: 0.9713 - val_cost: 3.7695\n",
            "Epoch 379/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4842 - val_loss: 0.1225 - val_auc: 0.9829 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 380/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9932 - accuracy: 0.9808 - cost: 2.4885 - val_loss: 0.1209 - val_auc: 0.9835 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 381/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5085 - val_loss: 0.1201 - val_auc: 0.9833 - val_accuracy: 0.9716 - val_cost: 3.5579\n",
            "Epoch 382/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9937 - accuracy: 0.9812 - cost: 2.4371 - val_loss: 0.1199 - val_auc: 0.9824 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 383/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5564 - val_loss: 0.1227 - val_auc: 0.9817 - val_accuracy: 0.9716 - val_cost: 3.4310\n",
            "Epoch 384/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5068 - val_loss: 0.1193 - val_auc: 0.9827 - val_accuracy: 0.9715 - val_cost: 3.5612\n",
            "Epoch 385/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4489 - val_loss: 0.1223 - val_auc: 0.9814 - val_accuracy: 0.9702 - val_cost: 3.7370\n",
            "Epoch 386/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9931 - accuracy: 0.9805 - cost: 2.5377 - val_loss: 0.1229 - val_auc: 0.9818 - val_accuracy: 0.9703 - val_cost: 3.6100\n",
            "Epoch 387/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9935 - accuracy: 0.9810 - cost: 2.4579 - val_loss: 0.1193 - val_auc: 0.9833 - val_accuracy: 0.9714 - val_cost: 3.6133\n",
            "Epoch 388/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9932 - accuracy: 0.9807 - cost: 2.4960 - val_loss: 0.1202 - val_auc: 0.9822 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 389/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9934 - accuracy: 0.9807 - cost: 2.4843 - val_loss: 0.1225 - val_auc: 0.9813 - val_accuracy: 0.9709 - val_cost: 3.6589\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1086 - auc: 0.9856 - accuracy: 0.9729 - cost: 3.4969\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:43.883474\n",
            "fold accuracy: 0.9728749990463257 - fold cost: 3.496875047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5481 - auc: 0.7078 - accuracy: 0.7137 - cost: 37.9522 - val_loss: 0.4113 - val_auc: 0.8483 - val_accuracy: 0.8189 - val_cost: 23.0273\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3656 - auc: 0.8778 - accuracy: 0.8423 - cost: 20.0894 - val_loss: 0.3220 - val_auc: 0.9069 - val_accuracy: 0.8632 - val_cost: 16.5755\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3136 - auc: 0.9110 - accuracy: 0.8702 - cost: 16.3928 - val_loss: 0.2917 - val_auc: 0.9256 - val_accuracy: 0.8790 - val_cost: 14.7070\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2870 - auc: 0.9262 - accuracy: 0.8832 - cost: 14.7532 - val_loss: 0.2687 - val_auc: 0.9377 - val_accuracy: 0.8917 - val_cost: 13.1999\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2642 - auc: 0.9378 - accuracy: 0.8946 - cost: 13.2945 - val_loss: 0.2509 - val_auc: 0.9460 - val_accuracy: 0.9013 - val_cost: 12.3958\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9461 - accuracy: 0.9030 - cost: 12.2815 - val_loss: 0.2344 - val_auc: 0.9525 - val_accuracy: 0.9106 - val_cost: 11.0384\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2303 - auc: 0.9526 - accuracy: 0.9107 - cost: 11.2857 - val_loss: 0.2211 - val_auc: 0.9575 - val_accuracy: 0.9169 - val_cost: 9.8958\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2176 - auc: 0.9575 - accuracy: 0.9163 - cost: 10.5376 - val_loss: 0.2081 - val_auc: 0.9615 - val_accuracy: 0.9244 - val_cost: 9.3880\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2053 - auc: 0.9621 - accuracy: 0.9223 - cost: 9.8168 - val_loss: 0.1983 - val_auc: 0.9647 - val_accuracy: 0.9273 - val_cost: 8.7109\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1961 - auc: 0.9654 - accuracy: 0.9262 - cost: 9.3313 - val_loss: 0.1893 - val_auc: 0.9670 - val_accuracy: 0.9325 - val_cost: 8.2357\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1867 - auc: 0.9686 - accuracy: 0.9309 - cost: 8.7503 - val_loss: 0.1826 - val_auc: 0.9682 - val_accuracy: 0.9356 - val_cost: 7.9297\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1800 - auc: 0.9705 - accuracy: 0.9343 - cost: 8.3314 - val_loss: 0.1759 - val_auc: 0.9708 - val_accuracy: 0.9378 - val_cost: 7.8353\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1742 - auc: 0.9721 - accuracy: 0.9372 - cost: 7.9480 - val_loss: 0.1732 - val_auc: 0.9717 - val_accuracy: 0.9388 - val_cost: 7.6855\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1693 - auc: 0.9735 - accuracy: 0.9393 - cost: 7.7021 - val_loss: 0.1686 - val_auc: 0.9725 - val_accuracy: 0.9410 - val_cost: 7.3438\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9749 - accuracy: 0.9415 - cost: 7.4345 - val_loss: 0.1635 - val_auc: 0.9737 - val_accuracy: 0.9426 - val_cost: 7.1094\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1597 - auc: 0.9761 - accuracy: 0.9434 - cost: 7.1865 - val_loss: 0.1598 - val_auc: 0.9752 - val_accuracy: 0.9446 - val_cost: 6.8783\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1563 - auc: 0.9772 - accuracy: 0.9449 - cost: 7.0001 - val_loss: 0.1570 - val_auc: 0.9755 - val_accuracy: 0.9465 - val_cost: 6.5755\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1529 - auc: 0.9777 - accuracy: 0.9464 - cost: 6.8114 - val_loss: 0.1556 - val_auc: 0.9764 - val_accuracy: 0.9472 - val_cost: 6.6960\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1491 - auc: 0.9786 - accuracy: 0.9478 - cost: 6.6368 - val_loss: 0.1530 - val_auc: 0.9768 - val_accuracy: 0.9480 - val_cost: 6.4258\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1467 - auc: 0.9794 - accuracy: 0.9491 - cost: 6.4845 - val_loss: 0.1506 - val_auc: 0.9772 - val_accuracy: 0.9489 - val_cost: 6.3281\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1426 - auc: 0.9804 - accuracy: 0.9508 - cost: 6.2330 - val_loss: 0.1490 - val_auc: 0.9776 - val_accuracy: 0.9515 - val_cost: 6.1621\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1415 - auc: 0.9803 - accuracy: 0.9519 - cost: 6.1174 - val_loss: 0.1469 - val_auc: 0.9779 - val_accuracy: 0.9516 - val_cost: 5.8561\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9810 - accuracy: 0.9527 - cost: 6.0024 - val_loss: 0.1460 - val_auc: 0.9780 - val_accuracy: 0.9521 - val_cost: 5.8919\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1362 - auc: 0.9816 - accuracy: 0.9545 - cost: 5.7964 - val_loss: 0.1439 - val_auc: 0.9788 - val_accuracy: 0.9538 - val_cost: 5.6901\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1340 - auc: 0.9822 - accuracy: 0.9548 - cost: 5.7478 - val_loss: 0.1441 - val_auc: 0.9781 - val_accuracy: 0.9534 - val_cost: 5.7910\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1329 - auc: 0.9825 - accuracy: 0.9557 - cost: 5.6494 - val_loss: 0.1395 - val_auc: 0.9797 - val_accuracy: 0.9560 - val_cost: 5.4069\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1298 - auc: 0.9831 - accuracy: 0.9564 - cost: 5.5521 - val_loss: 0.1383 - val_auc: 0.9800 - val_accuracy: 0.9554 - val_cost: 5.6478\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9832 - accuracy: 0.9572 - cost: 5.4558 - val_loss: 0.1380 - val_auc: 0.9800 - val_accuracy: 0.9562 - val_cost: 5.4785\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1271 - auc: 0.9836 - accuracy: 0.9576 - cost: 5.4081 - val_loss: 0.1353 - val_auc: 0.9804 - val_accuracy: 0.9580 - val_cost: 5.2018\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1252 - auc: 0.9841 - accuracy: 0.9589 - cost: 5.2308 - val_loss: 0.1355 - val_auc: 0.9796 - val_accuracy: 0.9588 - val_cost: 5.0944\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9843 - accuracy: 0.9587 - cost: 5.2715 - val_loss: 0.1331 - val_auc: 0.9813 - val_accuracy: 0.9582 - val_cost: 5.2441\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1226 - auc: 0.9846 - accuracy: 0.9602 - cost: 5.0614 - val_loss: 0.1340 - val_auc: 0.9806 - val_accuracy: 0.9580 - val_cost: 5.1204\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1209 - auc: 0.9849 - accuracy: 0.9597 - cost: 5.1363 - val_loss: 0.1319 - val_auc: 0.9809 - val_accuracy: 0.9589 - val_cost: 5.0228\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1198 - auc: 0.9848 - accuracy: 0.9611 - cost: 4.9565 - val_loss: 0.1303 - val_auc: 0.9804 - val_accuracy: 0.9597 - val_cost: 4.9609\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1184 - auc: 0.9851 - accuracy: 0.9614 - cost: 4.9150 - val_loss: 0.1315 - val_auc: 0.9804 - val_accuracy: 0.9597 - val_cost: 5.0163\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1180 - auc: 0.9854 - accuracy: 0.9623 - cost: 4.7933 - val_loss: 0.1295 - val_auc: 0.9804 - val_accuracy: 0.9601 - val_cost: 4.8633\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9857 - accuracy: 0.9629 - cost: 4.7189 - val_loss: 0.1288 - val_auc: 0.9812 - val_accuracy: 0.9610 - val_cost: 4.7884\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9858 - accuracy: 0.9634 - cost: 4.6502 - val_loss: 0.1275 - val_auc: 0.9813 - val_accuracy: 0.9607 - val_cost: 5.0260\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1131 - auc: 0.9863 - accuracy: 0.9640 - cost: 4.5939 - val_loss: 0.1270 - val_auc: 0.9814 - val_accuracy: 0.9610 - val_cost: 5.0065\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1120 - auc: 0.9863 - accuracy: 0.9649 - cost: 4.4752 - val_loss: 0.1288 - val_auc: 0.9808 - val_accuracy: 0.9608 - val_cost: 4.8568\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1112 - auc: 0.9866 - accuracy: 0.9643 - cost: 4.5516 - val_loss: 0.1254 - val_auc: 0.9816 - val_accuracy: 0.9617 - val_cost: 4.7428\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1094 - auc: 0.9866 - accuracy: 0.9657 - cost: 4.3581 - val_loss: 0.1249 - val_auc: 0.9815 - val_accuracy: 0.9631 - val_cost: 4.6875\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1076 - auc: 0.9871 - accuracy: 0.9662 - cost: 4.3030 - val_loss: 0.1252 - val_auc: 0.9814 - val_accuracy: 0.9617 - val_cost: 4.6224\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1084 - auc: 0.9870 - accuracy: 0.9657 - cost: 4.3701 - val_loss: 0.1232 - val_auc: 0.9816 - val_accuracy: 0.9625 - val_cost: 4.5703\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9871 - accuracy: 0.9659 - cost: 4.3623 - val_loss: 0.1216 - val_auc: 0.9819 - val_accuracy: 0.9639 - val_cost: 4.3034\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1071 - auc: 0.9870 - accuracy: 0.9666 - cost: 4.2546 - val_loss: 0.1226 - val_auc: 0.9813 - val_accuracy: 0.9635 - val_cost: 4.2969\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1048 - auc: 0.9877 - accuracy: 0.9673 - cost: 4.1651 - val_loss: 0.1232 - val_auc: 0.9813 - val_accuracy: 0.9639 - val_cost: 4.4336\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1050 - auc: 0.9875 - accuracy: 0.9674 - cost: 4.1627 - val_loss: 0.1230 - val_auc: 0.9818 - val_accuracy: 0.9637 - val_cost: 4.3815\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9876 - accuracy: 0.9677 - cost: 4.1291 - val_loss: 0.1219 - val_auc: 0.9816 - val_accuracy: 0.9651 - val_cost: 4.2513\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1033 - auc: 0.9879 - accuracy: 0.9677 - cost: 4.1362 - val_loss: 0.1225 - val_auc: 0.9818 - val_accuracy: 0.9637 - val_cost: 4.8242\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1017 - auc: 0.9883 - accuracy: 0.9686 - cost: 4.0074 - val_loss: 0.1205 - val_auc: 0.9819 - val_accuracy: 0.9652 - val_cost: 4.2806\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9883 - accuracy: 0.9685 - cost: 4.0186 - val_loss: 0.1224 - val_auc: 0.9809 - val_accuracy: 0.9649 - val_cost: 4.2969\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1010 - auc: 0.9886 - accuracy: 0.9687 - cost: 4.0126 - val_loss: 0.1198 - val_auc: 0.9815 - val_accuracy: 0.9672 - val_cost: 3.9779\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1005 - auc: 0.9885 - accuracy: 0.9697 - cost: 3.8822 - val_loss: 0.1204 - val_auc: 0.9816 - val_accuracy: 0.9653 - val_cost: 4.2611\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0994 - auc: 0.9884 - accuracy: 0.9694 - cost: 3.9016 - val_loss: 0.1196 - val_auc: 0.9823 - val_accuracy: 0.9660 - val_cost: 4.1504\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0990 - auc: 0.9886 - accuracy: 0.9697 - cost: 3.8708 - val_loss: 0.1172 - val_auc: 0.9826 - val_accuracy: 0.9666 - val_cost: 4.1602\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0982 - auc: 0.9886 - accuracy: 0.9697 - cost: 3.8692 - val_loss: 0.1203 - val_auc: 0.9817 - val_accuracy: 0.9658 - val_cost: 4.1895\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9890 - accuracy: 0.9704 - cost: 3.7896 - val_loss: 0.1179 - val_auc: 0.9821 - val_accuracy: 0.9667 - val_cost: 3.8867\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9888 - accuracy: 0.9706 - cost: 3.7595 - val_loss: 0.1200 - val_auc: 0.9821 - val_accuracy: 0.9673 - val_cost: 3.7728\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9887 - accuracy: 0.9709 - cost: 3.7129 - val_loss: 0.1173 - val_auc: 0.9818 - val_accuracy: 0.9665 - val_cost: 4.1764\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0951 - auc: 0.9892 - accuracy: 0.9711 - cost: 3.6921 - val_loss: 0.1173 - val_auc: 0.9819 - val_accuracy: 0.9667 - val_cost: 4.1341\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0952 - auc: 0.9893 - accuracy: 0.9712 - cost: 3.6918 - val_loss: 0.1174 - val_auc: 0.9824 - val_accuracy: 0.9669 - val_cost: 4.0625\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0954 - auc: 0.9894 - accuracy: 0.9710 - cost: 3.7139 - val_loss: 0.1166 - val_auc: 0.9823 - val_accuracy: 0.9685 - val_cost: 3.8021\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0939 - auc: 0.9894 - accuracy: 0.9718 - cost: 3.6162 - val_loss: 0.1167 - val_auc: 0.9821 - val_accuracy: 0.9679 - val_cost: 3.9128\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9893 - accuracy: 0.9717 - cost: 3.6321 - val_loss: 0.1167 - val_auc: 0.9824 - val_accuracy: 0.9663 - val_cost: 4.0299\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9892 - accuracy: 0.9716 - cost: 3.6410 - val_loss: 0.1175 - val_auc: 0.9829 - val_accuracy: 0.9686 - val_cost: 3.9062\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9895 - accuracy: 0.9722 - cost: 3.5577 - val_loss: 0.1169 - val_auc: 0.9818 - val_accuracy: 0.9682 - val_cost: 3.8477\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9895 - accuracy: 0.9722 - cost: 3.5435 - val_loss: 0.1158 - val_auc: 0.9823 - val_accuracy: 0.9685 - val_cost: 3.8607\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9897 - accuracy: 0.9728 - cost: 3.4949 - val_loss: 0.1166 - val_auc: 0.9822 - val_accuracy: 0.9682 - val_cost: 3.8249\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0918 - auc: 0.9896 - accuracy: 0.9720 - cost: 3.5956 - val_loss: 0.1161 - val_auc: 0.9820 - val_accuracy: 0.9677 - val_cost: 3.9518\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9898 - accuracy: 0.9726 - cost: 3.5041 - val_loss: 0.1164 - val_auc: 0.9825 - val_accuracy: 0.9686 - val_cost: 3.9030\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9898 - accuracy: 0.9729 - cost: 3.4795 - val_loss: 0.1152 - val_auc: 0.9820 - val_accuracy: 0.9685 - val_cost: 3.8737\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0911 - auc: 0.9897 - accuracy: 0.9730 - cost: 3.4551 - val_loss: 0.1143 - val_auc: 0.9825 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9900 - accuracy: 0.9732 - cost: 3.4398 - val_loss: 0.1159 - val_auc: 0.9827 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9897 - accuracy: 0.9732 - cost: 3.4500 - val_loss: 0.1152 - val_auc: 0.9824 - val_accuracy: 0.9676 - val_cost: 3.9421\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9902 - accuracy: 0.9733 - cost: 3.4077 - val_loss: 0.1154 - val_auc: 0.9824 - val_accuracy: 0.9694 - val_cost: 3.6751\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9901 - accuracy: 0.9733 - cost: 3.4269 - val_loss: 0.1154 - val_auc: 0.9813 - val_accuracy: 0.9681 - val_cost: 3.9453\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9899 - accuracy: 0.9735 - cost: 3.3939 - val_loss: 0.1131 - val_auc: 0.9829 - val_accuracy: 0.9692 - val_cost: 3.8281\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9902 - accuracy: 0.9740 - cost: 3.3514 - val_loss: 0.1127 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9902 - accuracy: 0.9740 - cost: 3.3294 - val_loss: 0.1137 - val_auc: 0.9831 - val_accuracy: 0.9693 - val_cost: 3.7663\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9901 - accuracy: 0.9739 - cost: 3.3556 - val_loss: 0.1122 - val_auc: 0.9828 - val_accuracy: 0.9697 - val_cost: 3.7565\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9902 - accuracy: 0.9739 - cost: 3.3485 - val_loss: 0.1116 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.8249\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9904 - accuracy: 0.9747 - cost: 3.2387 - val_loss: 0.1141 - val_auc: 0.9828 - val_accuracy: 0.9688 - val_cost: 4.0430\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9903 - accuracy: 0.9745 - cost: 3.2866 - val_loss: 0.1127 - val_auc: 0.9824 - val_accuracy: 0.9695 - val_cost: 3.6849\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0871 - auc: 0.9903 - accuracy: 0.9748 - cost: 3.2382 - val_loss: 0.1132 - val_auc: 0.9824 - val_accuracy: 0.9698 - val_cost: 3.6882\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0868 - auc: 0.9904 - accuracy: 0.9738 - cost: 3.3659 - val_loss: 0.1124 - val_auc: 0.9828 - val_accuracy: 0.9717 - val_cost: 3.6654\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0855 - auc: 0.9905 - accuracy: 0.9748 - cost: 3.2473 - val_loss: 0.1131 - val_auc: 0.9825 - val_accuracy: 0.9698 - val_cost: 3.7337\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9905 - accuracy: 0.9746 - cost: 3.2682 - val_loss: 0.1149 - val_auc: 0.9817 - val_accuracy: 0.9696 - val_cost: 3.6198\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9907 - accuracy: 0.9747 - cost: 3.2347 - val_loss: 0.1126 - val_auc: 0.9831 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9907 - accuracy: 0.9747 - cost: 3.2502 - val_loss: 0.1130 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9906 - accuracy: 0.9751 - cost: 3.2080 - val_loss: 0.1127 - val_auc: 0.9830 - val_accuracy: 0.9699 - val_cost: 3.8118\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0845 - auc: 0.9909 - accuracy: 0.9750 - cost: 3.2052 - val_loss: 0.1127 - val_auc: 0.9823 - val_accuracy: 0.9712 - val_cost: 3.6003\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9906 - accuracy: 0.9754 - cost: 3.1621 - val_loss: 0.1121 - val_auc: 0.9827 - val_accuracy: 0.9701 - val_cost: 3.6719\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9905 - accuracy: 0.9751 - cost: 3.2206 - val_loss: 0.1133 - val_auc: 0.9827 - val_accuracy: 0.9686 - val_cost: 3.7663\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9909 - accuracy: 0.9752 - cost: 3.1790 - val_loss: 0.1132 - val_auc: 0.9832 - val_accuracy: 0.9709 - val_cost: 3.6523\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0842 - auc: 0.9909 - accuracy: 0.9755 - cost: 3.1516 - val_loss: 0.1130 - val_auc: 0.9826 - val_accuracy: 0.9697 - val_cost: 3.7663\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9910 - accuracy: 0.9755 - cost: 3.1415 - val_loss: 0.1146 - val_auc: 0.9824 - val_accuracy: 0.9687 - val_cost: 3.9583\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9910 - accuracy: 0.9755 - cost: 3.1674 - val_loss: 0.1138 - val_auc: 0.9824 - val_accuracy: 0.9690 - val_cost: 3.8346\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9912 - accuracy: 0.9756 - cost: 3.1372 - val_loss: 0.1125 - val_auc: 0.9827 - val_accuracy: 0.9711 - val_cost: 3.5840\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9908 - accuracy: 0.9753 - cost: 3.1712 - val_loss: 0.1135 - val_auc: 0.9819 - val_accuracy: 0.9693 - val_cost: 3.8053\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9911 - accuracy: 0.9758 - cost: 3.1167 - val_loss: 0.1137 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.5872\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9911 - accuracy: 0.9759 - cost: 3.0927 - val_loss: 0.1165 - val_auc: 0.9821 - val_accuracy: 0.9692 - val_cost: 3.4928\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9910 - accuracy: 0.9756 - cost: 3.1277 - val_loss: 0.1141 - val_auc: 0.9826 - val_accuracy: 0.9694 - val_cost: 3.7760\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9911 - accuracy: 0.9768 - cost: 2.9859 - val_loss: 0.1124 - val_auc: 0.9829 - val_accuracy: 0.9702 - val_cost: 3.7467\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9911 - accuracy: 0.9756 - cost: 3.1464 - val_loss: 0.1128 - val_auc: 0.9830 - val_accuracy: 0.9701 - val_cost: 3.6816\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9909 - accuracy: 0.9758 - cost: 3.1109 - val_loss: 0.1144 - val_auc: 0.9825 - val_accuracy: 0.9695 - val_cost: 3.6719\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9912 - accuracy: 0.9762 - cost: 3.0472 - val_loss: 0.1147 - val_auc: 0.9828 - val_accuracy: 0.9703 - val_cost: 3.7305\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9912 - accuracy: 0.9764 - cost: 3.0297 - val_loss: 0.1128 - val_auc: 0.9824 - val_accuracy: 0.9696 - val_cost: 3.8314\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9911 - accuracy: 0.9762 - cost: 3.0610 - val_loss: 0.1140 - val_auc: 0.9824 - val_accuracy: 0.9707 - val_cost: 3.6621\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0723 - val_loss: 0.1137 - val_auc: 0.9828 - val_accuracy: 0.9707 - val_cost: 3.5417\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9910 - accuracy: 0.9763 - cost: 3.0408 - val_loss: 0.1154 - val_auc: 0.9822 - val_accuracy: 0.9697 - val_cost: 3.7272\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9912 - accuracy: 0.9763 - cost: 3.0461 - val_loss: 0.1126 - val_auc: 0.9829 - val_accuracy: 0.9710 - val_cost: 3.5905\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9914 - accuracy: 0.9765 - cost: 3.0299 - val_loss: 0.1147 - val_auc: 0.9828 - val_accuracy: 0.9704 - val_cost: 3.6100\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9914 - accuracy: 0.9769 - cost: 2.9724 - val_loss: 0.1136 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9914 - accuracy: 0.9764 - cost: 3.0314 - val_loss: 0.1148 - val_auc: 0.9829 - val_accuracy: 0.9717 - val_cost: 3.4440\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9911 - accuracy: 0.9763 - cost: 3.0474 - val_loss: 0.1159 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.6035\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9918 - accuracy: 0.9770 - cost: 2.9654 - val_loss: 0.1150 - val_auc: 0.9823 - val_accuracy: 0.9704 - val_cost: 3.6393\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9913 - accuracy: 0.9769 - cost: 2.9844 - val_loss: 0.1138 - val_auc: 0.9828 - val_accuracy: 0.9710 - val_cost: 3.5677\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9913 - accuracy: 0.9768 - cost: 2.9851 - val_loss: 0.1154 - val_auc: 0.9825 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0803 - auc: 0.9912 - accuracy: 0.9773 - cost: 2.9127 - val_loss: 0.1170 - val_auc: 0.9821 - val_accuracy: 0.9699 - val_cost: 3.7142\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9915 - accuracy: 0.9769 - cost: 2.9722 - val_loss: 0.1166 - val_auc: 0.9827 - val_accuracy: 0.9703 - val_cost: 3.6393\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9634 - val_loss: 0.1170 - val_auc: 0.9823 - val_accuracy: 0.9704 - val_cost: 3.6035\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9649 - val_loss: 0.1143 - val_auc: 0.9827 - val_accuracy: 0.9701 - val_cost: 3.7305\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9915 - accuracy: 0.9772 - cost: 2.9274 - val_loss: 0.1146 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9914 - accuracy: 0.9767 - cost: 3.0040 - val_loss: 0.1159 - val_auc: 0.9833 - val_accuracy: 0.9703 - val_cost: 3.6556\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9916 - accuracy: 0.9770 - cost: 2.9479 - val_loss: 0.1149 - val_auc: 0.9823 - val_accuracy: 0.9704 - val_cost: 3.6719\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9918 - accuracy: 0.9771 - cost: 2.9554 - val_loss: 0.1139 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.5970\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9916 - accuracy: 0.9768 - cost: 2.9962 - val_loss: 0.1171 - val_auc: 0.9818 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9918 - accuracy: 0.9775 - cost: 2.8992 - val_loss: 0.1151 - val_auc: 0.9831 - val_accuracy: 0.9699 - val_cost: 3.7891\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9770 - cost: 2.9484 - val_loss: 0.1183 - val_auc: 0.9828 - val_accuracy: 0.9702 - val_cost: 3.6230\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0785 - auc: 0.9918 - accuracy: 0.9770 - cost: 2.9616 - val_loss: 0.1143 - val_auc: 0.9832 - val_accuracy: 0.9711 - val_cost: 3.5710\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9916 - accuracy: 0.9775 - cost: 2.8880 - val_loss: 0.1156 - val_auc: 0.9822 - val_accuracy: 0.9703 - val_cost: 3.7044\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9917 - accuracy: 0.9775 - cost: 2.9014 - val_loss: 0.1179 - val_auc: 0.9826 - val_accuracy: 0.9701 - val_cost: 3.6751\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9916 - accuracy: 0.9775 - cost: 2.8988 - val_loss: 0.1158 - val_auc: 0.9824 - val_accuracy: 0.9706 - val_cost: 3.7240\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9917 - accuracy: 0.9780 - cost: 2.8391 - val_loss: 0.1171 - val_auc: 0.9823 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9058 - val_loss: 0.1157 - val_auc: 0.9829 - val_accuracy: 0.9715 - val_cost: 3.5124\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9918 - accuracy: 0.9775 - cost: 2.9037 - val_loss: 0.1142 - val_auc: 0.9826 - val_accuracy: 0.9707 - val_cost: 3.6784\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9917 - accuracy: 0.9774 - cost: 2.9108 - val_loss: 0.1171 - val_auc: 0.9827 - val_accuracy: 0.9704 - val_cost: 3.6654\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9919 - accuracy: 0.9776 - cost: 2.8805 - val_loss: 0.1159 - val_auc: 0.9825 - val_accuracy: 0.9719 - val_cost: 3.4245\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9918 - accuracy: 0.9775 - cost: 2.8960 - val_loss: 0.1170 - val_auc: 0.9822 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9920 - accuracy: 0.9775 - cost: 2.9108 - val_loss: 0.1194 - val_auc: 0.9816 - val_accuracy: 0.9698 - val_cost: 3.6556\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8618 - val_loss: 0.1184 - val_auc: 0.9821 - val_accuracy: 0.9702 - val_cost: 3.6165\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9920 - accuracy: 0.9780 - cost: 2.8484 - val_loss: 0.1175 - val_auc: 0.9823 - val_accuracy: 0.9711 - val_cost: 3.5742\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9917 - accuracy: 0.9772 - cost: 2.9440 - val_loss: 0.1190 - val_auc: 0.9822 - val_accuracy: 0.9694 - val_cost: 3.8053\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9915 - accuracy: 0.9776 - cost: 2.8966 - val_loss: 0.1178 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.5938\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9918 - accuracy: 0.9780 - cost: 2.8303 - val_loss: 0.1175 - val_auc: 0.9827 - val_accuracy: 0.9699 - val_cost: 3.7565\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9918 - accuracy: 0.9777 - cost: 2.8711 - val_loss: 0.1159 - val_auc: 0.9835 - val_accuracy: 0.9704 - val_cost: 3.7695\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9917 - accuracy: 0.9776 - cost: 2.8936 - val_loss: 0.1168 - val_auc: 0.9831 - val_accuracy: 0.9719 - val_cost: 3.4017\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9135 - val_loss: 0.1170 - val_auc: 0.9828 - val_accuracy: 0.9710 - val_cost: 3.4375\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9922 - accuracy: 0.9776 - cost: 2.8789 - val_loss: 0.1156 - val_auc: 0.9826 - val_accuracy: 0.9724 - val_cost: 3.3952\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9921 - accuracy: 0.9779 - cost: 2.8520 - val_loss: 0.1185 - val_auc: 0.9823 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9919 - accuracy: 0.9781 - cost: 2.8243 - val_loss: 0.1183 - val_auc: 0.9822 - val_accuracy: 0.9716 - val_cost: 3.5156\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9918 - accuracy: 0.9779 - cost: 2.8513 - val_loss: 0.1181 - val_auc: 0.9821 - val_accuracy: 0.9709 - val_cost: 3.5124\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9923 - accuracy: 0.9780 - cost: 2.8376 - val_loss: 0.1165 - val_auc: 0.9834 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9918 - accuracy: 0.9780 - cost: 2.8381 - val_loss: 0.1169 - val_auc: 0.9827 - val_accuracy: 0.9706 - val_cost: 3.6230\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9922 - accuracy: 0.9783 - cost: 2.7897 - val_loss: 0.1163 - val_auc: 0.9828 - val_accuracy: 0.9708 - val_cost: 3.5807\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9922 - accuracy: 0.9786 - cost: 2.7662 - val_loss: 0.1164 - val_auc: 0.9829 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9920 - accuracy: 0.9779 - cost: 2.8530 - val_loss: 0.1193 - val_auc: 0.9828 - val_accuracy: 0.9700 - val_cost: 3.6556\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9921 - accuracy: 0.9787 - cost: 2.7529 - val_loss: 0.1186 - val_auc: 0.9827 - val_accuracy: 0.9706 - val_cost: 3.5319\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9919 - accuracy: 0.9783 - cost: 2.8043 - val_loss: 0.1164 - val_auc: 0.9834 - val_accuracy: 0.9708 - val_cost: 3.6914\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9921 - accuracy: 0.9785 - cost: 2.7647 - val_loss: 0.1158 - val_auc: 0.9831 - val_accuracy: 0.9707 - val_cost: 3.6686\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9922 - accuracy: 0.9780 - cost: 2.8236 - val_loss: 0.1178 - val_auc: 0.9819 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8204 - val_loss: 0.1176 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.5319\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9923 - accuracy: 0.9784 - cost: 2.7953 - val_loss: 0.1155 - val_auc: 0.9825 - val_accuracy: 0.9725 - val_cost: 3.3952\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9924 - accuracy: 0.9787 - cost: 2.7501 - val_loss: 0.1178 - val_auc: 0.9832 - val_accuracy: 0.9705 - val_cost: 3.6784\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7516 - val_loss: 0.1178 - val_auc: 0.9825 - val_accuracy: 0.9706 - val_cost: 3.6035\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.8032 - val_loss: 0.1183 - val_auc: 0.9825 - val_accuracy: 0.9710 - val_cost: 3.5124\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7933 - val_loss: 0.1181 - val_auc: 0.9826 - val_accuracy: 0.9702 - val_cost: 3.6003\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9920 - accuracy: 0.9783 - cost: 2.7963 - val_loss: 0.1165 - val_auc: 0.9830 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9923 - accuracy: 0.9780 - cost: 2.8484 - val_loss: 0.1178 - val_auc: 0.9828 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9924 - accuracy: 0.9784 - cost: 2.7888 - val_loss: 0.1180 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.6393\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9922 - accuracy: 0.9779 - cost: 2.8654 - val_loss: 0.1165 - val_auc: 0.9832 - val_accuracy: 0.9707 - val_cost: 3.6426\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7404 - val_loss: 0.1172 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.6523\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7863 - val_loss: 0.1175 - val_auc: 0.9824 - val_accuracy: 0.9714 - val_cost: 3.4766\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9923 - accuracy: 0.9787 - cost: 2.7458 - val_loss: 0.1180 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.6068\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9922 - accuracy: 0.9780 - cost: 2.8492 - val_loss: 0.1192 - val_auc: 0.9823 - val_accuracy: 0.9713 - val_cost: 3.5221\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7399 - val_loss: 0.1171 - val_auc: 0.9831 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8205 - val_loss: 0.1212 - val_auc: 0.9816 - val_accuracy: 0.9699 - val_cost: 3.4668\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9921 - accuracy: 0.9786 - cost: 2.7445 - val_loss: 0.1190 - val_auc: 0.9825 - val_accuracy: 0.9700 - val_cost: 3.5938\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9787 - cost: 2.7518 - val_loss: 0.1171 - val_auc: 0.9826 - val_accuracy: 0.9705 - val_cost: 3.6133\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9921 - accuracy: 0.9791 - cost: 2.6984 - val_loss: 0.1178 - val_auc: 0.9826 - val_accuracy: 0.9706 - val_cost: 3.6458\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9924 - accuracy: 0.9785 - cost: 2.7794 - val_loss: 0.1180 - val_auc: 0.9828 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9922 - accuracy: 0.9785 - cost: 2.7799 - val_loss: 0.1172 - val_auc: 0.9823 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9925 - accuracy: 0.9783 - cost: 2.7936 - val_loss: 0.1156 - val_auc: 0.9827 - val_accuracy: 0.9717 - val_cost: 3.5514\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9924 - accuracy: 0.9787 - cost: 2.7513 - val_loss: 0.1167 - val_auc: 0.9830 - val_accuracy: 0.9706 - val_cost: 3.6426\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7245 - val_loss: 0.1198 - val_auc: 0.9821 - val_accuracy: 0.9713 - val_cost: 3.4896\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.7170 - val_loss: 0.1186 - val_auc: 0.9822 - val_accuracy: 0.9706 - val_cost: 3.5742\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9922 - accuracy: 0.9789 - cost: 2.7109 - val_loss: 0.1186 - val_auc: 0.9827 - val_accuracy: 0.9719 - val_cost: 3.5254\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6758 - val_loss: 0.1191 - val_auc: 0.9819 - val_accuracy: 0.9708 - val_cost: 3.5840\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.6876 - val_loss: 0.1166 - val_auc: 0.9828 - val_accuracy: 0.9715 - val_cost: 3.5221\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9926 - accuracy: 0.9786 - cost: 2.7685 - val_loss: 0.1188 - val_auc: 0.9821 - val_accuracy: 0.9714 - val_cost: 3.4733\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9924 - accuracy: 0.9784 - cost: 2.7873 - val_loss: 0.1166 - val_auc: 0.9829 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7282 - val_loss: 0.1172 - val_auc: 0.9824 - val_accuracy: 0.9717 - val_cost: 3.6654\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9922 - accuracy: 0.9783 - cost: 2.7976 - val_loss: 0.1192 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.4863\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7393 - val_loss: 0.1184 - val_auc: 0.9819 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.6971 - val_loss: 0.1176 - val_auc: 0.9825 - val_accuracy: 0.9711 - val_cost: 3.6003\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9924 - accuracy: 0.9797 - cost: 2.6262 - val_loss: 0.1191 - val_auc: 0.9823 - val_accuracy: 0.9713 - val_cost: 3.4863\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9925 - accuracy: 0.9789 - cost: 2.7244 - val_loss: 0.1189 - val_auc: 0.9822 - val_accuracy: 0.9722 - val_cost: 3.4277\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6714 - val_loss: 0.1180 - val_auc: 0.9822 - val_accuracy: 0.9721 - val_cost: 3.3919\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9925 - accuracy: 0.9793 - cost: 2.6646 - val_loss: 0.1194 - val_auc: 0.9828 - val_accuracy: 0.9709 - val_cost: 3.6035\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9922 - accuracy: 0.9795 - cost: 2.6416 - val_loss: 0.1184 - val_auc: 0.9827 - val_accuracy: 0.9717 - val_cost: 3.4766\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6558 - val_loss: 0.1206 - val_auc: 0.9819 - val_accuracy: 0.9714 - val_cost: 3.4342\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9922 - accuracy: 0.9786 - cost: 2.7493 - val_loss: 0.1185 - val_auc: 0.9827 - val_accuracy: 0.9707 - val_cost: 3.6068\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7636 - val_loss: 0.1176 - val_auc: 0.9826 - val_accuracy: 0.9711 - val_cost: 3.5970\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6781 - val_loss: 0.1162 - val_auc: 0.9831 - val_accuracy: 0.9715 - val_cost: 3.5124\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6787 - val_loss: 0.1195 - val_auc: 0.9826 - val_accuracy: 0.9708 - val_cost: 3.7142\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6699 - val_loss: 0.1211 - val_auc: 0.9820 - val_accuracy: 0.9703 - val_cost: 3.6621\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9921 - accuracy: 0.9787 - cost: 2.7520 - val_loss: 0.1197 - val_auc: 0.9821 - val_accuracy: 0.9711 - val_cost: 3.5384\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.6943 - val_loss: 0.1191 - val_auc: 0.9821 - val_accuracy: 0.9701 - val_cost: 3.6003\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.6797 - val_loss: 0.1164 - val_auc: 0.9827 - val_accuracy: 0.9719 - val_cost: 3.4831\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6424 - val_loss: 0.1156 - val_auc: 0.9826 - val_accuracy: 0.9712 - val_cost: 3.5970\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9927 - accuracy: 0.9788 - cost: 2.7333 - val_loss: 0.1179 - val_auc: 0.9825 - val_accuracy: 0.9714 - val_cost: 3.5775\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9927 - accuracy: 0.9798 - cost: 2.6056 - val_loss: 0.1197 - val_auc: 0.9823 - val_accuracy: 0.9711 - val_cost: 3.5156\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6764 - val_loss: 0.1199 - val_auc: 0.9822 - val_accuracy: 0.9714 - val_cost: 3.5449\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6835 - val_loss: 0.1194 - val_auc: 0.9825 - val_accuracy: 0.9711 - val_cost: 3.5905\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6291 - val_loss: 0.1187 - val_auc: 0.9822 - val_accuracy: 0.9720 - val_cost: 3.4212\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9925 - accuracy: 0.9797 - cost: 2.6168 - val_loss: 0.1180 - val_auc: 0.9823 - val_accuracy: 0.9718 - val_cost: 3.4603\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6899 - val_loss: 0.1210 - val_auc: 0.9823 - val_accuracy: 0.9715 - val_cost: 3.4993\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6432 - val_loss: 0.1169 - val_auc: 0.9831 - val_accuracy: 0.9722 - val_cost: 3.6100\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9794 - cost: 2.6654 - val_loss: 0.1190 - val_auc: 0.9830 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9929 - accuracy: 0.9787 - cost: 2.7553 - val_loss: 0.1187 - val_auc: 0.9821 - val_accuracy: 0.9726 - val_cost: 3.3887\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6820 - val_loss: 0.1172 - val_auc: 0.9831 - val_accuracy: 0.9712 - val_cost: 3.5579\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9925 - accuracy: 0.9796 - cost: 2.6311 - val_loss: 0.1199 - val_auc: 0.9820 - val_accuracy: 0.9708 - val_cost: 3.6198\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5887 - val_loss: 0.1178 - val_auc: 0.9831 - val_accuracy: 0.9721 - val_cost: 3.4831\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0718 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6212 - val_loss: 0.1178 - val_auc: 0.9826 - val_accuracy: 0.9716 - val_cost: 3.5124\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6540 - val_loss: 0.1224 - val_auc: 0.9821 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6184 - val_loss: 0.1183 - val_auc: 0.9824 - val_accuracy: 0.9716 - val_cost: 3.5026\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6529 - val_loss: 0.1188 - val_auc: 0.9822 - val_accuracy: 0.9712 - val_cost: 3.5807\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9927 - accuracy: 0.9793 - cost: 2.6656 - val_loss: 0.1186 - val_auc: 0.9828 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7411 - val_loss: 0.1172 - val_auc: 0.9833 - val_accuracy: 0.9722 - val_cost: 3.3594\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9924 - accuracy: 0.9792 - cost: 2.6900 - val_loss: 0.1222 - val_auc: 0.9822 - val_accuracy: 0.9708 - val_cost: 3.4896\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5827 - val_loss: 0.1208 - val_auc: 0.9823 - val_accuracy: 0.9707 - val_cost: 3.5547\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9923 - accuracy: 0.9796 - cost: 2.6489 - val_loss: 0.1193 - val_auc: 0.9821 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5976 - val_loss: 0.1201 - val_auc: 0.9819 - val_accuracy: 0.9723 - val_cost: 3.2975\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9924 - accuracy: 0.9795 - cost: 2.6460 - val_loss: 0.1185 - val_auc: 0.9831 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6776 - val_loss: 0.1200 - val_auc: 0.9828 - val_accuracy: 0.9719 - val_cost: 3.4115\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9926 - accuracy: 0.9792 - cost: 2.6838 - val_loss: 0.1196 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.5221\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6253 - val_loss: 0.1185 - val_auc: 0.9833 - val_accuracy: 0.9703 - val_cost: 3.6035\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6458 - val_loss: 0.1199 - val_auc: 0.9821 - val_accuracy: 0.9708 - val_cost: 3.5254\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6405 - val_loss: 0.1196 - val_auc: 0.9827 - val_accuracy: 0.9701 - val_cost: 3.6100\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9927 - accuracy: 0.9795 - cost: 2.6454 - val_loss: 0.1185 - val_auc: 0.9829 - val_accuracy: 0.9720 - val_cost: 3.3822\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9926 - accuracy: 0.9801 - cost: 2.5553 - val_loss: 0.1185 - val_auc: 0.9828 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9803 - cost: 2.5435 - val_loss: 0.1204 - val_auc: 0.9822 - val_accuracy: 0.9724 - val_cost: 3.3171\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9930 - accuracy: 0.9807 - cost: 2.4846 - val_loss: 0.1181 - val_auc: 0.9828 - val_accuracy: 0.9718 - val_cost: 3.4928\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6376 - val_loss: 0.1190 - val_auc: 0.9831 - val_accuracy: 0.9714 - val_cost: 3.5286\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9925 - accuracy: 0.9800 - cost: 2.5768 - val_loss: 0.1174 - val_auc: 0.9832 - val_accuracy: 0.9719 - val_cost: 3.4701\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9928 - accuracy: 0.9800 - cost: 2.5793 - val_loss: 0.1176 - val_auc: 0.9834 - val_accuracy: 0.9715 - val_cost: 3.5319\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9930 - accuracy: 0.9807 - cost: 2.4895 - val_loss: 0.1204 - val_auc: 0.9824 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9927 - accuracy: 0.9798 - cost: 2.5964 - val_loss: 0.1173 - val_auc: 0.9835 - val_accuracy: 0.9714 - val_cost: 3.7272\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5882 - val_loss: 0.1198 - val_auc: 0.9818 - val_accuracy: 0.9717 - val_cost: 3.4538\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6312 - val_loss: 0.1212 - val_auc: 0.9828 - val_accuracy: 0.9711 - val_cost: 3.5254\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6364 - val_loss: 0.1183 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.7044\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9927 - accuracy: 0.9796 - cost: 2.6410 - val_loss: 0.1206 - val_auc: 0.9828 - val_accuracy: 0.9714 - val_cost: 3.6491\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9929 - accuracy: 0.9794 - cost: 2.6689 - val_loss: 0.1191 - val_auc: 0.9824 - val_accuracy: 0.9709 - val_cost: 3.5417\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6142 - val_loss: 0.1174 - val_auc: 0.9827 - val_accuracy: 0.9724 - val_cost: 3.4180\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6096 - val_loss: 0.1181 - val_auc: 0.9821 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9932 - accuracy: 0.9796 - cost: 2.6337 - val_loss: 0.1171 - val_auc: 0.9828 - val_accuracy: 0.9721 - val_cost: 3.6003\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5612 - val_loss: 0.1198 - val_auc: 0.9825 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9930 - accuracy: 0.9803 - cost: 2.5380 - val_loss: 0.1208 - val_auc: 0.9821 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6434 - val_loss: 0.1198 - val_auc: 0.9815 - val_accuracy: 0.9716 - val_cost: 3.4505\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6253 - val_loss: 0.1232 - val_auc: 0.9818 - val_accuracy: 0.9709 - val_cost: 3.5352\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6183 - val_loss: 0.1214 - val_auc: 0.9822 - val_accuracy: 0.9713 - val_cost: 3.5482\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9930 - accuracy: 0.9794 - cost: 2.6612 - val_loss: 0.1216 - val_auc: 0.9818 - val_accuracy: 0.9707 - val_cost: 3.5254\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9802 - cost: 2.5608 - val_loss: 0.1187 - val_auc: 0.9823 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9794 - cost: 2.6647 - val_loss: 0.1200 - val_auc: 0.9821 - val_accuracy: 0.9708 - val_cost: 3.5449\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6134 - val_loss: 0.1228 - val_auc: 0.9821 - val_accuracy: 0.9708 - val_cost: 3.5059\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5660 - val_loss: 0.1210 - val_auc: 0.9822 - val_accuracy: 0.9708 - val_cost: 3.5352\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9801 - cost: 2.5641 - val_loss: 0.1201 - val_auc: 0.9827 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9805 - cost: 2.5227 - val_loss: 0.1193 - val_auc: 0.9835 - val_accuracy: 0.9717 - val_cost: 3.4733\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9928 - accuracy: 0.9799 - cost: 2.5991 - val_loss: 0.1207 - val_auc: 0.9826 - val_accuracy: 0.9710 - val_cost: 3.5742\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5506 - val_loss: 0.1200 - val_auc: 0.9817 - val_accuracy: 0.9717 - val_cost: 3.4863\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9930 - accuracy: 0.9801 - cost: 2.5783 - val_loss: 0.1206 - val_auc: 0.9819 - val_accuracy: 0.9714 - val_cost: 3.4993\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6120 - val_loss: 0.1198 - val_auc: 0.9817 - val_accuracy: 0.9713 - val_cost: 3.6458\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9930 - accuracy: 0.9797 - cost: 2.6294 - val_loss: 0.1182 - val_auc: 0.9823 - val_accuracy: 0.9715 - val_cost: 3.6621\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6196 - val_loss: 0.1169 - val_auc: 0.9826 - val_accuracy: 0.9719 - val_cost: 3.4375\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9934 - accuracy: 0.9801 - cost: 2.5678 - val_loss: 0.1203 - val_auc: 0.9822 - val_accuracy: 0.9721 - val_cost: 3.4277\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5572 - val_loss: 0.1240 - val_auc: 0.9823 - val_accuracy: 0.9714 - val_cost: 3.4049\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5430 - val_loss: 0.1198 - val_auc: 0.9827 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5869 - val_loss: 0.1207 - val_auc: 0.9822 - val_accuracy: 0.9715 - val_cost: 3.4375\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5518 - val_loss: 0.1225 - val_auc: 0.9816 - val_accuracy: 0.9698 - val_cost: 3.7142\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.5915 - val_loss: 0.1212 - val_auc: 0.9828 - val_accuracy: 0.9709 - val_cost: 3.7826\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5828 - val_loss: 0.1216 - val_auc: 0.9822 - val_accuracy: 0.9702 - val_cost: 3.6491\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6355 - val_loss: 0.1198 - val_auc: 0.9828 - val_accuracy: 0.9706 - val_cost: 3.6328\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.5861 - val_loss: 0.1206 - val_auc: 0.9822 - val_accuracy: 0.9703 - val_cost: 3.6003\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5348 - val_loss: 0.1191 - val_auc: 0.9824 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9928 - accuracy: 0.9801 - cost: 2.5826 - val_loss: 0.1209 - val_auc: 0.9824 - val_accuracy: 0.9711 - val_cost: 3.5970\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5891 - val_loss: 0.1198 - val_auc: 0.9825 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6217 - val_loss: 0.1216 - val_auc: 0.9823 - val_accuracy: 0.9704 - val_cost: 3.5352\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5840 - val_loss: 0.1205 - val_auc: 0.9822 - val_accuracy: 0.9709 - val_cost: 3.5221\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5256 - val_loss: 0.1188 - val_auc: 0.9821 - val_accuracy: 0.9712 - val_cost: 3.4896\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5759 - val_loss: 0.1196 - val_auc: 0.9829 - val_accuracy: 0.9709 - val_cost: 3.6296\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5899 - val_loss: 0.1217 - val_auc: 0.9829 - val_accuracy: 0.9704 - val_cost: 3.4538\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5414 - val_loss: 0.1202 - val_auc: 0.9822 - val_accuracy: 0.9710 - val_cost: 3.7207\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5329 - val_loss: 0.1226 - val_auc: 0.9821 - val_accuracy: 0.9710 - val_cost: 3.4961\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1009 - auc: 0.9869 - accuracy: 0.9726 - cost: 3.5094\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:48.463442\n",
            "fold accuracy: 0.9726250171661377 - fold cost: 3.5093750953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 3s 7ms/step - loss: 0.5426 - auc: 0.7143 - accuracy: 0.7179 - cost: 37.3215 - val_loss: 0.4068 - val_auc: 0.8546 - val_accuracy: 0.8234 - val_cost: 22.4056\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3650 - auc: 0.8784 - accuracy: 0.8438 - cost: 19.8780 - val_loss: 0.3179 - val_auc: 0.9091 - val_accuracy: 0.8653 - val_cost: 16.3835\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3152 - auc: 0.9104 - accuracy: 0.8691 - cost: 16.5779 - val_loss: 0.2903 - val_auc: 0.9257 - val_accuracy: 0.8791 - val_cost: 14.8014\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2877 - auc: 0.9261 - accuracy: 0.8829 - cost: 14.8147 - val_loss: 0.2676 - val_auc: 0.9390 - val_accuracy: 0.8910 - val_cost: 13.8704\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2654 - auc: 0.9374 - accuracy: 0.8943 - cost: 13.3930 - val_loss: 0.2477 - val_auc: 0.9470 - val_accuracy: 0.9023 - val_cost: 12.2656\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9456 - accuracy: 0.9023 - cost: 12.3756 - val_loss: 0.2321 - val_auc: 0.9533 - val_accuracy: 0.9108 - val_cost: 10.8529\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2327 - auc: 0.9515 - accuracy: 0.9103 - cost: 11.3392 - val_loss: 0.2187 - val_auc: 0.9586 - val_accuracy: 0.9177 - val_cost: 10.1725\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2186 - auc: 0.9575 - accuracy: 0.9162 - cost: 10.5966 - val_loss: 0.2074 - val_auc: 0.9618 - val_accuracy: 0.9229 - val_cost: 9.5215\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2067 - auc: 0.9619 - accuracy: 0.9221 - cost: 9.8701 - val_loss: 0.1948 - val_auc: 0.9660 - val_accuracy: 0.9292 - val_cost: 8.8086\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1962 - auc: 0.9651 - accuracy: 0.9270 - cost: 9.2483 - val_loss: 0.1871 - val_auc: 0.9676 - val_accuracy: 0.9303 - val_cost: 8.8021\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9684 - accuracy: 0.9309 - cost: 8.7671 - val_loss: 0.1789 - val_auc: 0.9703 - val_accuracy: 0.9363 - val_cost: 8.3594\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1797 - auc: 0.9704 - accuracy: 0.9350 - cost: 8.2680 - val_loss: 0.1719 - val_auc: 0.9719 - val_accuracy: 0.9384 - val_cost: 7.7018\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1749 - auc: 0.9720 - accuracy: 0.9365 - cost: 8.0450 - val_loss: 0.1661 - val_auc: 0.9739 - val_accuracy: 0.9404 - val_cost: 7.9134\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1678 - auc: 0.9739 - accuracy: 0.9395 - cost: 7.7052 - val_loss: 0.1644 - val_auc: 0.9745 - val_accuracy: 0.9419 - val_cost: 7.0671\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1632 - auc: 0.9753 - accuracy: 0.9425 - cost: 7.2994 - val_loss: 0.1592 - val_auc: 0.9756 - val_accuracy: 0.9427 - val_cost: 7.5065\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1577 - auc: 0.9767 - accuracy: 0.9442 - cost: 7.1010 - val_loss: 0.1546 - val_auc: 0.9766 - val_accuracy: 0.9477 - val_cost: 6.7578\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1549 - auc: 0.9773 - accuracy: 0.9462 - cost: 6.8483 - val_loss: 0.1530 - val_auc: 0.9773 - val_accuracy: 0.9479 - val_cost: 6.5104\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1504 - auc: 0.9785 - accuracy: 0.9479 - cost: 6.6238 - val_loss: 0.1477 - val_auc: 0.9780 - val_accuracy: 0.9483 - val_cost: 6.7546\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1466 - auc: 0.9795 - accuracy: 0.9489 - cost: 6.5149 - val_loss: 0.1467 - val_auc: 0.9787 - val_accuracy: 0.9503 - val_cost: 6.1686\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1448 - auc: 0.9798 - accuracy: 0.9496 - cost: 6.4376 - val_loss: 0.1440 - val_auc: 0.9790 - val_accuracy: 0.9510 - val_cost: 6.0938\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1410 - auc: 0.9804 - accuracy: 0.9522 - cost: 6.1019 - val_loss: 0.1419 - val_auc: 0.9794 - val_accuracy: 0.9519 - val_cost: 6.0482\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1395 - auc: 0.9810 - accuracy: 0.9531 - cost: 5.9525 - val_loss: 0.1383 - val_auc: 0.9805 - val_accuracy: 0.9532 - val_cost: 6.1654\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9818 - accuracy: 0.9539 - cost: 5.8745 - val_loss: 0.1369 - val_auc: 0.9809 - val_accuracy: 0.9533 - val_cost: 6.3281\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1340 - auc: 0.9819 - accuracy: 0.9542 - cost: 5.8323 - val_loss: 0.1357 - val_auc: 0.9806 - val_accuracy: 0.9542 - val_cost: 6.1882\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1310 - auc: 0.9828 - accuracy: 0.9564 - cost: 5.5368 - val_loss: 0.1328 - val_auc: 0.9812 - val_accuracy: 0.9561 - val_cost: 5.8203\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1282 - auc: 0.9834 - accuracy: 0.9569 - cost: 5.4929 - val_loss: 0.1332 - val_auc: 0.9815 - val_accuracy: 0.9567 - val_cost: 5.5176\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1274 - auc: 0.9833 - accuracy: 0.9576 - cost: 5.4093 - val_loss: 0.1305 - val_auc: 0.9819 - val_accuracy: 0.9570 - val_cost: 5.9180\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9838 - accuracy: 0.9587 - cost: 5.2608 - val_loss: 0.1279 - val_auc: 0.9826 - val_accuracy: 0.9587 - val_cost: 5.4688\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1222 - auc: 0.9844 - accuracy: 0.9606 - cost: 5.0273 - val_loss: 0.1258 - val_auc: 0.9827 - val_accuracy: 0.9596 - val_cost: 5.2767\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1210 - auc: 0.9849 - accuracy: 0.9609 - cost: 4.9769 - val_loss: 0.1259 - val_auc: 0.9825 - val_accuracy: 0.9585 - val_cost: 5.4167\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1193 - auc: 0.9851 - accuracy: 0.9611 - cost: 4.9498 - val_loss: 0.1239 - val_auc: 0.9830 - val_accuracy: 0.9607 - val_cost: 5.2344\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1185 - auc: 0.9853 - accuracy: 0.9613 - cost: 4.9298 - val_loss: 0.1235 - val_auc: 0.9827 - val_accuracy: 0.9610 - val_cost: 5.0781\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1168 - auc: 0.9855 - accuracy: 0.9626 - cost: 4.7547 - val_loss: 0.1233 - val_auc: 0.9828 - val_accuracy: 0.9606 - val_cost: 5.3255\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1149 - auc: 0.9858 - accuracy: 0.9629 - cost: 4.7437 - val_loss: 0.1220 - val_auc: 0.9831 - val_accuracy: 0.9617 - val_cost: 4.9772\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1142 - auc: 0.9858 - accuracy: 0.9634 - cost: 4.6767 - val_loss: 0.1204 - val_auc: 0.9836 - val_accuracy: 0.9620 - val_cost: 4.9512\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1122 - auc: 0.9863 - accuracy: 0.9642 - cost: 4.5623 - val_loss: 0.1190 - val_auc: 0.9836 - val_accuracy: 0.9637 - val_cost: 4.8112\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1106 - auc: 0.9866 - accuracy: 0.9649 - cost: 4.4727 - val_loss: 0.1192 - val_auc: 0.9835 - val_accuracy: 0.9619 - val_cost: 5.0260\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1096 - auc: 0.9869 - accuracy: 0.9653 - cost: 4.4246 - val_loss: 0.1183 - val_auc: 0.9838 - val_accuracy: 0.9631 - val_cost: 4.9089\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9871 - accuracy: 0.9653 - cost: 4.4367 - val_loss: 0.1188 - val_auc: 0.9839 - val_accuracy: 0.9634 - val_cost: 4.6582\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1078 - auc: 0.9870 - accuracy: 0.9666 - cost: 4.2646 - val_loss: 0.1154 - val_auc: 0.9844 - val_accuracy: 0.9635 - val_cost: 4.7559\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9872 - accuracy: 0.9670 - cost: 4.2161 - val_loss: 0.1156 - val_auc: 0.9845 - val_accuracy: 0.9644 - val_cost: 4.6029\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1065 - auc: 0.9872 - accuracy: 0.9667 - cost: 4.2557 - val_loss: 0.1165 - val_auc: 0.9843 - val_accuracy: 0.9626 - val_cost: 5.0000\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1045 - auc: 0.9879 - accuracy: 0.9677 - cost: 4.1326 - val_loss: 0.1147 - val_auc: 0.9844 - val_accuracy: 0.9642 - val_cost: 4.6191\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9877 - accuracy: 0.9674 - cost: 4.1685 - val_loss: 0.1147 - val_auc: 0.9843 - val_accuracy: 0.9655 - val_cost: 4.3783\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9877 - accuracy: 0.9679 - cost: 4.1107 - val_loss: 0.1153 - val_auc: 0.9843 - val_accuracy: 0.9638 - val_cost: 4.3620\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9880 - accuracy: 0.9683 - cost: 4.0520 - val_loss: 0.1131 - val_auc: 0.9848 - val_accuracy: 0.9657 - val_cost: 4.3913\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1021 - auc: 0.9883 - accuracy: 0.9685 - cost: 4.0305 - val_loss: 0.1140 - val_auc: 0.9848 - val_accuracy: 0.9658 - val_cost: 4.2513\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9881 - accuracy: 0.9693 - cost: 3.9271 - val_loss: 0.1108 - val_auc: 0.9852 - val_accuracy: 0.9673 - val_cost: 4.3001\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9879 - accuracy: 0.9690 - cost: 3.9661 - val_loss: 0.1111 - val_auc: 0.9851 - val_accuracy: 0.9669 - val_cost: 4.3034\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0987 - auc: 0.9887 - accuracy: 0.9700 - cost: 3.8361 - val_loss: 0.1107 - val_auc: 0.9850 - val_accuracy: 0.9669 - val_cost: 4.4010\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9883 - accuracy: 0.9693 - cost: 3.9250 - val_loss: 0.1116 - val_auc: 0.9850 - val_accuracy: 0.9667 - val_cost: 4.5345\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0983 - auc: 0.9885 - accuracy: 0.9705 - cost: 3.7840 - val_loss: 0.1113 - val_auc: 0.9849 - val_accuracy: 0.9660 - val_cost: 4.3945\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9884 - accuracy: 0.9699 - cost: 3.8446 - val_loss: 0.1107 - val_auc: 0.9853 - val_accuracy: 0.9665 - val_cost: 4.3132\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0976 - auc: 0.9886 - accuracy: 0.9705 - cost: 3.7668 - val_loss: 0.1104 - val_auc: 0.9855 - val_accuracy: 0.9672 - val_cost: 4.1699\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9889 - accuracy: 0.9706 - cost: 3.7629 - val_loss: 0.1109 - val_auc: 0.9849 - val_accuracy: 0.9658 - val_cost: 4.1732\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0958 - auc: 0.9889 - accuracy: 0.9710 - cost: 3.7129 - val_loss: 0.1100 - val_auc: 0.9852 - val_accuracy: 0.9675 - val_cost: 4.0951\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9890 - accuracy: 0.9714 - cost: 3.6722 - val_loss: 0.1088 - val_auc: 0.9853 - val_accuracy: 0.9677 - val_cost: 4.1992\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9890 - accuracy: 0.9715 - cost: 3.6442 - val_loss: 0.1102 - val_auc: 0.9855 - val_accuracy: 0.9669 - val_cost: 4.2122\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0948 - auc: 0.9892 - accuracy: 0.9711 - cost: 3.7034 - val_loss: 0.1112 - val_auc: 0.9850 - val_accuracy: 0.9672 - val_cost: 4.2643\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0934 - auc: 0.9894 - accuracy: 0.9718 - cost: 3.6246 - val_loss: 0.1094 - val_auc: 0.9854 - val_accuracy: 0.9678 - val_cost: 4.2318\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0943 - auc: 0.9893 - accuracy: 0.9717 - cost: 3.6196 - val_loss: 0.1087 - val_auc: 0.9855 - val_accuracy: 0.9670 - val_cost: 4.2383\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0935 - auc: 0.9892 - accuracy: 0.9722 - cost: 3.5472 - val_loss: 0.1083 - val_auc: 0.9855 - val_accuracy: 0.9681 - val_cost: 3.9648\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0926 - auc: 0.9895 - accuracy: 0.9725 - cost: 3.5120 - val_loss: 0.1082 - val_auc: 0.9859 - val_accuracy: 0.9679 - val_cost: 4.3815\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9896 - accuracy: 0.9724 - cost: 3.5376 - val_loss: 0.1085 - val_auc: 0.9860 - val_accuracy: 0.9676 - val_cost: 4.3880\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9895 - accuracy: 0.9726 - cost: 3.5114 - val_loss: 0.1097 - val_auc: 0.9854 - val_accuracy: 0.9680 - val_cost: 4.0202\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9898 - accuracy: 0.9727 - cost: 3.5156 - val_loss: 0.1095 - val_auc: 0.9855 - val_accuracy: 0.9675 - val_cost: 4.2057\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9898 - accuracy: 0.9729 - cost: 3.4718 - val_loss: 0.1086 - val_auc: 0.9855 - val_accuracy: 0.9683 - val_cost: 4.0397\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9897 - accuracy: 0.9731 - cost: 3.4463 - val_loss: 0.1090 - val_auc: 0.9851 - val_accuracy: 0.9687 - val_cost: 4.0918\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9898 - accuracy: 0.9730 - cost: 3.4646 - val_loss: 0.1084 - val_auc: 0.9852 - val_accuracy: 0.9690 - val_cost: 4.0951\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9902 - accuracy: 0.9732 - cost: 3.4314 - val_loss: 0.1078 - val_auc: 0.9855 - val_accuracy: 0.9677 - val_cost: 4.2448\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9902 - accuracy: 0.9734 - cost: 3.4151 - val_loss: 0.1072 - val_auc: 0.9852 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9899 - accuracy: 0.9731 - cost: 3.4511 - val_loss: 0.1080 - val_auc: 0.9854 - val_accuracy: 0.9685 - val_cost: 4.2969\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0901 - auc: 0.9900 - accuracy: 0.9735 - cost: 3.3973 - val_loss: 0.1113 - val_auc: 0.9850 - val_accuracy: 0.9677 - val_cost: 4.2708\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9905 - accuracy: 0.9739 - cost: 3.3287 - val_loss: 0.1082 - val_auc: 0.9855 - val_accuracy: 0.9696 - val_cost: 3.8835\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9902 - accuracy: 0.9742 - cost: 3.3117 - val_loss: 0.1088 - val_auc: 0.9853 - val_accuracy: 0.9680 - val_cost: 4.2350\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9903 - accuracy: 0.9740 - cost: 3.3469 - val_loss: 0.1074 - val_auc: 0.9856 - val_accuracy: 0.9688 - val_cost: 4.0462\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0886 - auc: 0.9901 - accuracy: 0.9740 - cost: 3.3300 - val_loss: 0.1073 - val_auc: 0.9853 - val_accuracy: 0.9692 - val_cost: 4.0267\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9901 - accuracy: 0.9741 - cost: 3.3312 - val_loss: 0.1069 - val_auc: 0.9857 - val_accuracy: 0.9693 - val_cost: 3.9258\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9903 - accuracy: 0.9741 - cost: 3.3266 - val_loss: 0.1073 - val_auc: 0.9855 - val_accuracy: 0.9690 - val_cost: 4.2415\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9907 - accuracy: 0.9747 - cost: 3.2504 - val_loss: 0.1097 - val_auc: 0.9852 - val_accuracy: 0.9688 - val_cost: 3.8737\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9907 - accuracy: 0.9745 - cost: 3.2781 - val_loss: 0.1063 - val_auc: 0.9863 - val_accuracy: 0.9702 - val_cost: 3.8997\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0865 - auc: 0.9903 - accuracy: 0.9749 - cost: 3.2316 - val_loss: 0.1076 - val_auc: 0.9853 - val_accuracy: 0.9689 - val_cost: 4.0365\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0852 - auc: 0.9908 - accuracy: 0.9751 - cost: 3.1916 - val_loss: 0.1074 - val_auc: 0.9852 - val_accuracy: 0.9704 - val_cost: 3.8574\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0864 - auc: 0.9905 - accuracy: 0.9751 - cost: 3.1996 - val_loss: 0.1073 - val_auc: 0.9853 - val_accuracy: 0.9699 - val_cost: 3.8379\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9907 - accuracy: 0.9749 - cost: 3.2203 - val_loss: 0.1066 - val_auc: 0.9858 - val_accuracy: 0.9701 - val_cost: 3.8444\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9908 - accuracy: 0.9756 - cost: 3.1314 - val_loss: 0.1088 - val_auc: 0.9856 - val_accuracy: 0.9693 - val_cost: 3.8021\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9908 - accuracy: 0.9749 - cost: 3.2275 - val_loss: 0.1080 - val_auc: 0.9851 - val_accuracy: 0.9707 - val_cost: 3.7663\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9910 - accuracy: 0.9751 - cost: 3.1972 - val_loss: 0.1089 - val_auc: 0.9858 - val_accuracy: 0.9698 - val_cost: 3.8151\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9909 - accuracy: 0.9751 - cost: 3.1876 - val_loss: 0.1068 - val_auc: 0.9856 - val_accuracy: 0.9696 - val_cost: 3.8672\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9913 - accuracy: 0.9754 - cost: 3.1659 - val_loss: 0.1072 - val_auc: 0.9859 - val_accuracy: 0.9688 - val_cost: 4.0267\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9908 - accuracy: 0.9750 - cost: 3.2155 - val_loss: 0.1086 - val_auc: 0.9851 - val_accuracy: 0.9683 - val_cost: 4.0267\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9912 - accuracy: 0.9752 - cost: 3.2006 - val_loss: 0.1064 - val_auc: 0.9857 - val_accuracy: 0.9707 - val_cost: 3.7598\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9911 - accuracy: 0.9755 - cost: 3.1463 - val_loss: 0.1071 - val_auc: 0.9857 - val_accuracy: 0.9699 - val_cost: 3.9030\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9908 - accuracy: 0.9757 - cost: 3.1235 - val_loss: 0.1063 - val_auc: 0.9859 - val_accuracy: 0.9712 - val_cost: 3.7305\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9912 - accuracy: 0.9755 - cost: 3.1375 - val_loss: 0.1060 - val_auc: 0.9863 - val_accuracy: 0.9703 - val_cost: 3.7891\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9909 - accuracy: 0.9755 - cost: 3.1495 - val_loss: 0.1068 - val_auc: 0.9858 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9911 - accuracy: 0.9761 - cost: 3.0664 - val_loss: 0.1068 - val_auc: 0.9858 - val_accuracy: 0.9699 - val_cost: 3.9518\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9915 - accuracy: 0.9758 - cost: 3.1094 - val_loss: 0.1066 - val_auc: 0.9850 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0831 - auc: 0.9912 - accuracy: 0.9758 - cost: 3.1048 - val_loss: 0.1070 - val_auc: 0.9857 - val_accuracy: 0.9701 - val_cost: 3.9095\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9912 - accuracy: 0.9764 - cost: 3.0307 - val_loss: 0.1074 - val_auc: 0.9858 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0813 - auc: 0.9914 - accuracy: 0.9764 - cost: 3.0461 - val_loss: 0.1089 - val_auc: 0.9856 - val_accuracy: 0.9704 - val_cost: 3.8639\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9915 - accuracy: 0.9760 - cost: 3.0860 - val_loss: 0.1067 - val_auc: 0.9859 - val_accuracy: 0.9703 - val_cost: 3.7728\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0812 - auc: 0.9914 - accuracy: 0.9766 - cost: 3.0022 - val_loss: 0.1067 - val_auc: 0.9862 - val_accuracy: 0.9704 - val_cost: 3.8346\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9917 - accuracy: 0.9763 - cost: 3.0408 - val_loss: 0.1065 - val_auc: 0.9862 - val_accuracy: 0.9701 - val_cost: 3.8542\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9912 - accuracy: 0.9761 - cost: 3.0721 - val_loss: 0.1068 - val_auc: 0.9858 - val_accuracy: 0.9709 - val_cost: 3.7533\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0809 - auc: 0.9915 - accuracy: 0.9768 - cost: 2.9907 - val_loss: 0.1075 - val_auc: 0.9854 - val_accuracy: 0.9697 - val_cost: 3.9030\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9916 - accuracy: 0.9766 - cost: 3.0133 - val_loss: 0.1086 - val_auc: 0.9857 - val_accuracy: 0.9696 - val_cost: 3.9714\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9914 - accuracy: 0.9766 - cost: 3.0049 - val_loss: 0.1090 - val_auc: 0.9858 - val_accuracy: 0.9699 - val_cost: 3.8379\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9912 - accuracy: 0.9763 - cost: 3.0450 - val_loss: 0.1099 - val_auc: 0.9850 - val_accuracy: 0.9702 - val_cost: 3.9258\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9913 - accuracy: 0.9766 - cost: 3.0176 - val_loss: 0.1074 - val_auc: 0.9860 - val_accuracy: 0.9707 - val_cost: 3.7760\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9914 - accuracy: 0.9770 - cost: 2.9405 - val_loss: 0.1079 - val_auc: 0.9859 - val_accuracy: 0.9708 - val_cost: 3.7956\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9914 - accuracy: 0.9767 - cost: 3.0238 - val_loss: 0.1084 - val_auc: 0.9857 - val_accuracy: 0.9700 - val_cost: 3.7891\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9917 - accuracy: 0.9769 - cost: 2.9651 - val_loss: 0.1086 - val_auc: 0.9857 - val_accuracy: 0.9705 - val_cost: 3.8314\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9916 - accuracy: 0.9766 - cost: 3.0206 - val_loss: 0.1079 - val_auc: 0.9854 - val_accuracy: 0.9699 - val_cost: 3.8639\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9915 - accuracy: 0.9771 - cost: 2.9478 - val_loss: 0.1085 - val_auc: 0.9854 - val_accuracy: 0.9695 - val_cost: 3.9779\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9915 - accuracy: 0.9771 - cost: 2.9462 - val_loss: 0.1087 - val_auc: 0.9856 - val_accuracy: 0.9695 - val_cost: 3.8672\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9917 - accuracy: 0.9771 - cost: 2.9492 - val_loss: 0.1077 - val_auc: 0.9856 - val_accuracy: 0.9706 - val_cost: 3.8216\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9918 - accuracy: 0.9764 - cost: 3.0487 - val_loss: 0.1056 - val_auc: 0.9855 - val_accuracy: 0.9708 - val_cost: 3.8249\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9916 - accuracy: 0.9771 - cost: 2.9505 - val_loss: 0.1091 - val_auc: 0.9854 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.8930 - val_loss: 0.1090 - val_auc: 0.9851 - val_accuracy: 0.9703 - val_cost: 3.9030\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9917 - accuracy: 0.9772 - cost: 2.9401 - val_loss: 0.1100 - val_auc: 0.9850 - val_accuracy: 0.9704 - val_cost: 3.6589\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9915 - accuracy: 0.9771 - cost: 2.9566 - val_loss: 0.1104 - val_auc: 0.9853 - val_accuracy: 0.9697 - val_cost: 3.7956\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9914 - accuracy: 0.9773 - cost: 2.9101 - val_loss: 0.1079 - val_auc: 0.9854 - val_accuracy: 0.9698 - val_cost: 3.8477\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9918 - accuracy: 0.9772 - cost: 2.9275 - val_loss: 0.1056 - val_auc: 0.9857 - val_accuracy: 0.9714 - val_cost: 3.7305\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9918 - accuracy: 0.9772 - cost: 2.9351 - val_loss: 0.1062 - val_auc: 0.9856 - val_accuracy: 0.9712 - val_cost: 3.7923\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0785 - auc: 0.9920 - accuracy: 0.9773 - cost: 2.9329 - val_loss: 0.1096 - val_auc: 0.9850 - val_accuracy: 0.9708 - val_cost: 3.7370\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9918 - accuracy: 0.9773 - cost: 2.9196 - val_loss: 0.1098 - val_auc: 0.9862 - val_accuracy: 0.9699 - val_cost: 4.0169\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9919 - accuracy: 0.9775 - cost: 2.9076 - val_loss: 0.1085 - val_auc: 0.9856 - val_accuracy: 0.9713 - val_cost: 3.7891\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0783 - auc: 0.9920 - accuracy: 0.9776 - cost: 2.8797 - val_loss: 0.1079 - val_auc: 0.9859 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0780 - auc: 0.9918 - accuracy: 0.9775 - cost: 2.8947 - val_loss: 0.1066 - val_auc: 0.9858 - val_accuracy: 0.9719 - val_cost: 3.6491\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9915 - accuracy: 0.9772 - cost: 2.9170 - val_loss: 0.1083 - val_auc: 0.9857 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9919 - accuracy: 0.9774 - cost: 2.8981 - val_loss: 0.1067 - val_auc: 0.9862 - val_accuracy: 0.9706 - val_cost: 3.7207\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9918 - accuracy: 0.9772 - cost: 2.9340 - val_loss: 0.1078 - val_auc: 0.9859 - val_accuracy: 0.9716 - val_cost: 3.7077\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9917 - accuracy: 0.9771 - cost: 2.9487 - val_loss: 0.1094 - val_auc: 0.9855 - val_accuracy: 0.9695 - val_cost: 3.9746\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9918 - accuracy: 0.9776 - cost: 2.8840 - val_loss: 0.1101 - val_auc: 0.9860 - val_accuracy: 0.9703 - val_cost: 3.7826\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9920 - accuracy: 0.9775 - cost: 2.9073 - val_loss: 0.1071 - val_auc: 0.9862 - val_accuracy: 0.9708 - val_cost: 3.8444\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8692 - val_loss: 0.1088 - val_auc: 0.9858 - val_accuracy: 0.9698 - val_cost: 3.8477\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9920 - accuracy: 0.9781 - cost: 2.8174 - val_loss: 0.1060 - val_auc: 0.9864 - val_accuracy: 0.9703 - val_cost: 3.8737\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9918 - accuracy: 0.9773 - cost: 2.9233 - val_loss: 0.1078 - val_auc: 0.9857 - val_accuracy: 0.9712 - val_cost: 3.6947\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9919 - accuracy: 0.9784 - cost: 2.7804 - val_loss: 0.1079 - val_auc: 0.9855 - val_accuracy: 0.9706 - val_cost: 3.8184\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9921 - accuracy: 0.9779 - cost: 2.8484 - val_loss: 0.1083 - val_auc: 0.9856 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9918 - accuracy: 0.9777 - cost: 2.8777 - val_loss: 0.1093 - val_auc: 0.9859 - val_accuracy: 0.9703 - val_cost: 3.6133\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9923 - accuracy: 0.9776 - cost: 2.8803 - val_loss: 0.1100 - val_auc: 0.9854 - val_accuracy: 0.9696 - val_cost: 3.8932\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9922 - accuracy: 0.9782 - cost: 2.8166 - val_loss: 0.1077 - val_auc: 0.9860 - val_accuracy: 0.9708 - val_cost: 3.7728\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9921 - accuracy: 0.9778 - cost: 2.8489 - val_loss: 0.1079 - val_auc: 0.9856 - val_accuracy: 0.9708 - val_cost: 3.7891\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9919 - accuracy: 0.9780 - cost: 2.8316 - val_loss: 0.1112 - val_auc: 0.9852 - val_accuracy: 0.9712 - val_cost: 3.6491\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0776 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8665 - val_loss: 0.1089 - val_auc: 0.9860 - val_accuracy: 0.9703 - val_cost: 3.9160\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0776 - auc: 0.9922 - accuracy: 0.9774 - cost: 2.9193 - val_loss: 0.1087 - val_auc: 0.9848 - val_accuracy: 0.9705 - val_cost: 3.7500\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0769 - auc: 0.9921 - accuracy: 0.9778 - cost: 2.8619 - val_loss: 0.1081 - val_auc: 0.9862 - val_accuracy: 0.9700 - val_cost: 3.8770\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8238 - val_loss: 0.1095 - val_auc: 0.9857 - val_accuracy: 0.9703 - val_cost: 3.8281\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0758 - auc: 0.9923 - accuracy: 0.9781 - cost: 2.8232 - val_loss: 0.1056 - val_auc: 0.9858 - val_accuracy: 0.9721 - val_cost: 3.6621\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0767 - auc: 0.9918 - accuracy: 0.9785 - cost: 2.7712 - val_loss: 0.1073 - val_auc: 0.9860 - val_accuracy: 0.9723 - val_cost: 3.5221\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0766 - auc: 0.9918 - accuracy: 0.9780 - cost: 2.8455 - val_loss: 0.1099 - val_auc: 0.9857 - val_accuracy: 0.9706 - val_cost: 3.7728\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8150 - val_loss: 0.1093 - val_auc: 0.9860 - val_accuracy: 0.9707 - val_cost: 3.8053\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9921 - accuracy: 0.9780 - cost: 2.8364 - val_loss: 0.1090 - val_auc: 0.9858 - val_accuracy: 0.9706 - val_cost: 3.8997\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9920 - accuracy: 0.9777 - cost: 2.8694 - val_loss: 0.1092 - val_auc: 0.9860 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.7982 - val_loss: 0.1088 - val_auc: 0.9864 - val_accuracy: 0.9705 - val_cost: 3.8704\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9922 - accuracy: 0.9783 - cost: 2.7944 - val_loss: 0.1104 - val_auc: 0.9856 - val_accuracy: 0.9701 - val_cost: 3.8802\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9921 - accuracy: 0.9782 - cost: 2.8196 - val_loss: 0.1087 - val_auc: 0.9853 - val_accuracy: 0.9706 - val_cost: 3.7858\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9923 - accuracy: 0.9787 - cost: 2.7490 - val_loss: 0.1101 - val_auc: 0.9856 - val_accuracy: 0.9706 - val_cost: 3.7663\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9923 - accuracy: 0.9783 - cost: 2.8149 - val_loss: 0.1113 - val_auc: 0.9861 - val_accuracy: 0.9707 - val_cost: 3.7370\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7410 - val_loss: 0.1104 - val_auc: 0.9859 - val_accuracy: 0.9705 - val_cost: 3.7077\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9922 - accuracy: 0.9781 - cost: 2.8266 - val_loss: 0.1078 - val_auc: 0.9861 - val_accuracy: 0.9724 - val_cost: 3.6035\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9922 - accuracy: 0.9789 - cost: 2.7141 - val_loss: 0.1105 - val_auc: 0.9856 - val_accuracy: 0.9699 - val_cost: 3.9616\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9924 - accuracy: 0.9782 - cost: 2.8075 - val_loss: 0.1115 - val_auc: 0.9856 - val_accuracy: 0.9701 - val_cost: 3.8574\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7660 - val_loss: 0.1102 - val_auc: 0.9851 - val_accuracy: 0.9701 - val_cost: 3.8216\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9920 - accuracy: 0.9788 - cost: 2.7509 - val_loss: 0.1128 - val_auc: 0.9846 - val_accuracy: 0.9691 - val_cost: 3.9355\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7358 - val_loss: 0.1126 - val_auc: 0.9854 - val_accuracy: 0.9705 - val_cost: 3.7695\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9926 - accuracy: 0.9788 - cost: 2.7455 - val_loss: 0.1121 - val_auc: 0.9852 - val_accuracy: 0.9714 - val_cost: 3.6003\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9920 - accuracy: 0.9787 - cost: 2.7490 - val_loss: 0.1097 - val_auc: 0.9855 - val_accuracy: 0.9710 - val_cost: 3.6947\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0748 - auc: 0.9922 - accuracy: 0.9790 - cost: 2.7097 - val_loss: 0.1105 - val_auc: 0.9853 - val_accuracy: 0.9707 - val_cost: 3.7305\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7408 - val_loss: 0.1099 - val_auc: 0.9851 - val_accuracy: 0.9706 - val_cost: 3.6556\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9922 - accuracy: 0.9791 - cost: 2.7084 - val_loss: 0.1114 - val_auc: 0.9845 - val_accuracy: 0.9698 - val_cost: 3.5775\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0754 - auc: 0.9924 - accuracy: 0.9788 - cost: 2.7381 - val_loss: 0.1105 - val_auc: 0.9853 - val_accuracy: 0.9705 - val_cost: 3.8184\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.7933 - val_loss: 0.1095 - val_auc: 0.9860 - val_accuracy: 0.9716 - val_cost: 3.5221\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9926 - accuracy: 0.9784 - cost: 2.7961 - val_loss: 0.1101 - val_auc: 0.9854 - val_accuracy: 0.9704 - val_cost: 3.8411\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9924 - accuracy: 0.9785 - cost: 2.7694 - val_loss: 0.1091 - val_auc: 0.9856 - val_accuracy: 0.9713 - val_cost: 3.6784\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9924 - accuracy: 0.9786 - cost: 2.7597 - val_loss: 0.1103 - val_auc: 0.9855 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9920 - accuracy: 0.9784 - cost: 2.7895 - val_loss: 0.1109 - val_auc: 0.9852 - val_accuracy: 0.9715 - val_cost: 3.6751\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9924 - accuracy: 0.9784 - cost: 2.7889 - val_loss: 0.1112 - val_auc: 0.9842 - val_accuracy: 0.9716 - val_cost: 3.6816\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9923 - accuracy: 0.9786 - cost: 2.7662 - val_loss: 0.1109 - val_auc: 0.9851 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.7809 - val_loss: 0.1123 - val_auc: 0.9845 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7457 - val_loss: 0.1111 - val_auc: 0.9857 - val_accuracy: 0.9717 - val_cost: 3.5579\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9923 - accuracy: 0.9788 - cost: 2.7391 - val_loss: 0.1106 - val_auc: 0.9855 - val_accuracy: 0.9717 - val_cost: 3.5482\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9924 - accuracy: 0.9789 - cost: 2.7278 - val_loss: 0.1133 - val_auc: 0.9847 - val_accuracy: 0.9706 - val_cost: 3.7826\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9922 - accuracy: 0.9788 - cost: 2.7320 - val_loss: 0.1102 - val_auc: 0.9856 - val_accuracy: 0.9712 - val_cost: 3.7728\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6907 - val_loss: 0.1126 - val_auc: 0.9849 - val_accuracy: 0.9716 - val_cost: 3.6230\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9926 - accuracy: 0.9791 - cost: 2.7055 - val_loss: 0.1108 - val_auc: 0.9854 - val_accuracy: 0.9709 - val_cost: 3.7500\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9924 - accuracy: 0.9786 - cost: 2.7670 - val_loss: 0.1129 - val_auc: 0.9850 - val_accuracy: 0.9714 - val_cost: 3.6816\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9926 - accuracy: 0.9790 - cost: 2.7181 - val_loss: 0.1132 - val_auc: 0.9848 - val_accuracy: 0.9708 - val_cost: 3.7760\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9924 - accuracy: 0.9783 - cost: 2.7979 - val_loss: 0.1114 - val_auc: 0.9854 - val_accuracy: 0.9701 - val_cost: 3.8509\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9924 - accuracy: 0.9793 - cost: 2.6685 - val_loss: 0.1103 - val_auc: 0.9854 - val_accuracy: 0.9714 - val_cost: 3.7435\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9927 - accuracy: 0.9784 - cost: 2.7809 - val_loss: 0.1108 - val_auc: 0.9855 - val_accuracy: 0.9715 - val_cost: 3.6751\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9929 - accuracy: 0.9788 - cost: 2.7325 - val_loss: 0.1134 - val_auc: 0.9846 - val_accuracy: 0.9706 - val_cost: 3.8346\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9925 - accuracy: 0.9784 - cost: 2.8074 - val_loss: 0.1130 - val_auc: 0.9851 - val_accuracy: 0.9706 - val_cost: 3.7923\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9789 - cost: 2.7294 - val_loss: 0.1128 - val_auc: 0.9846 - val_accuracy: 0.9706 - val_cost: 3.8118\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9926 - accuracy: 0.9789 - cost: 2.7388 - val_loss: 0.1114 - val_auc: 0.9847 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9928 - accuracy: 0.9785 - cost: 2.7821 - val_loss: 0.1109 - val_auc: 0.9855 - val_accuracy: 0.9713 - val_cost: 3.7760\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9928 - accuracy: 0.9793 - cost: 2.6851 - val_loss: 0.1127 - val_auc: 0.9855 - val_accuracy: 0.9706 - val_cost: 3.6654\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6969 - val_loss: 0.1130 - val_auc: 0.9855 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9926 - accuracy: 0.9789 - cost: 2.7199 - val_loss: 0.1116 - val_auc: 0.9852 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9923 - accuracy: 0.9787 - cost: 2.7800 - val_loss: 0.1126 - val_auc: 0.9849 - val_accuracy: 0.9705 - val_cost: 3.8151\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6946 - val_loss: 0.1127 - val_auc: 0.9855 - val_accuracy: 0.9706 - val_cost: 3.7500\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6599 - val_loss: 0.1136 - val_auc: 0.9844 - val_accuracy: 0.9714 - val_cost: 3.6816\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9794 - cost: 2.6694 - val_loss: 0.1144 - val_auc: 0.9843 - val_accuracy: 0.9700 - val_cost: 3.8086\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9926 - accuracy: 0.9794 - cost: 2.6574 - val_loss: 0.1137 - val_auc: 0.9849 - val_accuracy: 0.9703 - val_cost: 3.9258\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9927 - accuracy: 0.9791 - cost: 2.6955 - val_loss: 0.1130 - val_auc: 0.9844 - val_accuracy: 0.9703 - val_cost: 3.8639\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9927 - accuracy: 0.9792 - cost: 2.6867 - val_loss: 0.1141 - val_auc: 0.9852 - val_accuracy: 0.9700 - val_cost: 3.8965\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9789 - cost: 2.7284 - val_loss: 0.1149 - val_auc: 0.9837 - val_accuracy: 0.9709 - val_cost: 3.7109\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9928 - accuracy: 0.9790 - cost: 2.7020 - val_loss: 0.1119 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.7207\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9925 - accuracy: 0.9790 - cost: 2.7099 - val_loss: 0.1129 - val_auc: 0.9846 - val_accuracy: 0.9707 - val_cost: 3.8021\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9927 - accuracy: 0.9789 - cost: 2.7365 - val_loss: 0.1147 - val_auc: 0.9840 - val_accuracy: 0.9699 - val_cost: 3.9193\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9925 - accuracy: 0.9792 - cost: 2.6850 - val_loss: 0.1127 - val_auc: 0.9846 - val_accuracy: 0.9709 - val_cost: 3.8314\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9927 - accuracy: 0.9786 - cost: 2.7690 - val_loss: 0.1134 - val_auc: 0.9847 - val_accuracy: 0.9701 - val_cost: 3.7663\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9927 - accuracy: 0.9794 - cost: 2.6551 - val_loss: 0.1125 - val_auc: 0.9853 - val_accuracy: 0.9703 - val_cost: 3.8151\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9930 - accuracy: 0.9794 - cost: 2.6572 - val_loss: 0.1132 - val_auc: 0.9844 - val_accuracy: 0.9711 - val_cost: 3.5938\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9928 - accuracy: 0.9793 - cost: 2.6810 - val_loss: 0.1139 - val_auc: 0.9849 - val_accuracy: 0.9701 - val_cost: 3.8477\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9928 - accuracy: 0.9793 - cost: 2.6749 - val_loss: 0.1123 - val_auc: 0.9844 - val_accuracy: 0.9713 - val_cost: 3.7565\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6386 - val_loss: 0.1145 - val_auc: 0.9844 - val_accuracy: 0.9703 - val_cost: 3.8411\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9926 - accuracy: 0.9796 - cost: 2.6483 - val_loss: 0.1149 - val_auc: 0.9838 - val_accuracy: 0.9699 - val_cost: 3.8216\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9925 - accuracy: 0.9791 - cost: 2.7100 - val_loss: 0.1131 - val_auc: 0.9847 - val_accuracy: 0.9709 - val_cost: 3.6947\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9930 - accuracy: 0.9794 - cost: 2.6718 - val_loss: 0.1149 - val_auc: 0.9848 - val_accuracy: 0.9702 - val_cost: 3.8281\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6373 - val_loss: 0.1133 - val_auc: 0.9846 - val_accuracy: 0.9704 - val_cost: 3.8704\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9928 - accuracy: 0.9792 - cost: 2.6967 - val_loss: 0.1142 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9928 - accuracy: 0.9790 - cost: 2.7248 - val_loss: 0.1140 - val_auc: 0.9842 - val_accuracy: 0.9712 - val_cost: 3.7077\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9931 - accuracy: 0.9795 - cost: 2.6556 - val_loss: 0.1151 - val_auc: 0.9840 - val_accuracy: 0.9703 - val_cost: 3.8411\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6228 - val_loss: 0.1152 - val_auc: 0.9847 - val_accuracy: 0.9710 - val_cost: 3.6784\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6417 - val_loss: 0.1130 - val_auc: 0.9856 - val_accuracy: 0.9705 - val_cost: 3.8770\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9926 - accuracy: 0.9789 - cost: 2.7413 - val_loss: 0.1139 - val_auc: 0.9847 - val_accuracy: 0.9710 - val_cost: 3.6523\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9926 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1127 - val_auc: 0.9848 - val_accuracy: 0.9721 - val_cost: 3.6458\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6504 - val_loss: 0.1150 - val_auc: 0.9846 - val_accuracy: 0.9712 - val_cost: 3.7695\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9930 - accuracy: 0.9797 - cost: 2.6375 - val_loss: 0.1128 - val_auc: 0.9849 - val_accuracy: 0.9712 - val_cost: 3.7793\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6487 - val_loss: 0.1140 - val_auc: 0.9843 - val_accuracy: 0.9705 - val_cost: 3.9030\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9930 - accuracy: 0.9793 - cost: 2.6776 - val_loss: 0.1165 - val_auc: 0.9842 - val_accuracy: 0.9711 - val_cost: 3.6816\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9926 - accuracy: 0.9793 - cost: 2.6768 - val_loss: 0.1144 - val_auc: 0.9850 - val_accuracy: 0.9713 - val_cost: 3.6849\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9928 - accuracy: 0.9795 - cost: 2.6758 - val_loss: 0.1155 - val_auc: 0.9846 - val_accuracy: 0.9708 - val_cost: 3.8249\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9930 - accuracy: 0.9797 - cost: 2.6342 - val_loss: 0.1153 - val_auc: 0.9843 - val_accuracy: 0.9712 - val_cost: 3.7630\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9929 - accuracy: 0.9794 - cost: 2.6742 - val_loss: 0.1159 - val_auc: 0.9839 - val_accuracy: 0.9708 - val_cost: 3.8379\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6233 - val_loss: 0.1153 - val_auc: 0.9847 - val_accuracy: 0.9699 - val_cost: 3.9355\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9929 - accuracy: 0.9795 - cost: 2.6553 - val_loss: 0.1169 - val_auc: 0.9845 - val_accuracy: 0.9702 - val_cost: 3.9486\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9930 - accuracy: 0.9796 - cost: 2.6462 - val_loss: 0.1164 - val_auc: 0.9844 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9930 - accuracy: 0.9793 - cost: 2.6789 - val_loss: 0.1137 - val_auc: 0.9848 - val_accuracy: 0.9719 - val_cost: 3.6686\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9927 - accuracy: 0.9797 - cost: 2.6257 - val_loss: 0.1157 - val_auc: 0.9837 - val_accuracy: 0.9706 - val_cost: 3.6523\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6344 - val_loss: 0.1162 - val_auc: 0.9841 - val_accuracy: 0.9715 - val_cost: 3.6296\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9799 - cost: 2.6038 - val_loss: 0.1136 - val_auc: 0.9845 - val_accuracy: 0.9717 - val_cost: 3.6751\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5990 - val_loss: 0.1165 - val_auc: 0.9842 - val_accuracy: 0.9710 - val_cost: 3.8151\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9795 - cost: 2.6484 - val_loss: 0.1168 - val_auc: 0.9840 - val_accuracy: 0.9707 - val_cost: 3.8477\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9929 - accuracy: 0.9800 - cost: 2.5968 - val_loss: 0.1157 - val_auc: 0.9840 - val_accuracy: 0.9708 - val_cost: 3.7858\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9796 - cost: 2.6342 - val_loss: 0.1163 - val_auc: 0.9840 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9929 - accuracy: 0.9791 - cost: 2.7192 - val_loss: 0.1157 - val_auc: 0.9846 - val_accuracy: 0.9707 - val_cost: 3.7826\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9932 - accuracy: 0.9799 - cost: 2.6043 - val_loss: 0.1165 - val_auc: 0.9842 - val_accuracy: 0.9704 - val_cost: 3.8542\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9929 - accuracy: 0.9794 - cost: 2.6712 - val_loss: 0.1134 - val_auc: 0.9849 - val_accuracy: 0.9715 - val_cost: 3.7598\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9931 - accuracy: 0.9795 - cost: 2.6373 - val_loss: 0.1165 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.6023 - val_loss: 0.1191 - val_auc: 0.9837 - val_accuracy: 0.9706 - val_cost: 3.5775\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5932 - val_loss: 0.1186 - val_auc: 0.9831 - val_accuracy: 0.9709 - val_cost: 3.5872\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9929 - accuracy: 0.9797 - cost: 2.6325 - val_loss: 0.1168 - val_auc: 0.9844 - val_accuracy: 0.9699 - val_cost: 3.9290\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9928 - accuracy: 0.9798 - cost: 2.6270 - val_loss: 0.1163 - val_auc: 0.9841 - val_accuracy: 0.9709 - val_cost: 3.6263\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9930 - accuracy: 0.9794 - cost: 2.6625 - val_loss: 0.1181 - val_auc: 0.9838 - val_accuracy: 0.9709 - val_cost: 3.5026\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9932 - accuracy: 0.9800 - cost: 2.5807 - val_loss: 0.1183 - val_auc: 0.9844 - val_accuracy: 0.9695 - val_cost: 3.9453\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9932 - accuracy: 0.9795 - cost: 2.6538 - val_loss: 0.1166 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.6621\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9928 - accuracy: 0.9796 - cost: 2.6357 - val_loss: 0.1181 - val_auc: 0.9839 - val_accuracy: 0.9703 - val_cost: 3.7435\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5614 - val_loss: 0.1166 - val_auc: 0.9843 - val_accuracy: 0.9711 - val_cost: 3.7109\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.6009 - val_loss: 0.1163 - val_auc: 0.9842 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5695 - val_loss: 0.1148 - val_auc: 0.9847 - val_accuracy: 0.9716 - val_cost: 3.7142\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0696 - auc: 0.9931 - accuracy: 0.9797 - cost: 2.6314 - val_loss: 0.1157 - val_auc: 0.9845 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6054 - val_loss: 0.1171 - val_auc: 0.9842 - val_accuracy: 0.9707 - val_cost: 3.7272\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9930 - accuracy: 0.9798 - cost: 2.6161 - val_loss: 0.1172 - val_auc: 0.9845 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9931 - accuracy: 0.9804 - cost: 2.5420 - val_loss: 0.1175 - val_auc: 0.9845 - val_accuracy: 0.9715 - val_cost: 3.6523\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5898 - val_loss: 0.1217 - val_auc: 0.9830 - val_accuracy: 0.9695 - val_cost: 3.8509\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5969 - val_loss: 0.1176 - val_auc: 0.9838 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9795 - cost: 2.6662 - val_loss: 0.1171 - val_auc: 0.9842 - val_accuracy: 0.9716 - val_cost: 3.6947\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5794 - val_loss: 0.1189 - val_auc: 0.9840 - val_accuracy: 0.9711 - val_cost: 3.7891\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9931 - accuracy: 0.9800 - cost: 2.5881 - val_loss: 0.1195 - val_auc: 0.9836 - val_accuracy: 0.9712 - val_cost: 3.6882\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9795 - cost: 2.6683 - val_loss: 0.1202 - val_auc: 0.9840 - val_accuracy: 0.9705 - val_cost: 3.7305\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9929 - accuracy: 0.9798 - cost: 2.6207 - val_loss: 0.1208 - val_auc: 0.9833 - val_accuracy: 0.9702 - val_cost: 3.7923\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6035 - val_loss: 0.1173 - val_auc: 0.9839 - val_accuracy: 0.9706 - val_cost: 3.8477\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9930 - accuracy: 0.9799 - cost: 2.6210 - val_loss: 0.1187 - val_auc: 0.9843 - val_accuracy: 0.9704 - val_cost: 3.7956\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5816 - val_loss: 0.1164 - val_auc: 0.9847 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5907 - val_loss: 0.1167 - val_auc: 0.9844 - val_accuracy: 0.9712 - val_cost: 3.7533\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9936 - accuracy: 0.9800 - cost: 2.5870 - val_loss: 0.1161 - val_auc: 0.9845 - val_accuracy: 0.9712 - val_cost: 3.7272\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5791 - val_loss: 0.1181 - val_auc: 0.9843 - val_accuracy: 0.9705 - val_cost: 3.7858\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9799 - cost: 2.6178 - val_loss: 0.1168 - val_auc: 0.9847 - val_accuracy: 0.9705 - val_cost: 3.8737\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9931 - accuracy: 0.9796 - cost: 2.6426 - val_loss: 0.1167 - val_auc: 0.9835 - val_accuracy: 0.9707 - val_cost: 3.7500\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9930 - accuracy: 0.9802 - cost: 2.5690 - val_loss: 0.1164 - val_auc: 0.9849 - val_accuracy: 0.9710 - val_cost: 3.7760\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9930 - accuracy: 0.9800 - cost: 2.5983 - val_loss: 0.1173 - val_auc: 0.9835 - val_accuracy: 0.9705 - val_cost: 3.6393\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6059 - val_loss: 0.1163 - val_auc: 0.9839 - val_accuracy: 0.9705 - val_cost: 3.7988\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9928 - accuracy: 0.9797 - cost: 2.6359 - val_loss: 0.1187 - val_auc: 0.9837 - val_accuracy: 0.9697 - val_cost: 3.8444\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9798 - cost: 2.6153 - val_loss: 0.1176 - val_auc: 0.9840 - val_accuracy: 0.9719 - val_cost: 3.6751\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9931 - accuracy: 0.9803 - cost: 2.5614 - val_loss: 0.1179 - val_auc: 0.9842 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9799 - cost: 2.6069 - val_loss: 0.1189 - val_auc: 0.9838 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9930 - accuracy: 0.9796 - cost: 2.6483 - val_loss: 0.1174 - val_auc: 0.9844 - val_accuracy: 0.9711 - val_cost: 3.8021\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9932 - accuracy: 0.9797 - cost: 2.6351 - val_loss: 0.1204 - val_auc: 0.9840 - val_accuracy: 0.9701 - val_cost: 3.8151\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9933 - accuracy: 0.9799 - cost: 2.5994 - val_loss: 0.1179 - val_auc: 0.9838 - val_accuracy: 0.9715 - val_cost: 3.6719\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5711 - val_loss: 0.1194 - val_auc: 0.9838 - val_accuracy: 0.9717 - val_cost: 3.6882\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5811 - val_loss: 0.1197 - val_auc: 0.9838 - val_accuracy: 0.9708 - val_cost: 3.7077\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9935 - accuracy: 0.9802 - cost: 2.5518 - val_loss: 0.1195 - val_auc: 0.9843 - val_accuracy: 0.9722 - val_cost: 3.5352\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9935 - accuracy: 0.9798 - cost: 2.6163 - val_loss: 0.1181 - val_auc: 0.9838 - val_accuracy: 0.9720 - val_cost: 3.6296\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5717 - val_loss: 0.1214 - val_auc: 0.9838 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5714 - val_loss: 0.1195 - val_auc: 0.9838 - val_accuracy: 0.9704 - val_cost: 3.6426\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5679 - val_loss: 0.1189 - val_auc: 0.9837 - val_accuracy: 0.9718 - val_cost: 3.3040\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5510 - val_loss: 0.1172 - val_auc: 0.9840 - val_accuracy: 0.9708 - val_cost: 3.7923\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9931 - accuracy: 0.9802 - cost: 2.5800 - val_loss: 0.1177 - val_auc: 0.9841 - val_accuracy: 0.9711 - val_cost: 3.7174\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9932 - accuracy: 0.9795 - cost: 2.6662 - val_loss: 0.1184 - val_auc: 0.9844 - val_accuracy: 0.9716 - val_cost: 3.6621\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5793 - val_loss: 0.1191 - val_auc: 0.9833 - val_accuracy: 0.9717 - val_cost: 3.5091\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9805 - cost: 2.5264 - val_loss: 0.1186 - val_auc: 0.9846 - val_accuracy: 0.9719 - val_cost: 3.4798\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9933 - accuracy: 0.9799 - cost: 2.6005 - val_loss: 0.1176 - val_auc: 0.9848 - val_accuracy: 0.9719 - val_cost: 3.6589\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5749 - val_loss: 0.1188 - val_auc: 0.9842 - val_accuracy: 0.9711 - val_cost: 3.7435\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0695 - auc: 0.9931 - accuracy: 0.9801 - cost: 2.5843 - val_loss: 0.1174 - val_auc: 0.9845 - val_accuracy: 0.9720 - val_cost: 3.6654\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5881 - val_loss: 0.1173 - val_auc: 0.9843 - val_accuracy: 0.9717 - val_cost: 3.5286\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9934 - accuracy: 0.9808 - cost: 2.4986 - val_loss: 0.1173 - val_auc: 0.9845 - val_accuracy: 0.9709 - val_cost: 3.9518\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9932 - accuracy: 0.9802 - cost: 2.5824 - val_loss: 0.1173 - val_auc: 0.9840 - val_accuracy: 0.9716 - val_cost: 3.4961\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9934 - accuracy: 0.9801 - cost: 2.5783 - val_loss: 0.1196 - val_auc: 0.9832 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9931 - accuracy: 0.9798 - cost: 2.6157 - val_loss: 0.1185 - val_auc: 0.9834 - val_accuracy: 0.9717 - val_cost: 3.7272\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9934 - accuracy: 0.9801 - cost: 2.5837 - val_loss: 0.1176 - val_auc: 0.9843 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5551 - val_loss: 0.1175 - val_auc: 0.9845 - val_accuracy: 0.9708 - val_cost: 3.7240\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9932 - accuracy: 0.9801 - cost: 2.5719 - val_loss: 0.1166 - val_auc: 0.9847 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9931 - accuracy: 0.9799 - cost: 2.6115 - val_loss: 0.1196 - val_auc: 0.9843 - val_accuracy: 0.9715 - val_cost: 3.6491\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9929 - accuracy: 0.9803 - cost: 2.5820 - val_loss: 0.1177 - val_auc: 0.9840 - val_accuracy: 0.9714 - val_cost: 3.7533\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9933 - accuracy: 0.9801 - cost: 2.5784 - val_loss: 0.1186 - val_auc: 0.9840 - val_accuracy: 0.9710 - val_cost: 3.7272\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5493 - val_loss: 0.1187 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.6849\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9802 - cost: 2.5754 - val_loss: 0.1186 - val_auc: 0.9843 - val_accuracy: 0.9703 - val_cost: 3.8118\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9934 - accuracy: 0.9805 - cost: 2.5312 - val_loss: 0.1215 - val_auc: 0.9830 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5642 - val_loss: 0.1191 - val_auc: 0.9846 - val_accuracy: 0.9728 - val_cost: 3.3496\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5406 - val_loss: 0.1212 - val_auc: 0.9833 - val_accuracy: 0.9713 - val_cost: 3.6719\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9934 - accuracy: 0.9800 - cost: 2.6115 - val_loss: 0.1182 - val_auc: 0.9844 - val_accuracy: 0.9715 - val_cost: 3.4798\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9935 - accuracy: 0.9799 - cost: 2.6004 - val_loss: 0.1167 - val_auc: 0.9842 - val_accuracy: 0.9733 - val_cost: 3.3366\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5396 - val_loss: 0.1199 - val_auc: 0.9837 - val_accuracy: 0.9714 - val_cost: 3.6816\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9933 - accuracy: 0.9801 - cost: 2.5805 - val_loss: 0.1204 - val_auc: 0.9840 - val_accuracy: 0.9707 - val_cost: 3.7858\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9935 - accuracy: 0.9803 - cost: 2.5678 - val_loss: 0.1225 - val_auc: 0.9834 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9935 - accuracy: 0.9803 - cost: 2.5637 - val_loss: 0.1206 - val_auc: 0.9833 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0676 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5137 - val_loss: 0.1184 - val_auc: 0.9844 - val_accuracy: 0.9717 - val_cost: 3.7207\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9936 - accuracy: 0.9804 - cost: 2.5504 - val_loss: 0.1204 - val_auc: 0.9834 - val_accuracy: 0.9710 - val_cost: 3.6296\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5445 - val_loss: 0.1217 - val_auc: 0.9843 - val_accuracy: 0.9712 - val_cost: 3.4245\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5406 - val_loss: 0.1186 - val_auc: 0.9839 - val_accuracy: 0.9717 - val_cost: 3.6719\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9800 - cost: 2.5975 - val_loss: 0.1193 - val_auc: 0.9841 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9937 - accuracy: 0.9804 - cost: 2.5420 - val_loss: 0.1199 - val_auc: 0.9830 - val_accuracy: 0.9710 - val_cost: 3.7565\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9936 - accuracy: 0.9805 - cost: 2.5292 - val_loss: 0.1187 - val_auc: 0.9843 - val_accuracy: 0.9730 - val_cost: 3.5156\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9935 - accuracy: 0.9803 - cost: 2.5474 - val_loss: 0.1203 - val_auc: 0.9831 - val_accuracy: 0.9719 - val_cost: 3.6133\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9934 - accuracy: 0.9806 - cost: 2.5312 - val_loss: 0.1184 - val_auc: 0.9841 - val_accuracy: 0.9713 - val_cost: 3.7858\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5337 - val_loss: 0.1199 - val_auc: 0.9838 - val_accuracy: 0.9701 - val_cost: 3.8900\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9934 - accuracy: 0.9802 - cost: 2.5600 - val_loss: 0.1211 - val_auc: 0.9844 - val_accuracy: 0.9706 - val_cost: 3.9160\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9936 - accuracy: 0.9804 - cost: 2.5418 - val_loss: 0.1197 - val_auc: 0.9843 - val_accuracy: 0.9710 - val_cost: 3.7044\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9932 - accuracy: 0.9804 - cost: 2.5305 - val_loss: 0.1210 - val_auc: 0.9838 - val_accuracy: 0.9711 - val_cost: 3.6849\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5528 - val_loss: 0.1195 - val_auc: 0.9838 - val_accuracy: 0.9703 - val_cost: 3.8281\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9935 - accuracy: 0.9797 - cost: 2.6378 - val_loss: 0.1217 - val_auc: 0.9836 - val_accuracy: 0.9715 - val_cost: 3.6230\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9935 - accuracy: 0.9806 - cost: 2.5093 - val_loss: 0.1213 - val_auc: 0.9844 - val_accuracy: 0.9712 - val_cost: 3.7305\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5486 - val_loss: 0.1211 - val_auc: 0.9837 - val_accuracy: 0.9712 - val_cost: 3.7565\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5586 - val_loss: 0.1201 - val_auc: 0.9838 - val_accuracy: 0.9713 - val_cost: 3.7305\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9936 - accuracy: 0.9800 - cost: 2.5903 - val_loss: 0.1184 - val_auc: 0.9844 - val_accuracy: 0.9718 - val_cost: 3.7207\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9934 - accuracy: 0.9804 - cost: 2.5517 - val_loss: 0.1231 - val_auc: 0.9831 - val_accuracy: 0.9711 - val_cost: 3.6849\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9937 - accuracy: 0.9804 - cost: 2.5427 - val_loss: 0.1219 - val_auc: 0.9841 - val_accuracy: 0.9699 - val_cost: 3.9551\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5148 - val_loss: 0.1191 - val_auc: 0.9841 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9936 - accuracy: 0.9804 - cost: 2.5484 - val_loss: 0.1208 - val_auc: 0.9833 - val_accuracy: 0.9712 - val_cost: 3.7435\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9933 - accuracy: 0.9806 - cost: 2.5286 - val_loss: 0.1235 - val_auc: 0.9832 - val_accuracy: 0.9715 - val_cost: 3.5156\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9936 - accuracy: 0.9805 - cost: 2.5315 - val_loss: 0.1224 - val_auc: 0.9837 - val_accuracy: 0.9706 - val_cost: 3.8216\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9935 - accuracy: 0.9805 - cost: 2.5519 - val_loss: 0.1209 - val_auc: 0.9839 - val_accuracy: 0.9709 - val_cost: 3.6296\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0676 - auc: 0.9937 - accuracy: 0.9804 - cost: 2.5466 - val_loss: 0.1234 - val_auc: 0.9842 - val_accuracy: 0.9713 - val_cost: 3.7207\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9933 - accuracy: 0.9803 - cost: 2.5693 - val_loss: 0.1211 - val_auc: 0.9841 - val_accuracy: 0.9704 - val_cost: 3.8802\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9935 - accuracy: 0.9804 - cost: 2.5478 - val_loss: 0.1202 - val_auc: 0.9845 - val_accuracy: 0.9708 - val_cost: 3.7695\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9932 - accuracy: 0.9803 - cost: 2.5600 - val_loss: 0.1230 - val_auc: 0.9836 - val_accuracy: 0.9707 - val_cost: 3.7533\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1144 - auc: 0.9831 - accuracy: 0.9711 - cost: 3.6375\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:27.015364\n",
            "fold accuracy: 0.9710624814033508 - fold cost: 3.637500047683716\n",
            "total train/predict time: 0:45:01.776143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_results = fold_results"
      ],
      "metadata": {
        "id": "fszFGfDwmD7r"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = (m4_results.get(i).get('predictions')[j])"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new4 = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    if m4_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new4[idx] = 1\n",
        "    else:\n",
        "      preds_new4[idx] = 0\n",
        "m4_cost_t = cost_func(y,preds_new4)\n",
        "m4_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7K7DWxmHit",
        "outputId": "01529a45-ef6c-4073-bc3f-d9a1f26c9544"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "541700"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "2e8a6f4f-2f31-4d78-a795-3735844539f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('model4.keras')"
      ],
      "metadata": {
        "id": "ew-ZtZUpzr0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model5 = tf.keras.Sequential()\n",
        "  model5.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model5.add(tf.keras.layers.Dropout(0.2))\n",
        "  model5.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model5.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model5.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model5.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model5.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "c04d2942-636c-49c6-93fb-69c127cf4744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5265 - auc: 0.8009 - accuracy: 0.7294 - cost: 35.9773 - val_loss: 0.3919 - val_auc: 0.9022 - val_accuracy: 0.8288 - val_cost: 21.9434\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3471 - auc: 0.9236 - accuracy: 0.8525 - cost: 18.7994 - val_loss: 0.3144 - val_auc: 0.9371 - val_accuracy: 0.8675 - val_cost: 16.4290\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3006 - auc: 0.9428 - accuracy: 0.8754 - cost: 15.7626 - val_loss: 0.2882 - val_auc: 0.9483 - val_accuracy: 0.8802 - val_cost: 15.3288\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2716 - auc: 0.9533 - accuracy: 0.8896 - cost: 13.9979 - val_loss: 0.2613 - val_auc: 0.9572 - val_accuracy: 0.8955 - val_cost: 12.6530\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2487 - auc: 0.9609 - accuracy: 0.9009 - cost: 12.5477 - val_loss: 0.2406 - val_auc: 0.9634 - val_accuracy: 0.9062 - val_cost: 11.6406\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2296 - auc: 0.9666 - accuracy: 0.9103 - cost: 11.3603 - val_loss: 0.2253 - val_auc: 0.9687 - val_accuracy: 0.9125 - val_cost: 10.2669\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2133 - auc: 0.9712 - accuracy: 0.9178 - cost: 10.4193 - val_loss: 0.2072 - val_auc: 0.9727 - val_accuracy: 0.9235 - val_cost: 9.2643\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1997 - auc: 0.9746 - accuracy: 0.9241 - cost: 9.6142 - val_loss: 0.1951 - val_auc: 0.9756 - val_accuracy: 0.9277 - val_cost: 8.8346\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1880 - auc: 0.9773 - accuracy: 0.9295 - cost: 8.9495 - val_loss: 0.1861 - val_auc: 0.9776 - val_accuracy: 0.9322 - val_cost: 8.5612\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1793 - auc: 0.9792 - accuracy: 0.9335 - cost: 8.4162 - val_loss: 0.1796 - val_auc: 0.9790 - val_accuracy: 0.9347 - val_cost: 8.2650\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1709 - auc: 0.9810 - accuracy: 0.9369 - cost: 7.9975 - val_loss: 0.1720 - val_auc: 0.9806 - val_accuracy: 0.9390 - val_cost: 7.8060\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1641 - auc: 0.9824 - accuracy: 0.9405 - cost: 7.5554 - val_loss: 0.1664 - val_auc: 0.9816 - val_accuracy: 0.9423 - val_cost: 7.5521\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9428 - cost: 7.2491 - val_loss: 0.1618 - val_auc: 0.9826 - val_accuracy: 0.9428 - val_cost: 7.3535\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9448 - cost: 6.9943 - val_loss: 0.1589 - val_auc: 0.9832 - val_accuracy: 0.9452 - val_cost: 7.0150\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1494 - auc: 0.9851 - accuracy: 0.9466 - cost: 6.7655 - val_loss: 0.1537 - val_auc: 0.9842 - val_accuracy: 0.9469 - val_cost: 6.9759\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1442 - auc: 0.9860 - accuracy: 0.9490 - cost: 6.4835 - val_loss: 0.1515 - val_auc: 0.9844 - val_accuracy: 0.9485 - val_cost: 6.6178\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1412 - auc: 0.9865 - accuracy: 0.9503 - cost: 6.2999 - val_loss: 0.1493 - val_auc: 0.9848 - val_accuracy: 0.9486 - val_cost: 6.6211\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1376 - auc: 0.9870 - accuracy: 0.9524 - cost: 6.0457 - val_loss: 0.1456 - val_auc: 0.9853 - val_accuracy: 0.9508 - val_cost: 6.3900\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9536 - cost: 5.8733 - val_loss: 0.1441 - val_auc: 0.9856 - val_accuracy: 0.9499 - val_cost: 6.2630\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1313 - auc: 0.9880 - accuracy: 0.9553 - cost: 5.6641 - val_loss: 0.1410 - val_auc: 0.9859 - val_accuracy: 0.9526 - val_cost: 6.1361\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1285 - auc: 0.9884 - accuracy: 0.9556 - cost: 5.6350 - val_loss: 0.1398 - val_auc: 0.9863 - val_accuracy: 0.9540 - val_cost: 6.3281\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1259 - auc: 0.9887 - accuracy: 0.9575 - cost: 5.3714 - val_loss: 0.1368 - val_auc: 0.9865 - val_accuracy: 0.9551 - val_cost: 5.7520\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1238 - auc: 0.9890 - accuracy: 0.9582 - cost: 5.3023 - val_loss: 0.1337 - val_auc: 0.9871 - val_accuracy: 0.9565 - val_cost: 5.6836\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9593 - cost: 5.1617 - val_loss: 0.1331 - val_auc: 0.9870 - val_accuracy: 0.9567 - val_cost: 5.5924\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1187 - auc: 0.9898 - accuracy: 0.9605 - cost: 5.0173 - val_loss: 0.1312 - val_auc: 0.9875 - val_accuracy: 0.9573 - val_cost: 5.5632\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1163 - auc: 0.9902 - accuracy: 0.9610 - cost: 4.9456 - val_loss: 0.1289 - val_auc: 0.9876 - val_accuracy: 0.9584 - val_cost: 5.4785\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1145 - auc: 0.9903 - accuracy: 0.9621 - cost: 4.8062 - val_loss: 0.1289 - val_auc: 0.9877 - val_accuracy: 0.9587 - val_cost: 5.3418\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1128 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7242 - val_loss: 0.1264 - val_auc: 0.9881 - val_accuracy: 0.9610 - val_cost: 5.0749\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1108 - auc: 0.9907 - accuracy: 0.9635 - cost: 4.6348 - val_loss: 0.1255 - val_auc: 0.9880 - val_accuracy: 0.9617 - val_cost: 4.9967\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.1099 - auc: 0.9908 - accuracy: 0.9644 - cost: 4.5170 - val_loss: 0.1234 - val_auc: 0.9883 - val_accuracy: 0.9615 - val_cost: 5.0260\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1076 - auc: 0.9911 - accuracy: 0.9649 - cost: 4.4675 - val_loss: 0.1223 - val_auc: 0.9883 - val_accuracy: 0.9629 - val_cost: 4.5443\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9663 - cost: 4.2752 - val_loss: 0.1210 - val_auc: 0.9885 - val_accuracy: 0.9631 - val_cost: 4.9544\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9915 - accuracy: 0.9661 - cost: 4.3101 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.6517\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9675 - cost: 4.1263 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9633 - val_cost: 4.7135\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1019 - auc: 0.9918 - accuracy: 0.9671 - cost: 4.1904 - val_loss: 0.1178 - val_auc: 0.9891 - val_accuracy: 0.9639 - val_cost: 4.6126\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9682 - cost: 4.0477 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.3848\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9684 - cost: 4.0164 - val_loss: 0.1162 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.4043\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9922 - accuracy: 0.9692 - cost: 3.9104 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.4076\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9145 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9660 - val_cost: 4.4629\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9697 - cost: 3.8575 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.0332\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9925 - accuracy: 0.9701 - cost: 3.7979 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9662 - val_cost: 4.1243\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0934 - auc: 0.9926 - accuracy: 0.9710 - cost: 3.6906 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.0137\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9928 - accuracy: 0.9707 - cost: 3.7322 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1211\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7232 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.2741\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9718 - cost: 3.5923 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9672 - val_cost: 4.1471\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5534 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9684 - val_cost: 4.0169\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9718 - cost: 3.5861 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.1895\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0880 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4710 - val_loss: 0.1084 - val_auc: 0.9899 - val_accuracy: 0.9687 - val_cost: 3.9909\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.4063 - val_loss: 0.1073 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.1243\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3203 - val_loss: 0.1068 - val_auc: 0.9900 - val_accuracy: 0.9678 - val_cost: 4.1699\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3823 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 4.0039\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9736 - cost: 3.3708 - val_loss: 0.1063 - val_auc: 0.9900 - val_accuracy: 0.9676 - val_cost: 4.1829\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0846 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3066 - val_loss: 0.1058 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9616\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2741 - val_loss: 0.1052 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.8314\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2439 - val_loss: 0.1054 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.8965\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2348 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.7728\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2344 - val_loss: 0.1050 - val_auc: 0.9903 - val_accuracy: 0.9691 - val_cost: 3.9160\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1639 - val_loss: 0.1050 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1860 - val_loss: 0.1040 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.7858\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9751 - cost: 3.1574 - val_loss: 0.1052 - val_auc: 0.9904 - val_accuracy: 0.9692 - val_cost: 3.6914\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0805 - auc: 0.9939 - accuracy: 0.9758 - cost: 3.0723 - val_loss: 0.1047 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7240\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0801 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0304 - val_loss: 0.1044 - val_auc: 0.9905 - val_accuracy: 0.9691 - val_cost: 3.9844\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0411 - val_loss: 0.1023 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.8314\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0258 - val_loss: 0.1038 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.5579\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9940 - accuracy: 0.9764 - cost: 3.0092 - val_loss: 0.1036 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.8574\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9771 - cost: 2.9087 - val_loss: 0.1036 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.4505\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0616 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.7174\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9983 - val_loss: 0.1031 - val_auc: 0.9908 - val_accuracy: 0.9706 - val_cost: 3.7923\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9700 - val_loss: 0.1035 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.6784\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9605 - val_loss: 0.1034 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.8672\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8807 - val_loss: 0.1030 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.9355\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.7968 - val_loss: 0.1031 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.8574\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8614 - val_loss: 0.1035 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.9030\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8294 - val_loss: 0.1027 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.6100\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8324 - val_loss: 0.1026 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.6165\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8735 - val_loss: 0.1028 - val_auc: 0.9904 - val_accuracy: 0.9714 - val_cost: 3.7207\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8425 - val_loss: 0.1039 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.7891\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8161 - val_loss: 0.1036 - val_auc: 0.9903 - val_accuracy: 0.9720 - val_cost: 3.4049\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7664 - val_loss: 0.1017 - val_auc: 0.9906 - val_accuracy: 0.9725 - val_cost: 3.3691\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7608 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.5840\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8000 - val_loss: 0.1022 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.5384\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7631 - val_loss: 0.1030 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.7630\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7779 - val_loss: 0.1036 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.4603\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7017 - val_loss: 0.1029 - val_auc: 0.9906 - val_accuracy: 0.9719 - val_cost: 3.6458\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7663 - val_loss: 0.1039 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.4538\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7263 - val_loss: 0.1022 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7890 - val_loss: 0.1037 - val_auc: 0.9907 - val_accuracy: 0.9714 - val_cost: 3.2650\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6880 - val_loss: 0.1029 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.5547\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6926 - val_loss: 0.1058 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.4570\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6809 - val_loss: 0.1037 - val_auc: 0.9901 - val_accuracy: 0.9724 - val_cost: 3.5612\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6741 - val_loss: 0.1037 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5059\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6505 - val_loss: 0.1038 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6849\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7213 - val_loss: 0.1033 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.5124\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7161 - val_loss: 0.1036 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.6393\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6717 - val_loss: 0.1048 - val_auc: 0.9901 - val_accuracy: 0.9728 - val_cost: 3.4766\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6674 - val_loss: 0.1044 - val_auc: 0.9900 - val_accuracy: 0.9723 - val_cost: 3.3919\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6128 - val_loss: 0.1049 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.8444\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6192 - val_loss: 0.1052 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5840\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5693 - val_loss: 0.1049 - val_auc: 0.9903 - val_accuracy: 0.9718 - val_cost: 3.3984\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6339 - val_loss: 0.1047 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.6654\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6718 - val_loss: 0.1034 - val_auc: 0.9904 - val_accuracy: 0.9727 - val_cost: 3.4635\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5457 - val_loss: 0.1043 - val_auc: 0.9906 - val_accuracy: 0.9733 - val_cost: 3.4049\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5760 - val_loss: 0.1060 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.6523\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6049 - val_loss: 0.1070 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5482\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6350 - val_loss: 0.1059 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.5482\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5482 - val_loss: 0.1049 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.7044\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5179 - val_loss: 0.1033 - val_auc: 0.9901 - val_accuracy: 0.9721 - val_cost: 3.6458\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5569 - val_loss: 0.1058 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.5482\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5157 - val_loss: 0.1052 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.6491\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5163 - val_loss: 0.1057 - val_auc: 0.9900 - val_accuracy: 0.9733 - val_cost: 3.3431\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4569 - val_loss: 0.1059 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.5677\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5365 - val_loss: 0.1050 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.7044\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5840 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.7728\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4885 - val_loss: 0.1070 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.6165\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5858 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.4245\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4898 - val_loss: 0.1064 - val_auc: 0.9903 - val_accuracy: 0.9723 - val_cost: 3.3626\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4536 - val_loss: 0.1068 - val_auc: 0.9900 - val_accuracy: 0.9724 - val_cost: 3.1608\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4288 - val_loss: 0.1054 - val_auc: 0.9900 - val_accuracy: 0.9716 - val_cost: 3.6849\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4748 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9722 - val_cost: 3.4505\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9815 - cost: 2.3601 - val_loss: 0.1066 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.5124\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4715 - val_loss: 0.1068 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6133\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4872 - val_loss: 0.1066 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.4342\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5017 - val_loss: 0.1057 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.3203\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4237 - val_loss: 0.1064 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5254\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4408 - val_loss: 0.1069 - val_auc: 0.9904 - val_accuracy: 0.9718 - val_cost: 3.7109\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4748 - val_loss: 0.1076 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.4961\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3764 - val_loss: 0.1079 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.2292\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4631 - val_loss: 0.1060 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.6068\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.3940 - val_loss: 0.1074 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.4375\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4655 - val_loss: 0.1076 - val_auc: 0.9903 - val_accuracy: 0.9722 - val_cost: 3.5514\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4549 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9729 - val_cost: 3.3105\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3804 - val_loss: 0.1069 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.2845\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1073 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4993\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3324 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.6100\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4530 - val_loss: 0.1075 - val_auc: 0.9898 - val_accuracy: 0.9733 - val_cost: 3.3171\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4374 - val_loss: 0.1079 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4180\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4263 - val_loss: 0.1075 - val_auc: 0.9900 - val_accuracy: 0.9728 - val_cost: 3.5449\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3870 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.3822\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4673 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9727 - val_cost: 3.3333\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3349 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9724 - val_cost: 3.5319\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3290 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9735 - val_cost: 3.1250\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4331 - val_loss: 0.1099 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.1966\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4095 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.9062\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3094 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.4440\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3665 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.4798\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3264 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.5742\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3530 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.7272\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.4022 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5710\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3604 - val_loss: 0.1112 - val_auc: 0.9890 - val_accuracy: 0.9727 - val_cost: 3.3822\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3785 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9726 - val_cost: 3.3496\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3531 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9732 - val_cost: 3.1217\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4237 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9726 - val_cost: 3.4766\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3135 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9729 - val_cost: 3.2650\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3094 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.7533\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.2966 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4701\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3069 - val_loss: 0.1103 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.3822\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3363 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9725 - val_cost: 3.5352\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3431 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.6133\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3155 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9721 - val_cost: 3.4896\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3643 - val_loss: 0.1082 - val_auc: 0.9898 - val_accuracy: 0.9737 - val_cost: 3.4082\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3381 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9729 - val_cost: 3.5840\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3518 - val_loss: 0.1092 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.6751\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2857 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5970\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3063 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9736 - val_cost: 3.0762\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2784 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.2910\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2316 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9726 - val_cost: 3.5286\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3145 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.6230\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3103 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.5645\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2631 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.6979\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2667 - val_loss: 0.1106 - val_auc: 0.9894 - val_accuracy: 0.9728 - val_cost: 3.5059\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2468 - val_loss: 0.1137 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.7174\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3032 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9723 - val_cost: 3.3757\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3352 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.3757\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2865 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.7207\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2647 - val_loss: 0.1130 - val_auc: 0.9891 - val_accuracy: 0.9714 - val_cost: 3.3724\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3132 - val_loss: 0.1100 - val_auc: 0.9894 - val_accuracy: 0.9726 - val_cost: 3.3789\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2838 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.7891\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2631 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.6979\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3024 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2863 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9721 - val_cost: 3.4082\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2740 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.4928\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2253 - val_loss: 0.1127 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.3268\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2448 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.3789\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2521 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5254\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3231 - val_loss: 0.1116 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2642 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9723 - val_cost: 3.5352\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2292 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9731 - val_cost: 3.3529\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2572 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4049\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2117 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9727 - val_cost: 3.3171\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2520 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9727 - val_cost: 3.3138\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2778 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.4668\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2153 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9723 - val_cost: 3.3724\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2575 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4473\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2329 - val_loss: 0.1145 - val_auc: 0.9889 - val_accuracy: 0.9721 - val_cost: 3.2422\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2417 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9727 - val_cost: 3.3333\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1756 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.4473\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2418 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4896\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2146 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.7728\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2063 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.2520\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2549 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.4993\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2665 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9721 - val_cost: 3.4538\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2666 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9719 - val_cost: 3.4668\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1869 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6458\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2545 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9735 - val_cost: 3.3984\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2399 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9726 - val_cost: 3.3757\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2397 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9726 - val_cost: 3.3333\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1781 - val_loss: 0.1147 - val_auc: 0.9888 - val_accuracy: 0.9719 - val_cost: 3.2878\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1993 - val_loss: 0.1187 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2587 - val_loss: 0.1148 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.4701\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1650 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9729 - val_cost: 3.2943\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2365 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6882\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1530 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9715 - val_cost: 3.4896\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1912 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.5221\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2100 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9731 - val_cost: 3.2552\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1108 - auc: 0.9901 - accuracy: 0.9694 - cost: 3.8531\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:59.979274\n",
            "fold accuracy: 0.9694374799728394 - fold cost: 3.8531250953674316\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5261 - auc: 0.8016 - accuracy: 0.7315 - cost: 35.7237 - val_loss: 0.3935 - val_auc: 0.9022 - val_accuracy: 0.8303 - val_cost: 22.6302\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3476 - auc: 0.9233 - accuracy: 0.8516 - cost: 18.9104 - val_loss: 0.3148 - val_auc: 0.9371 - val_accuracy: 0.8664 - val_cost: 16.5788\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2988 - auc: 0.9435 - accuracy: 0.8766 - cost: 15.6157 - val_loss: 0.2861 - val_auc: 0.9486 - val_accuracy: 0.8805 - val_cost: 15.2051\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2707 - auc: 0.9537 - accuracy: 0.8893 - cost: 14.0262 - val_loss: 0.2595 - val_auc: 0.9575 - val_accuracy: 0.8971 - val_cost: 12.7441\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2471 - auc: 0.9615 - accuracy: 0.9010 - cost: 12.5469 - val_loss: 0.2404 - val_auc: 0.9637 - val_accuracy: 0.9060 - val_cost: 11.5560\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2281 - auc: 0.9670 - accuracy: 0.9103 - cost: 11.3711 - val_loss: 0.2232 - val_auc: 0.9685 - val_accuracy: 0.9154 - val_cost: 10.8529\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2123 - auc: 0.9713 - accuracy: 0.9178 - cost: 10.3852 - val_loss: 0.2095 - val_auc: 0.9721 - val_accuracy: 0.9197 - val_cost: 10.2930\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1994 - auc: 0.9746 - accuracy: 0.9237 - cost: 9.6481 - val_loss: 0.1975 - val_auc: 0.9753 - val_accuracy: 0.9284 - val_cost: 9.3392\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1878 - auc: 0.9774 - accuracy: 0.9297 - cost: 8.9106 - val_loss: 0.1872 - val_auc: 0.9775 - val_accuracy: 0.9328 - val_cost: 8.8737\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.1776 - auc: 0.9796 - accuracy: 0.9349 - cost: 8.2354 - val_loss: 0.1802 - val_auc: 0.9789 - val_accuracy: 0.9360 - val_cost: 8.3561\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1703 - auc: 0.9811 - accuracy: 0.9380 - cost: 7.8678 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9385 - val_cost: 8.1380\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1637 - auc: 0.9824 - accuracy: 0.9408 - cost: 7.5093 - val_loss: 0.1686 - val_auc: 0.9812 - val_accuracy: 0.9403 - val_cost: 7.9004\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1573 - auc: 0.9836 - accuracy: 0.9435 - cost: 7.1656 - val_loss: 0.1625 - val_auc: 0.9826 - val_accuracy: 0.9429 - val_cost: 7.2591\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1526 - auc: 0.9845 - accuracy: 0.9456 - cost: 6.8969 - val_loss: 0.1578 - val_auc: 0.9832 - val_accuracy: 0.9456 - val_cost: 7.1842\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1475 - auc: 0.9854 - accuracy: 0.9479 - cost: 6.6102 - val_loss: 0.1541 - val_auc: 0.9841 - val_accuracy: 0.9467 - val_cost: 6.9141\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1445 - auc: 0.9859 - accuracy: 0.9490 - cost: 6.4497 - val_loss: 0.1519 - val_auc: 0.9844 - val_accuracy: 0.9478 - val_cost: 6.8197\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1404 - auc: 0.9865 - accuracy: 0.9513 - cost: 6.1777 - val_loss: 0.1498 - val_auc: 0.9847 - val_accuracy: 0.9476 - val_cost: 6.9401\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9528 - cost: 5.9875 - val_loss: 0.1463 - val_auc: 0.9855 - val_accuracy: 0.9488 - val_cost: 6.4421\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9543 - cost: 5.8094 - val_loss: 0.1462 - val_auc: 0.9856 - val_accuracy: 0.9501 - val_cost: 6.6960\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1315 - auc: 0.9880 - accuracy: 0.9551 - cost: 5.6998 - val_loss: 0.1422 - val_auc: 0.9862 - val_accuracy: 0.9522 - val_cost: 6.0514\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9561 - cost: 5.5698 - val_loss: 0.1411 - val_auc: 0.9862 - val_accuracy: 0.9519 - val_cost: 6.3151\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9887 - accuracy: 0.9571 - cost: 5.4477 - val_loss: 0.1392 - val_auc: 0.9867 - val_accuracy: 0.9542 - val_cost: 5.8626\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1236 - auc: 0.9892 - accuracy: 0.9581 - cost: 5.3092 - val_loss: 0.1373 - val_auc: 0.9868 - val_accuracy: 0.9549 - val_cost: 6.0124\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2286 - val_loss: 0.1370 - val_auc: 0.9868 - val_accuracy: 0.9548 - val_cost: 5.6738\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1197 - auc: 0.9897 - accuracy: 0.9596 - cost: 5.1200 - val_loss: 0.1333 - val_auc: 0.9873 - val_accuracy: 0.9569 - val_cost: 5.6315\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9720 - val_loss: 0.1328 - val_auc: 0.9874 - val_accuracy: 0.9570 - val_cost: 5.4102\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1153 - auc: 0.9902 - accuracy: 0.9618 - cost: 4.8539 - val_loss: 0.1319 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.1986\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1132 - auc: 0.9905 - accuracy: 0.9625 - cost: 4.7699 - val_loss: 0.1314 - val_auc: 0.9875 - val_accuracy: 0.9577 - val_cost: 5.3646\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9631 - cost: 4.6849 - val_loss: 0.1290 - val_auc: 0.9879 - val_accuracy: 0.9581 - val_cost: 5.4980\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9642 - cost: 4.5584 - val_loss: 0.1258 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 4.9772\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1087 - auc: 0.9910 - accuracy: 0.9646 - cost: 4.4944 - val_loss: 0.1263 - val_auc: 0.9881 - val_accuracy: 0.9599 - val_cost: 5.1823\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9653 - cost: 4.4097 - val_loss: 0.1250 - val_auc: 0.9884 - val_accuracy: 0.9617 - val_cost: 4.7917\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3572 - val_loss: 0.1239 - val_auc: 0.9885 - val_accuracy: 0.9619 - val_cost: 4.8600\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1041 - auc: 0.9915 - accuracy: 0.9664 - cost: 4.2683 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9627 - val_cost: 4.6842\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9918 - accuracy: 0.9673 - cost: 4.1469 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9608 - val_cost: 4.7038\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1013 - auc: 0.9920 - accuracy: 0.9675 - cost: 4.1224 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9621 - val_cost: 5.0358\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1222 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9625 - val_cost: 4.8958\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9687 - cost: 3.9819 - val_loss: 0.1195 - val_auc: 0.9890 - val_accuracy: 0.9624 - val_cost: 4.6452\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9403 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9620 - val_cost: 4.9707\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9065 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9641 - val_cost: 4.5801\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9698 - cost: 3.8361 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9633 - val_cost: 4.5573\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9706 - cost: 3.7442 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9640 - val_cost: 4.4173\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9928 - accuracy: 0.9715 - cost: 3.6276 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9652 - val_cost: 4.4727\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6934 - val_loss: 0.1173 - val_auc: 0.9894 - val_accuracy: 0.9640 - val_cost: 4.2643\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9709 - cost: 3.7031 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9653 - val_cost: 4.3522\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9712 - cost: 3.6680 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9663 - val_cost: 4.3066\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9931 - accuracy: 0.9720 - cost: 3.5760 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9656 - val_cost: 4.2253\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9726 - cost: 3.4841 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.1634\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4795 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9651 - val_cost: 4.2220\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4553 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9663 - val_cost: 4.3359\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4255 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9660 - val_cost: 4.1309\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0857 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3892 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9664 - val_cost: 4.2839\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3576 - val_loss: 0.1105 - val_auc: 0.9902 - val_accuracy: 0.9668 - val_cost: 4.0234\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0844 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2509 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9677 - val_cost: 4.1374\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9936 - accuracy: 0.9742 - cost: 3.2928 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9672 - val_cost: 4.1146\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9936 - accuracy: 0.9744 - cost: 3.2747 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9665 - val_cost: 4.2090\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2256 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9684 - val_cost: 4.0365\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0829 - auc: 0.9938 - accuracy: 0.9743 - cost: 3.2814 - val_loss: 0.1072 - val_auc: 0.9905 - val_accuracy: 0.9678 - val_cost: 3.9811\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1344 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9666 - val_cost: 4.2025\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1116 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9674 - val_cost: 3.8770\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1241 - val_loss: 0.1081 - val_auc: 0.9904 - val_accuracy: 0.9677 - val_cost: 3.9421\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1146 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9676 - val_cost: 4.0007\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9940 - accuracy: 0.9762 - cost: 3.0371 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8086\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0911 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 3.8574\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0031 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9683 - val_cost: 3.9290\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0836 - val_loss: 0.1072 - val_auc: 0.9905 - val_accuracy: 0.9681 - val_cost: 3.9583\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9998 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9682 - val_cost: 3.8542\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0229 - val_loss: 0.1071 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 3.6784\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.9132 - val_loss: 0.1065 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 3.8932\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9521 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9193\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9389 - val_loss: 0.1070 - val_auc: 0.9905 - val_accuracy: 0.9685 - val_cost: 3.8672\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9155 - val_loss: 0.1070 - val_auc: 0.9904 - val_accuracy: 0.9686 - val_cost: 3.8411\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9094 - val_loss: 0.1054 - val_auc: 0.9906 - val_accuracy: 0.9694 - val_cost: 3.7891\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8850 - val_loss: 0.1074 - val_auc: 0.9906 - val_accuracy: 0.9694 - val_cost: 3.8216\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8419 - val_loss: 0.1065 - val_auc: 0.9905 - val_accuracy: 0.9690 - val_cost: 3.8053\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8199 - val_loss: 0.1078 - val_auc: 0.9906 - val_accuracy: 0.9688 - val_cost: 3.7858\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8775 - val_loss: 0.1075 - val_auc: 0.9903 - val_accuracy: 0.9691 - val_cost: 3.8249\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8101 - val_loss: 0.1073 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.7598\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8258 - val_loss: 0.1068 - val_auc: 0.9905 - val_accuracy: 0.9681 - val_cost: 3.8802\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8228 - val_loss: 0.1061 - val_auc: 0.9906 - val_accuracy: 0.9698 - val_cost: 3.6491\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7965 - val_loss: 0.1047 - val_auc: 0.9907 - val_accuracy: 0.9696 - val_cost: 3.7598\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9783 - cost: 2.7885 - val_loss: 0.1057 - val_auc: 0.9906 - val_accuracy: 0.9696 - val_cost: 4.0202\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9947 - accuracy: 0.9788 - cost: 2.7131 - val_loss: 0.1054 - val_auc: 0.9906 - val_accuracy: 0.9692 - val_cost: 3.7598\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7665 - val_loss: 0.1078 - val_auc: 0.9906 - val_accuracy: 0.9696 - val_cost: 3.9160\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7806 - val_loss: 0.1054 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.5840\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7797 - val_loss: 0.1068 - val_auc: 0.9907 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6805 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.8086\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7651 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9696 - val_cost: 3.7695\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7390 - val_loss: 0.1048 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.7337\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7352 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6698 - val_loss: 0.1057 - val_auc: 0.9905 - val_accuracy: 0.9689 - val_cost: 3.7956\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7416 - val_loss: 0.1037 - val_auc: 0.9910 - val_accuracy: 0.9702 - val_cost: 3.6751\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6429 - val_loss: 0.1035 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6844 - val_loss: 0.1062 - val_auc: 0.9907 - val_accuracy: 0.9698 - val_cost: 3.9225\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6429 - val_loss: 0.1052 - val_auc: 0.9908 - val_accuracy: 0.9713 - val_cost: 3.5091\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6161 - val_loss: 0.1054 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.7109\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6590 - val_loss: 0.1055 - val_auc: 0.9909 - val_accuracy: 0.9696 - val_cost: 3.9421\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6342 - val_loss: 0.1055 - val_auc: 0.9908 - val_accuracy: 0.9705 - val_cost: 3.6458\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6937 - val_loss: 0.1081 - val_auc: 0.9907 - val_accuracy: 0.9696 - val_cost: 3.6263\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5463 - val_loss: 0.1060 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.7044\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5682 - val_loss: 0.1059 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.6686\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5677 - val_loss: 0.1055 - val_auc: 0.9909 - val_accuracy: 0.9698 - val_cost: 3.9616\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5776 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.6523\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5415 - val_loss: 0.1064 - val_auc: 0.9909 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5402 - val_loss: 0.1059 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.8053\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6431 - val_loss: 0.1085 - val_auc: 0.9906 - val_accuracy: 0.9694 - val_cost: 3.6523\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5513 - val_loss: 0.1075 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.6882\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5439 - val_loss: 0.1071 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.7109\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9952 - accuracy: 0.9801 - cost: 2.5638 - val_loss: 0.1051 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5277 - val_loss: 0.1069 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.6491\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5386 - val_loss: 0.1085 - val_auc: 0.9905 - val_accuracy: 0.9687 - val_cost: 3.7956\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5406 - val_loss: 0.1078 - val_auc: 0.9910 - val_accuracy: 0.9702 - val_cost: 3.7598\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5379 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.6361\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5305 - val_loss: 0.1075 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.8802\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4463 - val_loss: 0.1094 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.7272\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4683 - val_loss: 0.1063 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4831 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9698 - val_cost: 3.9258\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5465 - val_loss: 0.1061 - val_auc: 0.9909 - val_accuracy: 0.9699 - val_cost: 3.8997\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5120 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9707 - val_cost: 3.5449\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4145 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.8477\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4613 - val_loss: 0.1100 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.5677\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4675 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9710 - val_cost: 3.7370\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4762 - val_loss: 0.1069 - val_auc: 0.9907 - val_accuracy: 0.9705 - val_cost: 3.6589\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4717 - val_loss: 0.1059 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.7337\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4868 - val_loss: 0.1061 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.6686\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3946 - val_loss: 0.1077 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.6816\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4779 - val_loss: 0.1055 - val_auc: 0.9908 - val_accuracy: 0.9719 - val_cost: 3.4928\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4073 - val_loss: 0.1070 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.5775\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4722 - val_loss: 0.1066 - val_auc: 0.9909 - val_accuracy: 0.9715 - val_cost: 3.3691\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4181 - val_loss: 0.1076 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.5840\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4437 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.6133\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3889 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.7988\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4160 - val_loss: 0.1070 - val_auc: 0.9905 - val_accuracy: 0.9715 - val_cost: 3.5742\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1083 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.6296\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4139 - val_loss: 0.1093 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.4017\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3726 - val_loss: 0.1105 - val_auc: 0.9905 - val_accuracy: 0.9719 - val_cost: 3.2194\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4300 - val_loss: 0.1079 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.4147\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4033 - val_loss: 0.1109 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.5905\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4136 - val_loss: 0.1066 - val_auc: 0.9908 - val_accuracy: 0.9717 - val_cost: 3.5026\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4272 - val_loss: 0.1097 - val_auc: 0.9906 - val_accuracy: 0.9699 - val_cost: 3.4766\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3617 - val_loss: 0.1077 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.5286\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3792 - val_loss: 0.1082 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.7923\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4095 - val_loss: 0.1071 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.5579\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3397 - val_loss: 0.1070 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.5938\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3706 - val_loss: 0.1081 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3375 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.4147\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3283 - val_loss: 0.1076 - val_auc: 0.9906 - val_accuracy: 0.9717 - val_cost: 3.4635\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3610 - val_loss: 0.1081 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.5840\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3499 - val_loss: 0.1077 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.5384\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2707 - val_loss: 0.1075 - val_auc: 0.9905 - val_accuracy: 0.9728 - val_cost: 3.3757\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3829 - val_loss: 0.1069 - val_auc: 0.9906 - val_accuracy: 0.9725 - val_cost: 3.3984\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3534 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.5124\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3266 - val_loss: 0.1105 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.4766\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9956 - accuracy: 0.9819 - cost: 2.3165 - val_loss: 0.1078 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.4896\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3843 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.4831\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3109 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.3171\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3153 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2792 - val_loss: 0.1095 - val_auc: 0.9905 - val_accuracy: 0.9717 - val_cost: 3.4473\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3253 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3316 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.5905\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.3021 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.4928\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2954 - val_loss: 0.1093 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.4115\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.2937 - val_loss: 0.1116 - val_auc: 0.9903 - val_accuracy: 0.9716 - val_cost: 3.4863\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3170 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9724 - val_cost: 3.4147\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3050 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.6068\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2907 - val_loss: 0.1087 - val_auc: 0.9905 - val_accuracy: 0.9723 - val_cost: 3.4245\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3753 - val_loss: 0.1099 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.5775\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2468 - val_loss: 0.1091 - val_auc: 0.9905 - val_accuracy: 0.9724 - val_cost: 3.2454\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2452 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9716 - val_cost: 3.4635\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3045 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9733 - val_cost: 3.2682\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9958 - accuracy: 0.9825 - cost: 2.2558 - val_loss: 0.1100 - val_auc: 0.9903 - val_accuracy: 0.9724 - val_cost: 3.3529\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3398 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9737 - val_cost: 3.2552\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2382 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.4147\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2942 - val_loss: 0.1103 - val_auc: 0.9905 - val_accuracy: 0.9725 - val_cost: 3.4538\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2488 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.2975\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2475 - val_loss: 0.1117 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.6393\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2661 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.4342\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2877 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.3887\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2305 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.6133\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2554 - val_loss: 0.1113 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.5352\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2568 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9728 - val_cost: 3.4049\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2454 - val_loss: 0.1127 - val_auc: 0.9901 - val_accuracy: 0.9713 - val_cost: 3.5352\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1870 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6719\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2367 - val_loss: 0.1151 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.5059\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2314 - val_loss: 0.1121 - val_auc: 0.9902 - val_accuracy: 0.9722 - val_cost: 3.4603\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2694 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.2650\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1071 - auc: 0.9906 - accuracy: 0.9714 - cost: 3.5125\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:41.677539\n",
            "fold accuracy: 0.9714375138282776 - fold cost: 3.512500047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 3s 6ms/step - loss: 0.5258 - auc: 0.8020 - accuracy: 0.7320 - cost: 35.6492 - val_loss: 0.3906 - val_auc: 0.9027 - val_accuracy: 0.8305 - val_cost: 21.4876\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3465 - auc: 0.9237 - accuracy: 0.8528 - cost: 18.7350 - val_loss: 0.3156 - val_auc: 0.9365 - val_accuracy: 0.8672 - val_cost: 16.1849\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9431 - accuracy: 0.8756 - cost: 15.7506 - val_loss: 0.2858 - val_auc: 0.9482 - val_accuracy: 0.8827 - val_cost: 14.3424\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2712 - auc: 0.9535 - accuracy: 0.8902 - cost: 13.8953 - val_loss: 0.2641 - val_auc: 0.9568 - val_accuracy: 0.8940 - val_cost: 13.8835\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2485 - auc: 0.9609 - accuracy: 0.9010 - cost: 12.5553 - val_loss: 0.2400 - val_auc: 0.9637 - val_accuracy: 0.9085 - val_cost: 11.3151\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2282 - auc: 0.9671 - accuracy: 0.9099 - cost: 11.4019 - val_loss: 0.2230 - val_auc: 0.9685 - val_accuracy: 0.9158 - val_cost: 10.3906\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2115 - auc: 0.9716 - accuracy: 0.9184 - cost: 10.3366 - val_loss: 0.2110 - val_auc: 0.9718 - val_accuracy: 0.9201 - val_cost: 9.7396\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1989 - auc: 0.9747 - accuracy: 0.9244 - cost: 9.5695 - val_loss: 0.1988 - val_auc: 0.9748 - val_accuracy: 0.9267 - val_cost: 9.1439\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1880 - auc: 0.9773 - accuracy: 0.9291 - cost: 8.9746 - val_loss: 0.1900 - val_auc: 0.9767 - val_accuracy: 0.9308 - val_cost: 8.8216\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1799 - auc: 0.9791 - accuracy: 0.9330 - cost: 8.5019 - val_loss: 0.1844 - val_auc: 0.9781 - val_accuracy: 0.9336 - val_cost: 8.5840\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1713 - auc: 0.9809 - accuracy: 0.9372 - cost: 7.9787 - val_loss: 0.1768 - val_auc: 0.9796 - val_accuracy: 0.9358 - val_cost: 8.3431\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1657 - auc: 0.9820 - accuracy: 0.9392 - cost: 7.7130 - val_loss: 0.1728 - val_auc: 0.9808 - val_accuracy: 0.9376 - val_cost: 8.0111\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1607 - auc: 0.9830 - accuracy: 0.9420 - cost: 7.3757 - val_loss: 0.1680 - val_auc: 0.9814 - val_accuracy: 0.9403 - val_cost: 7.5684\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1557 - auc: 0.9839 - accuracy: 0.9439 - cost: 7.1130 - val_loss: 0.1644 - val_auc: 0.9824 - val_accuracy: 0.9409 - val_cost: 7.3438\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1513 - auc: 0.9847 - accuracy: 0.9459 - cost: 6.8527 - val_loss: 0.1604 - val_auc: 0.9830 - val_accuracy: 0.9431 - val_cost: 7.1549\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1472 - auc: 0.9853 - accuracy: 0.9480 - cost: 6.5824 - val_loss: 0.1580 - val_auc: 0.9835 - val_accuracy: 0.9431 - val_cost: 7.4512\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1437 - auc: 0.9859 - accuracy: 0.9494 - cost: 6.4247 - val_loss: 0.1552 - val_auc: 0.9840 - val_accuracy: 0.9449 - val_cost: 6.9368\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9507 - cost: 6.2541 - val_loss: 0.1520 - val_auc: 0.9845 - val_accuracy: 0.9465 - val_cost: 6.8652\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1380 - auc: 0.9869 - accuracy: 0.9521 - cost: 6.0752 - val_loss: 0.1509 - val_auc: 0.9847 - val_accuracy: 0.9462 - val_cost: 6.5885\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1364 - auc: 0.9871 - accuracy: 0.9531 - cost: 5.9331 - val_loss: 0.1477 - val_auc: 0.9852 - val_accuracy: 0.9481 - val_cost: 6.6504\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1330 - auc: 0.9878 - accuracy: 0.9533 - cost: 5.9178 - val_loss: 0.1473 - val_auc: 0.9853 - val_accuracy: 0.9485 - val_cost: 6.5951\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1313 - auc: 0.9879 - accuracy: 0.9547 - cost: 5.7667 - val_loss: 0.1447 - val_auc: 0.9857 - val_accuracy: 0.9502 - val_cost: 6.3281\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1292 - auc: 0.9882 - accuracy: 0.9566 - cost: 5.5125 - val_loss: 0.1419 - val_auc: 0.9860 - val_accuracy: 0.9514 - val_cost: 6.0775\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1265 - auc: 0.9887 - accuracy: 0.9574 - cost: 5.4063 - val_loss: 0.1417 - val_auc: 0.9861 - val_accuracy: 0.9521 - val_cost: 6.1849\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9576 - cost: 5.3842 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9520 - val_cost: 6.1165\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1228 - auc: 0.9892 - accuracy: 0.9588 - cost: 5.2275 - val_loss: 0.1383 - val_auc: 0.9866 - val_accuracy: 0.9529 - val_cost: 6.0677\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1207 - auc: 0.9895 - accuracy: 0.9595 - cost: 5.1394 - val_loss: 0.1391 - val_auc: 0.9865 - val_accuracy: 0.9528 - val_cost: 6.2044\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1200 - auc: 0.9896 - accuracy: 0.9600 - cost: 5.0668 - val_loss: 0.1353 - val_auc: 0.9868 - val_accuracy: 0.9551 - val_cost: 5.9017\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1172 - auc: 0.9900 - accuracy: 0.9611 - cost: 4.9421 - val_loss: 0.1355 - val_auc: 0.9867 - val_accuracy: 0.9543 - val_cost: 6.0254\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1159 - auc: 0.9901 - accuracy: 0.9616 - cost: 4.8904 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9549 - val_cost: 5.9017\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9628 - cost: 4.7366 - val_loss: 0.1309 - val_auc: 0.9875 - val_accuracy: 0.9576 - val_cost: 5.5273\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9905 - accuracy: 0.9634 - cost: 4.6391 - val_loss: 0.1304 - val_auc: 0.9875 - val_accuracy: 0.9557 - val_cost: 5.8105\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9636 - cost: 4.6183 - val_loss: 0.1285 - val_auc: 0.9877 - val_accuracy: 0.9589 - val_cost: 5.3874\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1094 - auc: 0.9909 - accuracy: 0.9643 - cost: 4.5480 - val_loss: 0.1286 - val_auc: 0.9878 - val_accuracy: 0.9574 - val_cost: 5.5632\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1079 - auc: 0.9911 - accuracy: 0.9647 - cost: 4.4960 - val_loss: 0.1259 - val_auc: 0.9879 - val_accuracy: 0.9598 - val_cost: 5.3548\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1067 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3440 - val_loss: 0.1248 - val_auc: 0.9883 - val_accuracy: 0.9601 - val_cost: 5.2441\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9914 - accuracy: 0.9666 - cost: 4.2395 - val_loss: 0.1257 - val_auc: 0.9882 - val_accuracy: 0.9610 - val_cost: 5.0065\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9913 - accuracy: 0.9668 - cost: 4.2196 - val_loss: 0.1225 - val_auc: 0.9883 - val_accuracy: 0.9604 - val_cost: 5.2279\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1034 - auc: 0.9915 - accuracy: 0.9670 - cost: 4.2043 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9602 - val_cost: 5.2018\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1011 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1666 - val_loss: 0.1216 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 5.0911\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1007 - auc: 0.9918 - accuracy: 0.9682 - cost: 4.0495 - val_loss: 0.1213 - val_auc: 0.9887 - val_accuracy: 0.9620 - val_cost: 4.9349\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9683 - cost: 4.0399 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9622 - val_cost: 4.7298\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9920 - accuracy: 0.9689 - cost: 3.9653 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9643 - val_cost: 4.5671\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0970 - auc: 0.9922 - accuracy: 0.9693 - cost: 3.8921 - val_loss: 0.1174 - val_auc: 0.9889 - val_accuracy: 0.9631 - val_cost: 4.8014\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0955 - auc: 0.9925 - accuracy: 0.9700 - cost: 3.8221 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9631 - val_cost: 4.5703\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9925 - accuracy: 0.9698 - cost: 3.8410 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9624 - val_cost: 4.6549\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0943 - auc: 0.9925 - accuracy: 0.9702 - cost: 3.7956 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9643 - val_cost: 4.6289\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9927 - accuracy: 0.9708 - cost: 3.7141 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9641 - val_cost: 4.6191\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6880 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9644 - val_cost: 4.5833\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9928 - accuracy: 0.9714 - cost: 3.6402 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9648 - val_cost: 4.6224\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9719 - cost: 3.5862 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.3424\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0903 - auc: 0.9930 - accuracy: 0.9721 - cost: 3.5648 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9648 - val_cost: 4.1309\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0891 - auc: 0.9931 - accuracy: 0.9726 - cost: 3.5018 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9662 - val_cost: 4.5020\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9727 - cost: 3.4813 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9654 - val_cost: 4.3001\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5078 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.1634\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9725 - cost: 3.4967 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9652 - val_cost: 4.4303\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9933 - accuracy: 0.9730 - cost: 3.4518 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.0527\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3764 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9664 - val_cost: 4.0690\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0865 - auc: 0.9934 - accuracy: 0.9739 - cost: 3.3290 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.3815\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9934 - accuracy: 0.9737 - cost: 3.3532 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.1439\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9934 - accuracy: 0.9736 - cost: 3.3647 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1927\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3475 - val_loss: 0.1124 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.1081\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2521 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9661 - val_cost: 4.1374\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3196 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.2448\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2265 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9671 - val_cost: 4.0592\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0825 - auc: 0.9937 - accuracy: 0.9750 - cost: 3.1925 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9662 - val_cost: 4.1536\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2322 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9663 - val_cost: 4.3880\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1288 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.0137\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0821 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1829 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0430\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1476 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.0755\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9938 - accuracy: 0.9754 - cost: 3.1395 - val_loss: 0.1123 - val_auc: 0.9892 - val_accuracy: 0.9674 - val_cost: 3.8965\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0609 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.2318\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1220 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.0397\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.1007 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9323\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0660 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 3.9616\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0220 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 3.9616\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0463 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9671 - val_cost: 4.0690\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0586 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.2578\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0630 - val_loss: 0.1103 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.0983\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9383 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9676 - val_cost: 3.9648\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0374 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0788\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9608 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9670 - val_cost: 4.0169\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9113 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 3.9160\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0765 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9167 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9676 - val_cost: 3.9616\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0085 - val_loss: 0.1086 - val_auc: 0.9900 - val_accuracy: 0.9675 - val_cost: 4.0820\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9581 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 3.9160\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9255 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8867 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.7695\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8552 - val_loss: 0.1129 - val_auc: 0.9893 - val_accuracy: 0.9679 - val_cost: 3.8737\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9116 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.8835\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8347 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.9421\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8602 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8737\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7922 - val_loss: 0.1100 - val_auc: 0.9893 - val_accuracy: 0.9679 - val_cost: 3.9583\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8316 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8444\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8629 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9095\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8363 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8216\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8524 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8672\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8231 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7272\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8640 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0202\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8253 - val_loss: 0.1088 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8672\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7806 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8151\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8087 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.8021\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7899 - val_loss: 0.1113 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.8965\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7525 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9160\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8068 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7760\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.6897 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8151\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7620 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8574\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8063 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8346\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7337 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.7240\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7723 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 3.9746\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7305 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.8379\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7404 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9030\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7019 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.7858\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7025 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9290\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6694 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.7988\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7393 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8997\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6445 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6225 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8802\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6493 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.8737\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6667 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 3.7467\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6610 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9679 - val_cost: 3.9225\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5837 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.7793\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6503 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9671 - val_cost: 4.0332\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6698 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9193\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6929 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9682 - val_cost: 3.8997\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5846 - val_loss: 0.1116 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.7240\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5943 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9682 - val_cost: 3.8411\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6570 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.8574\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6012 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.7467\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6562 - val_loss: 0.1137 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6328\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6434 - val_loss: 0.1132 - val_auc: 0.9891 - val_accuracy: 0.9687 - val_cost: 3.8867\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6069 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7533\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6365 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6102 - val_loss: 0.1131 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.6849\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5885 - val_loss: 0.1138 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.7760\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5863 - val_loss: 0.1140 - val_auc: 0.9890 - val_accuracy: 0.9691 - val_cost: 3.7565\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5654 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 3.9551\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6049 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9693 - val_cost: 3.8216\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5548 - val_loss: 0.1148 - val_auc: 0.9890 - val_accuracy: 0.9686 - val_cost: 3.7663\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5683 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.7370\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5932 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 3.9453\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6300 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.8249\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5496 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7012\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5596 - val_loss: 0.1146 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.8021\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5506 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9686 - val_cost: 3.8216\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5154 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5699 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6979\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5318 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9691 - val_cost: 3.7663\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6274 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5753 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.7565\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5453 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5235 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.7012\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5074 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4926 - val_loss: 0.1158 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7858\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5292 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.8411\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5669 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.8802\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9957 - accuracy: 0.9799 - cost: 2.5747 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9684 - val_cost: 3.8997\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4125 - val_loss: 0.1169 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.7500\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5098 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9691 - val_cost: 3.8639\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5080 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.7760\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4660 - val_loss: 0.1193 - val_auc: 0.9882 - val_accuracy: 0.9685 - val_cost: 3.8509\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5350 - val_loss: 0.1192 - val_auc: 0.9883 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5404 - val_loss: 0.1159 - val_auc: 0.9889 - val_accuracy: 0.9700 - val_cost: 3.6947\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5413 - val_loss: 0.1179 - val_auc: 0.9889 - val_accuracy: 0.9685 - val_cost: 3.9160\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5310 - val_loss: 0.1209 - val_auc: 0.9885 - val_accuracy: 0.9686 - val_cost: 3.7305\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5181 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.4974 - val_loss: 0.1207 - val_auc: 0.9882 - val_accuracy: 0.9685 - val_cost: 3.8900\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5418 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9684 - val_cost: 3.8314\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4912 - val_loss: 0.1208 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.8118\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4687 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.7272\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4783 - val_loss: 0.1196 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.7305\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4396 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4461 - val_loss: 0.1193 - val_auc: 0.9885 - val_accuracy: 0.9687 - val_cost: 3.8737\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4928 - val_loss: 0.1189 - val_auc: 0.9889 - val_accuracy: 0.9689 - val_cost: 3.8444\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.3973 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.7402\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4889 - val_loss: 0.1205 - val_auc: 0.9888 - val_accuracy: 0.9700 - val_cost: 3.6296\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4774 - val_loss: 0.1171 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_cost: 3.7240\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4870 - val_loss: 0.1219 - val_auc: 0.9881 - val_accuracy: 0.9684 - val_cost: 3.8151\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4494 - val_loss: 0.1216 - val_auc: 0.9885 - val_accuracy: 0.9688 - val_cost: 3.8346\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4455 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9694 - val_cost: 3.7728\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4423 - val_loss: 0.1195 - val_auc: 0.9885 - val_accuracy: 0.9686 - val_cost: 3.7467\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4005 - val_loss: 0.1182 - val_auc: 0.9883 - val_accuracy: 0.9692 - val_cost: 3.7858\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4628 - val_loss: 0.1199 - val_auc: 0.9884 - val_accuracy: 0.9687 - val_cost: 3.9486\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4434 - val_loss: 0.1186 - val_auc: 0.9886 - val_accuracy: 0.9696 - val_cost: 3.7826\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4051 - val_loss: 0.1195 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.7435\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9805 - cost: 2.5013 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9686 - val_cost: 3.8151\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4455 - val_loss: 0.1198 - val_auc: 0.9883 - val_accuracy: 0.9691 - val_cost: 3.8184\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4974 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.7402\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4695 - val_loss: 0.1192 - val_auc: 0.9886 - val_accuracy: 0.9677 - val_cost: 3.9714\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4894 - val_loss: 0.1202 - val_auc: 0.9883 - val_accuracy: 0.9685 - val_cost: 3.8900\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3949 - val_loss: 0.1225 - val_auc: 0.9883 - val_accuracy: 0.9682 - val_cost: 3.8607\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4742 - val_loss: 0.1201 - val_auc: 0.9888 - val_accuracy: 0.9684 - val_cost: 3.7728\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4652 - val_loss: 0.1194 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.8216\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4111 - val_loss: 0.1188 - val_auc: 0.9884 - val_accuracy: 0.9693 - val_cost: 3.7793\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4226 - val_loss: 0.1232 - val_auc: 0.9883 - val_accuracy: 0.9688 - val_cost: 3.8607\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4553 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.8835\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4485 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.8672\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4916 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9691 - val_cost: 3.7923\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4709 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.6914\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3523 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9684 - val_cost: 3.8053\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.3977 - val_loss: 0.1233 - val_auc: 0.9881 - val_accuracy: 0.9682 - val_cost: 3.8704\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3973 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9684 - val_cost: 3.8477\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1202 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.7826\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4186 - val_loss: 0.1215 - val_auc: 0.9884 - val_accuracy: 0.9687 - val_cost: 3.8053\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3798 - val_loss: 0.1196 - val_auc: 0.9885 - val_accuracy: 0.9688 - val_cost: 3.8249\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4226 - val_loss: 0.1191 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.7793\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9960 - accuracy: 0.9810 - cost: 2.4308 - val_loss: 0.1214 - val_auc: 0.9886 - val_accuracy: 0.9689 - val_cost: 3.8802\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4004 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3590 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.7207\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4191 - val_loss: 0.1206 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8737\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4260 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9692 - val_cost: 3.7533\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4214 - val_loss: 0.1202 - val_auc: 0.9882 - val_accuracy: 0.9695 - val_cost: 3.7695\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3970 - val_loss: 0.1209 - val_auc: 0.9882 - val_accuracy: 0.9701 - val_cost: 3.6589\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3921 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9355\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4200 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9697 - val_cost: 3.7109\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4147 - val_loss: 0.1225 - val_auc: 0.9881 - val_accuracy: 0.9685 - val_cost: 3.9844\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9962 - accuracy: 0.9815 - cost: 2.3707 - val_loss: 0.1234 - val_auc: 0.9882 - val_accuracy: 0.9685 - val_cost: 3.9030\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4054 - val_loss: 0.1223 - val_auc: 0.9881 - val_accuracy: 0.9680 - val_cost: 3.9486\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4117 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9962 - accuracy: 0.9812 - cost: 2.4155 - val_loss: 0.1244 - val_auc: 0.9881 - val_accuracy: 0.9694 - val_cost: 3.7337\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3611 - val_loss: 0.1187 - val_auc: 0.9883 - val_accuracy: 0.9692 - val_cost: 3.9062\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4223 - val_loss: 0.1237 - val_auc: 0.9879 - val_accuracy: 0.9682 - val_cost: 3.9421\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3794 - val_loss: 0.1233 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.8704\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3641 - val_loss: 0.1231 - val_auc: 0.9882 - val_accuracy: 0.9693 - val_cost: 3.7500\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3704 - val_loss: 0.1206 - val_auc: 0.9884 - val_accuracy: 0.9691 - val_cost: 3.8932\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4181 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9692 - val_cost: 3.8379\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9721 - cost: 3.5469\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:04.012204\n",
            "fold accuracy: 0.9720625281333923 - fold cost: 3.546875\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5249 - auc: 0.8029 - accuracy: 0.7321 - cost: 35.5695 - val_loss: 0.3867 - val_auc: 0.9046 - val_accuracy: 0.8326 - val_cost: 21.4388\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3461 - auc: 0.9239 - accuracy: 0.8521 - cost: 18.8079 - val_loss: 0.3120 - val_auc: 0.9382 - val_accuracy: 0.8698 - val_cost: 15.9473\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2984 - auc: 0.9437 - accuracy: 0.8750 - cost: 15.8360 - val_loss: 0.2798 - val_auc: 0.9505 - val_accuracy: 0.8858 - val_cost: 14.0039\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2709 - auc: 0.9536 - accuracy: 0.8896 - cost: 13.9626 - val_loss: 0.2556 - val_auc: 0.9587 - val_accuracy: 0.8966 - val_cost: 12.8906\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9010 - cost: 12.5193 - val_loss: 0.2361 - val_auc: 0.9650 - val_accuracy: 0.9087 - val_cost: 11.0417\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2273 - auc: 0.9674 - accuracy: 0.9117 - cost: 11.1737 - val_loss: 0.2191 - val_auc: 0.9695 - val_accuracy: 0.9155 - val_cost: 10.3190\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.2109 - auc: 0.9718 - accuracy: 0.9187 - cost: 10.2815 - val_loss: 0.2057 - val_auc: 0.9733 - val_accuracy: 0.9237 - val_cost: 9.4629\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1979 - auc: 0.9750 - accuracy: 0.9245 - cost: 9.5446 - val_loss: 0.1928 - val_auc: 0.9762 - val_accuracy: 0.9299 - val_cost: 8.5612\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1870 - auc: 0.9777 - accuracy: 0.9296 - cost: 8.8928 - val_loss: 0.1845 - val_auc: 0.9782 - val_accuracy: 0.9337 - val_cost: 8.1217\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1783 - auc: 0.9794 - accuracy: 0.9338 - cost: 8.3830 - val_loss: 0.1774 - val_auc: 0.9795 - val_accuracy: 0.9383 - val_cost: 7.9818\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1705 - auc: 0.9811 - accuracy: 0.9370 - cost: 7.9794 - val_loss: 0.1718 - val_auc: 0.9808 - val_accuracy: 0.9399 - val_cost: 7.4154\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1638 - auc: 0.9825 - accuracy: 0.9397 - cost: 7.6394 - val_loss: 0.1660 - val_auc: 0.9819 - val_accuracy: 0.9419 - val_cost: 7.7148\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1586 - auc: 0.9834 - accuracy: 0.9429 - cost: 7.2303 - val_loss: 0.1619 - val_auc: 0.9826 - val_accuracy: 0.9428 - val_cost: 7.4512\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1537 - auc: 0.9844 - accuracy: 0.9451 - cost: 6.9543 - val_loss: 0.1590 - val_auc: 0.9835 - val_accuracy: 0.9444 - val_cost: 6.9401\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1497 - auc: 0.9850 - accuracy: 0.9472 - cost: 6.6941 - val_loss: 0.1567 - val_auc: 0.9840 - val_accuracy: 0.9442 - val_cost: 7.1257\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1454 - auc: 0.9858 - accuracy: 0.9482 - cost: 6.5777 - val_loss: 0.1515 - val_auc: 0.9847 - val_accuracy: 0.9470 - val_cost: 7.0443\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1423 - auc: 0.9863 - accuracy: 0.9494 - cost: 6.4171 - val_loss: 0.1498 - val_auc: 0.9849 - val_accuracy: 0.9485 - val_cost: 6.8197\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9506 - cost: 6.2491 - val_loss: 0.1473 - val_auc: 0.9853 - val_accuracy: 0.9496 - val_cost: 7.0215\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1366 - auc: 0.9873 - accuracy: 0.9524 - cost: 6.0286 - val_loss: 0.1464 - val_auc: 0.9854 - val_accuracy: 0.9497 - val_cost: 6.5951\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1342 - auc: 0.9876 - accuracy: 0.9537 - cost: 5.8740 - val_loss: 0.1435 - val_auc: 0.9857 - val_accuracy: 0.9517 - val_cost: 6.2695\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1321 - auc: 0.9879 - accuracy: 0.9543 - cost: 5.7988 - val_loss: 0.1425 - val_auc: 0.9860 - val_accuracy: 0.9515 - val_cost: 6.3965\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1304 - auc: 0.9881 - accuracy: 0.9557 - cost: 5.6126 - val_loss: 0.1413 - val_auc: 0.9863 - val_accuracy: 0.9527 - val_cost: 5.7747\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1278 - auc: 0.9886 - accuracy: 0.9570 - cost: 5.4551 - val_loss: 0.1400 - val_auc: 0.9862 - val_accuracy: 0.9540 - val_cost: 6.0514\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1258 - auc: 0.9889 - accuracy: 0.9569 - cost: 5.4609 - val_loss: 0.1379 - val_auc: 0.9868 - val_accuracy: 0.9541 - val_cost: 5.9896\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9891 - accuracy: 0.9586 - cost: 5.2722 - val_loss: 0.1371 - val_auc: 0.9867 - val_accuracy: 0.9554 - val_cost: 5.8594\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1223 - auc: 0.9893 - accuracy: 0.9590 - cost: 5.2211 - val_loss: 0.1362 - val_auc: 0.9869 - val_accuracy: 0.9563 - val_cost: 5.5957\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9896 - accuracy: 0.9597 - cost: 5.1027 - val_loss: 0.1343 - val_auc: 0.9871 - val_accuracy: 0.9551 - val_cost: 6.1361\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1182 - auc: 0.9899 - accuracy: 0.9606 - cost: 5.0022 - val_loss: 0.1343 - val_auc: 0.9871 - val_accuracy: 0.9571 - val_cost: 5.5046\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1168 - auc: 0.9901 - accuracy: 0.9608 - cost: 4.9732 - val_loss: 0.1333 - val_auc: 0.9872 - val_accuracy: 0.9565 - val_cost: 5.3613\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1154 - auc: 0.9902 - accuracy: 0.9618 - cost: 4.8480 - val_loss: 0.1310 - val_auc: 0.9875 - val_accuracy: 0.9588 - val_cost: 5.4362\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1141 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7749 - val_loss: 0.1322 - val_auc: 0.9873 - val_accuracy: 0.9578 - val_cost: 5.2214\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1124 - auc: 0.9906 - accuracy: 0.9628 - cost: 4.7242 - val_loss: 0.1298 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.4655\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9907 - accuracy: 0.9634 - cost: 4.6505 - val_loss: 0.1283 - val_auc: 0.9880 - val_accuracy: 0.9594 - val_cost: 4.8340\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1103 - auc: 0.9908 - accuracy: 0.9640 - cost: 4.5642 - val_loss: 0.1278 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 4.8958\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9912 - accuracy: 0.9653 - cost: 4.4046 - val_loss: 0.1267 - val_auc: 0.9878 - val_accuracy: 0.9599 - val_cost: 4.9837\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1074 - auc: 0.9913 - accuracy: 0.9650 - cost: 4.4269 - val_loss: 0.1273 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.1009\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9652 - cost: 4.4037 - val_loss: 0.1251 - val_auc: 0.9882 - val_accuracy: 0.9603 - val_cost: 5.2148\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.2919 - val_loss: 0.1246 - val_auc: 0.9882 - val_accuracy: 0.9613 - val_cost: 4.8503\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1033 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1722 - val_loss: 0.1236 - val_auc: 0.9883 - val_accuracy: 0.9624 - val_cost: 4.8991\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1026 - auc: 0.9918 - accuracy: 0.9671 - cost: 4.1852 - val_loss: 0.1228 - val_auc: 0.9884 - val_accuracy: 0.9626 - val_cost: 4.7461\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9919 - accuracy: 0.9679 - cost: 4.0675 - val_loss: 0.1232 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.8079\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1013 - auc: 0.9919 - accuracy: 0.9680 - cost: 4.0746 - val_loss: 0.1225 - val_auc: 0.9883 - val_accuracy: 0.9626 - val_cost: 4.6582\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0040 - val_loss: 0.1223 - val_auc: 0.9883 - val_accuracy: 0.9628 - val_cost: 4.6322\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9683 - cost: 4.0249 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9637 - val_cost: 4.8796\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8879 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9640 - val_cost: 4.5182\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8896 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.7852\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8487 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9632 - val_cost: 5.0618\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7696 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9645 - val_cost: 4.6289\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.7016 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.8503\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0932 - auc: 0.9927 - accuracy: 0.9710 - cost: 3.6802 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.4922\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6526 - val_loss: 0.1160 - val_auc: 0.9892 - val_accuracy: 0.9655 - val_cost: 4.2969\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9716 - cost: 3.6301 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9641 - val_cost: 4.6615\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9722 - cost: 3.5368 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9665 - val_cost: 4.4629\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9724 - cost: 3.5232 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.3229\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0887 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5002 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9662 - val_cost: 4.4108\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9933 - accuracy: 0.9728 - cost: 3.4537 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9668 - val_cost: 4.3457\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3791 - val_loss: 0.1130 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1764\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9738 - cost: 3.3343 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.1667\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3721 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 4.0365\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0862 - auc: 0.9934 - accuracy: 0.9738 - cost: 3.3263 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 4.0592\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9934 - accuracy: 0.9743 - cost: 3.2786 - val_loss: 0.1113 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.8770\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9742 - cost: 3.2884 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9974\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3146 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 4.3001\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9751 - cost: 3.1759 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 4.1406\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9753 - cost: 3.1558 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.8965\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0824 - auc: 0.9937 - accuracy: 0.9750 - cost: 3.1986 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9679 - val_cost: 4.0137\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1522 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 4.2122\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1384 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 4.0234\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1285 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9844\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9759 - cost: 3.0823 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8574\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0854 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9225\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9939 - accuracy: 0.9762 - cost: 3.0406 - val_loss: 0.1094 - val_auc: 0.9902 - val_accuracy: 0.9683 - val_cost: 3.9681\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0356 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 4.0072\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1186 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 4.1081\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9766 - cost: 2.9895 - val_loss: 0.1092 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7695\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9941 - accuracy: 0.9769 - cost: 2.9495 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 4.1569\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0788 - auc: 0.9942 - accuracy: 0.9764 - cost: 3.0258 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7402\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9505 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9160\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9942 - accuracy: 0.9773 - cost: 2.8862 - val_loss: 0.1077 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8411\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8521 - val_loss: 0.1083 - val_auc: 0.9904 - val_accuracy: 0.9689 - val_cost: 4.0202\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9260 - val_loss: 0.1080 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.8314\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9050 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.9811\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9300 - val_loss: 0.1072 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.8867\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.9097 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8281\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8384 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 4.0202\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8822 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.7728\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8186 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.8151\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9944 - accuracy: 0.9777 - cost: 2.8589 - val_loss: 0.1090 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8932\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7824 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8346\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7833 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.8216\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8293 - val_loss: 0.1071 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.7695\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7951 - val_loss: 0.1086 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7402\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7735 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8184\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7407 - val_loss: 0.1083 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7923\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7265 - val_loss: 0.1076 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7873 - val_loss: 0.1066 - val_auc: 0.9901 - val_accuracy: 0.9715 - val_cost: 3.6816\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7001 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.7142\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6700 - val_loss: 0.1082 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.9193\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7092 - val_loss: 0.1074 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6393\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6896 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.7500\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6674 - val_loss: 0.1082 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.8216\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6979 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.8184\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6579 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7956\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6879 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6491\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6012 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6133\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9796 - cost: 2.6225 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.6914\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6433 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8672\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6714 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6849\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6434 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.7793\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5900 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.6849\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6575 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9713 - val_cost: 3.6165\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6178 - val_loss: 0.1088 - val_auc: 0.9902 - val_accuracy: 0.9704 - val_cost: 3.8737\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6654 - val_loss: 0.1079 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.7012\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5975 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8867\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9799 - cost: 2.5763 - val_loss: 0.1077 - val_auc: 0.9904 - val_accuracy: 0.9720 - val_cost: 3.5677\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6087 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6621\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5923 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.7044\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5163 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6589\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6181 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.7109\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5745 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7240\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5660 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6719\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5790 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6426\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4970 - val_loss: 0.1106 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.6914\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5495 - val_loss: 0.1081 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.7012\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4930 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9720 - val_cost: 3.5645\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5567 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9731 - val_cost: 3.3919\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5563 - val_loss: 0.1084 - val_auc: 0.9899 - val_accuracy: 0.9723 - val_cost: 3.6035\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4930 - val_loss: 0.1075 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.7174\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4737 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.6198\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4881 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5775\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.4874 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.8607\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4728 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.7142\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4877 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6426\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4997 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9725 - val_cost: 3.6133\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4526 - val_loss: 0.1097 - val_auc: 0.9902 - val_accuracy: 0.9725 - val_cost: 3.5059\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4809 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6426\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4627 - val_loss: 0.1110 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5775\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4693 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.7044\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4839 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.6328\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4531 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6198\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3729 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6068\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4362 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.6621\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4365 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4172 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.6849\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4108 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6621\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3290 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.7174\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4625 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7370\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4426 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.6882\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4403 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7272\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4091 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.7370\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4096 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3467 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6230\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3756 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.6165\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3814 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.7174\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3532 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3702 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6686\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3382 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9721 - val_cost: 3.5840\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3602 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6719\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3233 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.7240\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4142 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7467\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3832 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6654\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3552 - val_loss: 0.1136 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7533\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3445 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3667 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6198\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3523 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.7663\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3348 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6979\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2970 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.7923\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3795 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7305\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3124 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.6589\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3473 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6979\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3479 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.8314\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3391 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6328\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3065 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6947\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3502 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7240\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3206 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.5710\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2917 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.6621\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1023 - auc: 0.9903 - accuracy: 0.9720 - cost: 3.4906\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:37.222040\n",
            "fold accuracy: 0.972000002861023 - fold cost: 3.4906249046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5280 - auc: 0.7996 - accuracy: 0.7308 - cost: 35.7990 - val_loss: 0.3931 - val_auc: 0.9017 - val_accuracy: 0.8292 - val_cost: 22.3730\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3484 - auc: 0.9228 - accuracy: 0.8502 - cost: 19.0535 - val_loss: 0.3144 - val_auc: 0.9370 - val_accuracy: 0.8659 - val_cost: 16.6243\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8758 - cost: 15.7348 - val_loss: 0.2836 - val_auc: 0.9490 - val_accuracy: 0.8833 - val_cost: 14.2285\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.2718 - auc: 0.9532 - accuracy: 0.8890 - cost: 14.0779 - val_loss: 0.2587 - val_auc: 0.9575 - val_accuracy: 0.8956 - val_cost: 12.8320\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2486 - auc: 0.9610 - accuracy: 0.9005 - cost: 12.5939 - val_loss: 0.2398 - val_auc: 0.9638 - val_accuracy: 0.9062 - val_cost: 11.5072\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2285 - auc: 0.9670 - accuracy: 0.9110 - cost: 11.2455 - val_loss: 0.2207 - val_auc: 0.9692 - val_accuracy: 0.9149 - val_cost: 10.6055\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2118 - auc: 0.9716 - accuracy: 0.9181 - cost: 10.3763 - val_loss: 0.2075 - val_auc: 0.9727 - val_accuracy: 0.9208 - val_cost: 9.7949\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1991 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6771 - val_loss: 0.1959 - val_auc: 0.9755 - val_accuracy: 0.9268 - val_cost: 8.9714\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1882 - auc: 0.9773 - accuracy: 0.9292 - cost: 8.9695 - val_loss: 0.1869 - val_auc: 0.9777 - val_accuracy: 0.9315 - val_cost: 8.6263\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1794 - auc: 0.9793 - accuracy: 0.9336 - cost: 8.4129 - val_loss: 0.1794 - val_auc: 0.9793 - val_accuracy: 0.9347 - val_cost: 8.3431\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1711 - auc: 0.9810 - accuracy: 0.9374 - cost: 7.9268 - val_loss: 0.1728 - val_auc: 0.9807 - val_accuracy: 0.9383 - val_cost: 7.9004\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1643 - auc: 0.9824 - accuracy: 0.9404 - cost: 7.5742 - val_loss: 0.1692 - val_auc: 0.9812 - val_accuracy: 0.9403 - val_cost: 7.5716\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1591 - auc: 0.9833 - accuracy: 0.9424 - cost: 7.3156 - val_loss: 0.1633 - val_auc: 0.9824 - val_accuracy: 0.9424 - val_cost: 7.4740\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1531 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9553 - val_loss: 0.1602 - val_auc: 0.9831 - val_accuracy: 0.9428 - val_cost: 7.1712\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1493 - auc: 0.9851 - accuracy: 0.9474 - cost: 6.6705 - val_loss: 0.1566 - val_auc: 0.9837 - val_accuracy: 0.9460 - val_cost: 6.9661\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1448 - auc: 0.9858 - accuracy: 0.9483 - cost: 6.5533 - val_loss: 0.1532 - val_auc: 0.9843 - val_accuracy: 0.9472 - val_cost: 6.7383\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1417 - auc: 0.9863 - accuracy: 0.9501 - cost: 6.3358 - val_loss: 0.1494 - val_auc: 0.9850 - val_accuracy: 0.9483 - val_cost: 6.6504\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9518 - cost: 6.1251 - val_loss: 0.1470 - val_auc: 0.9853 - val_accuracy: 0.9491 - val_cost: 6.6732\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1359 - auc: 0.9873 - accuracy: 0.9526 - cost: 6.0349 - val_loss: 0.1460 - val_auc: 0.9857 - val_accuracy: 0.9490 - val_cost: 6.3281\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1322 - auc: 0.9879 - accuracy: 0.9547 - cost: 5.7541 - val_loss: 0.1435 - val_auc: 0.9860 - val_accuracy: 0.9506 - val_cost: 6.3672\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1299 - auc: 0.9882 - accuracy: 0.9558 - cost: 5.6184 - val_loss: 0.1409 - val_auc: 0.9863 - val_accuracy: 0.9530 - val_cost: 6.1393\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1268 - auc: 0.9886 - accuracy: 0.9570 - cost: 5.4582 - val_loss: 0.1397 - val_auc: 0.9864 - val_accuracy: 0.9544 - val_cost: 5.9668\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1260 - auc: 0.9887 - accuracy: 0.9578 - cost: 5.3702 - val_loss: 0.1358 - val_auc: 0.9868 - val_accuracy: 0.9557 - val_cost: 5.5566\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1226 - auc: 0.9893 - accuracy: 0.9588 - cost: 5.2346 - val_loss: 0.1347 - val_auc: 0.9871 - val_accuracy: 0.9563 - val_cost: 5.7357\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9599 - cost: 5.1022 - val_loss: 0.1345 - val_auc: 0.9871 - val_accuracy: 0.9560 - val_cost: 5.5990\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9603 - cost: 5.0427 - val_loss: 0.1325 - val_auc: 0.9875 - val_accuracy: 0.9579 - val_cost: 5.3971\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1160 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.8972 - val_loss: 0.1291 - val_auc: 0.9878 - val_accuracy: 0.9584 - val_cost: 5.3158\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1140 - auc: 0.9903 - accuracy: 0.9623 - cost: 4.8002 - val_loss: 0.1297 - val_auc: 0.9879 - val_accuracy: 0.9582 - val_cost: 5.3776\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7381 - val_loss: 0.1307 - val_auc: 0.9879 - val_accuracy: 0.9587 - val_cost: 4.9609\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9637 - cost: 4.6213 - val_loss: 0.1273 - val_auc: 0.9878 - val_accuracy: 0.9588 - val_cost: 5.1693\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1080 - auc: 0.9911 - accuracy: 0.9645 - cost: 4.5124 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9600 - val_cost: 5.0651\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1071 - auc: 0.9912 - accuracy: 0.9655 - cost: 4.3917 - val_loss: 0.1237 - val_auc: 0.9885 - val_accuracy: 0.9608 - val_cost: 5.0879\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1051 - auc: 0.9915 - accuracy: 0.9660 - cost: 4.3208 - val_loss: 0.1237 - val_auc: 0.9887 - val_accuracy: 0.9610 - val_cost: 5.0260\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9665 - cost: 4.2502 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9607 - val_cost: 5.1660\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1029 - auc: 0.9917 - accuracy: 0.9670 - cost: 4.1993 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9627 - val_cost: 4.7201\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1016 - auc: 0.9919 - accuracy: 0.9675 - cost: 4.1461 - val_loss: 0.1214 - val_auc: 0.9886 - val_accuracy: 0.9620 - val_cost: 4.6680\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9684 - cost: 4.0111 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9633 - val_cost: 4.4531\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0227 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9631 - val_cost: 4.7493\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9691 - cost: 3.9428 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9644 - val_cost: 4.3197\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8423 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9649 - val_cost: 4.2025\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0950 - auc: 0.9926 - accuracy: 0.9702 - cost: 3.7883 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.3262\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9702 - cost: 3.7921 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9650 - val_cost: 4.3099\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0932 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7267 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9660 - val_cost: 4.1406\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9929 - accuracy: 0.9715 - cost: 3.6298 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9660 - val_cost: 4.3424\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0922 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6896 - val_loss: 0.1120 - val_auc: 0.9899 - val_accuracy: 0.9657 - val_cost: 4.1536\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6338 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9642 - val_cost: 4.3132\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5505 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9662 - val_cost: 4.1406\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0882 - auc: 0.9932 - accuracy: 0.9730 - cost: 3.4436 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.1634\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9728 - cost: 3.4769 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9660 - val_cost: 4.1341\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4415 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9665 - val_cost: 4.0755\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4326 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9670 - val_cost: 4.3327\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4577 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9669 - val_cost: 4.0072\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9734 - cost: 3.3853 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9674 - val_cost: 3.9909\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0851 - auc: 0.9935 - accuracy: 0.9746 - cost: 3.2482 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9675 - val_cost: 4.0332\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3307 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9669 - val_cost: 4.1211\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2598 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9676 - val_cost: 4.0853\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9936 - accuracy: 0.9746 - cost: 3.2374 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.9160\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2546 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 3.8770\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2265 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9714\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1885 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 4.0007\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1113 - val_loss: 0.1077 - val_auc: 0.9901 - val_accuracy: 0.9677 - val_cost: 4.1634\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2356 - val_loss: 0.1091 - val_auc: 0.9899 - val_accuracy: 0.9677 - val_cost: 3.8704\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0834 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 4.0365\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0660 - val_loss: 0.1069 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0299\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0304 - val_loss: 0.1061 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.8965\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0530 - val_loss: 0.1050 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8444\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0018 - val_loss: 0.1047 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.9095\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9854 - val_loss: 0.1049 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_cost: 3.9160\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0783 - auc: 0.9942 - accuracy: 0.9767 - cost: 2.9763 - val_loss: 0.1081 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0781 - auc: 0.9941 - accuracy: 0.9767 - cost: 2.9716 - val_loss: 0.1052 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.9421\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9766 - cost: 2.9849 - val_loss: 0.1051 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7728\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9943 - accuracy: 0.9770 - cost: 2.9378 - val_loss: 0.1055 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.8249\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9686 - val_loss: 0.1070 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 4.0495\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9517 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8216\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9776 - cost: 2.8574 - val_loss: 0.1044 - val_auc: 0.9905 - val_accuracy: 0.9698 - val_cost: 3.8477\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.8976 - val_loss: 0.1059 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.9681\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9778 - cost: 2.8356 - val_loss: 0.1063 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9746\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1059 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.9160\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8431 - val_loss: 0.1058 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7760\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8135 - val_loss: 0.1057 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 4.0267\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8762 - val_loss: 0.1050 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.7858\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8117 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8184\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8165 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.8965\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8278 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.7988\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7737 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7663\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9945 - accuracy: 0.9781 - cost: 2.7979 - val_loss: 0.1043 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.6784\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7582 - val_loss: 0.1072 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7630\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6632 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9699 - val_cost: 3.8672\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.6930 - val_loss: 0.1072 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7565\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0731 - auc: 0.9946 - accuracy: 0.9784 - cost: 2.7545 - val_loss: 0.1047 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8184\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7510 - val_loss: 0.1069 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7174\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7109 - val_loss: 0.1063 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7435\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7405 - val_loss: 0.1062 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7240\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9948 - accuracy: 0.9793 - cost: 2.6509 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6361\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7722 - val_loss: 0.1059 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6960 - val_loss: 0.1077 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6458\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.6974 - val_loss: 0.1045 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.7435\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6647 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.6100\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6714 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7598\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6601 - val_loss: 0.1070 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.8184\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6184 - val_loss: 0.1053 - val_auc: 0.9902 - val_accuracy: 0.9719 - val_cost: 3.5677\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6506 - val_loss: 0.1065 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.6523\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6025 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6979\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.6032 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.7142\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5761 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.7174\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9949 - accuracy: 0.9796 - cost: 2.6204 - val_loss: 0.1067 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.6230\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6183 - val_loss: 0.1063 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8704\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5984 - val_loss: 0.1057 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.7402\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5355 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.7305\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9950 - accuracy: 0.9801 - cost: 2.5657 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5091\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5251 - val_loss: 0.1073 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.4701\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5674 - val_loss: 0.1087 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5547\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9951 - accuracy: 0.9804 - cost: 2.5160 - val_loss: 0.1074 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5782 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.7240\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5441 - val_loss: 0.1090 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.9128\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5887 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.5221\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5347 - val_loss: 0.1081 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.7500\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9806 - cost: 2.4951 - val_loss: 0.1084 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6914\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9808 - cost: 2.4555 - val_loss: 0.1065 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.6003\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4757 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.5221\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5160 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4882 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.7402\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4957 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8737\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.4998 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6719\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9807 - cost: 2.4728 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7858\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4605 - val_loss: 0.1068 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.6947\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5411 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.4668\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4607 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6719\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5385 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.6491\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4899 - val_loss: 0.1089 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.7012\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4691 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.7012\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4621 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7207\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9811 - cost: 2.4169 - val_loss: 0.1071 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.7207\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4385 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.6914\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4777 - val_loss: 0.1073 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5286\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4208 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7663\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.3998 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6133\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4261 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.3496\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9810 - cost: 2.4290 - val_loss: 0.1091 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.5840\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3612 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6979\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9813 - cost: 2.3936 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5710\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9817 - cost: 2.3359 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.4603\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4426 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.8151\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4161 - val_loss: 0.1089 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4831\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9955 - accuracy: 0.9818 - cost: 2.3414 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7044\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9955 - accuracy: 0.9815 - cost: 2.3690 - val_loss: 0.1084 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7109\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.3937 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3858 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7142\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3625 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.8314\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3812 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.4961\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4544 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.5319\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3724 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.5645\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4031 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.4993\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9816 - cost: 2.3619 - val_loss: 0.1122 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4733\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3393 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.7174\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4172 - val_loss: 0.1116 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3798 - val_loss: 0.1121 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.5905\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3003 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5710\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9821 - cost: 2.2993 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.7598\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3121 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8444\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9822 - cost: 2.2769 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.6816\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3364 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.7207\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3253 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.8086\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9956 - accuracy: 0.9818 - cost: 2.3322 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.7663\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3232 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7174\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3371 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7630\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.3042 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.7663\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2862 - val_loss: 0.1126 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6426\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3230 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6947\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3450 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.4733\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3429 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6882\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0617 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2776 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6491\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2588 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6816\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2861 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5254\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3223 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.4277\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9959 - accuracy: 0.9828 - cost: 2.2175 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6003\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9957 - accuracy: 0.9821 - cost: 2.2988 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.3626\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9823 - cost: 2.2789 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.5124\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3362 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.7077\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2963 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9720 - val_cost: 3.6068\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3259 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4993\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2730 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.4603\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2863 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.5417\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2206 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4961\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3357 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9726 - val_cost: 3.5286\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2304 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.3138\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2730 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9728 - val_cost: 3.5286\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3129 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4798\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2835 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.5384\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9958 - accuracy: 0.9821 - cost: 2.2891 - val_loss: 0.1150 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.3789\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2677 - val_loss: 0.1161 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4180\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9959 - accuracy: 0.9827 - cost: 2.2216 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5905\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2864 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4603\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9830 - cost: 2.1862 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3105\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2925 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6589\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2151 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6361\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2213 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.6003\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9959 - accuracy: 0.9826 - cost: 2.2197 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.7012\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2667 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9718 - val_cost: 3.4896\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.2176 - val_loss: 0.1174 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.4440\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2380 - val_loss: 0.1186 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1864 - val_loss: 0.1152 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.5612\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.2108 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6751\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2626 - val_loss: 0.1179 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6719\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1947 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.6100\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2339 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6589\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1946 - val_loss: 0.1167 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.4766\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2522 - val_loss: 0.1185 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.5221\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2122 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7109\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3135 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9731 - val_cost: 3.4928\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2456 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.5775\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1639 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9724 - val_cost: 3.5221\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1772 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6003\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2877 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.5677\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1925 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.4212\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2084 - val_loss: 0.1181 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.5514\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1837 - val_loss: 0.1174 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.6003\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2119 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8379\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2857 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9832 - cost: 2.1554 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6621\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1674 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4570\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2167 - val_loss: 0.1179 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7337\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1530 - val_loss: 0.1192 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.6296\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1941 - val_loss: 0.1182 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6751\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2426 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.5514\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2132 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.6100\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1799 - val_loss: 0.1183 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6654\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9833 - cost: 2.1435 - val_loss: 0.1189 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5612\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1766 - val_loss: 0.1189 - val_auc: 0.9892 - val_accuracy: 0.9718 - val_cost: 3.4310\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1914 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5938\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1818 - val_loss: 0.1196 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.5905\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2080 - val_loss: 0.1244 - val_auc: 0.9889 - val_accuracy: 0.9698 - val_cost: 3.8086\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1559 - val_loss: 0.1191 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5352\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1525 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9710 - val_cost: 3.5352\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1674 - val_loss: 0.1211 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.4701\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1316 - val_loss: 0.1201 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.4766\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1647 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9728 - val_cost: 3.2975\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1663 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9720 - val_cost: 3.5710\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9963 - accuracy: 0.9837 - cost: 2.0835 - val_loss: 0.1218 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.5612\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1809 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1464 - val_loss: 0.1208 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6263\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1309 - val_loss: 0.1213 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.6393\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1503 - val_loss: 0.1197 - val_auc: 0.9892 - val_accuracy: 0.9723 - val_cost: 3.5221\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0580 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1774 - val_loss: 0.1190 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4408\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9963 - accuracy: 0.9838 - cost: 2.0809 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6230\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1764 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.4538\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1694 - val_loss: 0.1234 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.4896\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1563 - val_loss: 0.1228 - val_auc: 0.9889 - val_accuracy: 0.9712 - val_cost: 3.4310\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1571 - val_loss: 0.1248 - val_auc: 0.9888 - val_accuracy: 0.9710 - val_cost: 3.5026\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1200 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.4603\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1923 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.5091\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1263 - val_loss: 0.1226 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.8086\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1203 - val_loss: 0.1223 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.6165\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1667 - val_loss: 0.1221 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8411\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1514 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6947\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1413 - val_loss: 0.1221 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.6361\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9833 - cost: 2.1493 - val_loss: 0.1219 - val_auc: 0.9891 - val_accuracy: 0.9709 - val_cost: 3.6393\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1786 - val_loss: 0.1255 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.7988\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1805 - val_loss: 0.1219 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.7240\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1290 - val_loss: 0.1210 - val_auc: 0.9892 - val_accuracy: 0.9725 - val_cost: 3.5449\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1660 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.5352\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0564 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1460 - val_loss: 0.1234 - val_auc: 0.9890 - val_accuracy: 0.9708 - val_cost: 3.6426\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1325 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9717 - val_cost: 3.5938\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1216 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9714 - val_cost: 3.5417\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1329 - val_loss: 0.1225 - val_auc: 0.9887 - val_accuracy: 0.9714 - val_cost: 3.6816\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1988 - val_loss: 0.1237 - val_auc: 0.9888 - val_accuracy: 0.9712 - val_cost: 3.5091\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1051 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.5286\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9964 - accuracy: 0.9838 - cost: 2.0841 - val_loss: 0.1261 - val_auc: 0.9884 - val_accuracy: 0.9708 - val_cost: 3.7370\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0559 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.0877 - val_loss: 0.1267 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.6458\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1616 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9716 - val_cost: 3.6784\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1276 - val_loss: 0.1264 - val_auc: 0.9885 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1243 - val_loss: 0.1251 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.6263\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9836 - cost: 2.1049 - val_loss: 0.1235 - val_auc: 0.9889 - val_accuracy: 0.9714 - val_cost: 3.6263\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9966 - accuracy: 0.9840 - cost: 2.0613 - val_loss: 0.1266 - val_auc: 0.9886 - val_accuracy: 0.9710 - val_cost: 3.6068\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1592 - val_loss: 0.1258 - val_auc: 0.9885 - val_accuracy: 0.9700 - val_cost: 3.9160\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1266 - val_loss: 0.1263 - val_auc: 0.9884 - val_accuracy: 0.9712 - val_cost: 3.4668\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9839 - cost: 2.0716 - val_loss: 0.1250 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0551 - auc: 0.9966 - accuracy: 0.9841 - cost: 2.0365 - val_loss: 0.1272 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.5775\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1178 - val_loss: 0.1247 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7826\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1788 - val_loss: 0.1228 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.6914\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0555 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1099 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9713 - val_cost: 3.6491\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0554 - auc: 0.9965 - accuracy: 0.9838 - cost: 2.0824 - val_loss: 0.1238 - val_auc: 0.9890 - val_accuracy: 0.9709 - val_cost: 3.3529\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1309 - val_loss: 0.1260 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.6914\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1435 - val_loss: 0.1258 - val_auc: 0.9886 - val_accuracy: 0.9700 - val_cost: 3.9128\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0546 - auc: 0.9967 - accuracy: 0.9838 - cost: 2.0926 - val_loss: 0.1275 - val_auc: 0.9886 - val_accuracy: 0.9709 - val_cost: 3.5449\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.1029 - val_loss: 0.1245 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7630\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.1036 - val_loss: 0.1257 - val_auc: 0.9887 - val_accuracy: 0.9713 - val_cost: 3.6328\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1054 - auc: 0.9913 - accuracy: 0.9723 - cost: 3.4719\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:41.952254\n",
            "fold accuracy: 0.9723125100135803 - fold cost: 3.471874952316284\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5248 - auc: 0.8028 - accuracy: 0.7316 - cost: 35.6855 - val_loss: 0.3935 - val_auc: 0.9015 - val_accuracy: 0.8296 - val_cost: 21.7415\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3482 - auc: 0.9230 - accuracy: 0.8514 - cost: 18.8816 - val_loss: 0.3188 - val_auc: 0.9356 - val_accuracy: 0.8640 - val_cost: 16.3151\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3000 - auc: 0.9430 - accuracy: 0.8758 - cost: 15.7191 - val_loss: 0.2868 - val_auc: 0.9480 - val_accuracy: 0.8817 - val_cost: 14.4694\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2710 - auc: 0.9536 - accuracy: 0.8898 - cost: 13.9448 - val_loss: 0.2624 - val_auc: 0.9563 - val_accuracy: 0.8953 - val_cost: 12.6270\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2478 - auc: 0.9613 - accuracy: 0.9014 - cost: 12.4762 - val_loss: 0.2421 - val_auc: 0.9630 - val_accuracy: 0.9053 - val_cost: 11.5755\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2292 - auc: 0.9668 - accuracy: 0.9107 - cost: 11.3052 - val_loss: 0.2252 - val_auc: 0.9679 - val_accuracy: 0.9132 - val_cost: 10.6445\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2135 - auc: 0.9711 - accuracy: 0.9176 - cost: 10.4226 - val_loss: 0.2123 - val_auc: 0.9714 - val_accuracy: 0.9201 - val_cost: 9.8503\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2010 - auc: 0.9743 - accuracy: 0.9234 - cost: 9.7140 - val_loss: 0.2009 - val_auc: 0.9743 - val_accuracy: 0.9272 - val_cost: 9.0755\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1895 - auc: 0.9770 - accuracy: 0.9287 - cost: 9.0097 - val_loss: 0.1916 - val_auc: 0.9766 - val_accuracy: 0.9308 - val_cost: 8.3561\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1809 - auc: 0.9789 - accuracy: 0.9325 - cost: 8.5363 - val_loss: 0.1826 - val_auc: 0.9783 - val_accuracy: 0.9345 - val_cost: 8.0990\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1728 - auc: 0.9806 - accuracy: 0.9362 - cost: 8.0918 - val_loss: 0.1764 - val_auc: 0.9797 - val_accuracy: 0.9366 - val_cost: 8.0241\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1662 - auc: 0.9820 - accuracy: 0.9392 - cost: 7.6938 - val_loss: 0.1727 - val_auc: 0.9808 - val_accuracy: 0.9382 - val_cost: 7.4577\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1593 - auc: 0.9833 - accuracy: 0.9425 - cost: 7.2649 - val_loss: 0.1656 - val_auc: 0.9820 - val_accuracy: 0.9409 - val_cost: 7.5879\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1551 - auc: 0.9840 - accuracy: 0.9449 - cost: 6.9799 - val_loss: 0.1620 - val_auc: 0.9826 - val_accuracy: 0.9415 - val_cost: 7.2721\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1499 - auc: 0.9850 - accuracy: 0.9472 - cost: 6.6989 - val_loss: 0.1576 - val_auc: 0.9834 - val_accuracy: 0.9449 - val_cost: 7.0996\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1458 - auc: 0.9857 - accuracy: 0.9491 - cost: 6.4510 - val_loss: 0.1546 - val_auc: 0.9840 - val_accuracy: 0.9454 - val_cost: 7.0703\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1422 - auc: 0.9863 - accuracy: 0.9502 - cost: 6.2903 - val_loss: 0.1515 - val_auc: 0.9845 - val_accuracy: 0.9463 - val_cost: 6.9596\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1397 - auc: 0.9867 - accuracy: 0.9517 - cost: 6.1217 - val_loss: 0.1496 - val_auc: 0.9850 - val_accuracy: 0.9488 - val_cost: 6.9857\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1369 - auc: 0.9871 - accuracy: 0.9524 - cost: 6.0384 - val_loss: 0.1460 - val_auc: 0.9855 - val_accuracy: 0.9480 - val_cost: 6.6895\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9543 - cost: 5.7915 - val_loss: 0.1469 - val_auc: 0.9855 - val_accuracy: 0.9488 - val_cost: 6.4062\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1317 - auc: 0.9879 - accuracy: 0.9549 - cost: 5.7094 - val_loss: 0.1419 - val_auc: 0.9861 - val_accuracy: 0.9507 - val_cost: 6.4941\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9560 - cost: 5.5783 - val_loss: 0.1407 - val_auc: 0.9861 - val_accuracy: 0.9520 - val_cost: 6.3118\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9887 - accuracy: 0.9569 - cost: 5.4626 - val_loss: 0.1376 - val_auc: 0.9867 - val_accuracy: 0.9533 - val_cost: 5.9440\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1248 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.4009 - val_loss: 0.1368 - val_auc: 0.9867 - val_accuracy: 0.9548 - val_cost: 5.6283\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1218 - auc: 0.9894 - accuracy: 0.9590 - cost: 5.1877 - val_loss: 0.1352 - val_auc: 0.9872 - val_accuracy: 0.9541 - val_cost: 5.8887\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1199 - auc: 0.9896 - accuracy: 0.9600 - cost: 5.0888 - val_loss: 0.1334 - val_auc: 0.9873 - val_accuracy: 0.9558 - val_cost: 5.8398\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9604 - cost: 5.0176 - val_loss: 0.1323 - val_auc: 0.9875 - val_accuracy: 0.9567 - val_cost: 5.4004\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1165 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.8966 - val_loss: 0.1305 - val_auc: 0.9876 - val_accuracy: 0.9572 - val_cost: 5.4655\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9620 - cost: 4.8117 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9574 - val_cost: 5.4948\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9638 - cost: 4.5863 - val_loss: 0.1288 - val_auc: 0.9878 - val_accuracy: 0.9585 - val_cost: 5.3027\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1099 - auc: 0.9909 - accuracy: 0.9643 - cost: 4.5205 - val_loss: 0.1260 - val_auc: 0.9882 - val_accuracy: 0.9594 - val_cost: 5.3223\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9909 - accuracy: 0.9647 - cost: 4.4798 - val_loss: 0.1257 - val_auc: 0.9881 - val_accuracy: 0.9592 - val_cost: 5.1921\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1068 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4390 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9608 - val_cost: 4.9609\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1047 - auc: 0.9915 - accuracy: 0.9662 - cost: 4.3051 - val_loss: 0.1225 - val_auc: 0.9885 - val_accuracy: 0.9614 - val_cost: 4.9186\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1042 - auc: 0.9915 - accuracy: 0.9668 - cost: 4.2202 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9617 - val_cost: 4.8796\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1022 - auc: 0.9917 - accuracy: 0.9672 - cost: 4.1562 - val_loss: 0.1197 - val_auc: 0.9889 - val_accuracy: 0.9628 - val_cost: 4.6322\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1012 - auc: 0.9919 - accuracy: 0.9678 - cost: 4.0791 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.5703\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0993 - auc: 0.9920 - accuracy: 0.9683 - cost: 4.0286 - val_loss: 0.1180 - val_auc: 0.9889 - val_accuracy: 0.9636 - val_cost: 4.5182\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0984 - auc: 0.9921 - accuracy: 0.9686 - cost: 3.9962 - val_loss: 0.1171 - val_auc: 0.9888 - val_accuracy: 0.9634 - val_cost: 4.6126\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9692 - cost: 3.9159 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9653 - val_cost: 4.4108\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9695 - cost: 3.8784 - val_loss: 0.1155 - val_auc: 0.9889 - val_accuracy: 0.9646 - val_cost: 4.5638\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0964 - auc: 0.9922 - accuracy: 0.9697 - cost: 3.8680 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9662 - val_cost: 4.1504\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0938 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7491 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.3620\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6939 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.3262\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0923 - auc: 0.9927 - accuracy: 0.9715 - cost: 3.6264 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.2220\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9715 - cost: 3.6405 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9674 - val_cost: 4.0658\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0903 - auc: 0.9930 - accuracy: 0.9721 - cost: 3.5566 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.0658\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9726 - cost: 3.4857 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.1243\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5133 - val_loss: 0.1119 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.3913\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9730 - cost: 3.4461 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.0592\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9733 - cost: 3.3942 - val_loss: 0.1095 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.0365\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9735 - cost: 3.3717 - val_loss: 0.1089 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.0885\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0869 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.4198 - val_loss: 0.1092 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.8900\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0855 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3463 - val_loss: 0.1082 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.0951\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9935 - accuracy: 0.9744 - cost: 3.2763 - val_loss: 0.1075 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 4.0169\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2551 - val_loss: 0.1073 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8932\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9745 - cost: 3.2492 - val_loss: 0.1070 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.9128\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2262 - val_loss: 0.1074 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.8118\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1606 - val_loss: 0.1061 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8509\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9938 - accuracy: 0.9752 - cost: 3.1642 - val_loss: 0.1060 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 3.9583\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1413 - val_loss: 0.1058 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.8346\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0818 - auc: 0.9938 - accuracy: 0.9756 - cost: 3.1223 - val_loss: 0.1048 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 3.8542\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0602 - val_loss: 0.1058 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9939 - accuracy: 0.9760 - cost: 3.0646 - val_loss: 0.1043 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.8835\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0792 - auc: 0.9940 - accuracy: 0.9763 - cost: 3.0400 - val_loss: 0.1047 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6654\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0596 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.7305\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0936 - val_loss: 0.1038 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.7533\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9915 - val_loss: 0.1046 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.8960 - val_loss: 0.1050 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8151\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9770 - cost: 2.9381 - val_loss: 0.1047 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6751\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9349 - val_loss: 0.1026 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.6751\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.8977 - val_loss: 0.1044 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.8411\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0759 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8917 - val_loss: 0.1032 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.7760\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9057 - val_loss: 0.1045 - val_auc: 0.9904 - val_accuracy: 0.9717 - val_cost: 3.6068\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8792 - val_loss: 0.1051 - val_auc: 0.9903 - val_accuracy: 0.9711 - val_cost: 3.7956\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0749 - auc: 0.9945 - accuracy: 0.9779 - cost: 2.8188 - val_loss: 0.1035 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.8444\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8222 - val_loss: 0.1048 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.7760\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.8117 - val_loss: 0.1042 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.6198\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8173 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7923\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8133 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7533\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8029 - val_loss: 0.1054 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.7467\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7743 - val_loss: 0.1043 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.8542\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7782 - val_loss: 0.1052 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.6882\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7343 - val_loss: 0.1059 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7548 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 4.0495\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7607 - val_loss: 0.1053 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.7174\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6939 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.8411\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.6834 - val_loss: 0.1043 - val_auc: 0.9906 - val_accuracy: 0.9707 - val_cost: 3.8151\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7218 - val_loss: 0.1033 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.8509\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6871 - val_loss: 0.1052 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.8770\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6817 - val_loss: 0.1057 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.8281\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6804 - val_loss: 0.1035 - val_auc: 0.9905 - val_accuracy: 0.9717 - val_cost: 3.6458\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6582 - val_loss: 0.1047 - val_auc: 0.9906 - val_accuracy: 0.9713 - val_cost: 3.6686\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6925 - val_loss: 0.1046 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.7174\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6764 - val_loss: 0.1054 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6230\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6246 - val_loss: 0.1044 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7728\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6188 - val_loss: 0.1050 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.7923\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6499 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.8607\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6903 - val_loss: 0.1048 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.6914\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6322 - val_loss: 0.1056 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.9551\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6300 - val_loss: 0.1048 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6263\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5906 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6589\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6047 - val_loss: 0.1061 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.8835\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.5141 - val_loss: 0.1058 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.8118\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6199 - val_loss: 0.1061 - val_auc: 0.9902 - val_accuracy: 0.9723 - val_cost: 3.5970\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5801 - val_loss: 0.1056 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 4.0104\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5613 - val_loss: 0.1056 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.9095\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5765 - val_loss: 0.1046 - val_auc: 0.9905 - val_accuracy: 0.9730 - val_cost: 3.6296\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5160 - val_loss: 0.1060 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.7923\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5605 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9722 - val_cost: 3.6003\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4995 - val_loss: 0.1060 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.8704\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5439 - val_loss: 0.1038 - val_auc: 0.9906 - val_accuracy: 0.9722 - val_cost: 3.7923\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9952 - accuracy: 0.9805 - cost: 2.4960 - val_loss: 0.1053 - val_auc: 0.9905 - val_accuracy: 0.9717 - val_cost: 3.7630\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5851 - val_loss: 0.1047 - val_auc: 0.9904 - val_accuracy: 0.9722 - val_cost: 3.6686\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5740 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.6133\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5441 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.8542\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4796 - val_loss: 0.1055 - val_auc: 0.9904 - val_accuracy: 0.9713 - val_cost: 3.8314\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5659 - val_loss: 0.1067 - val_auc: 0.9901 - val_accuracy: 0.9722 - val_cost: 3.5742\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5347 - val_loss: 0.1070 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.7988\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4733 - val_loss: 0.1062 - val_auc: 0.9904 - val_accuracy: 0.9719 - val_cost: 3.6556\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4743 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.7630\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4937 - val_loss: 0.1066 - val_auc: 0.9903 - val_accuracy: 0.9715 - val_cost: 3.9616\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4508 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9710 - val_cost: 3.8281\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4552 - val_loss: 0.1062 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.8346\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4887 - val_loss: 0.1063 - val_auc: 0.9902 - val_accuracy: 0.9720 - val_cost: 3.7793\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4805 - val_loss: 0.1084 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.9062\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4426 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.8997\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4973 - val_loss: 0.1090 - val_auc: 0.9903 - val_accuracy: 0.9721 - val_cost: 3.8021\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4465 - val_loss: 0.1066 - val_auc: 0.9905 - val_accuracy: 0.9722 - val_cost: 3.9290\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4787 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.8867\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4764 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.7500\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4632 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 4.1536\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4606 - val_loss: 0.1081 - val_auc: 0.9905 - val_accuracy: 0.9710 - val_cost: 3.8835\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4105 - val_loss: 0.1083 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.7663\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3968 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.9811\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4224 - val_loss: 0.1091 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 4.0007\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4534 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.5710\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4617 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9719 - val_cost: 3.7272\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4155 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 4.1178\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4454 - val_loss: 0.1099 - val_auc: 0.9902 - val_accuracy: 0.9718 - val_cost: 3.8835\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4338 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 4.0007\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3846 - val_loss: 0.1120 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 4.0365\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3953 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 4.0104\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4510 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 4.0430\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4224 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 4.1309\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4047 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 4.1178\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3285 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 4.1667\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4051 - val_loss: 0.1116 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.8574\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3845 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 4.2220\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3897 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 4.1471\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3624 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.8737\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9957 - accuracy: 0.9820 - cost: 2.3031 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.8542\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3781 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 4.0104\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3526 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.9876\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3500 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.9388\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3539 - val_loss: 0.1119 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 4.0820\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 4.0365\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3913 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.9095\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3913 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 4.1113\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3554 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 4.0820\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4225 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 4.0299\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3500 - val_loss: 0.1109 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.9811\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3598 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.9681\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3938 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.8965\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3446 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 4.0755\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3454 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 4.2415\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.4000 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 4.0137\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3432 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8607\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3518 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.9616\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3247 - val_loss: 0.1142 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.8932\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3362 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 4.0397\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3800 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.8249\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2961 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 4.0495\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3447 - val_loss: 0.1139 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 4.0267\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2673 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.9258\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2862 - val_loss: 0.1151 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 4.0299\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3265 - val_loss: 0.1129 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 4.0592\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2742 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 4.0690\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2762 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 4.1439\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3124 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 4.2155\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2630 - val_loss: 0.1155 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 4.0397\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2774 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 4.1960\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3289 - val_loss: 0.1144 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 4.0299\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3028 - val_loss: 0.1180 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 4.1536\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2803 - val_loss: 0.1148 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.8118\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2935 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 4.1178\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3318 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.8509\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1100 - auc: 0.9901 - accuracy: 0.9701 - cost: 3.8094\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:43.806792\n",
            "fold accuracy: 0.9700624942779541 - fold cost: 3.809375047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.5245 - auc: 0.8034 - accuracy: 0.7324 - cost: 35.5634 - val_loss: 0.3908 - val_auc: 0.9022 - val_accuracy: 0.8295 - val_cost: 21.8424\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.3472 - auc: 0.9235 - accuracy: 0.8508 - cost: 18.9853 - val_loss: 0.3141 - val_auc: 0.9372 - val_accuracy: 0.8643 - val_cost: 16.5885\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2996 - auc: 0.9433 - accuracy: 0.8760 - cost: 15.6933 - val_loss: 0.2848 - val_auc: 0.9489 - val_accuracy: 0.8815 - val_cost: 14.2090\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2705 - auc: 0.9538 - accuracy: 0.8899 - cost: 13.9156 - val_loss: 0.2607 - val_auc: 0.9570 - val_accuracy: 0.8947 - val_cost: 12.9688\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2474 - auc: 0.9614 - accuracy: 0.9005 - cost: 12.5905 - val_loss: 0.2423 - val_auc: 0.9629 - val_accuracy: 0.9051 - val_cost: 11.4323\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2282 - auc: 0.9671 - accuracy: 0.9100 - cost: 11.3999 - val_loss: 0.2266 - val_auc: 0.9675 - val_accuracy: 0.9113 - val_cost: 10.7845\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2125 - auc: 0.9714 - accuracy: 0.9180 - cost: 10.3666 - val_loss: 0.2127 - val_auc: 0.9715 - val_accuracy: 0.9203 - val_cost: 9.9382\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1995 - auc: 0.9747 - accuracy: 0.9235 - cost: 9.6787 - val_loss: 0.2014 - val_auc: 0.9742 - val_accuracy: 0.9262 - val_cost: 8.9355\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1883 - auc: 0.9773 - accuracy: 0.9292 - cost: 8.9750 - val_loss: 0.1926 - val_auc: 0.9763 - val_accuracy: 0.9317 - val_cost: 8.0208\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1784 - auc: 0.9794 - accuracy: 0.9343 - cost: 8.3417 - val_loss: 0.1850 - val_auc: 0.9779 - val_accuracy: 0.9342 - val_cost: 8.1966\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1714 - auc: 0.9809 - accuracy: 0.9368 - cost: 8.0085 - val_loss: 0.1782 - val_auc: 0.9791 - val_accuracy: 0.9356 - val_cost: 8.1999\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1652 - auc: 0.9821 - accuracy: 0.9392 - cost: 7.7158 - val_loss: 0.1730 - val_auc: 0.9803 - val_accuracy: 0.9393 - val_cost: 7.7409\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1592 - auc: 0.9833 - accuracy: 0.9421 - cost: 7.3427 - val_loss: 0.1690 - val_auc: 0.9811 - val_accuracy: 0.9415 - val_cost: 7.3470\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1544 - auc: 0.9842 - accuracy: 0.9446 - cost: 7.0158 - val_loss: 0.1645 - val_auc: 0.9820 - val_accuracy: 0.9424 - val_cost: 6.9727\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1502 - auc: 0.9849 - accuracy: 0.9464 - cost: 6.7806 - val_loss: 0.1607 - val_auc: 0.9827 - val_accuracy: 0.9451 - val_cost: 6.8717\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1455 - auc: 0.9857 - accuracy: 0.9488 - cost: 6.4871 - val_loss: 0.1577 - val_auc: 0.9832 - val_accuracy: 0.9454 - val_cost: 6.7383\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1431 - auc: 0.9861 - accuracy: 0.9498 - cost: 6.3691 - val_loss: 0.1567 - val_auc: 0.9839 - val_accuracy: 0.9451 - val_cost: 6.4290\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9868 - accuracy: 0.9507 - cost: 6.2543 - val_loss: 0.1526 - val_auc: 0.9841 - val_accuracy: 0.9478 - val_cost: 6.3737\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1370 - auc: 0.9871 - accuracy: 0.9519 - cost: 6.0868 - val_loss: 0.1504 - val_auc: 0.9844 - val_accuracy: 0.9494 - val_cost: 6.1849\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1336 - auc: 0.9876 - accuracy: 0.9537 - cost: 5.8557 - val_loss: 0.1487 - val_auc: 0.9847 - val_accuracy: 0.9503 - val_cost: 6.2435\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9881 - accuracy: 0.9549 - cost: 5.7144 - val_loss: 0.1472 - val_auc: 0.9849 - val_accuracy: 0.9500 - val_cost: 6.2826\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1296 - auc: 0.9883 - accuracy: 0.9557 - cost: 5.6222 - val_loss: 0.1451 - val_auc: 0.9854 - val_accuracy: 0.9518 - val_cost: 5.8789\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1263 - auc: 0.9888 - accuracy: 0.9571 - cost: 5.4465 - val_loss: 0.1432 - val_auc: 0.9857 - val_accuracy: 0.9527 - val_cost: 5.5859\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1248 - auc: 0.9890 - accuracy: 0.9571 - cost: 5.4459 - val_loss: 0.1416 - val_auc: 0.9859 - val_accuracy: 0.9533 - val_cost: 5.7227\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1231 - auc: 0.9892 - accuracy: 0.9581 - cost: 5.2881 - val_loss: 0.1406 - val_auc: 0.9859 - val_accuracy: 0.9548 - val_cost: 5.6413\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1206 - auc: 0.9896 - accuracy: 0.9594 - cost: 5.1478 - val_loss: 0.1388 - val_auc: 0.9860 - val_accuracy: 0.9551 - val_cost: 5.5827\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1186 - auc: 0.9898 - accuracy: 0.9603 - cost: 5.0337 - val_loss: 0.1386 - val_auc: 0.9862 - val_accuracy: 0.9559 - val_cost: 5.5501\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1169 - auc: 0.9899 - accuracy: 0.9613 - cost: 4.9192 - val_loss: 0.1348 - val_auc: 0.9867 - val_accuracy: 0.9571 - val_cost: 5.3483\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1153 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8307 - val_loss: 0.1348 - val_auc: 0.9866 - val_accuracy: 0.9573 - val_cost: 5.3255\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9623 - cost: 4.7746 - val_loss: 0.1325 - val_auc: 0.9870 - val_accuracy: 0.9578 - val_cost: 5.3418\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1127 - auc: 0.9906 - accuracy: 0.9633 - cost: 4.6633 - val_loss: 0.1315 - val_auc: 0.9870 - val_accuracy: 0.9594 - val_cost: 5.0586\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1103 - auc: 0.9909 - accuracy: 0.9641 - cost: 4.5567 - val_loss: 0.1309 - val_auc: 0.9871 - val_accuracy: 0.9596 - val_cost: 5.1693\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9910 - accuracy: 0.9644 - cost: 4.5060 - val_loss: 0.1275 - val_auc: 0.9877 - val_accuracy: 0.9609 - val_cost: 4.9577\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1073 - auc: 0.9912 - accuracy: 0.9651 - cost: 4.4279 - val_loss: 0.1291 - val_auc: 0.9871 - val_accuracy: 0.9606 - val_cost: 4.9251\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1057 - auc: 0.9915 - accuracy: 0.9654 - cost: 4.4012 - val_loss: 0.1269 - val_auc: 0.9878 - val_accuracy: 0.9615 - val_cost: 4.8014\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9663 - cost: 4.2729 - val_loss: 0.1266 - val_auc: 0.9876 - val_accuracy: 0.9613 - val_cost: 4.6452\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9665 - cost: 4.2494 - val_loss: 0.1250 - val_auc: 0.9878 - val_accuracy: 0.9612 - val_cost: 4.6777\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1020 - auc: 0.9917 - accuracy: 0.9671 - cost: 4.1874 - val_loss: 0.1247 - val_auc: 0.9879 - val_accuracy: 0.9616 - val_cost: 4.6354\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1006 - auc: 0.9920 - accuracy: 0.9677 - cost: 4.1123 - val_loss: 0.1237 - val_auc: 0.9882 - val_accuracy: 0.9615 - val_cost: 4.8047\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9923 - accuracy: 0.9684 - cost: 4.0060 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9642 - val_cost: 4.5215\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0980 - auc: 0.9923 - accuracy: 0.9691 - cost: 3.9147 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9628 - val_cost: 4.5671\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9690 - cost: 3.9291 - val_loss: 0.1206 - val_auc: 0.9884 - val_accuracy: 0.9630 - val_cost: 4.4694\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9924 - accuracy: 0.9698 - cost: 3.8265 - val_loss: 0.1199 - val_auc: 0.9885 - val_accuracy: 0.9647 - val_cost: 4.2773\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9698 - cost: 3.8286 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.4727\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7710 - val_loss: 0.1176 - val_auc: 0.9887 - val_accuracy: 0.9649 - val_cost: 4.2611\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0931 - auc: 0.9927 - accuracy: 0.9710 - cost: 3.6675 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9641 - val_cost: 4.4987\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6263 - val_loss: 0.1168 - val_auc: 0.9888 - val_accuracy: 0.9657 - val_cost: 4.1211\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0917 - auc: 0.9928 - accuracy: 0.9715 - cost: 3.6303 - val_loss: 0.1182 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.4564\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9930 - accuracy: 0.9716 - cost: 3.6177 - val_loss: 0.1160 - val_auc: 0.9889 - val_accuracy: 0.9651 - val_cost: 4.2839\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0895 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5202 - val_loss: 0.1174 - val_auc: 0.9890 - val_accuracy: 0.9643 - val_cost: 4.2448\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0897 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5690 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9651 - val_cost: 4.1602\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.5066 - val_loss: 0.1159 - val_auc: 0.9887 - val_accuracy: 0.9657 - val_cost: 4.1699\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9933 - accuracy: 0.9729 - cost: 3.4378 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.1471\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4879 - val_loss: 0.1144 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 4.1634\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9735 - cost: 3.3717 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0397\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9935 - accuracy: 0.9734 - cost: 3.3788 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9662 - val_cost: 4.0755\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3442 - val_loss: 0.1149 - val_auc: 0.9890 - val_accuracy: 0.9659 - val_cost: 4.1504\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2859 - val_loss: 0.1146 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 3.9844\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2972 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1699\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3059 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 3.8802\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9743 - cost: 3.2673 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.2285\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2535 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 3.7402\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2307 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 3.7012\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2142 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 3.9355\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0816 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1426 - val_loss: 0.1132 - val_auc: 0.9892 - val_accuracy: 0.9668 - val_cost: 4.1732\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1746 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.1536\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1366 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.8932\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0805 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.0919 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.0820\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1109 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1048\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.0983 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 3.9518\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9943 - accuracy: 0.9755 - cost: 3.1171 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.0853\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0790 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0285 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.8965\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0219 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 3.9714\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0778 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9813 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9671 - val_cost: 3.9616\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9564 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9670 - val_cost: 4.1471\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9502 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 3.9258\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9525 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9844\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9682 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0560\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8818 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.2220\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8786 - val_loss: 0.1143 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 3.8249\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9425 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.1081\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8843 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 4.1048\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8538 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9685 - val_cost: 4.0527\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8764 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0853\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8189 - val_loss: 0.1161 - val_auc: 0.9894 - val_accuracy: 0.9666 - val_cost: 4.1536\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8610 - val_loss: 0.1125 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.1536\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8833 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.7109\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8214 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9909\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8094 - val_loss: 0.1135 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9844\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8041 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9674 - val_cost: 4.0918\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8102 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0104\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7572 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.8118\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7644 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8346\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7341 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9160\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7078 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9160\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7418 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0104\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7796 - val_loss: 0.1139 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0234\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7241 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9355\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6883 - val_loss: 0.1125 - val_auc: 0.9893 - val_accuracy: 0.9691 - val_cost: 3.9355\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6763 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 4.0267\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7068 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.9616\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6822 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9518\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7108 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 3.9551\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7011 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9681 - val_cost: 4.0430\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6095 - val_loss: 0.1153 - val_auc: 0.9892 - val_accuracy: 0.9682 - val_cost: 3.9486\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6801 - val_loss: 0.1159 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9453\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6942 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.7305\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6215 - val_loss: 0.1157 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 3.8249\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5933 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9696 - val_cost: 3.7760\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6358 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9689 - val_cost: 3.9193\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6943 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8704\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6766 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6304 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9160\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5510 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6139 - val_loss: 0.1148 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7988\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6357 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 4.0072\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.5995 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9690 - val_cost: 4.0234\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5546 - val_loss: 0.1162 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 4.0072\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6404 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.7565\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6668 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8118\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5766 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.8086\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5978 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9699 - val_cost: 3.8607\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5759 - val_loss: 0.1176 - val_auc: 0.9887 - val_accuracy: 0.9691 - val_cost: 3.9421\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.5945 - val_loss: 0.1154 - val_auc: 0.9890 - val_accuracy: 0.9689 - val_cost: 3.9681\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5822 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.8379\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5075 - val_loss: 0.1170 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.9388\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5622 - val_loss: 0.1157 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.9355\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5357 - val_loss: 0.1154 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.8249\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5124 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9687 - val_cost: 3.9486\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5922 - val_loss: 0.1172 - val_auc: 0.9887 - val_accuracy: 0.9691 - val_cost: 3.8867\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5797 - val_loss: 0.1157 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.6621\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.4946 - val_loss: 0.1156 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4737 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5383 - val_loss: 0.1146 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.8770\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4965 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9062\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4996 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8835\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5187 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8477\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5414 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.8867\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5288 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8216\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4692 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7402\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4370 - val_loss: 0.1176 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.9193\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5342 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9697 - val_cost: 3.6621\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5093 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4519 - val_loss: 0.1177 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.9746\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4653 - val_loss: 0.1173 - val_auc: 0.9890 - val_accuracy: 0.9692 - val_cost: 3.9030\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5037 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.6914\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4802 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9687 - val_cost: 3.9323\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4426 - val_loss: 0.1165 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 4.1016\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4981 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9691 - val_cost: 3.8672\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4819 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8151\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4446 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9703 - val_cost: 3.8411\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4784 - val_loss: 0.1193 - val_auc: 0.9881 - val_accuracy: 0.9697 - val_cost: 3.9062\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5039 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9698 - val_cost: 3.8835\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4682 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9697 - val_cost: 3.8216\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4720 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9697 - val_cost: 3.8672\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4467 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 3.8444\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4415 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9689 - val_cost: 3.7598\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4225 - val_loss: 0.1197 - val_auc: 0.9887 - val_accuracy: 0.9691 - val_cost: 3.9518\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4732 - val_loss: 0.1203 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.7923\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4535 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9693 - val_cost: 3.8639\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4684 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9692 - val_cost: 3.8737\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4715 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9689 - val_cost: 3.7467\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4366 - val_loss: 0.1191 - val_auc: 0.9888 - val_accuracy: 0.9709 - val_cost: 3.7467\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3911 - val_loss: 0.1206 - val_auc: 0.9885 - val_accuracy: 0.9696 - val_cost: 3.8411\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3526 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.6979\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4444 - val_loss: 0.1196 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8542\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4092 - val_loss: 0.1200 - val_auc: 0.9884 - val_accuracy: 0.9701 - val_cost: 3.7728\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4149 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9708 - val_cost: 3.7240\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.3984 - val_loss: 0.1187 - val_auc: 0.9889 - val_accuracy: 0.9701 - val_cost: 3.6100\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4216 - val_loss: 0.1172 - val_auc: 0.9887 - val_accuracy: 0.9708 - val_cost: 3.6296\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4754 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.8574\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.3928 - val_loss: 0.1223 - val_auc: 0.9886 - val_accuracy: 0.9694 - val_cost: 3.8281\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3797 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.7109\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3558 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9712 - val_cost: 3.6686\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3812 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3949 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.8281\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3353 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9699 - val_cost: 3.8379\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3538 - val_loss: 0.1192 - val_auc: 0.9886 - val_accuracy: 0.9701 - val_cost: 3.6719\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3699 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.7630\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4136 - val_loss: 0.1214 - val_auc: 0.9886 - val_accuracy: 0.9692 - val_cost: 3.7240\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3834 - val_loss: 0.1220 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 4.0202\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3025 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7467\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3710 - val_loss: 0.1205 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.8053\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4068 - val_loss: 0.1181 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.6198\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3628 - val_loss: 0.1210 - val_auc: 0.9883 - val_accuracy: 0.9697 - val_cost: 3.8965\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3455 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9704 - val_cost: 3.5482\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4034 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9710 - val_cost: 3.5482\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3886 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9706 - val_cost: 3.7695\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3790 - val_loss: 0.1213 - val_auc: 0.9888 - val_accuracy: 0.9706 - val_cost: 3.6165\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3289 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.6393\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3307 - val_loss: 0.1209 - val_auc: 0.9887 - val_accuracy: 0.9699 - val_cost: 3.7012\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3126 - val_loss: 0.1220 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.4896\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4239 - val_loss: 0.1198 - val_auc: 0.9887 - val_accuracy: 0.9707 - val_cost: 3.5645\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3095 - val_loss: 0.1215 - val_auc: 0.9885 - val_accuracy: 0.9712 - val_cost: 3.7109\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3469 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.7012\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3788 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9706 - val_cost: 3.7370\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3626 - val_loss: 0.1204 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.5742\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3347 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9705 - val_cost: 3.5970\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3291 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9708 - val_cost: 3.6230\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3254 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9703 - val_cost: 3.7695\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3836 - val_loss: 0.1233 - val_auc: 0.9882 - val_accuracy: 0.9692 - val_cost: 3.8770\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3428 - val_loss: 0.1238 - val_auc: 0.9886 - val_accuracy: 0.9697 - val_cost: 3.6556\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3326 - val_loss: 0.1217 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.7109\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.3003 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9706 - val_cost: 3.6133\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3285 - val_loss: 0.1217 - val_auc: 0.9885 - val_accuracy: 0.9700 - val_cost: 3.7760\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9703 - val_cost: 3.6719\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3030 - val_loss: 0.1236 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.7435\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3286 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9705 - val_cost: 3.6556\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3238 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9697 - val_cost: 3.7402\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3439 - val_loss: 0.1245 - val_auc: 0.9884 - val_accuracy: 0.9689 - val_cost: 3.7402\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3367 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9698 - val_cost: 3.7728\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3341 - val_loss: 0.1239 - val_auc: 0.9884 - val_accuracy: 0.9704 - val_cost: 3.5807\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2951 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9710 - val_cost: 3.6784\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1232 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.6719\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3378 - val_loss: 0.1263 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.7533\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3533 - val_loss: 0.1225 - val_auc: 0.9887 - val_accuracy: 0.9691 - val_cost: 3.7077\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3311 - val_loss: 0.1245 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.7044\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3845 - val_loss: 0.1249 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.6784\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2752 - val_loss: 0.1234 - val_auc: 0.9889 - val_accuracy: 0.9699 - val_cost: 3.6230\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3077 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9695 - val_cost: 3.6751\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3052 - val_loss: 0.1244 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.7630\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2870 - val_loss: 0.1224 - val_auc: 0.9884 - val_accuracy: 0.9705 - val_cost: 3.6003\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2923 - val_loss: 0.1222 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.7305\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3130 - val_loss: 0.1254 - val_auc: 0.9884 - val_accuracy: 0.9706 - val_cost: 3.5872\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2894 - val_loss: 0.1230 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.7533\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2509 - val_loss: 0.1241 - val_auc: 0.9886 - val_accuracy: 0.9699 - val_cost: 3.6882\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3177 - val_loss: 0.1247 - val_auc: 0.9885 - val_accuracy: 0.9708 - val_cost: 3.5612\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2773 - val_loss: 0.1249 - val_auc: 0.9881 - val_accuracy: 0.9698 - val_cost: 3.5286\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2764 - val_loss: 0.1236 - val_auc: 0.9885 - val_accuracy: 0.9699 - val_cost: 3.7305\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2300 - val_loss: 0.1261 - val_auc: 0.9883 - val_accuracy: 0.9695 - val_cost: 3.6491\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3338 - val_loss: 0.1255 - val_auc: 0.9885 - val_accuracy: 0.9696 - val_cost: 3.8574\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2713 - val_loss: 0.1253 - val_auc: 0.9882 - val_accuracy: 0.9693 - val_cost: 3.7012\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2530 - val_loss: 0.1276 - val_auc: 0.9879 - val_accuracy: 0.9685 - val_cost: 3.8574\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2351 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9689 - val_cost: 3.6198\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2888 - val_loss: 0.1230 - val_auc: 0.9886 - val_accuracy: 0.9696 - val_cost: 3.7272\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2399 - val_loss: 0.1267 - val_auc: 0.9884 - val_accuracy: 0.9690 - val_cost: 3.5742\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2780 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9690 - val_cost: 3.7272\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2610 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9697 - val_cost: 3.5514\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3012 - val_loss: 0.1242 - val_auc: 0.9882 - val_accuracy: 0.9695 - val_cost: 3.9876\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3332 - val_loss: 0.1226 - val_auc: 0.9887 - val_accuracy: 0.9701 - val_cost: 3.8509\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2272 - val_loss: 0.1275 - val_auc: 0.9886 - val_accuracy: 0.9698 - val_cost: 3.5156\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2725 - val_loss: 0.1258 - val_auc: 0.9884 - val_accuracy: 0.9695 - val_cost: 3.6914\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1130 - auc: 0.9899 - accuracy: 0.9697 - cost: 3.7781\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:14.720627\n",
            "fold accuracy: 0.9697499871253967 - fold cost: 3.778125047683716\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5262 - auc: 0.8018 - accuracy: 0.7322 - cost: 35.6144 - val_loss: 0.3912 - val_auc: 0.9032 - val_accuracy: 0.8282 - val_cost: 22.5716\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3475 - auc: 0.9233 - accuracy: 0.8508 - cost: 18.9842 - val_loss: 0.3163 - val_auc: 0.9363 - val_accuracy: 0.8644 - val_cost: 17.0247\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2981 - auc: 0.9437 - accuracy: 0.8761 - cost: 15.6815 - val_loss: 0.2866 - val_auc: 0.9479 - val_accuracy: 0.8802 - val_cost: 15.0065\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2696 - auc: 0.9541 - accuracy: 0.8908 - cost: 13.8226 - val_loss: 0.2597 - val_auc: 0.9574 - val_accuracy: 0.8953 - val_cost: 12.7832\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9616 - accuracy: 0.9011 - cost: 12.5189 - val_loss: 0.2399 - val_auc: 0.9636 - val_accuracy: 0.9072 - val_cost: 11.2077\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2268 - auc: 0.9675 - accuracy: 0.9115 - cost: 11.2144 - val_loss: 0.2239 - val_auc: 0.9682 - val_accuracy: 0.9128 - val_cost: 10.7194\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2118 - auc: 0.9715 - accuracy: 0.9183 - cost: 10.3100 - val_loss: 0.2095 - val_auc: 0.9720 - val_accuracy: 0.9222 - val_cost: 9.4108\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1982 - auc: 0.9749 - accuracy: 0.9243 - cost: 9.5642 - val_loss: 0.1991 - val_auc: 0.9751 - val_accuracy: 0.9255 - val_cost: 8.9388\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1876 - auc: 0.9774 - accuracy: 0.9291 - cost: 8.9771 - val_loss: 0.1874 - val_auc: 0.9776 - val_accuracy: 0.9317 - val_cost: 8.6263\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1785 - auc: 0.9794 - accuracy: 0.9331 - cost: 8.4588 - val_loss: 0.1788 - val_auc: 0.9792 - val_accuracy: 0.9359 - val_cost: 8.1120\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.1698 - auc: 0.9812 - accuracy: 0.9371 - cost: 7.9646 - val_loss: 0.1737 - val_auc: 0.9804 - val_accuracy: 0.9374 - val_cost: 7.7311\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1639 - auc: 0.9823 - accuracy: 0.9406 - cost: 7.5092 - val_loss: 0.1674 - val_auc: 0.9814 - val_accuracy: 0.9415 - val_cost: 7.8320\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9432 - cost: 7.2036 - val_loss: 0.1635 - val_auc: 0.9823 - val_accuracy: 0.9435 - val_cost: 7.1354\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1520 - auc: 0.9846 - accuracy: 0.9459 - cost: 6.8623 - val_loss: 0.1586 - val_auc: 0.9831 - val_accuracy: 0.9454 - val_cost: 7.1354\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1490 - auc: 0.9851 - accuracy: 0.9472 - cost: 6.6863 - val_loss: 0.1557 - val_auc: 0.9838 - val_accuracy: 0.9466 - val_cost: 7.1159\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1461 - auc: 0.9856 - accuracy: 0.9481 - cost: 6.5820 - val_loss: 0.1518 - val_auc: 0.9846 - val_accuracy: 0.9479 - val_cost: 6.8457\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9509 - cost: 6.2201 - val_loss: 0.1505 - val_auc: 0.9845 - val_accuracy: 0.9480 - val_cost: 6.9434\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1390 - auc: 0.9868 - accuracy: 0.9512 - cost: 6.1904 - val_loss: 0.1495 - val_auc: 0.9850 - val_accuracy: 0.9490 - val_cost: 6.5592\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9528 - cost: 5.9748 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9489 - val_cost: 6.3867\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1329 - auc: 0.9878 - accuracy: 0.9539 - cost: 5.8423 - val_loss: 0.1435 - val_auc: 0.9859 - val_accuracy: 0.9513 - val_cost: 6.7676\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1306 - auc: 0.9881 - accuracy: 0.9549 - cost: 5.7077 - val_loss: 0.1418 - val_auc: 0.9861 - val_accuracy: 0.9517 - val_cost: 6.6406\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9560 - cost: 5.5796 - val_loss: 0.1403 - val_auc: 0.9864 - val_accuracy: 0.9540 - val_cost: 5.8757\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1255 - auc: 0.9889 - accuracy: 0.9572 - cost: 5.4248 - val_loss: 0.1382 - val_auc: 0.9868 - val_accuracy: 0.9538 - val_cost: 6.0742\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9891 - accuracy: 0.9579 - cost: 5.3270 - val_loss: 0.1391 - val_auc: 0.9866 - val_accuracy: 0.9553 - val_cost: 5.8431\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1217 - auc: 0.9895 - accuracy: 0.9589 - cost: 5.2355 - val_loss: 0.1358 - val_auc: 0.9869 - val_accuracy: 0.9560 - val_cost: 5.6087\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1203 - auc: 0.9896 - accuracy: 0.9595 - cost: 5.1471 - val_loss: 0.1347 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.4492\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1183 - auc: 0.9898 - accuracy: 0.9607 - cost: 4.9711 - val_loss: 0.1329 - val_auc: 0.9872 - val_accuracy: 0.9571 - val_cost: 5.6413\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1163 - auc: 0.9902 - accuracy: 0.9605 - cost: 5.0132 - val_loss: 0.1324 - val_auc: 0.9873 - val_accuracy: 0.9573 - val_cost: 5.5111\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1149 - auc: 0.9904 - accuracy: 0.9617 - cost: 4.8642 - val_loss: 0.1316 - val_auc: 0.9876 - val_accuracy: 0.9579 - val_cost: 5.2637\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1139 - auc: 0.9905 - accuracy: 0.9621 - cost: 4.8016 - val_loss: 0.1304 - val_auc: 0.9875 - val_accuracy: 0.9590 - val_cost: 4.9544\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1115 - auc: 0.9907 - accuracy: 0.9639 - cost: 4.5895 - val_loss: 0.1288 - val_auc: 0.9880 - val_accuracy: 0.9585 - val_cost: 5.1432\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9637 - cost: 4.5881 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9605 - val_cost: 5.0521\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1085 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4572 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9604 - val_cost: 4.9121\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1071 - auc: 0.9913 - accuracy: 0.9648 - cost: 4.4756 - val_loss: 0.1261 - val_auc: 0.9883 - val_accuracy: 0.9604 - val_cost: 5.1139\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9656 - cost: 4.3615 - val_loss: 0.1253 - val_auc: 0.9884 - val_accuracy: 0.9608 - val_cost: 4.6549\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1038 - auc: 0.9917 - accuracy: 0.9661 - cost: 4.3051 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9613 - val_cost: 4.4954\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1041 - auc: 0.9917 - accuracy: 0.9663 - cost: 4.2762 - val_loss: 0.1245 - val_auc: 0.9883 - val_accuracy: 0.9612 - val_cost: 4.8470\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9670 - cost: 4.1724 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9616 - val_cost: 4.6224\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1015 - auc: 0.9920 - accuracy: 0.9675 - cost: 4.1325 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9619 - val_cost: 4.7526\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1004 - auc: 0.9921 - accuracy: 0.9681 - cost: 4.0557 - val_loss: 0.1203 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.4889\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9682 - cost: 4.0415 - val_loss: 0.1221 - val_auc: 0.9885 - val_accuracy: 0.9626 - val_cost: 4.5182\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9924 - accuracy: 0.9688 - cost: 3.9531 - val_loss: 0.1203 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.4596\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9087 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9644 - val_cost: 4.4727\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8590 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9643 - val_cost: 4.3327\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9698 - cost: 3.8496 - val_loss: 0.1175 - val_auc: 0.9890 - val_accuracy: 0.9651 - val_cost: 4.4336\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0935 - auc: 0.9927 - accuracy: 0.9706 - cost: 3.7458 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9646 - val_cost: 4.2383\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6840 - val_loss: 0.1173 - val_auc: 0.9889 - val_accuracy: 0.9653 - val_cost: 4.2643\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6783 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.1634\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0910 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6433 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.2025\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0905 - auc: 0.9931 - accuracy: 0.9711 - cost: 3.6758 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9653 - val_cost: 4.1862\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5520 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9659 - val_cost: 4.1406\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0889 - auc: 0.9932 - accuracy: 0.9719 - cost: 3.5806 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9655 - val_cost: 4.3978\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5299 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9657 - val_cost: 4.0951\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4888 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9659 - val_cost: 4.2188\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4225 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.3522\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9731 - cost: 3.4162 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 4.0983\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9732 - cost: 3.4246 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0658\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0851 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3623 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.2350\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9738 - cost: 3.3363 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9671 - val_cost: 4.0169\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0837 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2183 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.1667\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2300 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9670 - val_cost: 4.0202\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2430 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 3.9648\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9938 - accuracy: 0.9750 - cost: 3.1904 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.0983\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0823 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2182 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9673 - val_cost: 4.0462\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0814 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1302 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 3.9388\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1398 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1960\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1043 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 3.8118\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.0956 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9676 - val_cost: 3.9095\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0744 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9665 - val_cost: 4.0104\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1118 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9663 - val_cost: 4.4564\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0795 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0738 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9670 - val_cost: 3.9779\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0460 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9323\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0786 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0398 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.8672\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9939 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9662 - val_cost: 4.0788\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9724 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9671 - val_cost: 4.0267\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9885 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.8249\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.8949 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0755\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.8967 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.0299\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.8987 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 4.0202\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8649 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9682 - val_cost: 4.0951\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8835 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9160\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8586 - val_loss: 0.1088 - val_auc: 0.9899 - val_accuracy: 0.9682 - val_cost: 3.8574\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9269 - val_loss: 0.1086 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.0202\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.9033 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 4.0918\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8678 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 4.1309\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8811 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9681 - val_cost: 3.8867\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7775 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.9779\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8353 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9691 - val_cost: 3.9095\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7867 - val_loss: 0.1080 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.9909\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8304 - val_loss: 0.1084 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.7695\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8428 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.9095\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9783 - cost: 2.7801 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.7370\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7492 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.7728\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7602 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8118\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.8094 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.7630\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7884 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 4.0755\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9789 - cost: 2.7111 - val_loss: 0.1073 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.7370\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6984 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.8704\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7563 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.7565\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7143 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.8867\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7446 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8965\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7166 - val_loss: 0.1072 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.5645\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.6968 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.7305\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6687 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.7272\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6963 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.7077\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6419 - val_loss: 0.1087 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.7337\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6723 - val_loss: 0.1084 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 3.8184\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6861 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.5710\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9950 - accuracy: 0.9798 - cost: 2.5810 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.7663\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5925 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7402\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6169 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7858\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6178 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.6198\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5851 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.6068\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5942 - val_loss: 0.1064 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6361\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6087 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.8151\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5746 - val_loss: 0.1079 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.9616\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5325 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.9746\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6071 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.7858\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5055 - val_loss: 0.1078 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.7174\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5699 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7565\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5871 - val_loss: 0.1086 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 4.1341\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5598 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.6719\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5651 - val_loss: 0.1097 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.5905\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5508 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.7467\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4928 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.8379\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5333 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7923\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5459 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.9551\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4883 - val_loss: 0.1074 - val_auc: 0.9902 - val_accuracy: 0.9711 - val_cost: 3.7109\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4872 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.8574\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4473 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.8379\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4569 - val_loss: 0.1061 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.8770\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5203 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.7630\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4974 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9704 - val_cost: 3.9062\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4655 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.6719\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4883 - val_loss: 0.1066 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.7012\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4937 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 4.1439\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5453 - val_loss: 0.1098 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 4.2220\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4682 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 4.0267\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4431 - val_loss: 0.1081 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.9746\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4544 - val_loss: 0.1094 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.8281\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4600 - val_loss: 0.1122 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 4.0527\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4426 - val_loss: 0.1078 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.9062\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4218 - val_loss: 0.1089 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.8932\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4237 - val_loss: 0.1080 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.8639\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.7826\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4514 - val_loss: 0.1098 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 4.0104\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4545 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9713 - val_cost: 3.7923\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.4003 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 4.0723\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9818 - cost: 2.3233 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6979\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4296 - val_loss: 0.1124 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.9323\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4279 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 4.1602\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4745 - val_loss: 0.1106 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.9746\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1007 - auc: 0.9913 - accuracy: 0.9721 - cost: 3.5531\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:25.427638\n",
            "fold accuracy: 0.9720625281333923 - fold cost: 3.5531249046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5274 - auc: 0.8003 - accuracy: 0.7309 - cost: 35.8000 - val_loss: 0.3946 - val_auc: 0.9016 - val_accuracy: 0.8296 - val_cost: 21.2402\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3473 - auc: 0.9233 - accuracy: 0.8512 - cost: 18.9504 - val_loss: 0.3151 - val_auc: 0.9375 - val_accuracy: 0.8667 - val_cost: 15.9961\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2981 - auc: 0.9438 - accuracy: 0.8768 - cost: 15.5972 - val_loss: 0.2831 - val_auc: 0.9496 - val_accuracy: 0.8845 - val_cost: 14.0104\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2697 - auc: 0.9541 - accuracy: 0.8901 - cost: 13.9117 - val_loss: 0.2578 - val_auc: 0.9583 - val_accuracy: 0.8970 - val_cost: 12.6172\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2465 - auc: 0.9617 - accuracy: 0.9013 - cost: 12.4845 - val_loss: 0.2393 - val_auc: 0.9639 - val_accuracy: 0.9057 - val_cost: 11.8229\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2274 - auc: 0.9673 - accuracy: 0.9105 - cost: 11.3316 - val_loss: 0.2233 - val_auc: 0.9683 - val_accuracy: 0.9167 - val_cost: 10.3353\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2123 - auc: 0.9714 - accuracy: 0.9177 - cost: 10.3931 - val_loss: 0.2089 - val_auc: 0.9725 - val_accuracy: 0.9219 - val_cost: 9.3359\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1988 - auc: 0.9748 - accuracy: 0.9248 - cost: 9.4917 - val_loss: 0.1970 - val_auc: 0.9751 - val_accuracy: 0.9288 - val_cost: 9.0039\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1873 - auc: 0.9774 - accuracy: 0.9293 - cost: 8.9331 - val_loss: 0.1869 - val_auc: 0.9774 - val_accuracy: 0.9335 - val_cost: 8.2064\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1779 - auc: 0.9796 - accuracy: 0.9343 - cost: 8.3044 - val_loss: 0.1799 - val_auc: 0.9788 - val_accuracy: 0.9365 - val_cost: 7.9036\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1702 - auc: 0.9812 - accuracy: 0.9372 - cost: 7.9565 - val_loss: 0.1735 - val_auc: 0.9801 - val_accuracy: 0.9385 - val_cost: 7.5814\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1635 - auc: 0.9825 - accuracy: 0.9405 - cost: 7.5323 - val_loss: 0.1682 - val_auc: 0.9812 - val_accuracy: 0.9395 - val_cost: 7.4447\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1581 - auc: 0.9835 - accuracy: 0.9430 - cost: 7.2115 - val_loss: 0.1653 - val_auc: 0.9819 - val_accuracy: 0.9422 - val_cost: 7.1387\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1537 - auc: 0.9844 - accuracy: 0.9449 - cost: 6.9639 - val_loss: 0.1628 - val_auc: 0.9824 - val_accuracy: 0.9438 - val_cost: 6.5788\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1493 - auc: 0.9852 - accuracy: 0.9468 - cost: 6.7418 - val_loss: 0.1578 - val_auc: 0.9832 - val_accuracy: 0.9453 - val_cost: 6.7513\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1453 - auc: 0.9857 - accuracy: 0.9482 - cost: 6.5620 - val_loss: 0.1554 - val_auc: 0.9835 - val_accuracy: 0.9458 - val_cost: 6.7904\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1416 - auc: 0.9865 - accuracy: 0.9500 - cost: 6.3083 - val_loss: 0.1528 - val_auc: 0.9840 - val_accuracy: 0.9487 - val_cost: 6.3053\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1395 - auc: 0.9867 - accuracy: 0.9514 - cost: 6.1633 - val_loss: 0.1523 - val_auc: 0.9842 - val_accuracy: 0.9494 - val_cost: 6.2533\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9524 - cost: 6.0362 - val_loss: 0.1498 - val_auc: 0.9847 - val_accuracy: 0.9488 - val_cost: 6.4128\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1343 - auc: 0.9875 - accuracy: 0.9534 - cost: 5.9020 - val_loss: 0.1477 - val_auc: 0.9848 - val_accuracy: 0.9501 - val_cost: 6.1035\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1316 - auc: 0.9880 - accuracy: 0.9544 - cost: 5.7622 - val_loss: 0.1459 - val_auc: 0.9851 - val_accuracy: 0.9519 - val_cost: 5.9049\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1283 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.5972 - val_loss: 0.1439 - val_auc: 0.9856 - val_accuracy: 0.9530 - val_cost: 5.7129\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1270 - auc: 0.9886 - accuracy: 0.9570 - cost: 5.4545 - val_loss: 0.1436 - val_auc: 0.9859 - val_accuracy: 0.9533 - val_cost: 5.4915\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1241 - auc: 0.9890 - accuracy: 0.9578 - cost: 5.3604 - val_loss: 0.1409 - val_auc: 0.9861 - val_accuracy: 0.9545 - val_cost: 5.5143\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1225 - auc: 0.9892 - accuracy: 0.9586 - cost: 5.2451 - val_loss: 0.1412 - val_auc: 0.9861 - val_accuracy: 0.9544 - val_cost: 5.3353\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1214 - auc: 0.9894 - accuracy: 0.9590 - cost: 5.1962 - val_loss: 0.1374 - val_auc: 0.9864 - val_accuracy: 0.9571 - val_cost: 5.2018\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1185 - auc: 0.9899 - accuracy: 0.9600 - cost: 5.0804 - val_loss: 0.1353 - val_auc: 0.9866 - val_accuracy: 0.9562 - val_cost: 5.2507\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1171 - auc: 0.9900 - accuracy: 0.9608 - cost: 4.9789 - val_loss: 0.1345 - val_auc: 0.9867 - val_accuracy: 0.9574 - val_cost: 4.9902\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9614 - cost: 4.8925 - val_loss: 0.1351 - val_auc: 0.9869 - val_accuracy: 0.9578 - val_cost: 4.8275\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1138 - auc: 0.9905 - accuracy: 0.9625 - cost: 4.7627 - val_loss: 0.1338 - val_auc: 0.9868 - val_accuracy: 0.9591 - val_cost: 4.7656\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1122 - auc: 0.9907 - accuracy: 0.9629 - cost: 4.7104 - val_loss: 0.1312 - val_auc: 0.9871 - val_accuracy: 0.9601 - val_cost: 4.8242\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9640 - cost: 4.5588 - val_loss: 0.1324 - val_auc: 0.9869 - val_accuracy: 0.9588 - val_cost: 4.8112\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1106 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6399 - val_loss: 0.1310 - val_auc: 0.9872 - val_accuracy: 0.9599 - val_cost: 4.7396\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1081 - auc: 0.9912 - accuracy: 0.9647 - cost: 4.4793 - val_loss: 0.1286 - val_auc: 0.9874 - val_accuracy: 0.9617 - val_cost: 4.4987\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3504 - val_loss: 0.1275 - val_auc: 0.9876 - val_accuracy: 0.9607 - val_cost: 4.6484\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1062 - auc: 0.9913 - accuracy: 0.9656 - cost: 4.3670 - val_loss: 0.1270 - val_auc: 0.9877 - val_accuracy: 0.9628 - val_cost: 4.3392\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9660 - cost: 4.3066 - val_loss: 0.1271 - val_auc: 0.9877 - val_accuracy: 0.9619 - val_cost: 4.4889\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9666 - cost: 4.2222 - val_loss: 0.1259 - val_auc: 0.9879 - val_accuracy: 0.9627 - val_cost: 4.5605\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1018 - auc: 0.9919 - accuracy: 0.9674 - cost: 4.1324 - val_loss: 0.1249 - val_auc: 0.9879 - val_accuracy: 0.9639 - val_cost: 4.3164\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1010 - auc: 0.9920 - accuracy: 0.9674 - cost: 4.1489 - val_loss: 0.1270 - val_auc: 0.9878 - val_accuracy: 0.9619 - val_cost: 4.3490\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1002 - auc: 0.9920 - accuracy: 0.9683 - cost: 4.0243 - val_loss: 0.1232 - val_auc: 0.9881 - val_accuracy: 0.9631 - val_cost: 4.3880\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9683 - cost: 4.0213 - val_loss: 0.1230 - val_auc: 0.9881 - val_accuracy: 0.9642 - val_cost: 4.2155\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0976 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9240 - val_loss: 0.1237 - val_auc: 0.9880 - val_accuracy: 0.9640 - val_cost: 4.1699\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0974 - auc: 0.9924 - accuracy: 0.9687 - cost: 3.9744 - val_loss: 0.1206 - val_auc: 0.9884 - val_accuracy: 0.9651 - val_cost: 4.0690\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0963 - auc: 0.9925 - accuracy: 0.9696 - cost: 3.8668 - val_loss: 0.1204 - val_auc: 0.9884 - val_accuracy: 0.9644 - val_cost: 4.2480\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0954 - auc: 0.9925 - accuracy: 0.9696 - cost: 3.8621 - val_loss: 0.1206 - val_auc: 0.9883 - val_accuracy: 0.9658 - val_cost: 4.0169\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9701 - cost: 3.7938 - val_loss: 0.1209 - val_auc: 0.9884 - val_accuracy: 0.9646 - val_cost: 4.1471\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0929 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7078 - val_loss: 0.1199 - val_auc: 0.9886 - val_accuracy: 0.9656 - val_cost: 3.9714\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0936 - auc: 0.9927 - accuracy: 0.9708 - cost: 3.7118 - val_loss: 0.1197 - val_auc: 0.9886 - val_accuracy: 0.9651 - val_cost: 4.0332\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0924 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6340 - val_loss: 0.1192 - val_auc: 0.9884 - val_accuracy: 0.9660 - val_cost: 4.0723\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0909 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6243 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9657 - val_cost: 4.0527\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5494 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9655 - val_cost: 4.1081\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5200 - val_loss: 0.1164 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 3.7370\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9723 - cost: 3.5137 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 3.8835\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9932 - accuracy: 0.9731 - cost: 3.4288 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 3.9355\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4467 - val_loss: 0.1148 - val_auc: 0.9890 - val_accuracy: 0.9686 - val_cost: 3.6751\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0870 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4194 - val_loss: 0.1164 - val_auc: 0.9889 - val_accuracy: 0.9663 - val_cost: 3.9323\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9733 - cost: 3.4093 - val_loss: 0.1169 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 3.7858\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9935 - accuracy: 0.9732 - cost: 3.4185 - val_loss: 0.1163 - val_auc: 0.9889 - val_accuracy: 0.9667 - val_cost: 3.8574\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3752 - val_loss: 0.1153 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.0234\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3432 - val_loss: 0.1128 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 3.9128\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2605 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9675 - val_cost: 3.7533\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0839 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3373 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9676 - val_cost: 3.9128\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2406 - val_loss: 0.1148 - val_auc: 0.9891 - val_accuracy: 0.9673 - val_cost: 3.7826\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0819 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2344 - val_loss: 0.1139 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.7044\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0833 - auc: 0.9937 - accuracy: 0.9746 - cost: 3.2241 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 3.7760\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1362 - val_loss: 0.1148 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 3.7435\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2121 - val_loss: 0.1135 - val_auc: 0.9891 - val_accuracy: 0.9692 - val_cost: 3.6133\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0809 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1575 - val_loss: 0.1149 - val_auc: 0.9891 - val_accuracy: 0.9681 - val_cost: 3.6621\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1561 - val_loss: 0.1140 - val_auc: 0.9890 - val_accuracy: 0.9683 - val_cost: 3.6979\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.0956 - val_loss: 0.1139 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 3.7467\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0874 - val_loss: 0.1120 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 3.7793\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9764 - cost: 3.0157 - val_loss: 0.1140 - val_auc: 0.9890 - val_accuracy: 0.9679 - val_cost: 3.7272\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0656 - val_loss: 0.1140 - val_auc: 0.9891 - val_accuracy: 0.9690 - val_cost: 3.5677\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0796 - auc: 0.9940 - accuracy: 0.9759 - cost: 3.0836 - val_loss: 0.1123 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 3.7337\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9912 - val_loss: 0.1122 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.8607\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9842 - val_loss: 0.1128 - val_auc: 0.9891 - val_accuracy: 0.9683 - val_cost: 3.7337\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9962 - val_loss: 0.1103 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.6100\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9440 - val_loss: 0.1113 - val_auc: 0.9893 - val_accuracy: 0.9685 - val_cost: 3.6458\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9352 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.6686\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9314 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.7891\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9499 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.5872\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9351 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.9648\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9777 - cost: 2.8374 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8021\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.8994 - val_loss: 0.1102 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8639\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8914 - val_loss: 0.1099 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6263\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8009 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.6849\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8390 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.5970\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9773 - cost: 2.8882 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.5710\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8362 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.6719\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8115 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.6719\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7795 - val_loss: 0.1086 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7109\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8001 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9702 - val_cost: 3.6523\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8313 - val_loss: 0.1086 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.6784\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.8021 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6882\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0722 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7521 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.4993\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7190 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6491\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7479 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.4993\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7698 - val_loss: 0.1095 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.4180\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7202 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.4733\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7198 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.4635\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0710 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7083 - val_loss: 0.1116 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.3822\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6925 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4147\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6428 - val_loss: 0.1087 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.5124\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7035 - val_loss: 0.1092 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.4961\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6934 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.4863\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0704 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6632 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.6947\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7046 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7988\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6720 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4212\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6264 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.5742\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6442 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.5352\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.5981 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6947\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6664 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.5026\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5999 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9697 - val_cost: 3.6003\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6362 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.5026\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6749 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.4082\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5709 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9716 - val_cost: 3.2975\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6196 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.2812\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6263 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.5547\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5909 - val_loss: 0.1112 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.4701\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5565 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.2422\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6139 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.4342\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6067 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.4375\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0684 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5411 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.2715\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5809 - val_loss: 0.1126 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.7109\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0674 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5164 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5189\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5815 - val_loss: 0.1111 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.3333\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5544 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6914\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5528 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4277\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.5030 - val_loss: 0.1156 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.5059\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5439 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.3822\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5847 - val_loss: 0.1123 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7109\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5829 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.3561\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5428 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7109\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5579 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7044\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5096 - val_loss: 0.1116 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.2194\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5106 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.5221\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4426 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5319\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4946 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.4603\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5041 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.3952\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4808 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.4049\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5407 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.3984\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5157 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9723 - val_cost: 3.4180\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5055 - val_loss: 0.1137 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.4212\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4755 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.4798\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5036 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.4082\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5292 - val_loss: 0.1116 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.4505\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4937 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.3398\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0656 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5288 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9704 - val_cost: 3.5026\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5149 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.4180\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3810 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.4277\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4441 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.4147\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3972 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.3887\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4732 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.4473\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3887 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.1999\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4621 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5449\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4533 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.3301\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4381 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.2552\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4267 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.4440\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4145 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.4245\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4057 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.3464\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4007 - val_loss: 0.1155 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.3268\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4174 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.4049\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4078 - val_loss: 0.1137 - val_auc: 0.9895 - val_accuracy: 0.9720 - val_cost: 3.3561\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3763 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9719 - val_cost: 3.3268\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3759 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9717 - val_cost: 3.2878\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3744 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9712 - val_cost: 3.2878\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3733 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.4212\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4207 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.1478\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3655 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9706 - val_cost: 3.5059\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4183 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.3887\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4331 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.4538\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3778 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9726 - val_cost: 3.1999\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4001 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9730 - val_cost: 3.2617\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3547 - val_loss: 0.1148 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.3464\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3834 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.2357\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4050 - val_loss: 0.1163 - val_auc: 0.9892 - val_accuracy: 0.9720 - val_cost: 3.4668\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3911 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.3203\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3782 - val_loss: 0.1170 - val_auc: 0.9892 - val_accuracy: 0.9719 - val_cost: 3.3464\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5514\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3316 - val_loss: 0.1169 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5482\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1172 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.2975\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3069 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9728 - val_cost: 3.3691\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0625 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4184 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9713 - val_cost: 3.7370\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3532 - val_loss: 0.1165 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.4049\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3446 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.5938\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3446 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9713 - val_cost: 3.5221\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3416 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5156\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3021 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.3822\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2886 - val_loss: 0.1180 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.5775\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2661 - val_loss: 0.1190 - val_auc: 0.9888 - val_accuracy: 0.9715 - val_cost: 3.4733\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3453 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9719 - val_cost: 3.6523\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3180 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9726 - val_cost: 3.1641\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0616 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3261 - val_loss: 0.1188 - val_auc: 0.9890 - val_accuracy: 0.9722 - val_cost: 3.3529\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9959 - accuracy: 0.9821 - cost: 2.2949 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9719 - val_cost: 3.4310\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2921 - val_loss: 0.1192 - val_auc: 0.9890 - val_accuracy: 0.9719 - val_cost: 3.4440\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2932 - val_loss: 0.1185 - val_auc: 0.9891 - val_accuracy: 0.9720 - val_cost: 3.3138\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3213 - val_loss: 0.1206 - val_auc: 0.9887 - val_accuracy: 0.9717 - val_cost: 3.5124\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2796 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9720 - val_cost: 3.2878\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3209 - val_loss: 0.1192 - val_auc: 0.9891 - val_accuracy: 0.9724 - val_cost: 3.7663\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2509 - val_loss: 0.1180 - val_auc: 0.9892 - val_accuracy: 0.9717 - val_cost: 3.4570\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2862 - val_loss: 0.1221 - val_auc: 0.9886 - val_accuracy: 0.9705 - val_cost: 3.3301\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3132 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.4635\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2939 - val_loss: 0.1181 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.6816\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2732 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9717 - val_cost: 3.5124\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3118 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9725 - val_cost: 3.3203\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2642 - val_loss: 0.1192 - val_auc: 0.9891 - val_accuracy: 0.9717 - val_cost: 3.4570\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3387 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9716 - val_cost: 3.6491\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2883 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9715 - val_cost: 3.6068\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3250 - val_loss: 0.1186 - val_auc: 0.9891 - val_accuracy: 0.9723 - val_cost: 3.4505\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2433 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9717 - val_cost: 3.5352\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0594 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2658 - val_loss: 0.1223 - val_auc: 0.9889 - val_accuracy: 0.9722 - val_cost: 3.2682\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2951 - val_loss: 0.1219 - val_auc: 0.9891 - val_accuracy: 0.9711 - val_cost: 3.4212\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2877 - val_loss: 0.1218 - val_auc: 0.9887 - val_accuracy: 0.9712 - val_cost: 3.4017\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2613 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9735 - val_cost: 3.3236\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.2973 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9724 - val_cost: 3.4863\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3082 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.2943\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0598 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2718 - val_loss: 0.1231 - val_auc: 0.9886 - val_accuracy: 0.9703 - val_cost: 3.5514\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2568 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9731 - val_cost: 3.3529\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1045 - auc: 0.9907 - accuracy: 0.9724 - cost: 3.5062\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:00.689286\n",
            "fold accuracy: 0.9723749756813049 - fold cost: 3.5062499046325684\n",
            "x_train shape: (144000, 69)\n",
            "Epoch 1/1000\n",
            "127/127 [==============================] - 2s 6ms/step - loss: 0.5223 - auc: 0.8047 - accuracy: 0.7337 - cost: 35.4095 - val_loss: 0.3889 - val_auc: 0.9049 - val_accuracy: 0.8323 - val_cost: 21.1003\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.3468 - auc: 0.9235 - accuracy: 0.8515 - cost: 18.8943 - val_loss: 0.3104 - val_auc: 0.9390 - val_accuracy: 0.8694 - val_cost: 16.0840\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2999 - auc: 0.9430 - accuracy: 0.8753 - cost: 15.8098 - val_loss: 0.2808 - val_auc: 0.9502 - val_accuracy: 0.8831 - val_cost: 14.4238\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2702 - auc: 0.9538 - accuracy: 0.8901 - cost: 13.9226 - val_loss: 0.2550 - val_auc: 0.9591 - val_accuracy: 0.8976 - val_cost: 12.9395\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 0.2467 - auc: 0.9615 - accuracy: 0.9013 - cost: 12.5381 - val_loss: 0.2354 - val_auc: 0.9648 - val_accuracy: 0.9070 - val_cost: 11.8001\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2293 - auc: 0.9667 - accuracy: 0.9094 - cost: 11.4770 - val_loss: 0.2185 - val_auc: 0.9697 - val_accuracy: 0.9161 - val_cost: 10.1855\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2132 - auc: 0.9712 - accuracy: 0.9174 - cost: 10.4487 - val_loss: 0.2055 - val_auc: 0.9735 - val_accuracy: 0.9217 - val_cost: 9.7005\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.2008 - auc: 0.9743 - accuracy: 0.9236 - cost: 9.6628 - val_loss: 0.1940 - val_auc: 0.9761 - val_accuracy: 0.9274 - val_cost: 9.0495\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1890 - auc: 0.9771 - accuracy: 0.9289 - cost: 9.0274 - val_loss: 0.1839 - val_auc: 0.9780 - val_accuracy: 0.9340 - val_cost: 8.3594\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1796 - auc: 0.9792 - accuracy: 0.9331 - cost: 8.4792 - val_loss: 0.1784 - val_auc: 0.9792 - val_accuracy: 0.9344 - val_cost: 8.5124\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1716 - auc: 0.9809 - accuracy: 0.9364 - cost: 8.0592 - val_loss: 0.1698 - val_auc: 0.9811 - val_accuracy: 0.9385 - val_cost: 8.1868\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1656 - auc: 0.9821 - accuracy: 0.9395 - cost: 7.6680 - val_loss: 0.1639 - val_auc: 0.9822 - val_accuracy: 0.9417 - val_cost: 7.4902\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1597 - auc: 0.9831 - accuracy: 0.9421 - cost: 7.3416 - val_loss: 0.1591 - val_auc: 0.9831 - val_accuracy: 0.9428 - val_cost: 7.5195\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1548 - auc: 0.9841 - accuracy: 0.9436 - cost: 7.1568 - val_loss: 0.1581 - val_auc: 0.9836 - val_accuracy: 0.9437 - val_cost: 6.9108\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1504 - auc: 0.9848 - accuracy: 0.9465 - cost: 6.7863 - val_loss: 0.1531 - val_auc: 0.9841 - val_accuracy: 0.9459 - val_cost: 7.0085\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1464 - auc: 0.9856 - accuracy: 0.9478 - cost: 6.6316 - val_loss: 0.1493 - val_auc: 0.9849 - val_accuracy: 0.9483 - val_cost: 6.7025\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1426 - auc: 0.9862 - accuracy: 0.9494 - cost: 6.4126 - val_loss: 0.1485 - val_auc: 0.9854 - val_accuracy: 0.9478 - val_cost: 6.6048\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1391 - auc: 0.9867 - accuracy: 0.9514 - cost: 6.1436 - val_loss: 0.1421 - val_auc: 0.9861 - val_accuracy: 0.9506 - val_cost: 6.6504\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1349 - auc: 0.9874 - accuracy: 0.9529 - cost: 5.9876 - val_loss: 0.1410 - val_auc: 0.9863 - val_accuracy: 0.9508 - val_cost: 6.3867\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1331 - auc: 0.9877 - accuracy: 0.9540 - cost: 5.8392 - val_loss: 0.1383 - val_auc: 0.9866 - val_accuracy: 0.9526 - val_cost: 6.0579\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1295 - auc: 0.9883 - accuracy: 0.9554 - cost: 5.6704 - val_loss: 0.1372 - val_auc: 0.9868 - val_accuracy: 0.9538 - val_cost: 6.0352\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1276 - auc: 0.9885 - accuracy: 0.9568 - cost: 5.4797 - val_loss: 0.1330 - val_auc: 0.9873 - val_accuracy: 0.9559 - val_cost: 5.7096\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1239 - auc: 0.9891 - accuracy: 0.9580 - cost: 5.3310 - val_loss: 0.1307 - val_auc: 0.9877 - val_accuracy: 0.9565 - val_cost: 5.9831\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1211 - auc: 0.9894 - accuracy: 0.9591 - cost: 5.2017 - val_loss: 0.1295 - val_auc: 0.9878 - val_accuracy: 0.9567 - val_cost: 5.9896\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1197 - auc: 0.9896 - accuracy: 0.9597 - cost: 5.1095 - val_loss: 0.1275 - val_auc: 0.9880 - val_accuracy: 0.9591 - val_cost: 5.3320\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1165 - auc: 0.9901 - accuracy: 0.9610 - cost: 4.9608 - val_loss: 0.1281 - val_auc: 0.9881 - val_accuracy: 0.9585 - val_cost: 5.4069\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9621 - cost: 4.8240 - val_loss: 0.1242 - val_auc: 0.9885 - val_accuracy: 0.9590 - val_cost: 5.4557\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1129 - auc: 0.9905 - accuracy: 0.9626 - cost: 4.7585 - val_loss: 0.1221 - val_auc: 0.9885 - val_accuracy: 0.9608 - val_cost: 5.2441\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9640 - cost: 4.5696 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9620 - val_cost: 5.0586\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9639 - cost: 4.5920 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9629 - val_cost: 4.6387\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1069 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4542 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9626 - val_cost: 5.1009\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9657 - cost: 4.3539 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9626 - val_cost: 4.6777\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1044 - auc: 0.9914 - accuracy: 0.9666 - cost: 4.2319 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9630 - val_cost: 4.7721\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2354 - val_loss: 0.1165 - val_auc: 0.9892 - val_accuracy: 0.9642 - val_cost: 4.4987\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.1019 - auc: 0.9918 - accuracy: 0.9672 - cost: 4.1709 - val_loss: 0.1161 - val_auc: 0.9894 - val_accuracy: 0.9644 - val_cost: 4.4954\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0998 - auc: 0.9921 - accuracy: 0.9677 - cost: 4.1087 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9649 - val_cost: 4.4206\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0981 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0063 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9655 - val_cost: 4.4466\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0972 - auc: 0.9923 - accuracy: 0.9692 - cost: 3.9118 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9649 - val_cost: 4.5215\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0966 - auc: 0.9924 - accuracy: 0.9696 - cost: 3.8709 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9653 - val_cost: 4.4434\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0954 - auc: 0.9925 - accuracy: 0.9696 - cost: 3.8516 - val_loss: 0.1097 - val_auc: 0.9899 - val_accuracy: 0.9667 - val_cost: 4.4954\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7617 - val_loss: 0.1093 - val_auc: 0.9899 - val_accuracy: 0.9660 - val_cost: 4.1146\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0942 - auc: 0.9926 - accuracy: 0.9703 - cost: 3.7677 - val_loss: 0.1085 - val_auc: 0.9901 - val_accuracy: 0.9672 - val_cost: 4.1178\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0921 - auc: 0.9928 - accuracy: 0.9714 - cost: 3.6341 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9668 - val_cost: 4.2904\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9715 - cost: 3.6427 - val_loss: 0.1083 - val_auc: 0.9899 - val_accuracy: 0.9661 - val_cost: 4.2253\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0914 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6108 - val_loss: 0.1082 - val_auc: 0.9901 - val_accuracy: 0.9669 - val_cost: 4.0658\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5528 - val_loss: 0.1069 - val_auc: 0.9902 - val_accuracy: 0.9673 - val_cost: 4.0658\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5138 - val_loss: 0.1069 - val_auc: 0.9902 - val_accuracy: 0.9677 - val_cost: 4.0234\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0884 - auc: 0.9931 - accuracy: 0.9727 - cost: 3.4693 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9684 - val_cost: 3.9648\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0883 - auc: 0.9932 - accuracy: 0.9726 - cost: 3.4982 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 3.9421\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4633 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9663 - val_cost: 4.2546\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0863 - auc: 0.9933 - accuracy: 0.9734 - cost: 3.3800 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9684 - val_cost: 4.1699\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0860 - auc: 0.9934 - accuracy: 0.9735 - cost: 3.3652 - val_loss: 0.1049 - val_auc: 0.9905 - val_accuracy: 0.9686 - val_cost: 4.0885\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.4040 - val_loss: 0.1045 - val_auc: 0.9906 - val_accuracy: 0.9685 - val_cost: 3.8867\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0841 - auc: 0.9935 - accuracy: 0.9744 - cost: 3.2578 - val_loss: 0.1038 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.1634\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0840 - auc: 0.9935 - accuracy: 0.9743 - cost: 3.2737 - val_loss: 0.1046 - val_auc: 0.9903 - val_accuracy: 0.9690 - val_cost: 3.8737\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2990 - val_loss: 0.1037 - val_auc: 0.9904 - val_accuracy: 0.9691 - val_cost: 3.7793\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0832 - auc: 0.9936 - accuracy: 0.9746 - cost: 3.2481 - val_loss: 0.1029 - val_auc: 0.9904 - val_accuracy: 0.9689 - val_cost: 4.1178\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9937 - accuracy: 0.9750 - cost: 3.1767 - val_loss: 0.1035 - val_auc: 0.9908 - val_accuracy: 0.9686 - val_cost: 4.0137\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1948 - val_loss: 0.1036 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7077\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0807 - auc: 0.9939 - accuracy: 0.9755 - cost: 3.1326 - val_loss: 0.1034 - val_auc: 0.9909 - val_accuracy: 0.9682 - val_cost: 4.1406\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1244 - val_loss: 0.1047 - val_auc: 0.9907 - val_accuracy: 0.9691 - val_cost: 3.8053\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1171 - val_loss: 0.1013 - val_auc: 0.9908 - val_accuracy: 0.9706 - val_cost: 3.6849\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9758 - cost: 3.0977 - val_loss: 0.1021 - val_auc: 0.9907 - val_accuracy: 0.9688 - val_cost: 4.0234\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0799 - auc: 0.9940 - accuracy: 0.9760 - cost: 3.0590 - val_loss: 0.1011 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.7630\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0793 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0872 - val_loss: 0.1042 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.6589\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9759 - cost: 3.0726 - val_loss: 0.1027 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.8249\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9763 - cost: 3.0261 - val_loss: 0.1024 - val_auc: 0.9909 - val_accuracy: 0.9690 - val_cost: 3.8997\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0779 - auc: 0.9942 - accuracy: 0.9765 - cost: 3.0029 - val_loss: 0.1028 - val_auc: 0.9907 - val_accuracy: 0.9697 - val_cost: 3.7826\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0782 - auc: 0.9942 - accuracy: 0.9763 - cost: 3.0114 - val_loss: 0.1036 - val_auc: 0.9905 - val_accuracy: 0.9698 - val_cost: 3.7109\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0286 - val_loss: 0.1036 - val_auc: 0.9908 - val_accuracy: 0.9705 - val_cost: 3.8379\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9186 - val_loss: 0.1029 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.7923\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9771 - cost: 2.9321 - val_loss: 0.1046 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.7663\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9769 - cost: 2.9406 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9685 - val_cost: 3.9128\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9226 - val_loss: 0.1029 - val_auc: 0.9905 - val_accuracy: 0.9695 - val_cost: 3.8900\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9549 - val_loss: 0.1035 - val_auc: 0.9908 - val_accuracy: 0.9690 - val_cost: 4.0755\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0748 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9364 - val_loss: 0.1037 - val_auc: 0.9908 - val_accuracy: 0.9701 - val_cost: 3.7891\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8755 - val_loss: 0.1027 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.9551\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0755 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8819 - val_loss: 0.1024 - val_auc: 0.9908 - val_accuracy: 0.9713 - val_cost: 3.8932\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0751 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8500 - val_loss: 0.1042 - val_auc: 0.9906 - val_accuracy: 0.9692 - val_cost: 4.3001\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8521 - val_loss: 0.1048 - val_auc: 0.9905 - val_accuracy: 0.9697 - val_cost: 3.7565\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8576 - val_loss: 0.1034 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.8639\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8098 - val_loss: 0.1052 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.9355\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8377 - val_loss: 0.1044 - val_auc: 0.9906 - val_accuracy: 0.9707 - val_cost: 3.5872\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8548 - val_loss: 0.1040 - val_auc: 0.9906 - val_accuracy: 0.9698 - val_cost: 3.8444\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8289 - val_loss: 0.1039 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.8867\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8543 - val_loss: 0.1060 - val_auc: 0.9907 - val_accuracy: 0.9688 - val_cost: 3.6719\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7856 - val_loss: 0.1052 - val_auc: 0.9907 - val_accuracy: 0.9697 - val_cost: 3.8672\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8548 - val_loss: 0.1029 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.7402\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7658 - val_loss: 0.1039 - val_auc: 0.9906 - val_accuracy: 0.9707 - val_cost: 3.7760\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9948 - accuracy: 0.9788 - cost: 2.7076 - val_loss: 0.1060 - val_auc: 0.9906 - val_accuracy: 0.9684 - val_cost: 4.0462\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8102 - val_loss: 0.1053 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.8379\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7445 - val_loss: 0.1046 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.8444\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9785 - cost: 2.7475 - val_loss: 0.1040 - val_auc: 0.9905 - val_accuracy: 0.9714 - val_cost: 3.8802\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9948 - accuracy: 0.9791 - cost: 2.6781 - val_loss: 0.1037 - val_auc: 0.9908 - val_accuracy: 0.9706 - val_cost: 3.7728\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6732 - val_loss: 0.1058 - val_auc: 0.9905 - val_accuracy: 0.9698 - val_cost: 3.8184\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6651 - val_loss: 0.1069 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.6947\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7228 - val_loss: 0.1049 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.7533\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6943 - val_loss: 0.1046 - val_auc: 0.9906 - val_accuracy: 0.9709 - val_cost: 3.5352\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6583 - val_loss: 0.1044 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8835\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6912 - val_loss: 0.1081 - val_auc: 0.9905 - val_accuracy: 0.9690 - val_cost: 3.6849\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6582 - val_loss: 0.1079 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.9714\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6767 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 3.7207\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6436 - val_loss: 0.1046 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7630\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6401 - val_loss: 0.1044 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7826\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6193 - val_loss: 0.1066 - val_auc: 0.9905 - val_accuracy: 0.9693 - val_cost: 3.9160\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6524 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5254\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6388 - val_loss: 0.1053 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6426\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9950 - accuracy: 0.9795 - cost: 2.6242 - val_loss: 0.1071 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.6328\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6231 - val_loss: 0.1058 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.9160\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6884 - val_loss: 0.1071 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8997\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5887 - val_loss: 0.1073 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.6393\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6025 - val_loss: 0.1079 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6816\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6173 - val_loss: 0.1082 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.6393\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5860 - val_loss: 0.1058 - val_auc: 0.9903 - val_accuracy: 0.9698 - val_cost: 3.8346\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5951 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.6654\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.4974 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6198\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5486 - val_loss: 0.1056 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.9095\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5726 - val_loss: 0.1050 - val_auc: 0.9904 - val_accuracy: 0.9701 - val_cost: 3.7337\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5638 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9708 - val_cost: 3.5710\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5642 - val_loss: 0.1074 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 4.1048\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5145 - val_loss: 0.1081 - val_auc: 0.9906 - val_accuracy: 0.9709 - val_cost: 3.5938\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5476 - val_loss: 0.1095 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.5352\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5288 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6979\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5639 - val_loss: 0.1078 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.6361\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5245 - val_loss: 0.1074 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.9941\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5325 - val_loss: 0.1086 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.6198\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5317 - val_loss: 0.1085 - val_auc: 0.9902 - val_accuracy: 0.9697 - val_cost: 4.1113\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6316 - val_loss: 0.1099 - val_auc: 0.9904 - val_accuracy: 0.9702 - val_cost: 4.0072\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5197 - val_loss: 0.1092 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.8249\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5164 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.6165\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5229 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.8411\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4896 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9702 - val_cost: 3.6068\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.5029 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.5938\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5110 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.7695\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4658 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.7370\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4688 - val_loss: 0.1081 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.6589\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5461 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.5645\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5127 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9692 - val_cost: 4.0820\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4782 - val_loss: 0.1094 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.6361\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4564 - val_loss: 0.1100 - val_auc: 0.9905 - val_accuracy: 0.9695 - val_cost: 3.8900\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4936 - val_loss: 0.1086 - val_auc: 0.9905 - val_accuracy: 0.9713 - val_cost: 3.6426\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3789 - val_loss: 0.1106 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7370\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4292 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 4.0104\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4781 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.7337\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4504 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.8379\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4803 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.5384\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4675 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.7012\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9817 - cost: 2.3577 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.6361\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4544 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.7695\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4268 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8184\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4086 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.6003\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4341 - val_loss: 0.1125 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.5807\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4160 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.9128\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4038 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6263\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4150 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.7826\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.4031 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8835\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1011 - auc: 0.9911 - accuracy: 0.9710 - cost: 3.6844\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:27.488074\n",
            "fold accuracy: 0.9710000157356262 - fold cost: 3.684375047683716\n",
            "total train/predict time: 0:18:57.928872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m5_results = fold_results"
      ],
      "metadata": {
        "id": "h8ySkCi9mPHh"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m5 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "m5_cost = cost_func(y,preds_m5)\n",
        "m5_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrG6or3mRV4",
        "outputId": "5de5309f-333c-4369-84e8-36028382a0dc"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "579600"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new5 = np.zeros(len(y))\n",
        "for i in m5_results.keys():\n",
        "  for j in range(len(m5_results.get(i).get('predictions'))):\n",
        "    idx = m5_results.get(i).get('index')[j]\n",
        "    if m5_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new5[idx] = 1\n",
        "    else:\n",
        "      preds_new5[idx] = 0\n",
        "\n",
        "m5_cost_t = cost_func(y,preds_new5)\n",
        "m5_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGSE-MSmS5Q",
        "outputId": "6e61486f-ea36-4784-e6b5-c666024e8721"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "561100"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhEJqvbmWkK",
        "outputId": "36dc6633-ac03-4551-d7db-81db85649aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4480      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,705\n",
            "Trainable params: 8,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('model5.keras')"
      ],
      "metadata": {
        "id": "bmq9o4ehJjIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_alt = pd.DataFrame()\n",
        "\n",
        "#one hot encoding categorical variables for model\n",
        "cols = df.columns\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = list((set(cols) - set(num_cols)))\n",
        "\n",
        "#creating dataframe of categorical columns\n",
        "cat_df = df[cat_cols]\n",
        "cat_df = pd.get_dummies(cat_df, columns=cat_df.columns,sparse=True)\n",
        "cat_df\n",
        "\n",
        "y_alt['Volume_high']= cat_df['Volume_high']\n",
        "y_alt['preds_m1']=preds_m1\n",
        "y_alt['preds_m2']=preds_m2\n",
        "y_alt['preds_m3']=preds_m3\n",
        "y_alt['preds_m4']=preds_m4\n",
        "y_alt['preds_m5']=preds_m5\n",
        "\n",
        "y_alt['preds_new4']=preds_new4\n",
        "y_alt['preds_new5']=preds_new5\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OK8IPut_IfuM",
        "outputId": "9e013cd2-1755-4e78-acf9-1fd3022336cd"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-180-10daa75af518>:26: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef69571e-4e00-47fa-93fd-f3b96744fa25\", \"results.csv\", 5168973)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zPmhthDgm1OQ",
        "outputId": "72b87ee4-8d50-4f9b-875e-a07fde069742"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Volume_high  preds_m1  preds_m2  preds_m3  preds_m4  preds_m5  \\\n",
              "0                 1         0         0       0.0       0.0       0.0   \n",
              "1                 1         1         0       0.0       0.0       0.0   \n",
              "2                 1         0         0       0.0       0.0       0.0   \n",
              "3                 1         1         1       1.0       0.0       0.0   \n",
              "4                 1         1         1       1.0       1.0       1.0   \n",
              "...             ...       ...       ...       ...       ...       ...   \n",
              "159995            1         1         1       1.0       1.0       1.0   \n",
              "159996            1         0         0       0.0       0.0       0.0   \n",
              "159997            1         1         0       0.0       1.0       0.0   \n",
              "159998            1         0         0       0.0       0.0       0.0   \n",
              "159999            1         0         1       1.0       1.0       1.0   \n",
              "\n",
              "        preds_new4  preds_new5  \n",
              "0              0.0         0.0  \n",
              "1              0.0         0.0  \n",
              "2              0.0         0.0  \n",
              "3              0.0         0.0  \n",
              "4              1.0         1.0  \n",
              "...            ...         ...  \n",
              "159995         1.0         1.0  \n",
              "159996         0.0         0.0  \n",
              "159997         1.0         0.0  \n",
              "159998         0.0         0.0  \n",
              "159999         1.0         1.0  \n",
              "\n",
              "[160000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-928397c1-162e-493a-a729-eb10e7f02f15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume_high</th>\n",
              "      <th>preds_m1</th>\n",
              "      <th>preds_m2</th>\n",
              "      <th>preds_m3</th>\n",
              "      <th>preds_m4</th>\n",
              "      <th>preds_m5</th>\n",
              "      <th>preds_new4</th>\n",
              "      <th>preds_new5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160000 rows  8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-928397c1-162e-493a-a729-eb10e7f02f15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3301fd0f-862b-405c-bae6-3bcff491394e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3301fd0f-862b-405c-bae6-3bcff491394e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3301fd0f-862b-405c-bae6-3bcff491394e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-928397c1-162e-493a-a729-eb10e7f02f15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-928397c1-162e-493a-a729-eb10e7f02f15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "OGDgxEMEAh0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix of Results\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m3 = confusion_matrix(y,preds_m3)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_new4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_new5)\n",
        "\n",
        "fig, ax = plt.subplots(1,5,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_m1).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Logistic Regression'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m1:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_m2).plot(ax= ax[1],cmap='Blues', colorbar=False)\n",
        "ax[1].set_title('Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m2:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_m3).plot(ax= ax[2],cmap='Blues', colorbar=False)\n",
        "ax[2].set_title('XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m3_cost:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm_preds_m4).plot(ax= ax[3],cmap='Blues', colorbar=False)\n",
        "ax[3].set_title('Neural Network 1'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m4_cost_t:,}'), fontsize = 12)\n",
        "ax[3].grid(False)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm_preds_m5).plot(ax= ax[4],cmap='Blues', colorbar=False)\n",
        "ax[4].set_title('Neural Network 2'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m5_cost_t:,}'), fontsize = 12)\n",
        "ax[4].grid(False)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "hYPzNzlQ36Ct",
        "outputId": "40cd7752-18e9-4287-a01c-96f3cd54cdc8"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembling"
      ],
      "metadata": {
        "id": "lV6Za3-7SvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for ensemble using logits\n",
        "preds_m4 = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = (m4_results.get(i).get('predictions')[j])\n",
        "\n",
        "preds_m5 = np.zeros(len(y))\n",
        "for i in m5_results.keys():\n",
        "  for j in range(len(m5_results.get(i).get('predictions'))):\n",
        "    idx = m5_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = (m5_results.get(i).get('predictions')[j])"
      ],
      "metadata": {
        "id": "3Yaixmx44Awv"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_alt = pd.DataFrame()\n",
        "\n",
        "#one hot encoding categorical variables for model\n",
        "cols = df.columns\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = list((set(cols) - set(num_cols)))\n",
        "\n",
        "#creating dataframe of categorical columns\n",
        "cat_df = df[cat_cols]\n",
        "cat_df = pd.get_dummies(cat_df, columns=cat_df.columns,sparse=True)\n",
        "cat_df\n",
        "\n",
        "y_alt['Volume_high']= cat_df['Volume_high']\n",
        "#y_alt['preds_m1']=preds_m1\n",
        "#y_alt['preds_m2']=preds_m2\n",
        "#y_alt['preds_m3']=preds_m3\n",
        "y_alt['preds_m4']=preds_m4\n",
        "y_alt['preds_m5']=preds_m5\n",
        "\n",
        "#y_alt['preds_new4']=m4_results\n",
        "#y_alt['preds_new5']=m4_results\n",
        "\n",
        "\n",
        "y_alt.to_csv('final_results.csv', encoding = 'utf-8-sig')\n",
        "files.download('final_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "b_ZaQ5xy21Pt",
        "outputId": "d68a008c-43d4-4c0b-8a8e-23e107d43cb8"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-240-dffccd0603d6>:26: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('final_results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7a275d96-9c53-4654-9b7e-fa12ec5c179c\", \"final_results.csv\", 7776734)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt = pd.read_csv(\"https://raw.githubusercontent.com/KendallScott/QTW/main/Case%20Study%207/final_results%20(3).csv\")\n",
        "y_alt = y_alt.drop(['Unnamed: 0'], axis=1)\n",
        "y_alt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ohFQ7cXn9KCQ",
        "outputId": "a5784e36-0b6e-42f1-9de4-0efc0bf36bbd"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Volume_high  preds_m4  preds_m5\n",
              "0                 1  0.000339  0.000406\n",
              "1                 1  0.001919  0.003698\n",
              "2                 1  0.000013  0.000556\n",
              "3                 1  0.010318  0.005824\n",
              "4                 1  1.000000  1.000000\n",
              "...             ...       ...       ...\n",
              "159995            1  1.000000  0.999979\n",
              "159996            1  0.001987  0.000092\n",
              "159997            1  0.731661  0.167556\n",
              "159998            1  0.022134  0.001144\n",
              "159999            1  1.000000  0.999996\n",
              "\n",
              "[160000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a2b47ab3-aebc-462c-a7b4-7545e4ab1361\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume_high</th>\n",
              "      <th>preds_m4</th>\n",
              "      <th>preds_m5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.000406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.003698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.005824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159995</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159996</th>\n",
              "      <td>1</td>\n",
              "      <td>0.001987</td>\n",
              "      <td>0.000092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159997</th>\n",
              "      <td>1</td>\n",
              "      <td>0.731661</td>\n",
              "      <td>0.167556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159998</th>\n",
              "      <td>1</td>\n",
              "      <td>0.022134</td>\n",
              "      <td>0.001144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159999</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160000 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b47ab3-aebc-462c-a7b4-7545e4ab1361')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ca9a617f-5ab7-4a3d-9bd3-d8465f1b6e59\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca9a617f-5ab7-4a3d-9bd3-d8465f1b6e59')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ca9a617f-5ab7-4a3d-9bd3-d8465f1b6e59 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2b47ab3-aebc-462c-a7b4-7545e4ab1361 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2b47ab3-aebc-462c-a7b4-7545e4ab1361');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "logR_ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf_ens = GridSearchCV(estimator=logR_ens,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf_ens.fit(y_alt,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "vElSNV8QmkMa",
        "outputId": "42efc6cf-e2af-4517-d488-e92d18013919"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          penalty='elasticnet',\n",
              "                                          random_state=807, solver='saga'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         'l1_ratio': [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         'max_iter': [25, 50, 75]})"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=807, shuffle=True),\n",
              "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                          penalty=&#x27;elasticnet&#x27;,\n",
              "                                          random_state=807, solver=&#x27;saga&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;C&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
              "                         &#x27;l1_ratio&#x27;: [0, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
              "                                      0.99, 1],\n",
              "                         &#x27;max_iter&#x27;: [25, 50, 75]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=807, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params_ens = lr_clf_ens.best_params_"
      ],
      "metadata": {
        "id": "J6RZiEvlpCh4"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf_ens.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyBtcaK0uF9",
        "outputId": "1c01a4d2-cb12-4683-ab4a-2d144b7da49f"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.0001, 'l1_ratio': 0.75, 'max_iter': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1ens = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1ens.set_params(**lr_params_ens)\n",
        "model1ens.fit(y_alt,y)\n",
        "skf.get_n_splits(y_alt,y)\n",
        "preds_ens2 = cross_val_predict(model1ens, y_alt,y,cv=skf)\n"
      ],
      "metadata": {
        "id": "IAtJAtyrot_t"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling\n",
        "cost_ens_log = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens_log = confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "bca2bRquon1j"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = (preds_new4+ preds_new5)/2\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = (preds_new4+ preds_new5+preds_new3 )/3\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))"
      ],
      "metadata": {
        "id": "2oJ4cy59VAFU"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_nn).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Combined Neural Networks'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_nn:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_ens).plot(ax = ax[1],cmap = 'Blues', colorbar=False)\n",
        "ax[1].set_title('Neural Networks and XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_ens_log).plot(ax = ax[2],cmap = 'Blues', colorbar=False)\n",
        "ax[2].set_title('Ensemble from both Neural Network logits'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens_log:,}'), fontsize = 12)\n",
        "ax[2].grid(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "J71VGqBYU7hF",
        "outputId": "840c6943-0217-406d-e59e-5bc4bd7b8c7c"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_alt['preds_nn']=preds_nn\n",
        "y_alt['preds_ens']=preds_ens\n",
        "y_alt['preds_ens2']=preds_ens2\n",
        "\n",
        "\n",
        "y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n",
        "files.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rUY2fsGRwGLf",
        "outputId": "78977f8a-e4c6-4526-e726-77ed79c836b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-174-f5d109dfe8d8>:6: FutureWarning: The behavior of .astype from SparseDtype to a non-sparse dtype is deprecated. In a future version, this will return a non-sparse array with the requested dtype. To retain the old behavior, use `obj.astype(SparseDtype(dtype))`\n",
            "  y_alt.to_csv('results.csv', encoding = 'utf-8-sig')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_358007fe-b3e1-403c-b2d2-c136dd0cfb11\", \"results.csv\", 6776923)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}